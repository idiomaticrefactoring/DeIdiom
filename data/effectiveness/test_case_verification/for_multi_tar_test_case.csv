repo_name,file_html,cl,me,old_code,new_code,flag_pass,test_html_list
gunicorn,https://github.com/benoitc/gunicorn/tree/master/gunicorn/util.py,,test_warn,"for (i, line) in enumerate(lines):
    if i == 0:
        line = 'WARNING: %s' % line
    print('!!! %s' % line, file=sys.stderr)","for e_target in enumerate(lines):
    line = e_target[1]
    i = e_target[0]
    if i == 0:
        line = 'WARNING: %s' % line
    print('!!! %s' % line, file=sys.stderr)

",1,"[['https://github.com/benoitc/gunicorn/tree/master/tests/test_util.py', 'tests.test_util', '', 'test_warn']]"
feature_engine,https://github.com/feature-engine/feature_engine/tree/master/feature_engine/creation/mathematical_combination.py,,test_error_when_null_values_in_variable,"for (new_variable_name, operation) in self.combination_dict_.items():
    X[new_variable_name] = X[self.variables_to_combine].agg(operation, axis=1)","for e_target in self.combination_dict_.items():
    operation = e_target[1]
    new_variable_name = e_target[0]
    X[new_variable_name] = X[self.variables_to_combine].agg(operation, axis=1)

",1,"[['https://github.com/feature-engine/feature_engine/tree/master/tests/test_creation/test_mathematical_combination.py', 'tests.test_creation.test_mathematical_combination', '', 'test_error_when_null_values_in_variable']]"
feature_engine,https://github.com/feature-engine/feature_engine/tree/master/feature_engine/selection/target_mean_selection.py,,test_categorical_variables_roc_auc,"for (train_index, test_index) in skf.split(X, y):
    (X_train, X_test) = (X.iloc[train_index], X.iloc[test_index])
    (y_train, y_test) = (y.iloc[train_index], y.iloc[test_index])
    _pipeline.fit(X_train, y_train)
    X_test = _pipeline.transform(X_test)
    if self.scoring == 'roc_auc_score':
        tmp_split = {f: roc_auc_score(y_test, X_test[f]) for f in self.variables_}
    else:
        tmp_split = {f: r2_score(y_test, X_test[f]) for f in self.variables_}
    feature_importances_cv.append(pd.Series(tmp_split))","for e_target in skf.split(X, y):
    test_index = e_target[1]
    train_index = e_target[0]
    (X_train, X_test) = (X.iloc[train_index], X.iloc[test_index])
    (y_train, y_test) = (y.iloc[train_index], y.iloc[test_index])
    _pipeline.fit(X_train, y_train)
    X_test = _pipeline.transform(X_test)
    if self.scoring == 'roc_auc_score':
        tmp_split = {f: roc_auc_score(y_test, X_test[f]) for f in self.variables_}
    else:
        tmp_split = {f: r2_score(y_test, X_test[f]) for f in self.variables_}
    feature_importances_cv.append(pd.Series(tmp_split))

",1,"[['https://github.com/feature-engine/feature_engine/tree/master/tests/test_selection/test_target_mean_selection.py', 'tests.test_selection.test_target_mean_selection', '', 'test_numerical_variables_roc_auc'], ['https://github.com/feature-engine/feature_engine/tree/master/tests/test_selection/test_target_mean_selection.py', 'tests.test_selection.test_target_mean_selection', '', 'test_error_if_y_not_passed'], ['https://github.com/feature-engine/feature_engine/tree/master/tests/test_selection/test_target_mean_selection.py', 'tests.test_selection.test_target_mean_selection', '', 'test_df_cat_and_num_variables_roc_auc'], ['https://github.com/feature-engine/feature_engine/tree/master/tests/test_selection/test_target_mean_selection.py', 'tests.test_selection.test_target_mean_selection', '', 'test_error_if_fit_input_not_dataframe'], ['https://github.com/feature-engine/feature_engine/tree/master/tests/test_selection/test_target_mean_selection.py', 'tests.test_selection.test_target_mean_selection', '', 'test_error_if_input_not_df'], ['https://github.com/feature-engine/feature_engine/tree/master/tests/test_selection/test_target_mean_selection.py', 'tests.test_selection.test_target_mean_selection', '', 'test_df_cat_and_num_variables_r2'], ['https://github.com/feature-engine/feature_engine/tree/master/tests/test_selection/test_target_mean_selection.py', 'tests.test_selection.test_target_mean_selection', '', 'test_categorical_variables_roc_auc']]"
jiant,https://github.com/nyu-mll/jiant/tree/master/jiant/utils/python/checks.py,,test_dict_equal,"for ((k1, v1), (k2, v2)) in zip(dict1.items(), dict2.items()):
    if k1 != k2:
        return False
    if v1 != v2:
        return False","for e_target in zip(dict1.items(), dict2.items()):
    v2 = e_target[1][1]
    k2 = e_target[1][0]
    v1 = e_target[0][1]
    k1 = e_target[0][0]
    if k1 != k2:
        return False
    if v1 != v2:
        return False

",1,"[['https://github.com/nyu-mll/jiant/tree/master/tests/utils/python/test_checks.py', 'tests.utils.python.test_checks', '', 'test_dict_equal']]"
jiant,https://github.com/nyu-mll/jiant/tree/master/jiant/utils/python/datastructures.py,,test_combine_dicts_with_disjoint_key_sets,"for (i, dictionary) in enumerate(dict_ls):
    for (k, v) in dictionary.items():
        if strict:
            if k in new_dict:
                raise RuntimeError(f'repeated key {k} seen in dict {i}')
        new_dict[k] = v","for e_target in enumerate(dict_ls):
    dictionary = e_target[1]
    i = e_target[0]
    for (k, v) in dictionary.items():
        if strict:
            if k in new_dict:
                raise RuntimeError(f'repeated key {k} seen in dict {i}')
        new_dict[k] = v

",1,"[['https://github.com/nyu-mll/jiant/tree/master/tests/utils/python/test_datastructures.py', 'tests.utils.python.test_datastructures', '', 'test_combine_dicts_with_overlapping_key_sets'], ['https://github.com/nyu-mll/jiant/tree/master/tests/utils/python/test_datastructures.py', 'tests.utils.python.test_datastructures', '', 'test_combine_dicts_with_disjoint_key_sets']]"
jiant,https://github.com/nyu-mll/jiant/tree/master/jiant/utils/python/datastructures.py,,test_combine_dicts_with_disjoint_key_sets,"for (k, v) in dictionary.items():
    if strict:
        if k in new_dict:
            raise RuntimeError(f'repeated key {k} seen in dict {i}')
    new_dict[k] = v","for e_target in dictionary.items():
    v = e_target[1]
    k = e_target[0]
    if strict:
        if k in new_dict:
            raise RuntimeError(f'repeated key {k} seen in dict {i}')
    new_dict[k] = v

",1,"[['https://github.com/nyu-mll/jiant/tree/master/tests/utils/python/test_datastructures.py', 'tests.utils.python.test_datastructures', '', 'test_combine_dicts_with_overlapping_key_sets'], ['https://github.com/nyu-mll/jiant/tree/master/tests/utils/python/test_datastructures.py', 'tests.utils.python.test_datastructures', '', 'test_combine_dicts_with_disjoint_key_sets']]"
inflect,https://github.com/jaraco/inflect/tree/master//inflect.py,,test_ancient_1,"for (k, v) in kwargs.items():
    if k in def_classical:
        self.classical_dict[k] = v
    else:
        raise UnknownClassicalModeError","for e_target in kwargs.items():
    v = e_target[1]
    k = e_target[0]
    if k in def_classical:
        self.classical_dict[k] = v
    else:
        raise UnknownClassicalModeError

",1,"[['https://github.com/jaraco/inflect/tree/master/tests/test_pwd.py', 'tests.test_pwd', 'test', 'test_user_input_fns'], ['https://github.com/jaraco/inflect/tree/master/tests/test_classical_all.py', 'tests.test_classical_all', 'test', 'test_classical'], ['https://github.com/jaraco/inflect/tree/master/tests/test_pwd.py', 'tests.test_pwd', 'test', 'test_postprocess'], ['https://github.com/jaraco/inflect/tree/master/tests/test_pwd.py', 'tests.test_pwd', 'test', 'test__plnoun'], ['https://github.com/jaraco/inflect/tree/master/tests/test_pwd.py', 'tests.test_pwd', 'test', 'test_classical_pl'], ['https://github.com/jaraco/inflect/tree/master/tests/test_classical_zero.py', 'tests.test_classical_zero', '', 'test_ancient_1'], ['https://github.com/jaraco/inflect/tree/master/tests/test_compounds.py', 'tests.test_compounds', '', 'test_unit_open_compound_nouns_classical'], ['https://github.com/jaraco/inflect/tree/master/tests/test_classical_herd.py', 'tests.test_classical_herd', '', 'test_ancient_1'], ['https://github.com/jaraco/inflect/tree/master/tests/test_pwd.py', 'tests.test_pwd', 'test', 'test_pl'], ['https://github.com/jaraco/inflect/tree/master/tests/test_inflections.py', 'tests.test_inflections', '', 'test_many'], ['https://github.com/jaraco/inflect/tree/master/tests/test_pl_si.py', 'tests.test_pl_si', '', 'test_pl_si'], ['https://github.com/jaraco/inflect/tree/master/tests/test_inflections.py', 'tests.test_inflections', '', 'test_def'], ['https://github.com/jaraco/inflect/tree/master/tests/test_classical_person.py', 'tests.test_classical_person', '', 'test_ancient_1'], ['https://github.com/jaraco/inflect/tree/master/tests/test_classical_names.py', 'tests.test_classical_names', '', 'test_ancient_1'], ['https://github.com/jaraco/inflect/tree/master/tests/test_pwd.py', 'tests.test_pwd', 'test', 'test__pl_special_verb'], ['https://github.com/jaraco/inflect/tree/master/tests/test_pwd.py', 'tests.test_pwd', 'test', 'test_classical'], ['https://github.com/jaraco/inflect/tree/master/tests/test_classical_ancient.py', 'tests.test_classical_ancient', '', 'test_ancient_1']]"
nox,https://github.com/theacodes/nox/tree/master/nox/tasks.py,,test_honor_list_request_noop,"for (session, selected) in manifest.list_all_sessions():
    output = '{marker} {color}{session}{reset}'
    if selected:
        marker = '*'
        color = selected_color
    else:
        marker = '-'
        color = skipped_color
    if session.description is not None:
        output += ' -> {description}'
    print(output.format(color=color, reset=reset, session=session.friendly_name, description=session.description, marker=marker))","for e_target in manifest.list_all_sessions():
    selected = e_target[1]
    session = e_target[0]
    output = '{marker} {color}{session}{reset}'
    if selected:
        marker = '*'
        color = selected_color
    else:
        marker = '-'
        color = skipped_color
    if session.description is not None:
        output += ' -> {description}'
    print(output.format(color=color, reset=reset, session=session.friendly_name, description=session.description, marker=marker))

",1,"[['https://github.com/theacodes/nox/tree/master/tests/test_tasks.py', 'tests.test_tasks', '', 'test_honor_list_request_prints_docstring_if_present'], ['https://github.com/theacodes/nox/tree/master/tests/test_tasks.py', 'tests.test_tasks', '', 'test_honor_list_request_skip_and_selected'], ['https://github.com/theacodes/nox/tree/master/tests/test_tasks.py', 'tests.test_tasks', '', 'test_honor_list_request_doesnt_print_docstring_if_not_present'], ['https://github.com/theacodes/nox/tree/master/tests/test_tasks.py', 'tests.test_tasks', '', 'test_honor_list_request_noop']]"
nox,https://github.com/theacodes/nox/tree/master/nox/_parametrize.py,,test_parametrize_decorator_multiple_and_stack,"for (param_arg_values, param_id) in itertools.zip_longest(_arg_values_list, ids):
    if isinstance(param_arg_values, Param):
        param_spec = param_arg_values
        param_spec.arg_names = tuple(arg_names)
    else:
        param_spec = Param(*param_arg_values, arg_names=arg_names, id=param_id)
    param_specs.append(param_spec)","for e_target in itertools.zip_longest(_arg_values_list, ids):
    param_id = e_target[1]
    param_arg_values = e_target[0]
    if isinstance(param_arg_values, Param):
        param_spec = param_arg_values
        param_spec.arg_names = tuple(arg_names)
    else:
        param_spec = Param(*param_arg_values, arg_names=arg_names, id=param_id)
    param_specs.append(param_spec)

",1,"[['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_multiple_args_as_list'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_one_param'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_id_list'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_param'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_multiple_args_as_string'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_stack'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_one_with_args'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_mixed_params'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_one'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_multiple_and_stack']]"
nox,https://github.com/theacodes/nox/tree/master/nox/_parametrize.py,,test_parametrize_decorator_multiple_and_stack,"for (n, value) in enumerate(_arg_values_list):
    if not isinstance(value, Param):
        _arg_values_list[n] = [value]","for e_target in enumerate(_arg_values_list):
    value = e_target[1]
    n = e_target[0]
    if not isinstance(value, Param):
        _arg_values_list[n] = [value]

",1,"[['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_multiple_args_as_list'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_one_param'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_id_list'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_param'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_multiple_args_as_string'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_stack'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_one_with_args'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_mixed_params'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_one'], ['https://github.com/theacodes/nox/tree/master/tests/test__parametrize.py', 'tests.test__parametrize', '', 'test_parametrize_decorator_multiple_and_stack']]"
nox,https://github.com/theacodes/nox/tree/master/nox/_option_set.py,TestOptionSet,test_namespace_values,"for (key, value) in kwargs.items():
    if key not in args:
        raise KeyError(f'{key} is not an option.')
    args[key] = value","for e_target in kwargs.items():
    value = e_target[1]
    key = e_target[0]
    if key not in args:
        raise KeyError(f'{key} is not an option.')
    args[key] = value

",1,"[['https://github.com/theacodes/nox/tree/master/tests/test__option_set.py', 'tests.test__option_set', 'TestOptionSet', 'test_namespace'], ['https://github.com/theacodes/nox/tree/master/tests/test__option_set.py', 'tests.test__option_set', 'TestOptionSet', 'test_namespace_non_existant_options_with_values'], ['https://github.com/theacodes/nox/tree/master/tests/test__option_set.py', 'tests.test__option_set', 'TestOptionSet', 'test_namespace_values']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/commonlocalfile.py,CommonLocalFileApiTestCase,test_11__get_imagedir_type,"for (checkfile, imagetype) in image_types_list:
    if os.path.exists(checkfile):
        return imagetype","for e_target in image_types_list:
    imagetype = e_target[1]
    checkfile = e_target[0]
    if os.path.exists(checkfile):
        return imagetype

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_commonlocalfile.py', 'tests.unit.test_commonlocalfile', 'CommonLocalFileApiTestCase', 'test_11__get_imagedir_type']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/docker.py,DockerLocalFileAPITestCase,test_10_save,"for (imagerepo, tag) in imagetag_list:
    status = self._save_image(imagerepo, tag, structure, tmp_imagedir)
    if not status:
        Msg().err('Error: save image failed:', imagerepo + ':' + tag)
        break","for e_target in imagetag_list:
    tag = e_target[1]
    imagerepo = e_target[0]
    status = self._save_image(imagerepo, tag, structure, tmp_imagedir)
    if not status:
        Msg().err('Error: save image failed:', imagerepo + ':' + tag)
        break

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_dockerlocalfileapi.py', 'tests.unit.test_dockerlocalfileapi', 'DockerLocalFileAPITestCase', 'test_10_save']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/cli.py,UdockerCLITestCase,test_24_do_images,"for (imagerepo, tag) in images_list:
    prot = ('.', 'P')[self.localrepo.isprotected_imagerepo(imagerepo, tag)]
    Msg().out('%-60.60s %c' % (imagerepo + ':' + tag, prot))
    if verbose:
        imagerepo_dir = self.localrepo.cd_imagerepo(imagerepo, tag)
        Msg().out('  %s' % imagerepo_dir)
        layers_list = self.localrepo.get_layers(imagerepo, tag)
        if layers_list:
            for (layer_name, size) in layers_list:
                file_size = size / (1024 * 1024)
                if not file_size and size:
                    file_size = 1
                Msg().out('    %s (%d MB)' % (layer_name.replace(imagerepo_dir, ''), file_size))","for e_target in images_list:
    tag = e_target[1]
    imagerepo = e_target[0]
    prot = ('.', 'P')[self.localrepo.isprotected_imagerepo(imagerepo, tag)]
    Msg().out('%-60.60s %c' % (imagerepo + ':' + tag, prot))
    if verbose:
        imagerepo_dir = self.localrepo.cd_imagerepo(imagerepo, tag)
        Msg().out('  %s' % imagerepo_dir)
        layers_list = self.localrepo.get_layers(imagerepo, tag)
        if layers_list:
            for (layer_name, size) in layers_list:
                file_size = size / (1024 * 1024)
                if not file_size and size:
                    file_size = 1
                Msg().out('    %s (%d MB)' % (layer_name.replace(imagerepo_dir, ''), file_size))

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_cli.py', 'tests.unit.test_cli', 'UdockerCLITestCase', 'test_24_do_images']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/cli.py,UdockerCLITestCase,test_24_do_images,"for (layer_name, size) in layers_list:
    file_size = size / (1024 * 1024)
    if not file_size and size:
        file_size = 1
    Msg().out('    %s (%d MB)' % (layer_name.replace(imagerepo_dir, ''), file_size))","for e_target in layers_list:
    size = e_target[1]
    layer_name = e_target[0]
    file_size = size / (1024 * 1024)
    if not file_size and size:
        file_size = 1
    Msg().out('    %s (%d MB)' % (layer_name.replace(imagerepo_dir, ''), file_size))

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_cli.py', 'tests.unit.test_cli', 'UdockerCLITestCase', 'test_24_do_images']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/engine/runc.py,RuncEngineTestCase,test_05__set_spec,"for (env_key, env_val) in self.opt['env']:
    json_obj['process']['env'].append('%s=%s' % (env_key, env_val))","for e_target in self.opt['env']:
    env_val = e_target[1]
    env_key = e_target[0]
    json_obj['process']['env'].append('%s=%s' % (env_key, env_val))

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_runc.py', 'tests.unit.test_runc', 'RuncEngineTestCase', 'test_05__set_spec']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/engine/singularity.py,SingularityEngineTestCase,test_04__singularity_env_get,"for (key, val) in self.opt['env']:
    singularityenv['SINGULARITYENV_%s' % key] = val","for e_target in self.opt['env']:
    val = e_target[1]
    key = e_target[0]
    singularityenv['SINGULARITYENV_%s' % key] = val

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_singularity.py', 'tests.unit.test_singularity', 'SingularityEngineTestCase', 'test_04__singularity_env_get']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/engine/base.py,ExecutionEngineCommonTestCase,test_05__set_cpu_affinity,"for (index, arg) in enumerate(exec_cmd):
    if arg == '%s':
        exec_cmd[index] = self.opt['cpuset']","for e_target in enumerate(exec_cmd):
    arg = e_target[1]
    index = e_target[0]
    if arg == '%s':
        exec_cmd[index] = self.opt['cpuset']

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_execenginecommon.py', 'tests.unit.test_execenginecommon', 'ExecutionEngineCommonTestCase', 'test_05__set_cpu_affinity']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/engine/proot.py,PRootEngineTestCase,test_06__get_network_map,"for (cont_port, host_port) in list(self._get_portsmap().items()):
    proot_netmap_list.extend(['-p', '%d:%d' % (cont_port, host_port)])","for e_target in list(self._get_portsmap().items()):
    host_port = e_target[1]
    cont_port = e_target[0]
    proot_netmap_list.extend(['-p', '%d:%d' % (cont_port, host_port)])

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_proot.py', 'tests.unit.test_proot', 'PRootEngineTestCase', 'test_06__get_network_map']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/helper/unshare.py,UnshareTestCase,test_02_namespace_exec,"for (subid, subcount) in NixAuthentication().user_in_subuid(user):
    newidmap.extend(['1', subid, subcount])","for e_target in NixAuthentication().user_in_subuid(user):
    subcount = e_target[1]
    subid = e_target[0]
    newidmap.extend(['1', subid, subcount])

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_unshare.py', 'tests.unit.test_unshare', 'UnshareTestCase', 'test_02_namespace_exec']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/helper/unshare.py,UnshareTestCase,test_02_namespace_exec,"for (subid, subcount) in NixAuthentication().user_in_subgid(user):
    newidmap.extend(['1', subid, subcount])","for e_target in NixAuthentication().user_in_subgid(user):
    subcount = e_target[1]
    subid = e_target[0]
    newidmap.extend(['1', subid, subcount])

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_unshare.py', 'tests.unit.test_unshare', 'UnshareTestCase', 'test_02_namespace_exec']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/helper/hostinfo.py,HostInfoTestCase,test_05_oskernel_isgreater,"for (idx, os_version) in enumerate(os_release.split('.')):
    if idx >= len(version):
        break
    if int(os_version) > int(version[idx]):
        return True
    if int(os_version) < int(version[idx]):
        return False","for e_target in enumerate(os_release.split('.')):
    os_version = e_target[1]
    idx = e_target[0]
    if idx >= len(version):
        break
    if int(os_version) > int(version[idx]):
        return True
    if int(os_version) < int(version[idx]):
        return False

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_hostinfo.py', 'tests.unit.test_hostinfo', 'HostInfoTestCase', 'test_05_oskernel_isgreater']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/helper/elfpatcher.py,ElfPatcherTestCase,test_04__walk_fs,"for (dir_path, dummy, files) in os.walk(root_path):
    for f_name in files:
        try:
            f_path = dir_path + '/' + f_name
            if os.path.islink(f_path):
                continue
            if os.stat(f_path).st_uid != self._uid:
                if action & self.ABORT_ON_ERROR:
                    return ''
                continue
            if action & self.BIN and os.access(f_path, os.X_OK) or (action & self.LIB and self._shlib.match(f_name)):
                out = Uprocess().get_output(self._replace(cmd, f_path))
                if out:
                    status = out
            if action & self.ABORT_ON_ERROR and status is None:
                return ''
            if action & self.ONE_SUCCESS and status is not None:
                return status
            if action & self.ONE_OUTPUT and status:
                return status
        except OSError:
            pass","for e_target in os.walk(root_path):
    files = e_target[2]
    dummy = e_target[1]
    dir_path = e_target[0]
    for f_name in files:
        try:
            f_path = dir_path + '/' + f_name
            if os.path.islink(f_path):
                continue
            if os.stat(f_path).st_uid != self._uid:
                if action & self.ABORT_ON_ERROR:
                    return ''
                continue
            if action & self.BIN and os.access(f_path, os.X_OK) or (action & self.LIB and self._shlib.match(f_name)):
                out = Uprocess().get_output(self._replace(cmd, f_path))
                if out:
                    status = out
            if action & self.ABORT_ON_ERROR and status is None:
                return ''
            if action & self.ONE_SUCCESS and status is not None:
                return status
            if action & self.ONE_OUTPUT and status:
                return status
        except OSError:
            pass

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_elfpatcher.py', 'tests.unit.test_elfpatcher', 'ElfPatcherTestCase', 'test_04__walk_fs']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/utils/uenv.py,UenvTestCase,test_12_list,"for (key, val) in self.env.items():
    env_list.append('%s=%s' % (key, val))","for e_target in self.env.items():
    val = e_target[1]
    key = e_target[0]
    env_list.append('%s=%s' % (key, val))

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_uenv.py', 'tests.unit.test_uenv', 'UenvTestCase', 'test_12_list']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/utils/fileutil.py,FileUtilTestCase,test_16__removedir,"for (dir_path, dirs, files) in os.walk(self.filename, topdown=False, followlinks=False):
    for f_name in files:
        f_path = dir_path + '/' + f_name
        if not os.path.islink(f_path):
            os.chmod(f_path, stat.S_IWUSR | stat.S_IRUSR)
        os.unlink(f_path)
    for f_name in dirs:
        f_path = dir_path + '/' + f_name
        if os.path.islink(f_path):
            os.unlink(f_path)
            continue
        os.chmod(f_path, stat.S_IWUSR | stat.S_IRUSR | stat.S_IXUSR)
        os.rmdir(f_path)","for e_target in os.walk(self.filename, topdown=False, followlinks=False):
    files = e_target[2]
    dirs = e_target[1]
    dir_path = e_target[0]
    for f_name in files:
        f_path = dir_path + '/' + f_name
        if not os.path.islink(f_path):
            os.chmod(f_path, stat.S_IWUSR | stat.S_IRUSR)
        os.unlink(f_path)
    for f_name in dirs:
        f_path = dir_path + '/' + f_name
        if os.path.islink(f_path):
            os.unlink(f_path)
            continue
        os.chmod(f_path, stat.S_IWUSR | stat.S_IRUSR | stat.S_IXUSR)
        os.rmdir(f_path)

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_fileutil.py', 'tests.unit.test_fileutil', 'FileUtilTestCase', 'test_16__removedir']]"
udocker,https://github.com/indigo-dc/udocker/tree/master/udocker/container/structure.py,ContainerStructureTestCase,test_04__dict_to_str,"for (key, val) in in_dict.items():
    out_str += '%s:%s ' % (str(key), str(val))","for e_target in in_dict.items():
    val = e_target[1]
    key = e_target[0]
    out_str += '%s:%s ' % (str(key), str(val))

",1,"[['https://github.com/indigo-dc/udocker/tree/master/tests/unit/test_containerstructure.py', 'tests.unit.test_containerstructure', 'ContainerStructureTestCase', 'test_04__dict_to_str']]"
tfc,https://github.com/maqp/tfc/tree/master/src/common/reed_solomon.py,TestSimpleFuncs,test_gf_poly_mul_simple,"for (j, _) in enumerate(q):
    qj = q[j]
    if qj != 0:
        lq = gf_log[qj]
        for (i, _) in enumerate(p):
            if p[i] != 0:
                r[i + j] ^= gf_exp[lp[i] + lq]","for e_target in enumerate(q):
    _ = e_target[1]
    j = e_target[0]
    qj = q[j]
    if qj != 0:
        lq = gf_log[qj]
        for (i, _) in enumerate(p):
            if p[i] != 0:
                r[i + j] ^= gf_exp[lp[i] + lq]

",1,"[['https://github.com/maqp/tfc/tree/master/tests/common/test_reed_solomon.py', 'tests.common.test_reed_solomon', 'TestSimpleFuncs', 'test_gf_poly_mul_simple']]"
tfc,https://github.com/maqp/tfc/tree/master/src/common/reed_solomon.py,TestSimpleFuncs,test_gf_poly_mul_simple,"for (i, _) in enumerate(p):
    if p[i] != 0:
        r[i + j] ^= gf_exp[lp[i] + lq]","for e_target in enumerate(p):
    _ = e_target[1]
    i = e_target[0]
    if p[i] != 0:
        r[i + j] ^= gf_exp[lp[i] + lq]

",1,"[['https://github.com/maqp/tfc/tree/master/tests/common/test_reed_solomon.py', 'tests.common.test_reed_solomon', 'TestSimpleFuncs', 'test_gf_poly_mul_simple']]"
fiber,https://github.com/uber/fiber/tree/master/fiber/backend.py,TestBackend,test_backend_selection,"for (backend_name, test) in BACKEND_TESTS.items():
    if test():
        name = backend_name
        break
else:
    name = config.default_backend","for e_target in BACKEND_TESTS.items():
    test = e_target[1]
    backend_name = e_target[0]
    if test():
        name = backend_name
        break
else:
    name = config.default_backend

",1,"[['https://github.com/uber/fiber/tree/master/tests/test_backend.py', 'tests.test_backend', 'TestBackend', 'test_backend_selection']]"
satellite,https://github.com/Blockstream/satellite/tree/master/blocksatcli/cache.py,TestCache,test_dot_notation,"for (i, key) in enumerate(nested_keys):
    if key not in tmp:
        return None
    if i == len(nested_keys) - 1:
        return tmp[key]
    tmp = tmp[key]","for e_target in enumerate(nested_keys):
    key = e_target[1]
    i = e_target[0]
    if key not in tmp:
        return None
    if i == len(nested_keys) - 1:
        return tmp[key]
    tmp = tmp[key]

",1,"[['https://github.com/Blockstream/satellite/tree/master/blocksatcli/test_cache.py', 'blocksatcli.test_cache', 'TestCache', 'test_dot_notation']]"
satellite,https://github.com/Blockstream/satellite/tree/master/blocksatcli/usb.py,TestApi,test_log_parser,"for (i, elem) in enumerate(elements):
    if elem[-1] == '=' and i + 1 <= n_elem:
        key = elem[:-1]
        raw_value = elements[i + 1]
        key = log_key_map[key]
        if '^' in raw_value:
            raw_value = raw_value.replace('x10^', 'e')
        unit = None
        if '%' in raw_value:
            unit = '%'
            val = float(raw_value[:-1].replace(',', '.'))
        elif raw_value[-2:] == 'dB':
            val = float(raw_value[:-2].replace(',', '.'))
            unit = 'dB'
        elif raw_value[-3:] == 'dBm':
            val = float(raw_value[:-3].replace(',', '.'))
            unit = 'dBm'
        else:
            val = float(raw_value.replace(',', '.'))
        d[key] = (val, unit)","for e_target in enumerate(elements):
    elem = e_target[1]
    i = e_target[0]
    if elem[-1] == '=' and i + 1 <= n_elem:
        key = elem[:-1]
        raw_value = elements[i + 1]
        key = log_key_map[key]
        if '^' in raw_value:
            raw_value = raw_value.replace('x10^', 'e')
        unit = None
        if '%' in raw_value:
            unit = '%'
            val = float(raw_value[:-1].replace(',', '.'))
        elif raw_value[-2:] == 'dB':
            val = float(raw_value[:-2].replace(',', '.'))
            unit = 'dB'
        elif raw_value[-3:] == 'dBm':
            val = float(raw_value[:-3].replace(',', '.'))
            unit = 'dBm'
        else:
            val = float(raw_value.replace(',', '.'))
        d[key] = (val, unit)

",1,"[['https://github.com/Blockstream/satellite/tree/master/blocksatcli/test_usb.py', 'blocksatcli.test_usb', 'TestApi', 'test_log_parser']]"
satellite,https://github.com/Blockstream/satellite/tree/master/blocksatcli/api/fec.py,TestFec,test_erasure_recovery,"for (i_chunk, chunk) in enumerate(fec_chunks):
    metadata = struct.pack(HEADER_FORMAT, i_obj, n_fec_objects, i_chunk, len(fec_object))
    fec_pkts.append(metadata + chunk)","for e_target in enumerate(fec_chunks):
    chunk = e_target[1]
    i_chunk = e_target[0]
    metadata = struct.pack(HEADER_FORMAT, i_obj, n_fec_objects, i_chunk, len(fec_object))
    fec_pkts.append(metadata + chunk)

",1,"[['https://github.com/Blockstream/satellite/tree/master/blocksatcli/api/test_fec.py', 'blocksatcli.api.test_fec', 'TestFec', 'test_encode_decode'], ['https://github.com/Blockstream/satellite/tree/master/blocksatcli/api/test_fec.py', 'blocksatcli.api.test_fec', 'TestFec', 'test_blocksat_pkt_alignment'], ['https://github.com/Blockstream/satellite/tree/master/blocksatcli/api/test_fec.py', 'blocksatcli.api.test_fec', 'TestFec', 'test_overhead'], ['https://github.com/Blockstream/satellite/tree/master/blocksatcli/api/test_fec.py', 'blocksatcli.api.test_fec', 'TestFec', 'test_erasure_recovery']]"
folium,https://github.com/python-visualization/folium/tree/master/folium/features.py,,test_geojson_find_identifier,"for (i, feature) in enumerate(feats):
    feature['id'] = str(i)","for e_target in enumerate(feats):
    feature = e_target[1]
    i = e_target[0]
    feature['id'] = str(i)

",1,"[['https://github.com/python-visualization/folium/tree/master/tests/test_features.py', 'tests.test_features', '', 'test_geojson_find_identifier']]"
betago,https://github.com/maxpumperla/betago/tree/master/betago/scoring.py,ScoringTestCase,test_identify_territory,"for (r, c) in itertools.product(list(range(board.board_size)), list(range(board.board_size))):
    if (r, c) in status:
        continue
    if (r, c) in board.board:
        status[r, c] = board.board[r, c]
    else:
        (group, neighbors) = _collect_region((r, c), board)
        if len(neighbors) == 1:
            fill_with = 'territory_' + neighbors.pop()
        else:
            fill_with = 'dame'
        for pos in group:
            status[pos] = fill_with","for e_target in itertools.product(list(range(board.board_size)), list(range(board.board_size))):
    c = e_target[1]
    r = e_target[0]
    if (r, c) in status:
        continue
    if (r, c) in board.board:
        status[r, c] = board.board[r, c]
    else:
        (group, neighbors) = _collect_region((r, c), board)
        if len(neighbors) == 1:
            fill_with = 'territory_' + neighbors.pop()
        else:
            fill_with = 'dame'
        for pos in group:
            status[pos] = fill_with

",1,"[['https://github.com/maxpumperla/betago/tree/master/tests/scoring_test.py', 'tests.scoring_test', 'ScoringTestCase', 'test_identify_territory']]"
betago,https://github.com/maxpumperla/betago/tree/master/betago/dataloader/goboard.py,ModelTestCase,test_get_first_valid_move,"for (r, row_string) in enumerate(rows):
    for (c, point) in enumerate(row_string):
        if point in ('b', 'w'):
            board.apply_move(point, (r, c))","for e_target in enumerate(rows):
    row_string = e_target[1]
    r = e_target[0]
    for (c, point) in enumerate(row_string):
        if point in ('b', 'w'):
            board.apply_move(point, (r, c))

",1,"[['https://github.com/maxpumperla/betago/tree/master/tests/scoring_test.py', 'tests.scoring_test', 'ScoringTestCase', 'test_identify_territory'], ['https://github.com/maxpumperla/betago/tree/master/tests/dataloader/goboard_test.py', 'tests.dataloader.goboard_test', 'GoBoardTest', 'test_from_string'], ['https://github.com/maxpumperla/betago/tree/master/tests/model_test.py', 'tests.model_test', 'ModelTestCase', 'test_all_empty_points'], ['https://github.com/maxpumperla/betago/tree/master/tests/model_test.py', 'tests.model_test', 'ModelTestCase', 'test_get_first_valid_move']]"
betago,https://github.com/maxpumperla/betago/tree/master/betago/dataloader/goboard.py,ModelTestCase,test_get_first_valid_move,"for (c, point) in enumerate(row_string):
    if point in ('b', 'w'):
        board.apply_move(point, (r, c))","for e_target in enumerate(row_string):
    point = e_target[1]
    c = e_target[0]
    if point in ('b', 'w'):
        board.apply_move(point, (r, c))

",1,"[['https://github.com/maxpumperla/betago/tree/master/tests/scoring_test.py', 'tests.scoring_test', 'ScoringTestCase', 'test_identify_territory'], ['https://github.com/maxpumperla/betago/tree/master/tests/dataloader/goboard_test.py', 'tests.dataloader.goboard_test', 'GoBoardTest', 'test_from_string'], ['https://github.com/maxpumperla/betago/tree/master/tests/model_test.py', 'tests.model_test', 'ModelTestCase', 'test_all_empty_points'], ['https://github.com/maxpumperla/betago/tree/master/tests/model_test.py', 'tests.model_test', 'ModelTestCase', 'test_get_first_valid_move']]"
betago,https://github.com/maxpumperla/betago/tree/master/betago/gosgf/sgf_grammar.py,SgfGrammarTestCase,test_serialise_game_tree,"for (prop_ident, prop_values) in sorted(list(properties.items()), key=lambda pair: (-(pair[0] == b'FF'), pair[0])):
    m = [prop_ident]
    for value in prop_values:
        m.append(b'[' + value + b']')
    l.append(b''.join(m))","for e_target in sorted(list(properties.items()), key=lambda pair: (-(pair[0] == b'FF'), pair[0])):
    prop_values = e_target[1]
    prop_ident = e_target[0]
    m = [prop_ident]
    for value in prop_values:
        m.append(b'[' + value + b']')
    l.append(b''.join(m))

",1,"[['https://github.com/maxpumperla/betago/tree/master/tests/gosgf/sgf_grammar_test.py', 'tests.gosgf.sgf_grammar_test', 'SgfGrammarTestCase', 'test_serialise_game_tree']]"
andriller,https://github.com/den4uk/andriller/tree/master/andriller/utils.py,,test_human_bytes,"for (pw, name) in powers.items():
    if size in range(2 ** pw):
        return f'{round(size / 2 ** (pw - 10), pw // 20)}{name}'","for e_target in powers.items():
    name = e_target[1]
    pw = e_target[0]
    if size in range(2 ** pw):
        return f'{round(size / 2 ** (pw - 10), pw // 20)}{name}'

",1,"[['https://github.com/den4uk/andriller/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_human_bytes']]"
andriller,https://github.com/den4uk/andriller/tree/master/andriller/utils.py,,test_get_koi,"for (k, v) in payload.items():
    if type(v) in targets:
        if k in keys:
            result[k] = v
    else:
        process(v)","for e_target in payload.items():
    v = e_target[1]
    k = e_target[0]
    if type(v) in targets:
        if k in keys:
            result[k] = v
    else:
        process(v)

",1,"[['https://github.com/den4uk/andriller/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_get_koi']]"
andriller,https://github.com/den4uk/andriller/tree/master/andriller/cracking.py,,test_crack_as_pw_good,"for (n, pin) in enumerate(feed, start=1):
    if not n % self.update_rate and tk_obj:
        self.set_rate(rate, n, started)
        self.set_tried(tried, n)
        self.set_prog(prog, n, self.total)
        tk_obj.set(pin.decode())
        if stop and stop.get():
            break
    if algo(pin) == self.key:
        self.set_tried(tried, n)
        return pin.decode()","for e_target in enumerate(feed, start=1):
    pin = e_target[1]
    n = e_target[0]
    if not n % self.update_rate and tk_obj:
        self.set_rate(rate, n, started)
        self.set_tried(tried, n)
        self.set_prog(prog, n, self.total)
        tk_obj.set(pin.decode())
        if stop and stop.get():
            break
    if algo(pin) == self.key:
        self.set_tried(tried, n)
        return pin.decode()

",1,"[['https://github.com/den4uk/andriller/tree/master/tests/test_cracking.py', 'tests.test_cracking', '', 'test_crack_pin_bad'], ['https://github.com/den4uk/andriller/tree/master/tests/test_cracking.py', 'tests.test_cracking', '', 'test_crack_pin_good'], ['https://github.com/den4uk/andriller/tree/master/tests/test_cracking.py', 'tests.test_cracking', '', 'test_crack_pin_good_sam'], ['https://github.com/den4uk/andriller/tree/master/tests/test_cracking.py', 'tests.test_cracking', '', 'test_crack_as_pw_bad'], ['https://github.com/den4uk/andriller/tree/master/tests/test_cracking.py', 'tests.test_cracking', '', 'test_crack_as_dict_good'], ['https://github.com/den4uk/andriller/tree/master/tests/test_cracking.py', 'tests.test_cracking', '', 'test_crack_as_pw_good']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/flask.py,,test_swagger_to_flask_url,"for (method, param) in six.iteritems(node):
    for (old, new) in _type(param.get('parameters', [])):
        url = url.replace(old, new)
    for k in SUPPORT_METHODS:
        if k in param:
            for (old, new) in _type(param[k].get('parameters', [])):
                url = url.replace(old, new)","for e_target in six.iteritems(node):
    param = e_target[1]
    method = e_target[0]
    for (old, new) in _type(param.get('parameters', [])):
        url = url.replace(old, new)
    for k in SUPPORT_METHODS:
        if k in param:
            for (old, new) in _type(param[k].get('parameters', [])):
                url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_flask.py', 'tests.test_flask', '', 'test_swagger_to_flask_url']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/flask.py,,test_swagger_to_flask_url,"for (old, new) in _type(param.get('parameters', [])):
    url = url.replace(old, new)","for e_target in _type(param.get('parameters', [])):
    new = e_target[1]
    old = e_target[0]
    url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_flask.py', 'tests.test_flask', '', 'test_swagger_to_flask_url']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/flask.py,,test_swagger_to_flask_url,"for (old, new) in _type(param[k].get('parameters', [])):
    url = url.replace(old, new)","for e_target in _type(param[k].get('parameters', [])):
    new = e_target[1]
    old = e_target[0]
    url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_flask.py', 'tests.test_flask', '', 'test_swagger_to_flask_url']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/tornado.py,,test_swagger_to_tornado_url,"for (old, new) in _type(node.get('parameters', [])):
    url = url.replace(old, new)","for e_target in _type(node.get('parameters', [])):
    new = e_target[1]
    old = e_target[0]
    url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_tornado.py', 'tests.test_tornado', '', 'test_swagger_to_tornado_url']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/tornado.py,,test_swagger_to_tornado_url,"for (old, new) in _type(node[k].get('parameters', [])):
    url = url.replace(old, new)","for e_target in _type(node[k].get('parameters', [])):
    new = e_target[1]
    old = e_target[0]
    url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_tornado.py', 'tests.test_tornado', '', 'test_swagger_to_tornado_url']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/jsonschema.py,,test_validators,"for (path, _) in swagger.search(['paths', '*']):
    path_param = []
    try:
        path_param = swagger.get(path + ('parameters',))
    except KeyError:
        pass
    for (p, data) in swagger.search(path + ('*',)):
        if p[-1] not in ['get', 'post', 'put', 'delete', 'patch', 'options', 'head']:
            continue
        method_param = []
        try:
            method_param = swagger.get(p + ('parameters',))
        except KeyError:
            pass
        endpoint = p[1]
        method = p[-1].upper()
        validator = dict(_parameters_to_schemas(path_param + method_param))
        if validator:
            validators[endpoint, method] = validator
        responses = data.get('responses')
        if responses:
            filter = {}
            for (status, res_data) in six.iteritems(responses):
                if isinstance(status, int) or status.isdigit():
                    filter[int(status)] = dict(headers=res_data.get('headers'), schema=res_data.get('schema'))
            filters[endpoint, method] = filter
        for security in data.get('security', []):
            scopes[endpoint, method] = list(security.values()).pop()
            break","for e_target in swagger.search(['paths', '*']):
    _ = e_target[1]
    path = e_target[0]
    path_param = []
    try:
        path_param = swagger.get(path + ('parameters',))
    except KeyError:
        pass
    for (p, data) in swagger.search(path + ('*',)):
        if p[-1] not in ['get', 'post', 'put', 'delete', 'patch', 'options', 'head']:
            continue
        method_param = []
        try:
            method_param = swagger.get(p + ('parameters',))
        except KeyError:
            pass
        endpoint = p[1]
        method = p[-1].upper()
        validator = dict(_parameters_to_schemas(path_param + method_param))
        if validator:
            validators[endpoint, method] = validator
        responses = data.get('responses')
        if responses:
            filter = {}
            for (status, res_data) in six.iteritems(responses):
                if isinstance(status, int) or status.isdigit():
                    filter[int(status)] = dict(headers=res_data.get('headers'), schema=res_data.get('schema'))
            filters[endpoint, method] = filter
        for security in data.get('security', []):
            scopes[endpoint, method] = list(security.values()).pop()
            break

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_ref_01'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_filters'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_01'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_02'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_03'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_validators']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/jsonschema.py,,test_validators,"for (p, data) in swagger.search(path + ('*',)):
    if p[-1] not in ['get', 'post', 'put', 'delete', 'patch', 'options', 'head']:
        continue
    method_param = []
    try:
        method_param = swagger.get(p + ('parameters',))
    except KeyError:
        pass
    endpoint = p[1]
    method = p[-1].upper()
    validator = dict(_parameters_to_schemas(path_param + method_param))
    if validator:
        validators[endpoint, method] = validator
    responses = data.get('responses')
    if responses:
        filter = {}
        for (status, res_data) in six.iteritems(responses):
            if isinstance(status, int) or status.isdigit():
                filter[int(status)] = dict(headers=res_data.get('headers'), schema=res_data.get('schema'))
        filters[endpoint, method] = filter
    for security in data.get('security', []):
        scopes[endpoint, method] = list(security.values()).pop()
        break","for e_target in swagger.search(path + ('*',)):
    data = e_target[1]
    p = e_target[0]
    if p[-1] not in ['get', 'post', 'put', 'delete', 'patch', 'options', 'head']:
        continue
    method_param = []
    try:
        method_param = swagger.get(p + ('parameters',))
    except KeyError:
        pass
    endpoint = p[1]
    method = p[-1].upper()
    validator = dict(_parameters_to_schemas(path_param + method_param))
    if validator:
        validators[endpoint, method] = validator
    responses = data.get('responses')
    if responses:
        filter = {}
        for (status, res_data) in six.iteritems(responses):
            if isinstance(status, int) or status.isdigit():
                filter[int(status)] = dict(headers=res_data.get('headers'), schema=res_data.get('schema'))
        filters[endpoint, method] = filter
    for security in data.get('security', []):
        scopes[endpoint, method] = list(security.values()).pop()
        break

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_ref_01'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_filters'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_01'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_02'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_03'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_validators']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/jsonschema.py,,test_validators,"for (status, res_data) in six.iteritems(responses):
    if isinstance(status, int) or status.isdigit():
        filter[int(status)] = dict(headers=res_data.get('headers'), schema=res_data.get('schema'))","for e_target in six.iteritems(responses):
    res_data = e_target[1]
    status = e_target[0]
    if isinstance(status, int) or status.isdigit():
        filter[int(status)] = dict(headers=res_data.get('headers'), schema=res_data.get('schema'))

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_ref_01'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_filters'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_01'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_02'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_schema_base_03'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_validators']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/jsonschema.py,,test_normalize_07,"for (k, v) in six.iteritems(dst):
    if isinstance(src, dict):
        if isinstance(v, dict):
            r = _merge_dict(src.get(k, {}), v)
            src[k] = r
        else:
            src[k] = v
    else:
        src = {k: v}","for e_target in six.iteritems(dst):
    v = e_target[1]
    k = e_target[0]
    if isinstance(src, dict):
        if isinstance(v, dict):
            r = _merge_dict(src.get(k, {}), v)
            src[k] = r
        else:
            src[k] = v
    else:
        src = {k: v}

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_03'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_09'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_02'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_04'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_06'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_01'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_08'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_05'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_07']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/jsonschema.py,,test_normalize_07,"for (key, _schema) in six.iteritems(schema.get('properties', {})):
    type_ = _schema.get('type', 'object')
    (value, has_key) = data.get_check(key)
    if has_key or '$ref' in _schema:
        result[key] = _normalize(_schema, value)
    elif 'default' in _schema:
        result[key] = _schema['default']
    elif key in schema.get('required', []):
        if type_ in required_defaults:
            result[key] = required_defaults[type_]
        else:
            errors.append(dict(name='property_missing', message='`%s` is required' % key))","for e_target in six.iteritems(schema.get('properties', {})):
    _schema = e_target[1]
    key = e_target[0]
    type_ = _schema.get('type', 'object')
    (value, has_key) = data.get_check(key)
    if has_key or '$ref' in _schema:
        result[key] = _normalize(_schema, value)
    elif 'default' in _schema:
        result[key] = _schema['default']
    elif key in schema.get('required', []):
        if type_ in required_defaults:
            result[key] = required_defaults[type_]
        else:
            errors.append(dict(name='property_missing', message='`%s` is required' % key))

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_03'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_09'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_02'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_04'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_06'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_01'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_08'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_05'], ['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_jsonschema.py', 'tests.test_jsonschema', '', 'test_normalize_07']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/sanic.py,,test_swagger_to_sanic_url,"for (old, new) in _type(node.get('parameters', [])):
    url = url.replace(old, new)","for e_target in _type(node.get('parameters', [])):
    new = e_target[1]
    old = e_target[0]
    url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_sanic.py', 'tests.test_sanic', '', 'test_swagger_to_sanic_url']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/sanic.py,,test_swagger_to_sanic_url,"for (old, new) in _type(node[k].get('parameters', [])):
    url = url.replace(old, new)","for e_target in _type(node[k].get('parameters', [])):
    new = e_target[1]
    old = e_target[0]
    url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_sanic.py', 'tests.test_sanic', '', 'test_swagger_to_sanic_url']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/falcon.py,,test_swagger_to_falcon_url,"for (old, new) in _type(node.get('parameters', [])):
    url = url.replace(old, new)","for e_target in _type(node.get('parameters', [])):
    new = e_target[1]
    old = e_target[0]
    url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_falcon.py', 'tests.test_falcon', '', 'test_swagger_to_falcon_url']]"
swagger-py-codegen,https://github.com/guokr/swagger-py-codegen/tree/master/swagger_py_codegen/falcon.py,,test_swagger_to_falcon_url,"for (old, new) in _type(node[k].get('parameters', [])):
    url = url.replace(old, new)","for e_target in _type(node[k].get('parameters', [])):
    new = e_target[1]
    old = e_target[0]
    url = url.replace(old, new)

",1,"[['https://github.com/guokr/swagger-py-codegen/tree/master/tests/test_falcon.py', 'tests.test_falcon', '', 'test_swagger_to_falcon_url']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/commands/borgmatic.py,,test_collect_configuration_run_summary_logs_info_for_success_with_list,"for (config_filename, config) in configs.items():
    results = list(run_configuration(config_filename, config, arguments))
    error_logs = tuple((result for result in results if isinstance(result, logging.LogRecord)))
    if error_logs:
        yield from make_error_log_records('{}: Error running configuration file'.format(config_filename))
        yield from error_logs
    else:
        yield logging.makeLogRecord(dict(levelno=logging.INFO, levelname='INFO', msg='{}: Successfully ran configuration file'.format(config_filename)))
        if results:
            json_results.extend(results)","for e_target in configs.items():
    config = e_target[1]
    config_filename = e_target[0]
    results = list(run_configuration(config_filename, config, arguments))
    error_logs = tuple((result for result in results if isinstance(result, logging.LogRecord)))
    if error_logs:
        yield from make_error_log_records('{}: Error running configuration file'.format(config_filename))
        yield from error_logs
    else:
        yield logging.makeLogRecord(dict(levelno=logging.INFO, levelname='INFO', msg='{}: Successfully ran configuration file'.format(config_filename)))
        if results:
            json_results.extend(results)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_post_hook_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_pre_hook_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_extract'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_run_configuration_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_outputs_merged_json_results'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_for_list_with_archive_and_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_mount'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_mount_with_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_missing_configs_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_run_umount_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_extract_with_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_executes_hooks_for_create'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_list']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/commands/borgmatic.py,,test_collect_configuration_run_summary_logs_info_for_success_with_list,"for (config_filename, config) in configs.items():
    hooks = config.get('hooks', {})
    command.execute_hook(hooks.get('before_everything'), hooks.get('umask'), config_filename, 'pre-everything', arguments['global'].dry_run)","for e_target in configs.items():
    config = e_target[1]
    config_filename = e_target[0]
    hooks = config.get('hooks', {})
    command.execute_hook(hooks.get('before_everything'), hooks.get('umask'), config_filename, 'pre-everything', arguments['global'].dry_run)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_post_hook_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_pre_hook_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_extract'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_run_configuration_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_outputs_merged_json_results'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_for_list_with_archive_and_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_mount'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_mount_with_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_missing_configs_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_run_umount_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_extract_with_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_executes_hooks_for_create'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_list']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/commands/borgmatic.py,,test_collect_configuration_run_summary_logs_info_for_success_with_list,"for (config_filename, config) in configs.items():
    hooks = config.get('hooks', {})
    command.execute_hook(hooks.get('after_everything'), hooks.get('umask'), config_filename, 'post-everything', arguments['global'].dry_run)","for e_target in configs.items():
    config = e_target[1]
    config_filename = e_target[0]
    hooks = config.get('hooks', {})
    command.execute_hook(hooks.get('after_everything'), hooks.get('umask'), config_filename, 'post-everything', arguments['global'].dry_run)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_post_hook_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_pre_hook_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_extract'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_run_configuration_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_outputs_merged_json_results'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_for_list_with_archive_and_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_mount'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_mount_with_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_missing_configs_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_run_umount_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_extract_with_repository_error'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_executes_hooks_for_create'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_borgmatic.py', 'tests.unit.commands.test_borgmatic', '', 'test_collect_configuration_run_summary_logs_info_for_success_with_list']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/commands/arguments.py,,test_parse_subparser_arguments_parses_borg_options_and_skips_other_subparsers,"for (subparser_name, subparser) in subparsers.items():
    if subparser_name not in remaining_arguments:
        continue
    canonical_name = alias_to_subparser_name.get(subparser_name, subparser_name)
    (parsed, unused_remaining) = subparser.parse_known_args(unparsed_arguments)
    for value in vars(parsed).values():
        if isinstance(value, str):
            if value in subparsers:
                remaining_arguments.remove(value)
        elif isinstance(value, list):
            for item in value:
                if item in subparsers:
                    remaining_arguments.remove(item)
    arguments[canonical_name] = parsed","for e_target in subparsers.items():
    subparser = e_target[1]
    subparser_name = e_target[0]
    if subparser_name not in remaining_arguments:
        continue
    canonical_name = alias_to_subparser_name.get(subparser_name, subparser_name)
    (parsed, unused_remaining) = subparser.parse_known_args(unparsed_arguments)
    for value in vars(parsed).values():
        if isinstance(value, str):
            if value in subparsers:
                remaining_arguments.remove(value)
        elif isinstance(value, list):
            for item in value:
                if item in subparsers:
                    remaining_arguments.remove(item)
    arguments[canonical_name] = parsed

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_before_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_multiple_subparser_arguments'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_passes_through_unknown_arguments_before_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_with_alias'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_after_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_passes_through_unknown_arguments_after_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_applies_default_subparsers'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_parses_borg_options_and_skips_other_subparsers']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/commands/arguments.py,,test_parse_subparser_arguments_parses_borg_options_and_skips_other_subparsers,"for (subparser_name, subparser) in subparsers.items():
    if subparser_name not in arguments.keys():
        continue
    subparser = subparsers[subparser_name]
    (unused_parsed, remaining_arguments) = subparser.parse_known_args(remaining_arguments)","for e_target in subparsers.items():
    subparser = e_target[1]
    subparser_name = e_target[0]
    if subparser_name not in arguments.keys():
        continue
    subparser = subparsers[subparser_name]
    (unused_parsed, remaining_arguments) = subparser.parse_known_args(remaining_arguments)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_before_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_multiple_subparser_arguments'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_passes_through_unknown_arguments_before_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_with_alias'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_after_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_passes_through_unknown_arguments_after_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_applies_default_subparsers'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_parses_borg_options_and_skips_other_subparsers']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/commands/arguments.py,,test_parse_subparser_arguments_parses_borg_options_and_skips_other_subparsers,"for (subparser_name, subparser) in subparsers.items():
    if subparser_name in remaining_arguments:
        remaining_arguments.remove(subparser_name)","for e_target in subparsers.items():
    subparser = e_target[1]
    subparser_name = e_target[0]
    if subparser_name in remaining_arguments:
        remaining_arguments.remove(subparser_name)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_before_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_multiple_subparser_arguments'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_passes_through_unknown_arguments_before_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_with_alias'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_consumes_subparser_arguments_after_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_passes_through_unknown_arguments_after_subparser_name'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_applies_default_subparsers'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/commands/test_arguments.py', 'tests.unit.commands.test_arguments', '', 'test_parse_subparser_arguments_parses_borg_options_and_skips_other_subparsers']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/config/generate.py,,test_add_comments_to_configuration_object_does_not_raise,"for (index, field_name) in enumerate(config.keys()):
    if skip_first and index == 0:
        continue
    field_schema = schema['properties'].get(field_name, {})
    description = field_schema.get('description', '').strip()
    if field_name not in REQUIRED_SECTION_NAMES and field_name not in REQUIRED_KEYS:
        description = '\n'.join((description, COMMENTED_OUT_SENTINEL)) if description else COMMENTED_OUT_SENTINEL
    if not field_schema or not description:
        continue
    config.yaml_set_comment_before_after_key(key=field_name, before=description, indent=indent)
    if index > 0:
        _insert_newline_before_comment(config, field_name)","for e_target in enumerate(config.keys()):
    field_name = e_target[1]
    index = e_target[0]
    if skip_first and index == 0:
        continue
    field_schema = schema['properties'].get(field_name, {})
    description = field_schema.get('description', '').strip()
    if field_name not in REQUIRED_SECTION_NAMES and field_name not in REQUIRED_KEYS:
        description = '\n'.join((description, COMMENTED_OUT_SENTINEL)) if description else COMMENTED_OUT_SENTINEL
    if not field_schema or not description:
        continue
    config.yaml_set_comment_before_after_key(key=field_name, before=description, indent=indent)
    if index > 0:
        _insert_newline_before_comment(config, field_name)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/integration/config/test_generate.py', 'tests.integration.config.test_generate', '', 'test_add_comments_to_configuration_object_with_skip_first_does_not_raise'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/integration/config/test_generate.py', 'tests.integration.config.test_generate', '', 'test_add_comments_to_configuration_object_does_not_raise']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/config/generate.py,,test_merge_source_configuration_into_destination_inserts_sequence_of_maps,"for (field_name, source_value) in source_config.items():
    remove_commented_out_sentinel(destination_config, field_name)
    if isinstance(source_value, collections.abc.Mapping):
        destination_config[field_name] = merge_source_configuration_into_destination(destination_config[field_name], source_value)
        continue
    if isinstance(source_value, collections.abc.Sequence) and (not isinstance(source_value, str)):
        destination_value = destination_config[field_name]
        destination_config[field_name] = yaml.comments.CommentedSeq([merge_source_configuration_into_destination(destination_value[index] if index < len(destination_value) else None, source_item) for (index, source_item) in enumerate(source_value)])
        continue
    destination_config[field_name] = source_config[field_name]","for e_target in source_config.items():
    source_value = e_target[1]
    field_name = e_target[0]
    remove_commented_out_sentinel(destination_config, field_name)
    if isinstance(source_value, collections.abc.Mapping):
        destination_config[field_name] = merge_source_configuration_into_destination(destination_config[field_name], source_value)
        continue
    if isinstance(source_value, collections.abc.Sequence) and (not isinstance(source_value, str)):
        destination_value = destination_config[field_name]
        destination_config[field_name] = yaml.comments.CommentedSeq([merge_source_configuration_into_destination(destination_value[index] if index < len(destination_value) else None, source_item) for (index, source_item) in enumerate(source_value)])
        continue
    destination_config[field_name] = source_config[field_name]

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/config/test_generate.py', 'tests.unit.config.test_generate', '', 'test_merge_source_configuration_into_destination_without_source_does_nothing'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/config/test_generate.py', 'tests.unit.config.test_generate', '', 'test_merge_source_configuration_into_destination_inserts_map_fields'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/config/test_generate.py', 'tests.unit.config.test_generate', '', 'test_merge_source_configuration_into_destination_inserts_nested_map_fields'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/config/test_generate.py', 'tests.unit.config.test_generate', '', 'test_merge_source_configuration_into_destination_inserts_sequence_fields'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/config/test_generate.py', 'tests.unit.config.test_generate', '', 'test_merge_source_configuration_into_destination_inserts_sequence_of_maps']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/config/convert.py,,test_convert_legacy_parsed_config_transforms_source_config_to_mapping,"for (section_name, section_config) in destination_config.items():
    generate.add_comments_to_configuration_object(section_config, schema['properties'][section_name], indent=generate.INDENT)","for e_target in destination_config.items():
    section_config = e_target[1]
    section_name = e_target[0]
    generate.add_comments_to_configuration_object(section_config, schema['properties'][section_name], indent=generate.INDENT)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/config/test_convert.py', 'tests.unit.config.test_convert', '', 'test_convert_legacy_parsed_config_splits_space_separated_values'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/config/test_convert.py', 'tests.unit.config.test_convert', '', 'test_convert_legacy_parsed_config_transforms_source_config_to_mapping']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/config/override.py,,test_apply_overrides_updates_config,"for (keys, value) in overrides:
    set_values(config, keys, value)","for e_target in overrides:
    value = e_target[1]
    keys = e_target[0]
    set_values(config, keys, value)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/integration/config/test_override.py', 'tests.integration.config.test_override', '', 'test_apply_overrides_updates_config']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/hooks/command.py,,test_interpolate_context_interpolates_variables,"for (name, value) in context.items():
    command = command.replace('{%s}' % name, str(value))","for e_target in context.items():
    value = e_target[1]
    name = e_target[0]
    command = command.replace('{%s}' % name, str(value))

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/hooks/test_command.py', 'tests.unit.hooks.test_command', '', 'test_interpolate_context_passes_through_command_without_variable'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/hooks/test_command.py', 'tests.unit.hooks.test_command', '', 'test_interpolate_context_passes_through_command_with_unknown_variable'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/hooks/test_command.py', 'tests.unit.hooks.test_command', '', 'test_interpolate_context_interpolates_variables']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/borg/environment.py,,test_initialize_with_ssh_command_should_set_environment,"for (option_name, environment_variable_name) in OPTION_TO_ENVIRONMENT_VARIABLE.items():
    value = storage_config.get(option_name) or os.environ.get(environment_variable_name)
    if value:
        os.environ[environment_variable_name] = value
    else:
        os.environ.pop(environment_variable_name, None)","for e_target in OPTION_TO_ENVIRONMENT_VARIABLE.items():
    environment_variable_name = e_target[1]
    option_name = e_target[0]
    value = storage_config.get(option_name) or os.environ.get(environment_variable_name)
    if value:
        os.environ[environment_variable_name] = value
    else:
        os.environ.pop(environment_variable_name, None)

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_prefers_configuration_option_over_borg_environment_variable'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_passes_through_existing_borg_environment_variable'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_with_passcommand_should_set_environment'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_with_passphrase_should_set_environment'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_with_relocated_repo_access_should_override_default'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_without_configuration_should_only_set_default_environment'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_with_ssh_command_should_set_environment']]"
borgmatic,https://github.com/borgmatic-collective/borgmatic/tree/master/borgmatic/borg/environment.py,,test_initialize_with_ssh_command_should_set_environment,"for (option_name, environment_variable_name) in DEFAULT_BOOL_OPTION_TO_ENVIRONMENT_VARIABLE.items():
    value = storage_config.get(option_name, False)
    os.environ[environment_variable_name] = 'yes' if value else 'no'","for e_target in DEFAULT_BOOL_OPTION_TO_ENVIRONMENT_VARIABLE.items():
    environment_variable_name = e_target[1]
    option_name = e_target[0]
    value = storage_config.get(option_name, False)
    os.environ[environment_variable_name] = 'yes' if value else 'no'

",1,"[['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_prefers_configuration_option_over_borg_environment_variable'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_passes_through_existing_borg_environment_variable'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_with_passcommand_should_set_environment'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_with_passphrase_should_set_environment'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_with_relocated_repo_access_should_override_default'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_without_configuration_should_only_set_default_environment'], ['https://github.com/borgmatic-collective/borgmatic/tree/master/tests/unit/borg/test_environment.py', 'tests.unit.borg.test_environment', '', 'test_initialize_with_ssh_command_should_set_environment']]"
mutmut,https://github.com/boxed/mutmut/tree/master/mutmut/cache.py,,test_sequence_ops,"for (tag, i1, i2, j1, j2) in sequence_matcher.get_opcodes():
    a_sub_sequence = a[i1:i2]
    b_sub_sequence = b[j1:j2]
    for x in zip_longest(a_sub_sequence, range(i1, i2), b_sub_sequence, range(j1, j2)):
        yield ((tag,) + x)","for e_target in sequence_matcher.get_opcodes():
    j2 = e_target[4]
    j1 = e_target[3]
    i2 = e_target[2]
    i1 = e_target[1]
    tag = e_target[0]
    a_sub_sequence = a[i1:i2]
    b_sub_sequence = b[j1:j2]
    for x in zip_longest(a_sub_sequence, range(i1, i2), b_sub_sequence, range(j1, j2)):
        yield ((tag,) + x)

",1,"[['https://github.com/boxed/mutmut/tree/master/tests/test_cache.py', 'tests.test_cache', '', 'test_sequence_ops']]"
in-toto,https://github.com/in-toto/in-toto/tree/master/in_toto/user_settings.py,TestUserSettings,test_set_settings,"for (name, value) in os.environ.items():
    if name.startswith(ENV_PREFIX) and len(name) > len(ENV_PREFIX):
        stripped_name = name[len(ENV_PREFIX):]
        env_dict[stripped_name] = _colon_split(value)","for e_target in os.environ.items():
    value = e_target[1]
    name = e_target[0]
    if name.startswith(ENV_PREFIX) and len(name) > len(ENV_PREFIX):
        stripped_name = name[len(ENV_PREFIX):]
        env_dict[stripped_name] = _colon_split(value)

",1,"[['https://github.com/in-toto/in-toto/tree/master/tests/test_user_settings.py', 'tests.test_user_settings', 'TestUserSettings', 'test_get_env'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_user_settings.py', 'tests.test_user_settings', 'TestUserSettings', 'test_set_settings']]"
in-toto,https://github.com/in-toto/in-toto/tree/master/in_toto/verifylib.py,TestInTotoVerifyThresholdsGpgSubkeys,test_verify_link_signature_thresholds__M_M_M,"for (link_keyid, link) in chain_link_dict.get(step.name, {}).items():
    for authorized_keyid in step.pubkeys:
        authorized_key = layout.keys.get(authorized_keyid)
        main_key_for_subkey = main_keys_for_subkeys.get(authorized_keyid)
        if authorized_key and link_keyid == authorized_keyid:
            verification_key = authorized_key
            break
        if main_key_for_subkey and link_keyid == authorized_keyid:
            verification_key = main_key_for_subkey
            break
        if authorized_key and link_keyid in authorized_key.get('subkeys', {}).keys():
            verification_key = authorized_key
            break
    else:
        LOG.info(""Skipping link. Keyid '{0}' is not authorized to sign links for step '{1}'"".format(link_keyid, step.name))
        continue
    try:
        link.verify_signature(verification_key)
    except SignatureVerificationError:
        LOG.info(""Skipping link. Broken link signature with keyid '{0}' for step '{1}'"".format(link_keyid, step.name))
        continue
    except KeyExpirationError as e:
        LOG.info('Skipping link. {}'.format(e))
        continue
    if verification_key['keyid'] in used_main_keyids:
        LOG.warning(""Found links signed by different subkeys of the same main key '{}' for step '{}'. Only one of them is counted towards the step threshold."".format(verification_key['keyid'], step.name))
    used_main_keyids.append(verification_key['keyid'])
    verified_key_link_dict[link_keyid] = link","for e_target in chain_link_dict.get(step.name, {}).items():
    link = e_target[1]
    link_keyid = e_target[0]
    for authorized_keyid in step.pubkeys:
        authorized_key = layout.keys.get(authorized_keyid)
        main_key_for_subkey = main_keys_for_subkeys.get(authorized_keyid)
        if authorized_key and link_keyid == authorized_keyid:
            verification_key = authorized_key
            break
        if main_key_for_subkey and link_keyid == authorized_keyid:
            verification_key = main_key_for_subkey
            break
        if authorized_key and link_keyid in authorized_key.get('subkeys', {}).keys():
            verification_key = authorized_key
            break
    else:
        LOG.info(""Skipping link. Keyid '{0}' is not authorized to sign links for step '{1}'"".format(link_keyid, step.name))
        continue
    try:
        link.verify_signature(verification_key)
    except SignatureVerificationError:
        LOG.info(""Skipping link. Broken link signature with keyid '{0}' for step '{1}'"".format(link_keyid, step.name))
        continue
    except KeyExpirationError as e:
        LOG.info('Skipping link. {}'.format(e))
        continue
    if verification_key['keyid'] in used_main_keyids:
        LOG.warning(""Found links signed by different subkeys of the same main key '{}' for step '{}'. Only one of them is counted towards the step threshold."".format(verification_key['keyid'], step.name))
    used_main_keyids.append(verification_key['keyid'])
    verified_key_link_dict[link_keyid] = link

",1,"[['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholds', 'test_thresholds_skip_unauthorized_links'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholdsGpgSubkeys', 'test_verify_link_signature_thresholds__S_M_S'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholdsGpgSubkeys', 'test_verify_subkey_thresholds'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholds', 'test_thresholds_fail_with_not_enough_valid_links'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholdsGpgSubkeys', 'test_verify_thresholds_skip_expired_key'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholdsGpgSubkeys', 'test_verify_link_signature_thresholds__S_S_M'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholds', 'test_thresholds_skip_links_with_failing_signature'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholdsGpgSubkeys', 'test_verify_link_signature_thresholds__S_M_M'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholdsGpgSubkeys', 'test_verify_link_signature_thresholds__S_S_S'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_verifylib.py', 'tests.test_verifylib', 'TestInTotoVerifyThresholdsGpgSubkeys', 'test_verify_link_signature_thresholds__M_M_M']]"
in-toto,https://github.com/in-toto/in-toto/tree/master/in_toto/runlib.py,TestRecordArtifactsAsDict,test_lstrip_paths_invalid_prefix_directory,"for (prefix_one, prefix_two) in itertools.combinations(lstrip_paths, 2):
    if prefix_one.startswith(prefix_two) or prefix_two.startswith(prefix_one):
        raise in_toto.exceptions.PrefixError(""'{}' and '{}' triggered a left substring error"".format(prefix_one, prefix_two))","for e_target in itertools.combinations(lstrip_paths, 2):
    prefix_two = e_target[1]
    prefix_one = e_target[0]
    if prefix_one.startswith(prefix_two) or prefix_two.startswith(prefix_one):
        raise in_toto.exceptions.PrefixError(""'{}' and '{}' triggered a left substring error"".format(prefix_one, prefix_two))

",1,"[['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_valid_unicode_prefix_file'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_bad_base_path_setting'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_empty_artifacts_list_record_nothing'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_bad_artifact_exclude_patterns_setting'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_files_and_subdirs'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_base_path_is_child_dir'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_non_unique_key'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_without_dead_symlinks'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_dot_check_files_hash_dict_schema'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_valid_prefix_directory'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_non_unique_key_file'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_not_existing_artifacts_in_list_record_nothing'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_substring_prefix_directory'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_valid_prefix_file'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_symlinked_files'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_base_path_is_parent_dir'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_follow_symlinked_directories'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_exclude_patterns'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_invalid_prefix_directory']]"
in-toto,https://github.com/in-toto/in-toto/tree/master/in_toto/runlib.py,TestRecordArtifactsAsDict,test_lstrip_paths_invalid_prefix_directory,"for (root, dirs, files) in os.walk(artifact, followlinks=follow_symlink_dirs):
    dirpaths = []
    for dirname in dirs:
        norm_dirpath = os.path.normpath(os.path.join(root, dirname))
        dirpaths.append(norm_dirpath)
    if exclude_patterns:
        dirpaths = _apply_exclude_patterns(dirpaths, exclude_filter)
    dirs[:] = []
    for dirpath in dirpaths:
        name = os.path.basename(dirpath)
        dirs.append(name)
    filepaths = []
    for filename in files:
        norm_filepath = os.path.normpath(os.path.join(root, filename))
        if os.path.isfile(norm_filepath):
            filepaths.append(norm_filepath)
        else:
            LOG.info(""File '{}' appears to be a broken symlink. Skipping..."".format(norm_filepath))
    if exclude_patterns:
        filepaths = _apply_exclude_patterns(filepaths, exclude_filter)
    for filepath in filepaths:
        normalized_filepath = filepath.replace('\\', '/')
        key = _apply_left_strip(normalized_filepath, artifacts_dict, lstrip_paths)
        artifacts_dict[key] = _hash_artifact(filepath, normalize_line_endings=normalize_line_endings)","for e_target in os.walk(artifact, followlinks=follow_symlink_dirs):
    files = e_target[2]
    dirs = e_target[1]
    root = e_target[0]
    dirpaths = []
    for dirname in dirs:
        norm_dirpath = os.path.normpath(os.path.join(root, dirname))
        dirpaths.append(norm_dirpath)
    if exclude_patterns:
        dirpaths = _apply_exclude_patterns(dirpaths, exclude_filter)
    dirs[:] = []
    for dirpath in dirpaths:
        name = os.path.basename(dirpath)
        dirs.append(name)
    filepaths = []
    for filename in files:
        norm_filepath = os.path.normpath(os.path.join(root, filename))
        if os.path.isfile(norm_filepath):
            filepaths.append(norm_filepath)
        else:
            LOG.info(""File '{}' appears to be a broken symlink. Skipping..."".format(norm_filepath))
    if exclude_patterns:
        filepaths = _apply_exclude_patterns(filepaths, exclude_filter)
    for filepath in filepaths:
        normalized_filepath = filepath.replace('\\', '/')
        key = _apply_left_strip(normalized_filepath, artifacts_dict, lstrip_paths)
        artifacts_dict[key] = _hash_artifact(filepath, normalize_line_endings=normalize_line_endings)

",1,"[['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_valid_unicode_prefix_file'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_bad_base_path_setting'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_empty_artifacts_list_record_nothing'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_bad_artifact_exclude_patterns_setting'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_files_and_subdirs'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_base_path_is_child_dir'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_non_unique_key'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_without_dead_symlinks'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_dot_check_files_hash_dict_schema'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_valid_prefix_directory'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_non_unique_key_file'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_not_existing_artifacts_in_list_record_nothing'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_substring_prefix_directory'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_valid_prefix_file'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_symlinked_files'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_base_path_is_parent_dir'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_record_follow_symlinked_directories'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_exclude_patterns'], ['https://github.com/in-toto/in-toto/tree/master/tests/test_runlib.py', 'tests.test_runlib', 'TestRecordArtifactsAsDict', 'test_lstrip_paths_invalid_prefix_directory']]"
doit,https://github.com/pydoit/doit/tree/master/doit/cmd_info.py,TestCmdInfo,test_get_reasons_str,"for (reason, sentence) in sentences.items():
    entries = reasons.get(reason)
    if entries:
        lines.append(' * {}'.format(sentence))
        for item in entries:
            lines.append('    - {}'.format(item))","for e_target in sentences.items():
    sentence = e_target[1]
    reason = e_target[0]
    entries = reasons.get(reason)
    if entries:
        lines.append(' * {}'.format(sentence))
        for item in entries:
            lines.append('    - {}'.format(item))

",1,"[['https://github.com/pydoit/doit/tree/master/tests/test_cmd_info.py', 'tests.test_cmd_info', 'TestCmdInfo', 'test_get_reasons_str']]"
doit,https://github.com/pydoit/doit/tree/master/doit/cmd_info.py,TestCmdInfo,test_get_reasons_str,"for (utd, utd_args, utd_kwargs) in reasons['uptodate_false']:
    msg = '    - {} (args={}, kwargs={})'
    lines.append(msg.format(utd, utd_args, utd_kwargs))","for e_target in reasons['uptodate_false']:
    utd_kwargs = e_target[2]
    utd_args = e_target[1]
    utd = e_target[0]
    msg = '    - {} (args={}, kwargs={})'
    lines.append(msg.format(utd, utd_args, utd_kwargs))

",1,"[['https://github.com/pydoit/doit/tree/master/tests/test_cmd_info.py', 'tests.test_cmd_info', 'TestCmdInfo', 'test_get_reasons_str']]"
doit,https://github.com/pydoit/doit/tree/master/doit/loader.py,TestFlatGenerator,test_nested,"for (value, value_doc) in flat_generator(item, item_doc):
    yield (value, value_doc)","for e_target in flat_generator(item, item_doc):
    value_doc = e_target[1]
    value = e_target[0]
    yield (value, value_doc)

",1,"[['https://github.com/pydoit/doit/tree/master/tests/test_loader.py', 'tests.test_loader', 'TestFlatGenerator', 'test_nested']]"
doit,https://github.com/pydoit/doit/tree/master/doit/cmdparse.py,TestDefaultUpdate,test_add_defaults,"for (key, value) in source.items():
    if key not in self:
        self.set_default(key, value)","for e_target in source.items():
    value = e_target[1]
    key = e_target[0]
    if key not in self:
        self.set_default(key, value)

",1,"[['https://github.com/pydoit/doit/tree/master/tests/test_cmdparse.py', 'tests.test_cmdparse', 'TestDefaultUpdate', 'test_add_defaults']]"
pupil,https://github.com/pupil-labs/pupil/tree/master/pupil_src/shared_modules/csv_utils.py,,test_read_write_key_value_file,"for (key, val) in dictionary.items():
    writer.writerow([key, val])","for e_target in dictionary.items():
    val = e_target[1]
    key = e_target[0]
    writer.writerow([key, val])

",1,"[['https://github.com/pupil-labs/pupil/tree/master/pupil_src/tests/test_csv_utils.py', 'pupil_src.tests.test_csv_utils', '', 'test_read_write_key_value_file']]"
cesium,https://github.com/cesium-ml/cesium/tree/master/cesium/time_series.py,,test_time_series_npz,"for (i, value_i) in enumerate(value):
    data[key + str(i)] = value_i","for e_target in enumerate(value):
    value_i = e_target[1]
    i = e_target[0]
    data[key + str(i)] = value_i

",1,"[['https://github.com/cesium-ml/cesium/tree/master/cesium/tests/test_time_series.py', 'cesium.tests.test_time_series', '', 'test_time_series_npz']]"
kafka-python,https://github.com/dpkp/kafka-python/tree/master/kafka/client_async.py,,test_idle_connection_manager,"for (conn_id, ts) in self.lru_connections.items():
    if oldest_conn_id is None or ts < oldest_ts:
        oldest_conn_id = conn_id
        oldest_ts = ts","for e_target in self.lru_connections.items():
    ts = e_target[1]
    conn_id = e_target[0]
    if oldest_conn_id is None or ts < oldest_ts:
        oldest_conn_id = conn_id
        oldest_ts = ts

",1,"[['https://github.com/dpkp/kafka-python/tree/master/test/test_client_async.py', 'test.test_client_async', '', 'test_idle_connection_manager']]"
kafka-python,https://github.com/dpkp/kafka-python/tree/master/kafka/cluster.py,,test_empty_broker_list,"for (p_error, partition, leader, replicas, isr) in partitions:
    _new_partitions[topic][partition] = PartitionMetadata(topic=topic, partition=partition, leader=leader, replicas=replicas, isr=isr, error=p_error)
    if leader != -1:
        _new_broker_partitions[leader].add(TopicPartition(topic, partition))","for e_target in partitions:
    isr = e_target[4]
    replicas = e_target[3]
    leader = e_target[2]
    partition = e_target[1]
    p_error = e_target[0]
    _new_partitions[topic][partition] = PartitionMetadata(topic=topic, partition=partition, leader=leader, replicas=replicas, isr=isr, error=p_error)
    if leader != -1:
        _new_broker_partitions[leader].add(TopicPartition(topic, partition))

",1,"[['https://github.com/dpkp/kafka-python/tree/master/test/test_cluster.py', 'test.test_cluster', '', 'test_empty_broker_list']]"
kafka-python,https://github.com/dpkp/kafka-python/tree/master/kafka/protocol/message.py,,test_encode_message_set,"for (offset, message) in items:
    encoded_values.append(Int64.encode(offset))
    encoded_values.append(Bytes.encode(message))","for e_target in items:
    message = e_target[1]
    offset = e_target[0]
    encoded_values.append(Int64.encode(offset))
    encoded_values.append(Bytes.encode(message))

",1,"[['https://github.com/dpkp/kafka-python/tree/master/test/test_protocol.py', 'test.test_protocol', '', 'test_encode_message_set']]"
kafka-python,https://github.com/dpkp/kafka-python/tree/master/kafka/coordinator/assignors/sticky/partition_movements.py,,test_should_detect_non_sticky_assignment,"for (topic, movements) in six.iteritems(self.partition_movements_by_topic):
    movement_pairs = set(movements.keys())
    if self._has_cycles(movement_pairs):
        log.error('Stickiness is violated for topic {}\nPartition movements for this topic occurred among the following consumer pairs:\n{}'.format(topic, movement_pairs))
        return False","for e_target in six.iteritems(self.partition_movements_by_topic):
    movements = e_target[1]
    topic = e_target[0]
    movement_pairs = set(movements.keys())
    if self._has_cycles(movement_pairs):
        log.error('Stickiness is violated for topic {}\nPartition movements for this topic occurred among the following consumer pairs:\n{}'.format(topic, movement_pairs))
        return False

",1,"[['https://github.com/dpkp/kafka-python/tree/master/test/test_partition_movements.py', 'test.test_partition_movements', '', 'test_empty_movements_are_sticky'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_partition_movements.py', 'test.test_partition_movements', '', 'test_sticky_movements'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_partition_movements.py', 'test.test_partition_movements', '', 'test_should_detect_non_sticky_assignment']]"
kafka-python,https://github.com/dpkp/kafka-python/tree/master/kafka/coordinator/assignors/sticky/sticky_assignor.py,,test_sticky_two_consumers_one_topic_two_partitions,"for (consumer, member_metadata) in six.iteritems(members):
    members_metadata[consumer] = cls.parse_member_metadata(member_metadata)","for e_target in six.iteritems(members):
    member_metadata = e_target[1]
    consumer = e_target[0]
    members_metadata[consumer] = cls.parse_member_metadata(member_metadata)

",1,"[['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_assignor1'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_one_consumer_multiple_topics'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_move_existing_assignments'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_one_consumer_one_topic'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_new_subscription'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_add_remove_topic_two_consumers'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_assignment_with_multiple_generations2'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_conflicting_previous_assignments'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_one_consumer_nonexisting_topic'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_add_remove_consumer_one_topic'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_one_consumer_no_topic'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_stickiness'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_assignor2'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_assignment_updated_for_deleted_topic'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_multiple_consumers_mixed_topic_subscriptions'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_should_only_assign_partitions_from_subscribed_topics'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_two_consumers_one_topic_one_partition'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_no_exceptions_when_only_subscribed_topic_is_deleted'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_reassignment_after_one_consumer_leaves'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_reassignment_after_one_consumer_added'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_assignment_with_multiple_generations1'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_same_subscriptions'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_large_assignment_with_multiple_consumers_leaving'], ['https://github.com/dpkp/kafka-python/tree/master/test/test_assignors.py', 'test.test_assignors', '', 'test_sticky_two_consumers_one_topic_two_partitions']]"
makesite,https://github.com/sunainapai/makesite/tree/master//makesite.py,ContentTest,test_content_date_missing,"for (key, val, end) in read_headers(text):
    content[key] = val","for e_target in read_headers(text):
    end = e_target[2]
    val = e_target[1]
    key = e_target[0]
    content[key] = val

",1,"[['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_content_date'], ['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_content_slug_undated'], ['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_content_content'], ['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_markdown_import_error'], ['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_no_markdown_rendering'], ['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_content_headers'], ['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_content_slug_dated'], ['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_no_markdown_import_error'], ['https://github.com/sunainapai/makesite/tree/master/test/test_content.py', 'test.test_content', 'ContentTest', 'test_content_date_missing']]"
python-louvain,https://github.com/taynaud/python-louvain/tree/master/community/community_louvain.py,GenerateDendrogramTest,test_nodes_stay_together,"for (node, community) in partition.items():
    partition[node] = dendrogram[index][community]","for e_target in partition.items():
    community = e_target[1]
    node = e_target[0]
    partition[node] = dendrogram[index][community]

",1,"[['https://github.com/taynaud/python-louvain/tree/master//test_community.py', 'test_community', 'GenerateDendrogramTest', 'test_modularity_increase'], ['https://github.com/taynaud/python-louvain/tree/master//test_community.py', 'test_community', 'GenerateDendrogramTest', 'test_nodes_stay_together']]"
moto,https://github.com/spulec/moto/tree/master/moto/utilities/tagging_service.py,,test_validate_tags,"for (idx, tag) in enumerate(tags, 1):
    for (tag_key, tag_value) in tag.items():
        if tag_key == self.key_name:
            if len(tag_value) > 128:
                errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.key' failed to satisfy constraint: Member must have length less than or equal to 128"")
            if not re.match(key_regex, tag_value):
                errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.key' failed to satisfy constraint: Member must satisfy regular expression pattern: ^(?!aws:)[{{a-zA-Z0-9 }}_.://=+-@%]*$"")
        elif tag_key == self.value_name:
            if len(tag_value) > 256:
                errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.value' failed to satisfy constraint: Member must have length less than or equal to 256"")
            if not re.match(value_regex, tag_value):
                errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.value' failed to satisfy constraint: Member must satisfy regular expression pattern: ^[{{a-zA-Z0-9 }}_.://=+-@%]*$"")","for e_target in enumerate(tags, 1):
    tag = e_target[1]
    idx = e_target[0]
    for (tag_key, tag_value) in tag.items():
        if tag_key == self.key_name:
            if len(tag_value) > 128:
                errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.key' failed to satisfy constraint: Member must have length less than or equal to 128"")
            if not re.match(key_regex, tag_value):
                errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.key' failed to satisfy constraint: Member must satisfy regular expression pattern: ^(?!aws:)[{{a-zA-Z0-9 }}_.://=+-@%]*$"")
        elif tag_key == self.value_name:
            if len(tag_value) > 256:
                errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.value' failed to satisfy constraint: Member must have length less than or equal to 256"")
            if not re.match(value_regex, tag_value):
                errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.value' failed to satisfy constraint: Member must satisfy regular expression pattern: ^[{{a-zA-Z0-9 }}_.://=+-@%]*$"")

",1,"[['https://github.com/spulec/moto/tree/master/tests/test_utilities/test_tagging_service.py', 'tests.test_utilities.test_tagging_service', '', 'test_validate_tags']]"
moto,https://github.com/spulec/moto/tree/master/moto/utilities/tagging_service.py,,test_validate_tags,"for (tag_key, tag_value) in tag.items():
    if tag_key == self.key_name:
        if len(tag_value) > 128:
            errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.key' failed to satisfy constraint: Member must have length less than or equal to 128"")
        if not re.match(key_regex, tag_value):
            errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.key' failed to satisfy constraint: Member must satisfy regular expression pattern: ^(?!aws:)[{{a-zA-Z0-9 }}_.://=+-@%]*$"")
    elif tag_key == self.value_name:
        if len(tag_value) > 256:
            errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.value' failed to satisfy constraint: Member must have length less than or equal to 256"")
        if not re.match(value_regex, tag_value):
            errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.value' failed to satisfy constraint: Member must satisfy regular expression pattern: ^[{{a-zA-Z0-9 }}_.://=+-@%]*$"")","for e_target in tag.items():
    tag_value = e_target[1]
    tag_key = e_target[0]
    if tag_key == self.key_name:
        if len(tag_value) > 128:
            errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.key' failed to satisfy constraint: Member must have length less than or equal to 128"")
        if not re.match(key_regex, tag_value):
            errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.key' failed to satisfy constraint: Member must satisfy regular expression pattern: ^(?!aws:)[{{a-zA-Z0-9 }}_.://=+-@%]*$"")
    elif tag_key == self.value_name:
        if len(tag_value) > 256:
            errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.value' failed to satisfy constraint: Member must have length less than or equal to 256"")
        if not re.match(value_regex, tag_value):
            errors.append(f""Value '{tag_value}' at 'tags.{idx}.member.value' failed to satisfy constraint: Member must satisfy regular expression pattern: ^[{{a-zA-Z0-9 }}_.://=+-@%]*$"")

",1,"[['https://github.com/spulec/moto/tree/master/tests/test_utilities/test_tagging_service.py', 'tests.test_utilities.test_tagging_service', '', 'test_validate_tags']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/plugin.py,TestPluginCanBePackage,test_plugin_register,"for (name, plugin) in zip(plugin_mapping.keys(), modules):
    log.debug('Initializing plugin %s: %s', name, plugin)
    plugin.awscli_initialize(event_hooks)","for e_target in zip(plugin_mapping.keys(), modules):
    plugin = e_target[1]
    name = e_target[0]
    log.debug('Initializing plugin %s: %s', name, plugin)
    plugin.awscli_initialize(event_hooks)

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/test_plugin.py', 'tests.unit.test_plugin', 'TestPlugins', 'test_event_hooks_can_be_passed_in'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/test_plugin.py', 'tests.unit.test_plugin', 'TestPlugins', 'test_plugin_register'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/test_plugin.py', 'tests.unit.test_plugin', 'TestPluginCanBePackage', 'test_plugin_register']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/table.py,TestVerticalTableConversion,test_convert_section_to_vertical,"for (i, section) in enumerate(sections):
    if len(section.rows) == 1 and section.headers:
        headers = section.headers
        new_section = Section()
        new_section.title = section.title
        new_section.indent_level = section.indent_level
        for (header, element) in zip(headers, section.rows[0]):
            new_section.add_row([header, element])
        sections[i] = new_section","for e_target in enumerate(sections):
    section = e_target[1]
    i = e_target[0]
    if len(section.rows) == 1 and section.headers:
        headers = section.headers
        new_section = Section()
        new_section.title = section.title
        new_section.indent_level = section.indent_level
        for (header, element) in zip(headers, section.rows[0]):
            new_section.add_row([header, element])
        sections[i] = new_section

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/test_table.py', 'tests.unit.test_table', 'TestVerticalTableConversion', 'test_convert_section_to_vertical']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/table.py,TestVerticalTableConversion,test_convert_section_to_vertical,"for (header, element) in zip(headers, section.rows[0]):
    new_section.add_row([header, element])","for e_target in zip(headers, section.rows[0]):
    element = e_target[1]
    header = e_target[0]
    new_section.add_row([header, element])

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/test_table.py', 'tests.unit.test_table', 'TestVerticalTableConversion', 'test_convert_section_to_vertical']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/compat.py,TestIgnoreUserSignals,test_ignore_signal_sigtstp,"for (sig, user_signal) in enumerate(signal_list):
    signal.signal(user_signal, actual_signals[sig])","for e_target in enumerate(signal_list):
    user_signal = e_target[1]
    sig = e_target[0]
    signal.signal(user_signal, actual_signals[sig])

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/test_compat.py', 'tests.unit.test_compat', 'TestIgnoreUserSignals', 'test_ignore_signal_sigint'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/test_compat.py', 'tests.unit.test_compat', 'TestIgnoreUserSignals', 'test_ignore_signal_sigquit'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/test_compat.py', 'tests.unit.test_compat', 'TestIgnoreUserSignals', 'test_ignore_signal_sigtstp']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/flatten.py,TestFlattenCommands,test_flatten_modify_args,"for (name, argument) in self.configs[command.name].items():
    argument_from_table = argument_table[name]
    overwritten = False
    LOG.debug('Flattening {0} argument {1} into {2}'.format(command.name, name, ', '.join([v['name'] for (k, v) in argument['flatten'].items()])))
    for (sub_argument, new_config) in argument['flatten'].items():
        config = new_config.copy()
        config['container'] = argument_from_table
        config['prop'] = sub_argument
        _arg = self._find_nested_arg(argument_from_table.argument_model, sub_argument)
        self._merge_member_config(_arg, sub_argument, config)
        new_arg = FlattenedArgument(**config)
        argument_table[new_config['name']] = new_arg
        if name == new_config['name']:
            overwritten = True
    if not overwritten and ('keep' not in argument or not argument['keep']):
        del argument_table[name]","for e_target in self.configs[command.name].items():
    argument = e_target[1]
    name = e_target[0]
    argument_from_table = argument_table[name]
    overwritten = False
    LOG.debug('Flattening {0} argument {1} into {2}'.format(command.name, name, ', '.join([v['name'] for (k, v) in argument['flatten'].items()])))
    for (sub_argument, new_config) in argument['flatten'].items():
        config = new_config.copy()
        config['container'] = argument_from_table
        config['prop'] = sub_argument
        _arg = self._find_nested_arg(argument_from_table.argument_model, sub_argument)
        self._merge_member_config(_arg, sub_argument, config)
        new_arg = FlattenedArgument(**config)
        argument_table[new_config['name']] = new_arg
        if name == new_config['name']:
            overwritten = True
    if not overwritten and ('keep' not in argument or not argument['keep']):
        del argument_table[name]

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_flatten.py', 'tests.unit.customizations.test_flatten', 'TestFlattenCommands', 'test_flatten_modify_args']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/flatten.py,TestFlattenCommands,test_flatten_modify_args,"for (sub_argument, new_config) in argument['flatten'].items():
    config = new_config.copy()
    config['container'] = argument_from_table
    config['prop'] = sub_argument
    _arg = self._find_nested_arg(argument_from_table.argument_model, sub_argument)
    self._merge_member_config(_arg, sub_argument, config)
    new_arg = FlattenedArgument(**config)
    argument_table[new_config['name']] = new_arg
    if name == new_config['name']:
        overwritten = True","for e_target in argument['flatten'].items():
    new_config = e_target[1]
    sub_argument = e_target[0]
    config = new_config.copy()
    config['container'] = argument_from_table
    config['prop'] = sub_argument
    _arg = self._find_nested_arg(argument_from_table.argument_model, sub_argument)
    self._merge_member_config(_arg, sub_argument, config)
    new_arg = FlattenedArgument(**config)
    argument_table[new_config['name']] = new_arg
    if name == new_config['name']:
        overwritten = True

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_flatten.py', 'tests.unit.customizations.test_flatten', 'TestFlattenCommands', 'test_flatten_modify_args']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/paginate.py,TestShouldEnablePagination,test_should_enable_pagination_with_no_args,"for (key, value) in shadowed_args.items():
    argument_table[key] = value","for e_target in shadowed_args.items():
    value = e_target[1]
    key = e_target[0]
    argument_table[key] = value

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_paginate.py', 'tests.unit.customizations.test_paginate', 'TestShouldEnablePagination', 'test_default_to_pagination_on_when_ambiguous'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_paginate.py', 'tests.unit.customizations.test_paginate', 'TestShouldEnablePagination', 'test_should_not_enable_pagination'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_paginate.py', 'tests.unit.customizations.test_paginate', 'TestShouldEnablePagination', 'test_shadowed_args_are_replaced_when_pagination_set_off'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_paginate.py', 'tests.unit.customizations.test_paginate', 'TestShouldEnablePagination', 'test_shadowed_args_are_replaced_when_pagination_turned_off'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_paginate.py', 'tests.unit.customizations.test_paginate', 'TestShouldEnablePagination', 'test_fall_back_to_original_max_items_when_pagination_turned_off'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_paginate.py', 'tests.unit.customizations.test_paginate', 'TestShouldEnablePagination', 'test_should_enable_pagination_with_no_args']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/dynamodb.py,TestParseLastEvaluatedKeyBinary,test_ignores_response_without_last_evaluated_key,"for (key, val) in last_evaluated_key.items():
    if 'B' in val:
        val['B'] = base64.b64decode(val['B'])","for e_target in last_evaluated_key.items():
    val = e_target[1]
    key = e_target[0]
    if 'B' in val:
        val['B'] = base64.b64decode(val['B'])

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/test_dynamodb.py', 'tests.unit.customizations.test_dynamodb', 'TestParseLastEvaluatedKeyBinary', 'test_ignores_response_without_last_evaluated_key']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/s3/filegenerator.py,S3FileGeneratorTest,test_s3_single_file_404,"for (src_path, extra_information) in file_iterator:
    (dest_path, compare_key) = find_dest_path_comp_key(files, src_path)
    file_stat_kwargs = {'src': src_path, 'dest': dest_path, 'compare_key': compare_key, 'src_type': src_type, 'dest_type': dest_type, 'operation_name': self.operation_name}
    self._inject_extra_information(file_stat_kwargs, extra_information)
    yield FileStat(**file_stat_kwargs)","for e_target in file_iterator:
    extra_information = e_target[1]
    src_path = e_target[0]
    (dest_path, compare_key) = find_dest_path_comp_key(files, src_path)
    file_stat_kwargs = {'src': src_path, 'dest': dest_path, 'compare_key': compare_key, 'src_type': src_type, 'dest_type': dest_type, 'operation_name': self.operation_name}
    self._inject_extra_information(file_stat_kwargs, extra_information)
    yield FileStat(**file_stat_kwargs)

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/s3/test_filegenerator.py', 'tests.unit.customizations.s3.test_filegenerator', 'TestSymlinksIgnoreFiles', 'test_warn_bad_symlink'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/s3/test_filegenerator.py', 'tests.unit.customizations.s3.test_filegenerator', 'S3FileGeneratorTest', 'test_s3_file'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/s3/test_filegenerator.py', 'tests.unit.customizations.s3.test_filegenerator', 'S3FileGeneratorTest', 'test_s3_single_file_delete'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/s3/test_filegenerator.py', 'tests.unit.customizations.s3.test_filegenerator', 'S3FileGeneratorTest', 'test_s3_single_file_404']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/s3/transferconfig.py,TestConvertToS3TransferConfig,test_convert,"for (key, value) in runtime_config.items():
    if key not in translation_map:
        continue
    kwargs[translation_map[key]] = value","for e_target in runtime_config.items():
    value = e_target[1]
    key = e_target[0]
    if key not in translation_map:
        continue
    kwargs[translation_map[key]] = value

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/s3/test_transferconfig.py', 'tests.unit.customizations.s3.test_transferconfig', 'TestConvertToS3TransferConfig', 'test_convert']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/cloudformation/artifact_exporter.py,TestPackageZipFiles,test_must_follow_symlinks,"for (root, dirs, files) in os.walk(source_root, followlinks=True):
    for filename in files:
        full_path = os.path.join(root, filename)
        relative_path = os.path.relpath(full_path, source_root)
        zf.write(full_path, relative_path)","for e_target in os.walk(source_root, followlinks=True):
    files = e_target[2]
    dirs = e_target[1]
    root = e_target[0]
    for filename in files:
        full_path = os.path.join(root, filename)
        relative_path = os.path.relpath(full_path, source_root)
        zf.write(full_path, relative_path)

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/cloudformation/test_artifact_exporter.py', 'tests.unit.customizations.cloudformation.test_artifact_exporter', 'TestArtifactExporter', 'test_make_zip'], ['https://github.com/aws/aws-cli/tree/master/tests/functional/cloudformation/test_package.py', 'tests.functional.cloudformation.test_package', 'TestPackageZipFiles', 'test_must_follow_symlinks']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/cloudformation/artifact_exporter.py,TestArtifactExporter,test_template_global_export,"for (key, val) in template_dict.items():
    if key in GLOBAL_EXPORT_DICT:
        template_dict[key] = GLOBAL_EXPORT_DICT[key](val, self.uploader, self.template_dir)
    elif isinstance(val, dict):
        self.export_global_artifacts(val)
    elif isinstance(val, list):
        for item in val:
            if isinstance(item, dict):
                self.export_global_artifacts(item)","for e_target in template_dict.items():
    val = e_target[1]
    key = e_target[0]
    if key in GLOBAL_EXPORT_DICT:
        template_dict[key] = GLOBAL_EXPORT_DICT[key](val, self.uploader, self.template_dir)
    elif isinstance(val, dict):
        self.export_global_artifacts(val)
    elif isinstance(val, list):
        for item in val:
            if isinstance(item, dict):
                self.export_global_artifacts(item)

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/cloudformation/test_artifact_exporter.py', 'tests.unit.customizations.cloudformation.test_artifact_exporter', 'TestArtifactExporter', 'test_template_global_export']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/gamelift/uploadbuild.py,TestZipDirectory,test_nested_file,"for (root, dirs, files) in os.walk(source_root):
    for filename in files:
        full_path = os.path.join(root, filename)
        relative_path = os.path.relpath(full_path, source_root)
        zf.write(full_path, relative_path)","for e_target in os.walk(source_root):
    files = e_target[2]
    dirs = e_target[1]
    root = e_target[0]
    for filename in files:
        full_path = os.path.join(root, filename)
        relative_path = os.path.relpath(full_path, source_root)
        zf.write(full_path, relative_path)

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/gamelift/test_uploadbuild.py', 'tests.unit.customizations.gamelift.test_uploadbuild', 'TestZipDirectory', 'test_multiple_files'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/gamelift/test_uploadbuild.py', 'tests.unit.customizations.gamelift.test_uploadbuild', 'TestZipDirectory', 'test_single_file'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/gamelift/test_uploadbuild.py', 'tests.unit.customizations.gamelift.test_uploadbuild', 'TestZipDirectory', 'test_nested_file']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/datapipeline/translator.py,TestTranslatePipelineDefinitions,test_list_value_with_strings,"for (key, value) in sorted(element.items()):
    fields.extend(_parse_each_field(key, value))","for e_target in sorted(element.items()):
    value = e_target[1]
    key = e_target[0]
    fields.extend(_parse_each_field(key, value))

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/datapipeline/test_translator.py', 'tests.unit.customizations.datapipeline.test_translator', 'TestTranslatePipelineDefinitions', 'test_objects_key_is_missing_raise_error'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/datapipeline/test_translator.py', 'tests.unit.customizations.datapipeline.test_translator', 'TestTranslatePipelineDefinitions', 'test_convert_df_to_api_with_name'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/datapipeline/test_translator.py', 'tests.unit.customizations.datapipeline.test_translator', 'TestTranslatePipelineDefinitions', 'test_value_with_refs'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/datapipeline/test_translator.py', 'tests.unit.customizations.datapipeline.test_translator', 'TestTranslatePipelineDefinitions', 'test_missing_id_field'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/datapipeline/test_translator.py', 'tests.unit.customizations.datapipeline.test_translator', 'TestTranslatePipelineDefinitions', 'test_convert_schedule_df_to_api'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/datapipeline/test_translator.py', 'tests.unit.customizations.datapipeline.test_translator', 'TestTranslatePipelineDefinitions', 'test_convert_df_to_api_schedule'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/customizations/datapipeline/test_translator.py', 'tests.unit.customizations.datapipeline.test_translator', 'TestTranslatePipelineDefinitions', 'test_list_value_with_strings']]"
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/bcdoc/restdoc.py,TestReSTDocument,test_remove_doc_string,"for (refname, link) in self.hrefs.items():
    self.style.link_target_definition(refname, link)","for e_target in self.hrefs.items():
    link = e_target[1]
    refname = e_target[0]
    self.style.link_target_definition(refname, link)

",1,"[['https://github.com/aws/aws-cli/tree/master/tests/unit/bcdoc/test_document.py', 'tests.unit.bcdoc.test_document', 'TestReSTDocument', 'test_add_links'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/bcdoc/test_document.py', 'tests.unit.bcdoc.test_document', 'TestReSTDocument', 'test_include_doc_string'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/bcdoc/test_document.py', 'tests.unit.bcdoc.test_document', 'TestReSTDocument', 'test_write'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/bcdoc/test_document.py', 'tests.unit.bcdoc.test_document', 'TestReSTDocument', 'test_writeln'], ['https://github.com/aws/aws-cli/tree/master/tests/unit/bcdoc/test_document.py', 'tests.unit.bcdoc.test_document', 'TestReSTDocument', 'test_remove_doc_string']]"
client_python,https://github.com/prometheus/client_python/tree/master/prometheus_client/exposition.py,TestGenerateText,test_timestamp,"for (suffix, lines) in sorted(om_samples.items()):
    output.append('# HELP {}{} {}\n'.format(metric.name, suffix, metric.documentation.replace('\\', '\\\\').replace('\n', '\\n')))
    output.append(f'# TYPE {metric.name}{suffix} gauge\n')
    output.extend(lines)","for e_target in sorted(om_samples.items()):
    lines = e_target[1]
    suffix = e_target[0]
    output.append('# HELP {}{} {}\n'.format(metric.name, suffix, metric.documentation.replace('\\', '\\\\').replace('\n', '\\n')))
    output.append(f'# TYPE {metric.name}{suffix} gauge\n')
    output.extend(lines)

",1,"[['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_nonnumber'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_counter_total'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_counter'], ['https://github.com/prometheus/client_python/tree/master/tests/test_parser.py', 'tests.test_parser', 'TestParse', 'test_roundtrip'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_summary'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_gaugehistogram'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_enum'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_unicode'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_histogram'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_info'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_gauge'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_counter_name_unit_append'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_escaping'], ['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_timestamp']]"
client_python,https://github.com/prometheus/client_python/tree/master/prometheus_client/metrics.py,TestGenerateText,test_histogram,"for (i, bound) in enumerate(self._upper_bounds):
    if amount <= bound:
        self._buckets[i].inc(1)
        if exemplar:
            _validate_exemplar(exemplar)
            self._buckets[i].set_exemplar(Exemplar(exemplar, amount, time.time()))
        break","for e_target in enumerate(self._upper_bounds):
    bound = e_target[1]
    i = e_target[0]
    if amount <= bound:
        self._buckets[i].inc(1)
        if exemplar:
            _validate_exemplar(exemplar)
            self._buckets[i].set_exemplar(Exemplar(exemplar, amount, time.time()))
        break

",1,"[['https://github.com/prometheus/client_python/tree/master/tests/test_exposition.py', 'tests.test_exposition', 'TestGenerateText', 'test_histogram'], ['https://github.com/prometheus/client_python/tree/master/tests/openmetrics/test_exposition.py', 'tests.openmetrics.test_exposition', 'TestGenerateText', 'test_histogram_negative_buckets'], ['https://github.com/prometheus/client_python/tree/master/tests/openmetrics/test_exposition.py', 'tests.openmetrics.test_exposition', 'TestGenerateText', 'test_histogram_exemplar'], ['https://github.com/prometheus/client_python/tree/master/tests/openmetrics/test_exposition.py', 'tests.openmetrics.test_exposition', 'TestGenerateText', 'test_histogram']]"
i3pystatus,https://github.com/enkore/i3pystatus/tree/master/i3pystatus/core/util.py,FormatPTests,test_nesting,"for (fieldspec, fieldname) in fields:
    if kwargs.get(fieldname, False):
        successful_fields += 1","for e_target in fields:
    fieldname = e_target[1]
    fieldspec = e_target[0]
    if kwargs.get(fieldname, False):
        successful_fields += 1

",1,"[['https://github.com/enkore/i3pystatus/tree/master/tests/test_core_util.py', 'tests.test_core_util', 'FormatPTests', 'test_bare'], ['https://github.com/enkore/i3pystatus/tree/master/tests/test_core_util.py', 'tests.test_core_util', 'FormatPTests', 'test_side_by_side'], ['https://github.com/enkore/i3pystatus/tree/master/tests/test_core_util.py', 'tests.test_core_util', 'FormatPTests', 'test_escaping'], ['https://github.com/enkore/i3pystatus/tree/master/tests/test_core_util.py', 'tests.test_core_util', 'FormatPTests', 'test_numerical'], ['https://github.com/enkore/i3pystatus/tree/master/tests/test_core_util.py', 'tests.test_core_util', 'FormatPTests', 'test_presuffix'], ['https://github.com/enkore/i3pystatus/tree/master/tests/test_core_util.py', 'tests.test_core_util', 'FormatPTests', 'test_complex_field'], ['https://github.com/enkore/i3pystatus/tree/master/tests/test_core_util.py', 'tests.test_core_util', 'FormatPTests', 'test_nesting']]"
cli,https://github.com/terraform-compliance/cli/tree/master/terraform_compliance/extensions/terraform.py,TestTerraformParser,test_remember_after_unknown,"for (key, value) in after_unknown.items():
    if key not in self.type_to_after_unknown_properties[resource_type]:
        self.type_to_after_unknown_properties[resource_type][key] = value","for e_target in after_unknown.items():
    value = e_target[1]
    key = e_target[0]
    if key not in self.type_to_after_unknown_properties[resource_type]:
        self.type_to_after_unknown_properties[resource_type][key] = value

",1,"[['https://github.com/terraform-compliance/cli/tree/master/tests/terraform_compliance/extensions/test_terraform.py', 'tests.terraform_compliance.extensions.test_terraform', 'TestTerraformParser', 'test_remember_after_unknown_simple'], ['https://github.com/terraform-compliance/cli/tree/master/tests/terraform_compliance/extensions/test_terraform.py', 'tests.terraform_compliance.extensions.test_terraform', 'TestTerraformParser', 'test_remember_after_unknown']]"
cli,https://github.com/terraform-compliance/cli/tree/master/terraform_compliance/common/helper.py,TestHelperFunctions,test_seek_in_dict_finding_a_key_in_root,"for (key, value) in haystack.items():
    if key.lower() == needle.lower():
        found.append({key: value})
    else:
        found.extend(seek_key_in_dict(value, needle))","for e_target in haystack.items():
    value = e_target[1]
    key = e_target[0]
    if key.lower() == needle.lower():
        found.append({key: value})
    else:
        found.extend(seek_key_in_dict(value, needle))

",1,"[['https://github.com/terraform-compliance/cli/tree/master/tests/terraform_compliance/common/test_helper.py', 'tests.terraform_compliance.common.test_helper', 'TestHelperFunctions', 'test_seek_in_dict_finding_a_key_in_nested_dict'], ['https://github.com/terraform-compliance/cli/tree/master/tests/terraform_compliance/common/test_helper.py', 'tests.terraform_compliance.common.test_helper', 'TestHelperFunctions', 'test_seek_in_dict_finding_multiple_keys_in_nested_dict'], ['https://github.com/terraform-compliance/cli/tree/master/tests/terraform_compliance/common/test_helper.py', 'tests.terraform_compliance.common.test_helper', 'TestHelperFunctions', 'test_seek_in_dict_finding_values_in_non_dicts'], ['https://github.com/terraform-compliance/cli/tree/master/tests/terraform_compliance/common/test_helper.py', 'tests.terraform_compliance.common.test_helper', 'TestHelperFunctions', 'test_seek_in_dict_for_root_and_non_root_values'], ['https://github.com/terraform-compliance/cli/tree/master/tests/terraform_compliance/common/test_helper.py', 'tests.terraform_compliance.common.test_helper', 'TestHelperFunctions', 'test_seek_in_dict_finding_values_in_non_dicts_on_root'], ['https://github.com/terraform-compliance/cli/tree/master/tests/terraform_compliance/common/test_helper.py', 'tests.terraform_compliance.common.test_helper', 'TestHelperFunctions', 'test_seek_in_dict_finding_a_key_in_root']]"
uvicorn,https://github.com/encode/uvicorn/tree/master/uvicorn/middleware/wsgi.py,,test_build_environ_encoding,"for (name, value) in scope.get('headers', []):
    name_str: str = name.decode('latin1')
    if name_str == 'content-length':
        corrected_name = 'CONTENT_LENGTH'
    elif name_str == 'content-type':
        corrected_name = 'CONTENT_TYPE'
    else:
        corrected_name = 'HTTP_%s' % name_str.upper().replace('-', '_')
    value_str: str = value.decode('latin1')
    if corrected_name in environ:
        corrected_name_environ = environ[corrected_name]
        assert isinstance(corrected_name_environ, str)
        value_str = corrected_name_environ + ',' + value_str
    environ[corrected_name] = value_str","for e_target in scope.get('headers', []):
    value = e_target[1]
    name = e_target[0]
    name_str: str = name.decode('latin1')
    if name_str == 'content-length':
        corrected_name = 'CONTENT_LENGTH'
    elif name_str == 'content-type':
        corrected_name = 'CONTENT_TYPE'
    else:
        corrected_name = 'HTTP_%s' % name_str.upper().replace('-', '_')
    value_str: str = value.decode('latin1')
    if corrected_name in environ:
        corrected_name_environ = environ[corrected_name]
        assert isinstance(corrected_name_environ, str)
        value_str = corrected_name_environ + ',' + value_str
    environ[corrected_name] = value_str

",1,"[['https://github.com/encode/uvicorn/tree/master/tests/middleware/test_wsgi.py', 'tests.middleware.test_wsgi', '', 'test_build_environ_encoding']]"
funcy,https://github.com/Suor/funcy/tree/master/funcy/colls.py,,test_join_with,"for (k, v) in iteritems(c):
    if k in lists:
        lists[k].append(v)
    else:
        lists[k] = [v]","for e_target in iteritems(c):
    v = e_target[1]
    k = e_target[0]
    if k in lists:
        lists[k].append(v)
    else:
        lists[k] = [v]

",1,"[['https://github.com/Suor/funcy/tree/master/tests/test_colls.py', 'tests.test_colls', '', 'test_join_with']]"
funcy,https://github.com/Suor/funcy/tree/master/funcy/colls.py,,test_join_with,"for (k, v) in iteritems(lists):
    lists[k] = f(v)","for e_target in iteritems(lists):
    v = e_target[1]
    k = e_target[0]
    lists[k] = f(v)

",1,"[['https://github.com/Suor/funcy/tree/master/tests/test_colls.py', 'tests.test_colls', '', 'test_join_with']]"
funcy,https://github.com/Suor/funcy/tree/master/funcy/seqs.py,,test_group_values,"for (key, value) in seq:
    result[key].append(value)","for e_target in seq:
    value = e_target[1]
    key = e_target[0]
    result[key].append(value)

",1,"[['https://github.com/Suor/funcy/tree/master/tests/test_seqs.py', 'tests.test_seqs', '', 'test_group_values']]"
funcy,https://github.com/Suor/funcy/tree/master/funcy/debug.py,,test_log_iter_dirations,"for (i, item) in enumerate(it):
    start = time.time()
    yield item
    duration = _format_time(time.time() - start)
    print_func('%s in iteration %d%s' % (duration, i, suffix))","for e_target in enumerate(it):
    item = e_target[1]
    i = e_target[0]
    start = time.time()
    yield item
    duration = _format_time(time.time() - start)
    print_func('%s in iteration %d%s' % (duration, i, suffix))

",1,"[['https://github.com/Suor/funcy/tree/master/tests/test_debug.py', 'tests.test_debug', '', 'test_log_iter_dirations']]"
micropython-lib,https://github.com/micropython/micropython-lib/tree/master/python-stdlib/urllib.parse/urllib/parse.py,UrlParseTestCase,test_urlencode_sequences,"for (k, v) in query:
    if isinstance(k, bytes):
        k = quote_plus(k, safe)
    else:
        k = quote_plus(str(k), safe, encoding, errors)
    if isinstance(v, bytes):
        v = quote_plus(v, safe)
    else:
        v = quote_plus(str(v), safe, encoding, errors)
    l.append(k + '=' + v)","for e_target in query:
    v = e_target[1]
    k = e_target[0]
    if isinstance(k, bytes):
        k = quote_plus(k, safe)
    else:
        k = quote_plus(str(k), safe, encoding, errors)
    if isinstance(v, bytes):
        v = quote_plus(v, safe)
    else:
        v = quote_plus(str(v), safe, encoding, errors)
    l.append(k + '=' + v)

",1,"[['https://github.com/micropython/micropython-lib/tree/master/python-stdlib/urllib.parse/test_urlparse.py', 'python-stdlib.urllib.parse.test_urlparse', 'UrlParseTestCase', 'test_urlencode_sequences']]"
micropython-lib,https://github.com/micropython/micropython-lib/tree/master/python-stdlib/urllib.parse/urllib/parse.py,UrlParseTestCase,test_urlencode_sequences,"for (k, v) in query:
    if isinstance(k, bytes):
        k = quote_plus(k, safe)
    else:
        k = quote_plus(str(k), safe, encoding, errors)
    if isinstance(v, bytes):
        v = quote_plus(v, safe)
        l.append(k + '=' + v)
    elif isinstance(v, str):
        v = quote_plus(v, safe, encoding, errors)
        l.append(k + '=' + v)
    else:
        try:
            x = len(v)
        except TypeError:
            v = quote_plus(str(v), safe, encoding, errors)
            l.append(k + '=' + v)
        else:
            for elt in v:
                if isinstance(elt, bytes):
                    elt = quote_plus(elt, safe)
                else:
                    elt = quote_plus(str(elt), safe, encoding, errors)
                l.append(k + '=' + elt)","for e_target in query:
    v = e_target[1]
    k = e_target[0]
    if isinstance(k, bytes):
        k = quote_plus(k, safe)
    else:
        k = quote_plus(str(k), safe, encoding, errors)
    if isinstance(v, bytes):
        v = quote_plus(v, safe)
        l.append(k + '=' + v)
    elif isinstance(v, str):
        v = quote_plus(v, safe, encoding, errors)
        l.append(k + '=' + v)
    else:
        try:
            x = len(v)
        except TypeError:
            v = quote_plus(str(v), safe, encoding, errors)
            l.append(k + '=' + v)
        else:
            for elt in v:
                if isinstance(elt, bytes):
                    elt = quote_plus(elt, safe)
                else:
                    elt = quote_plus(str(elt), safe, encoding, errors)
                l.append(k + '=' + elt)

",1,"[['https://github.com/micropython/micropython-lib/tree/master/python-stdlib/urllib.parse/test_urlparse.py', 'python-stdlib.urllib.parse.test_urlparse', 'UrlParseTestCase', 'test_urlencode_sequences']]"
python-inquirer,https://github.com/magmax/python-inquirer/tree/master/inquirer/themes.py,ThemeTests,test_invalid_question_field,"for (question_type, settings) in dict_theme.items():
    if question_type not in vars(t):
        raise ThemeError('Error while parsing theme. Question type `{}` not found or not customizable.'.format(question_type))
    question_fields = list(filter(lambda x: not x.startswith('_'), vars(getattr(t, question_type))))
    for (field, value) in settings.items():
        if field not in question_fields:
            raise ThemeError('Error while parsing theme. Field `{}` invalid for question type `{}`'.format(field, question_type))
        actual_value = getattr(term, value) or value
        setattr(getattr(t, question_type), field, actual_value)","for e_target in dict_theme.items():
    settings = e_target[1]
    question_type = e_target[0]
    if question_type not in vars(t):
        raise ThemeError('Error while parsing theme. Question type `{}` not found or not customizable.'.format(question_type))
    question_fields = list(filter(lambda x: not x.startswith('_'), vars(getattr(t, question_type))))
    for (field, value) in settings.items():
        if field not in question_fields:
            raise ThemeError('Error while parsing theme. Field `{}` invalid for question type `{}`'.format(field, question_type))
        actual_value = getattr(term, value) or value
        setattr(getattr(t, question_type), field, actual_value)

",1,"[['https://github.com/magmax/python-inquirer/tree/master/tests/unit/test_theme.py', 'tests.unit.test_theme', 'ThemeTests', 'test_load_from_dict'], ['https://github.com/magmax/python-inquirer/tree/master/tests/unit/test_theme.py', 'tests.unit.test_theme', 'ThemeTests', 'test_invalid_question'], ['https://github.com/magmax/python-inquirer/tree/master/tests/unit/test_theme.py', 'tests.unit.test_theme', 'ThemeTests', 'test_invalid_question_field']]"
python-inquirer,https://github.com/magmax/python-inquirer/tree/master/inquirer/themes.py,ThemeTests,test_invalid_question_field,"for (field, value) in settings.items():
    if field not in question_fields:
        raise ThemeError('Error while parsing theme. Field `{}` invalid for question type `{}`'.format(field, question_type))
    actual_value = getattr(term, value) or value
    setattr(getattr(t, question_type), field, actual_value)","for e_target in settings.items():
    value = e_target[1]
    field = e_target[0]
    if field not in question_fields:
        raise ThemeError('Error while parsing theme. Field `{}` invalid for question type `{}`'.format(field, question_type))
    actual_value = getattr(term, value) or value
    setattr(getattr(t, question_type), field, actual_value)

",1,"[['https://github.com/magmax/python-inquirer/tree/master/tests/unit/test_theme.py', 'tests.unit.test_theme', 'ThemeTests', 'test_load_from_dict'], ['https://github.com/magmax/python-inquirer/tree/master/tests/unit/test_theme.py', 'tests.unit.test_theme', 'ThemeTests', 'test_invalid_question'], ['https://github.com/magmax/python-inquirer/tree/master/tests/unit/test_theme.py', 'tests.unit.test_theme', 'ThemeTests', 'test_invalid_question_field']]"
blockade,https://github.com/worstcase/blockade/tree/master/blockade/config.py,ConfigTests,test_parse_with_volumes_3,"for (name, container_dict) in containers.items():
    try:
        for cnt in BlockadeContainerConfig.from_dict(name, container_dict):
            if cnt.container_name:
                cname = cnt.container_name
                existing = [c for c in parsed_containers.values() if c.container_name == cname]
                if existing:
                    raise BlockadeConfigError(""Duplicate 'container_name' definition: %s"" % cname)
            parsed_containers[cnt.name] = cnt
    except Exception as err:
        raise BlockadeConfigError(""Container '%s' config problem: %s"" % (name, err))","for e_target in containers.items():
    container_dict = e_target[1]
    name = e_target[0]
    try:
        for cnt in BlockadeContainerConfig.from_dict(name, container_dict):
            if cnt.container_name:
                cname = cnt.container_name
                existing = [c for c in parsed_containers.values() if c.container_name == cname]
                if existing:
                    raise BlockadeConfigError(""Duplicate 'container_name' definition: %s"" % cname)
            parsed_containers[cnt.name] = cnt
    except Exception as err:
        raise BlockadeConfigError(""Container '%s' config problem: %s"" % (name, err))

",1,"[['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_multiple_cap_add'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_fail_1'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_env_1'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_start_delay_2'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_1'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_start_delay_fail_negative'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_start_delay_fail_nonnumeric'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_numeric_port'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_count_1'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_volumes_2'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_fail_2'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_cap_add'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_volumes_4'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_publish_1'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_start_delay_1'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_volumes_1'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_name'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_2'], ['https://github.com/worstcase/blockade/tree/master/blockade/tests/test_config.py', 'blockade.tests.test_config', 'ConfigTests', 'test_parse_with_volumes_3']]"
bottle,https://github.com/bottlepy/bottle/tree/master//bottle.py,TestSendFile,test_range_parser,"for (start, end) in ranges:
    try:
        if not start:
            (start, end) = (max(0, maxlen - int(end)), maxlen)
        elif not end:
            (start, end) = (int(start), maxlen)
        else:
            (start, end) = (int(start), min(int(end) + 1, maxlen))
        if 0 <= start < end <= maxlen:
            yield (start, end)
    except ValueError:
        pass","for e_target in ranges:
    end = e_target[1]
    start = e_target[0]
    try:
        if not start:
            (start, end) = (max(0, maxlen - int(end)), maxlen)
        elif not end:
            (start, end) = (int(start), maxlen)
        else:
            (start, end) = (int(start), min(int(end) + 1, maxlen))
        if 0 <= start < end <= maxlen:
            yield (start, end)
    except ValueError:
        pass

",1,"[['https://github.com/bottlepy/bottle/tree/master/test/test_sendfile.py', 'test.test_sendfile', 'TestSendFile', 'test_range_parser']]"
bottle,https://github.com/bottlepy/bottle/tree/master//bottle.py,TestResponse,test_clone_cookie,"for (k, v) in self._cookies.items():
    cookies[k] = v.value
    cookies[k].update(v)","for e_target in self._cookies.items():
    v = e_target[1]
    k = e_target[0]
    cookies[k] = v.value
    cookies[k].update(v)

",1,"[['https://github.com/bottlepy/bottle/tree/master/test/test_environ.py', 'test.test_environ', 'TestResponse', 'test_clone_cookie']]"
bottle,https://github.com/bottlepy/bottle/tree/master//bottle.py,TestConfDict,test_string_save_keys,"for (key, value) in source.items():
    if isinstance(key, basestring):
        nskey = (namespace + '.' + key).strip('.')
        if isinstance(value, dict):
            self.load_dict(value, namespace=nskey)
        else:
            self[nskey] = value
    else:
        raise TypeError('Key has type %r (not a string)' % type(key))","for e_target in source.items():
    value = e_target[1]
    key = e_target[0]
    if isinstance(key, basestring):
        nskey = (namespace + '.' + key).strip('.')
        if isinstance(value, dict):
            self.load_dict(value, namespace=nskey)
        else:
            self[nskey] = value
    else:
        raise TypeError('Key has type %r (not a string)' % type(key))

",1,"[['https://github.com/bottlepy/bottle/tree/master/test/test_config.py', 'test.test_config', 'TestConfDict', 'test_load_dict'], ['https://github.com/bottlepy/bottle/tree/master/test/test_config.py', 'test.test_config', 'TestConfDict', 'test_string_save_keys']]"
bottle,https://github.com/bottlepy/bottle/tree/master/test/tools.py,TestRequest,test_multipart,"for (name, value) in fields:
    body += boundary + '\n'
    body += 'Content-Disposition: form-data; name=""%s""\n\n' % name
    body += value + '\n'","for e_target in fields:
    value = e_target[1]
    name = e_target[0]
    body += boundary + '\n'
    body += 'Content-Disposition: form-data; name=""%s""\n\n' % name
    body += value + '\n'

",1,"[['https://github.com/bottlepy/bottle/tree/master/test/test_environ.py', 'test.test_environ', 'TestRequest', 'test_multipart']]"
bottle,https://github.com/bottlepy/bottle/tree/master/test/tools.py,TestRequest,test_multipart,"for (name, filename, content) in files:
    mimetype = str(mimetypes.guess_type(filename)[0]) or 'application/octet-stream'
    body += boundary + '\n'
    body += 'Content-Disposition: file; name=""%s""; filename=""%s""\n' % (name, filename)
    body += 'Content-Type: %s\n\n' % mimetype
    body += content + '\n'","for e_target in files:
    content = e_target[2]
    filename = e_target[1]
    name = e_target[0]
    mimetype = str(mimetypes.guess_type(filename)[0]) or 'application/octet-stream'
    body += boundary + '\n'
    body += 'Content-Disposition: file; name=""%s""; filename=""%s""\n' % (name, filename)
    body += 'Content-Type: %s\n\n' % mimetype
    body += content + '\n'

",1,"[['https://github.com/bottlepy/bottle/tree/master/test/test_environ.py', 'test.test_environ', 'TestRequest', 'test_multipart']]"
pyexcel,https://github.com/pyexcel/pyexcel/tree/master/pyexcel/core.py,,test_issue_95_preserve_order_in_iget_orders,"for (row_index, row) in enumerate(sheet_stream.payload):
    if row_index == 0:
        headers = row
    elif custom_headers:
        tmp_dict = dict(zip_longest(headers, row, fillvalue=constants.DEFAULT_NA))
        ordered_dict = OrderedDict()
        for name in custom_headers:
            ordered_dict[name] = tmp_dict[name]
        yield ordered_dict
    else:
        yield OrderedDict(zip_longest(headers, row, fillvalue=constants.DEFAULT_NA))","for e_target in enumerate(sheet_stream.payload):
    row = e_target[1]
    row_index = e_target[0]
    if row_index == 0:
        headers = row
    elif custom_headers:
        tmp_dict = dict(zip_longest(headers, row, fillvalue=constants.DEFAULT_NA))
        ordered_dict = OrderedDict()
        for name in custom_headers:
            ordered_dict[name] = tmp_dict[name]
        yield ordered_dict
    else:
        yield OrderedDict(zip_longest(headers, row, fillvalue=constants.DEFAULT_NA))

",1,"[['https://github.com/pyexcel/pyexcel/tree/master/tests/test_bug_fixes.py', 'tests.test_bug_fixes', '', 'test_issue_95_preserve_custom_order_in_iget_orders'], ['https://github.com/pyexcel/pyexcel/tree/master/tests/test_bug_fixes.py', 'tests.test_bug_fixes', '', 'test_issue_95_preserve_order_in_iget_orders']]"
pygorithm,https://github.com/OmkarPathak/pygorithm/tree/master/pygorithm/data_structures/trie.py,TestTrie,test_stack,"for (i, c) in enumerate(word):
    last = False
    if i == l - 1:
        last = True
    if c not in curr.children:
        curr.children[c] = Node(c, curr, last)
    elif last:
        curr.children[c].word = True
    curr = curr.children[c]","for e_target in enumerate(word):
    c = e_target[1]
    i = e_target[0]
    last = False
    if i == l - 1:
        last = True
    if c not in curr.children:
        curr.children[c] = Node(c, curr, last)
    elif last:
        curr.children[c].word = True
    curr = curr.children[c]

",1,"[['https://github.com/OmkarPathak/pygorithm/tree/master/tests/test_data_structure.py', 'tests.test_data_structure', 'TestTrie', 'test_stack']]"
pygorithm,https://github.com/OmkarPathak/pygorithm/tree/master/pygorithm/data_structures/graph.py,TestKruskal,test_minimum_spanning_tree_2,"for (u, v) in self.graph:
    (u_set, v_set) = (self._set_of(u), self._set_of(v))
    if u_set != v_set:
        self._union(u_set, v_set)
        edges_explored.append(((u, v), self.graph[u, v]))","for e_target in self.graph:
    v = e_target[1]
    u = e_target[0]
    (u_set, v_set) = (self._set_of(u), self._set_of(v))
    if u_set != v_set:
        self._union(u_set, v_set)
        edges_explored.append(((u, v), self.graph[u, v]))

",1,"[['https://github.com/OmkarPathak/pygorithm/tree/master/tests/test_data_structure.py', 'tests.test_data_structure', 'TestKruskal', 'test_minimum_spanning_tree'], ['https://github.com/OmkarPathak/pygorithm/tree/master/tests/test_data_structure.py', 'tests.test_data_structure', 'TestKruskal', 'test_minimum_spanning_tree_2']]"
pygorithm,https://github.com/OmkarPathak/pygorithm/tree/master/pygorithm/binary/base16.py,TestBase16,test_base16_to_base10,"for (i, v) in enumerate(hex_char_list):
    if visualize:
        print('{} -> {} || {} * (16 ^ {}) = {}'.format(v, str(HEX_LETTER_VALUES[v]), str(HEX_LETTER_VALUES[v]), str(i), str(HEX_LETTER_VALUES[v] * pow(16, i))))
    value += HEX_LETTER_VALUES[v] * pow(16, i)","for e_target in enumerate(hex_char_list):
    v = e_target[1]
    i = e_target[0]
    if visualize:
        print('{} -> {} || {} * (16 ^ {}) = {}'.format(v, str(HEX_LETTER_VALUES[v]), str(HEX_LETTER_VALUES[v]), str(i), str(HEX_LETTER_VALUES[v] * pow(16, i))))
    value += HEX_LETTER_VALUES[v] * pow(16, i)

",1,"[['https://github.com/OmkarPathak/pygorithm/tree/master/tests/test_binary.py', 'tests.test_binary', 'TestBase16', 'test_base16_to_base10']]"
stravalib,https://github.com/hozn/stravalib/tree/master/stravalib/attributes.py,EntityAttributeTest,test_unmarshal_non_ascii_chars,"for (k, v) in value.items():
    if not hasattr(o.__class__, k):
        self.log.warning('Unable to set attribute {0} on entity {1!r}'.format(k, o))
    else:
        setattr(o, k, v)","for e_target in value.items():
    v = e_target[1]
    k = e_target[0]
    if not hasattr(o.__class__, k):
        self.log.warning('Unable to set attribute {0} on entity {1!r}'.format(k, o))
    else:
        setattr(o, k, v)

",1,"[['https://github.com/hozn/stravalib/tree/master/stravalib/tests/unit/test_attributes.py', 'stravalib.tests.unit.test_attributes', 'EntityAttributeTest', 'test_unmarshal_non_ascii_chars']]"
carbonate,https://github.com/graphite-project/carbonate/tree/master/carbonate/list.py,ListTest,test_list_with_trailing_slash_withsym,"for (root, _, filenames) in walk(storage_dir, followlinks=follow_sym_links):
    for filename in filenames:
        if metric_regex.match(filename):
            root_path = root[len(storage_dir) + 1:]
            m_path = os.path.join(root_path, filename)
            (m_name, m_ext) = os.path.splitext(m_path)
            m_name = m_name.replace('/', '.')
            yield m_name","for e_target in walk(storage_dir, followlinks=follow_sym_links):
    filenames = e_target[2]
    _ = e_target[1]
    root = e_target[0]
    for filename in filenames:
        if metric_regex.match(filename):
            root_path = root[len(storage_dir) + 1:]
            m_path = os.path.join(root_path, filename)
            (m_name, m_ext) = os.path.splitext(m_path)
            m_name = m_name.replace('/', '.')
            yield m_name

",1,"[['https://github.com/graphite-project/carbonate/tree/master/tests/test_list.py', 'tests.test_list', 'ListTest', 'test_list_with_trailing_slash'], ['https://github.com/graphite-project/carbonate/tree/master/tests/test_list.py', 'tests.test_list', 'ListTest', 'test_list'], ['https://github.com/graphite-project/carbonate/tree/master/tests/test_list.py', 'tests.test_list', 'ListTest', 'test_list_withsym'], ['https://github.com/graphite-project/carbonate/tree/master/tests/test_list.py', 'tests.test_list', 'ListTest', 'test_list_with_trailing_slash_withsym']]"
sentry-python,https://github.com/getsentry/sentry-python/tree/master/sentry_sdk/utils.py,,test_abs_path,"for (exc_type, exc_value, tb) in walk_exception_chain(exc_info):
    rv.append(single_exception_from_error_tuple(exc_type, exc_value, tb, client_options, mechanism))","for e_target in walk_exception_chain(exc_info):
    tb = e_target[2]
    exc_value = e_target[1]
    exc_type = e_target[0]
    rv.append(single_exception_from_error_tuple(exc_type, exc_value, tb, client_options, mechanism))

",1,"[['https://github.com/getsentry/sentry-python/tree/master/tests/utils/test_general.py', 'tests.utils.test_general', '', 'test_abs_path']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/cli.py,MyTests,test_cli_about_jc,"for (k, v) in parser_entry.items():
    if not k.startswith('__'):
        info_dict[k] = v","for e_target in parser_entry.items():
    v = e_target[1]
    k = e_target[0]
    if not k.startswith('__'):
        info_dict[k] = v

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_cli.py', 'tests.test_cli', 'MyTests', 'test_cli_about_jc']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/hosts.py,MyTests,test_hosts_nodata,"for (i, item) in enumerate(hosts_list):
    if '#' in item:
        comment_found = True
        comment_item = i
        break","for e_target in enumerate(hosts_list):
    item = e_target[1]
    i = e_target[0]
    if '#' in item:
        comment_found = True
        comment_item = i
        break

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_hosts.py', 'tests.test_hosts', 'MyTests', 'test_hosts_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_hosts.py', 'tests.test_hosts', 'MyTests', 'test_hosts_ubuntu_18_4'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_hosts.py', 'tests.test_hosts', 'MyTests', 'test_hosts_nodata']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/pip_list.py,MyTests,test_pip_list_legacy_ubuntu_18_4,"for (i, line) in reversed(list(enumerate(cleandata))):
    if '---' in line:
        cleandata.pop(i)","for e_target in reversed(list(enumerate(cleandata))):
    line = e_target[1]
    i = e_target[0]
    if '---' in line:
        cleandata.pop(i)

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_pip_list.py', 'tests.test_pip_list', 'MyTests', 'test_pip_list_nodata'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_pip_list.py', 'tests.test_pip_list', 'MyTests', 'test_pip_list_ubuntu_18_4'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_pip_list.py', 'tests.test_pip_list', 'MyTests', 'test_pip_list_osx_10_14_6'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_pip_list.py', 'tests.test_pip_list', 'MyTests', 'test_pip_list_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_pip_list.py', 'tests.test_pip_list', 'MyTests', 'test_pip_list_osx_10_11_6'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_pip_list.py', 'tests.test_pip_list', 'MyTests', 'test_pip_list_legacy_ubuntu_18_4']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/crontab.py,MyTests,test_crontab_nodata,"for (i, line) in reversed(list(enumerate(cleandata))):
    if line.strip().startswith('#'):
        cleandata.pop(i)","for e_target in reversed(list(enumerate(cleandata))):
    line = e_target[1]
    i = e_target[0]
    if line.strip().startswith('#'):
        cleandata.pop(i)

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab.py', 'tests.test_crontab', 'MyTests', 'test_crontab_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab.py', 'tests.test_crontab', 'MyTests', 'test_crontab_nodata']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/crontab.py,MyTests,test_crontab_nodata,"for (i, line) in reversed(list(enumerate(cleandata))):
    if '=' in line and (not line.strip()[0].isdigit()) and (not line.strip()[0] == '@'):
        var_line = cleandata.pop(i)
        var_name = var_line.split('=', maxsplit=1)[0].strip()
        var_value = var_line.split('=', maxsplit=1)[1].strip()
        cron_var.append({'name': var_name, 'value': var_value})","for e_target in reversed(list(enumerate(cleandata))):
    line = e_target[1]
    i = e_target[0]
    if '=' in line and (not line.strip()[0].isdigit()) and (not line.strip()[0] == '@'):
        var_line = cleandata.pop(i)
        var_name = var_line.split('=', maxsplit=1)[0].strip()
        var_value = var_line.split('=', maxsplit=1)[1].strip()
        cron_var.append({'name': var_name, 'value': var_value})

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab.py', 'tests.test_crontab', 'MyTests', 'test_crontab_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab.py', 'tests.test_crontab', 'MyTests', 'test_crontab_nodata']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/crontab.py,MyTests,test_crontab_nodata,"for (i, line) in reversed(list(enumerate(cleandata))):
    if line.strip().startswith('@'):
        shortcut_line = cleandata.pop(i)
        occurrence = shortcut_line.split(maxsplit=1)[0].strip().lstrip('@')
        cmd = shortcut_line.split(maxsplit=1)[1].strip()
        shortcut_list.append({'occurrence': occurrence, 'command': cmd})","for e_target in reversed(list(enumerate(cleandata))):
    line = e_target[1]
    i = e_target[0]
    if line.strip().startswith('@'):
        shortcut_line = cleandata.pop(i)
        occurrence = shortcut_line.split(maxsplit=1)[0].strip().lstrip('@')
        cmd = shortcut_line.split(maxsplit=1)[1].strip()
        shortcut_list.append({'occurrence': occurrence, 'command': cmd})

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab.py', 'tests.test_crontab', 'MyTests', 'test_crontab_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab.py', 'tests.test_crontab', 'MyTests', 'test_crontab_nodata']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/crontab_u.py,MyTests,test_crontab_u_debian10,"for (i, line) in reversed(list(enumerate(cleandata))):
    if line.strip().startswith('#'):
        cleandata.pop(i)","for e_target in reversed(list(enumerate(cleandata))):
    line = e_target[1]
    i = e_target[0]
    if line.strip().startswith('#'):
        cleandata.pop(i)

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_nodata'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_ubuntu_18_4'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_debian10']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/crontab_u.py,MyTests,test_crontab_u_debian10,"for (i, line) in reversed(list(enumerate(cleandata))):
    if '=' in line and (not line.strip()[0].isdigit()) and (not line.strip()[0] == '@'):
        var_line = cleandata.pop(i)
        var_name = var_line.split('=', maxsplit=1)[0].strip()
        var_value = var_line.split('=', maxsplit=1)[1].strip()
        cron_var.append({'name': var_name, 'value': var_value})","for e_target in reversed(list(enumerate(cleandata))):
    line = e_target[1]
    i = e_target[0]
    if '=' in line and (not line.strip()[0].isdigit()) and (not line.strip()[0] == '@'):
        var_line = cleandata.pop(i)
        var_name = var_line.split('=', maxsplit=1)[0].strip()
        var_value = var_line.split('=', maxsplit=1)[1].strip()
        cron_var.append({'name': var_name, 'value': var_value})

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_nodata'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_ubuntu_18_4'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_debian10']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/crontab_u.py,MyTests,test_crontab_u_debian10,"for (i, line) in reversed(list(enumerate(cleandata))):
    if line.strip().startswith('@'):
        shortcut_line = cleandata.pop(i)
        occurrence = shortcut_line.split(maxsplit=1)[0].strip().lstrip('@')
        usr = shortcut_line.split(maxsplit=2)[1].strip()
        cmd = shortcut_line.split(maxsplit=2)[2].strip()
        shortcut_list.append({'occurrence': occurrence, 'user': usr, 'command': cmd})","for e_target in reversed(list(enumerate(cleandata))):
    line = e_target[1]
    i = e_target[0]
    if line.strip().startswith('@'):
        shortcut_line = cleandata.pop(i)
        occurrence = shortcut_line.split(maxsplit=1)[0].strip().lstrip('@')
        usr = shortcut_line.split(maxsplit=2)[1].strip()
        cmd = shortcut_line.split(maxsplit=2)[2].strip()
        shortcut_list.append({'occurrence': occurrence, 'user': usr, 'command': cmd})

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_nodata'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_ubuntu_18_4'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_crontab_u.py', 'tests.test_crontab_u', 'MyTests', 'test_crontab_u_debian10']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/ntpq.py,MyTests,test_ntpq_p_ubuntu_18_4,"for (i, line) in list(enumerate(cleandata[1:])):
    if line[0] == ' ':
        cleandata[i + 1] = '~  ' + line[1:]
    else:
        cleandata[i + 1] = line[:1] + '  ' + line[1:]
    cleandata[i + 1] = cleandata[i + 1].replace(' (', '_(')","for e_target in list(enumerate(cleandata[1:])):
    line = e_target[1]
    i = e_target[0]
    if line[0] == ' ':
        cleandata[i + 1] = '~  ' + line[1:]
    else:
        cleandata[i + 1] = line[:1] + '  ' + line[1:]
    cleandata[i + 1] = cleandata[i + 1].replace(' (', '_(')

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ntpq.py', 'tests.test_ntpq', 'MyTests', 'test_ntpq_pn_ubuntu_18_4'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ntpq.py', 'tests.test_ntpq', 'MyTests', 'test_ntpq_p_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ntpq.py', 'tests.test_ntpq', 'MyTests', 'test_ntpq_pn_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ntpq.py', 'tests.test_ntpq', 'MyTests', 'test_ntpq_p_freebsd12'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ntpq.py', 'tests.test_ntpq', 'MyTests', 'test_ntpq_p_nodata'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ntpq.py', 'tests.test_ntpq', 'MyTests', 'test_ntpq_p2_ubuntu_18_4'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ntpq.py', 'tests.test_ntpq', 'MyTests', 'test_ntpq_p_ubuntu_18_4']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/ini.py,MyTests,test_ini_nodata,"for (key, value) in output_dict['data'].items():
    raw_output[key] = value","for e_target in output_dict['data'].items():
    value = e_target[1]
    key = e_target[0]
    raw_output[key] = value

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ini.py', 'tests.test_ini', 'MyTests', 'test_ini_iptelserver'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ini.py', 'tests.test_ini', 'MyTests', 'test_ini_test'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_ini.py', 'tests.test_ini', 'MyTests', 'test_ini_nodata']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/systeminfo.py,MyTests,test_windows_systeminfo,"for (k, v) in raw_data.items():
    k = _transform_key(k)
    k = k.rstrip(delim)
    if k in ['hotfixs', 'processors']:
        raw_output[k] = _parse_hotfixs_or_processors(v)
    elif k in ['network_cards']:
        raw_output[k] = _parse_network_cards(v)
    elif k in ['hyperv_requirements']:
        raw_output[k] = _parse_hyperv_requirements(v)
    elif k in ['total_physical_memory', 'available_physical_memory', 'virtual_memory_max_size', 'virtual_memory_available', 'virtual_memory_in_use']:
        raw_output[k + '_mb'] = v.strip()
    else:
        raw_output[k] = v.strip()","for e_target in raw_data.items():
    v = e_target[1]
    k = e_target[0]
    k = _transform_key(k)
    k = k.rstrip(delim)
    if k in ['hotfixs', 'processors']:
        raw_output[k] = _parse_hotfixs_or_processors(v)
    elif k in ['network_cards']:
        raw_output[k] = _parse_network_cards(v)
    elif k in ['hyperv_requirements']:
        raw_output[k] = _parse_hyperv_requirements(v)
    elif k in ['total_physical_memory', 'available_physical_memory', 'virtual_memory_max_size', 'virtual_memory_available', 'virtual_memory_in_use']:
        raw_output[k + '_mb'] = v.strip()
    else:
        raw_output[k] = v.strip()

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_systeminfo.py', 'tests.test_systeminfo', 'MyTests', 'test_windows_systeminfo']]"
jc,https://github.com/kellyjonbrazil/jc/tree/master/jc/parsers/finger.py,MyTests,test_finger_ubuntu_18_4,"for (index, line) in enumerate(second_half):
    dt = re.search(pattern, line)
    if dt:
        if dt.group(1) and dt.group(2):
            raw_output[index]['login_time'] = dt.group(1).strip() + ' ' + dt.group(2).strip()
        if dt.group(3):
            raw_output[index]['details'] = dt.group(3).strip()","for e_target in enumerate(second_half):
    line = e_target[1]
    index = e_target[0]
    dt = re.search(pattern, line)
    if dt:
        if dt.group(1) and dt.group(2):
            raw_output[index]['login_time'] = dt.group(1).strip() + ' ' + dt.group(2).strip()
        if dt.group(3):
            raw_output[index]['details'] = dt.group(3).strip()

",1,"[['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_finger.py', 'tests.test_finger', 'MyTests', 'test_finger_centos_7_7'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_finger.py', 'tests.test_finger', 'MyTests', 'test_finger_osx_10_14_6'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_finger.py', 'tests.test_finger', 'MyTests', 'test_finger_nodata'], ['https://github.com/kellyjonbrazil/jc/tree/master/tests/test_finger.py', 'tests.test_finger', 'MyTests', 'test_finger_ubuntu_18_4']]"
CobaltStrikeParser,https://github.com/Sentinel-One/CobaltStrikeParser/tree/master//parse_beacon_config.py,TestBeaconParsing,test_encrypted_x86_64,"for (i, c) in enumerate(enc_data):
    dec_data.append(c ^ key[i % 4])","for e_target in enumerate(enc_data):
    c = e_target[1]
    i = e_target[0]
    dec_data.append(c ^ key[i % 4])

",1,"[['https://github.com/Sentinel-One/CobaltStrikeParser/tree/master//test_parse_beacon_config.py', 'test_parse_beacon_config', 'TestBeaconParsing', 'test_encrypted_x86'], ['https://github.com/Sentinel-One/CobaltStrikeParser/tree/master//test_parse_beacon_config.py', 'test_parse_beacon_config', 'TestBeaconParsing', 'test_non_pe_x86'], ['https://github.com/Sentinel-One/CobaltStrikeParser/tree/master//test_parse_beacon_config.py', 'test_parse_beacon_config', 'TestBeaconParsing', 'test_encrypted_x86_64']]"
LibCST,https://github.com/Instagram/LibCST/tree/master/libcst/helpers/module.py,ModuleTest,test_insert_header_comments,"for (i, line) in enumerate(node.header):
    if line.comment is not None:
        last_comment_index = i","for e_target in enumerate(node.header):
    line = e_target[1]
    i = e_target[0]
    if line.comment is not None:
        last_comment_index = i

",1,"[['https://github.com/Instagram/LibCST/tree/master/libcst/helpers/tests/test_module.py', 'libcst.helpers.tests.test_module', 'ModuleTest', 'test_insert_header_comments']]"
symspellpy,https://github.com/mammothb/symspellpy/tree/master/symspellpy/helpers.py,TestHelpers,test_case_transfer_similar_empty_w_casing,"for (tag, ia1, ia2, ib1, ib2) in matcher.get_opcodes():
    if tag == 'delete':
        continue
    if tag == 'insert':
        ia_ref = ia1 if ia1 == 0 or cased_text[ia1 - 1] == ' ' else ia1 - 1
        if cased_text[ia_ref].isupper():
            result += uncased_text[ib1:ib2].upper()
        else:
            result += uncased_text[ib1:ib2].lower()
    elif tag == 'equal':
        result += cased_text[ia1:ia2]
    else:
        cased_seq = cased_text[ia1:ia2]
        uncased_seq = uncased_text[ib1:ib2]
        if len(cased_seq) == len(uncased_seq):
            result += case_transfer_matching(cased_seq, uncased_seq)
        else:
            for (cased, uncased) in zip(cased_seq, uncased_seq):
                result += uncased.upper() if cased.isupper() else uncased.lower()
            if len(cased_seq) < len(uncased_seq):
                upper = cased_seq[-1].isupper()
                idx = len(cased_seq)
                result += ''.join(map(str.upper if upper else str.lower, uncased_seq[idx:]))","for e_target in matcher.get_opcodes():
    ib2 = e_target[4]
    ib1 = e_target[3]
    ia2 = e_target[2]
    ia1 = e_target[1]
    tag = e_target[0]
    if tag == 'delete':
        continue
    if tag == 'insert':
        ia_ref = ia1 if ia1 == 0 or cased_text[ia1 - 1] == ' ' else ia1 - 1
        if cased_text[ia_ref].isupper():
            result += uncased_text[ib1:ib2].upper()
        else:
            result += uncased_text[ib1:ib2].lower()
    elif tag == 'equal':
        result += cased_text[ia1:ia2]
    else:
        cased_seq = cased_text[ia1:ia2]
        uncased_seq = uncased_text[ib1:ib2]
        if len(cased_seq) == len(uncased_seq):
            result += case_transfer_matching(cased_seq, uncased_seq)
        else:
            for (cased, uncased) in zip(cased_seq, uncased_seq):
                result += uncased.upper() if cased.isupper() else uncased.lower()
            if len(cased_seq) < len(uncased_seq):
                upper = cased_seq[-1].isupper()
                idx = len(cased_seq)
                result += ''.join(map(str.upper if upper else str.lower, uncased_seq[idx:]))

",1,"[['https://github.com/mammothb/symspellpy/tree/master/tests/test_helpers.py', 'tests.test_helpers', 'TestHelpers', 'test_case_transfer_similar_empty_wo_casing'], ['https://github.com/mammothb/symspellpy/tree/master/tests/test_helpers.py', 'tests.test_helpers', 'TestHelpers', 'test_case_transfer_similar'], ['https://github.com/mammothb/symspellpy/tree/master/tests/test_helpers.py', 'tests.test_helpers', 'TestHelpers', 'test_case_transfer_similar_empty_w_casing']]"
symspellpy,https://github.com/mammothb/symspellpy/tree/master/symspellpy/helpers.py,TestHelpers,test_case_transfer_similar_empty_w_casing,"for (cased, uncased) in zip(cased_seq, uncased_seq):
    result += uncased.upper() if cased.isupper() else uncased.lower()","for e_target in zip(cased_seq, uncased_seq):
    uncased = e_target[1]
    cased = e_target[0]
    result += uncased.upper() if cased.isupper() else uncased.lower()

",1,"[['https://github.com/mammothb/symspellpy/tree/master/tests/test_helpers.py', 'tests.test_helpers', 'TestHelpers', 'test_case_transfer_similar_empty_wo_casing'], ['https://github.com/mammothb/symspellpy/tree/master/tests/test_helpers.py', 'tests.test_helpers', 'TestHelpers', 'test_case_transfer_similar'], ['https://github.com/mammothb/symspellpy/tree/master/tests/test_helpers.py', 'tests.test_helpers', 'TestHelpers', 'test_case_transfer_similar_empty_w_casing']]"
yt-dlp,https://github.com/yt-dlp/yt-dlp/tree/master/test/helper.py,TestInfoExtractor,test_parse_f4m_formats,"for (index, (item_got, item_expected)) in enumerate(zip(got, expected)):
    type_got = type(item_got)
    type_expected = type(item_expected)
    self.assertEqual(type_expected, type_got, 'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (index, field, type_expected, type_got))
    expect_value(self, item_got, item_expected, field)","for e_target in enumerate(zip(got, expected)):
    item_expected = e_target[1][1]
    item_got = e_target[1][0]
    index = e_target[0]
    type_got = type(item_got)
    type_expected = type(item_expected)
    self.assertEqual(type_expected, type_got, 'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (index, field, type_expected, type_got))
    expect_value(self, item_got, item_expected, field)

",1,"[['https://github.com/yt-dlp/yt-dlp/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_m3u8_formats'], ['https://github.com/yt-dlp/yt-dlp/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_xspf'], ['https://github.com/yt-dlp/yt-dlp/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_mpd_formats'], ['https://github.com/yt-dlp/yt-dlp/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_ism_formats'], ['https://github.com/yt-dlp/yt-dlp/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_f4m_formats']]"
yt-dlp,https://github.com/yt-dlp/yt-dlp/tree/master/yt_dlp/utils.py,TestUtil,test_sanitize_url,"for (mistake, fixup) in COMMON_TYPOS:
    if re.match(mistake, url):
        return re.sub(mistake, fixup, url)","for e_target in COMMON_TYPOS:
    fixup = e_target[1]
    mistake = e_target[0]
    if re.match(mistake, url):
        return re.sub(mistake, fixup, url)

",1,"[['https://github.com/yt-dlp/yt-dlp/tree/master/test/test_utils.py', 'test.test_utils', 'TestUtil', 'test_sanitize_url']]"
yt-dlp,https://github.com/yt-dlp/yt-dlp/tree/master/yt_dlp/options.py,TestOptions,test_hide_login_info,"for (idx, opt) in enumerate(opts):
    if opt in PRIVATE_OPTS and idx + 1 < len(opts):
        opts[idx + 1] = 'PRIVATE'","for e_target in enumerate(opts):
    opt = e_target[1]
    idx = e_target[0]
    if opt in PRIVATE_OPTS and idx + 1 < len(opts):
        opts[idx + 1] = 'PRIVATE'

",1,"[['https://github.com/yt-dlp/yt-dlp/tree/master/test/test_options.py', 'test.test_options', 'TestOptions', 'test_hide_login_info']]"
schematics,https://github.com/schematics/schematics/tree/master/schematics/transforms.py,,test_serialize_print_none_always_gets_you_something,"for (field_name, field, value) in atoms(schema, instance_or_dict):
    serialized_name = field.serialized_name or field_name
    if filter_func is not None and filter_func(field_name, value):
        continue
    _export_level = field.get_export_level(context)
    if _export_level == DROP:
        continue
    elif value is not None and value is not Undefined:
        value = _field_converter(field, value, context)
    if value is Undefined:
        if _export_level <= DEFAULT:
            continue
    elif value is None:
        if _export_level <= NOT_NONE:
            continue
    elif field.is_compound and len(value) == 0:
        if _export_level <= NONEMPTY:
            continue
    if value is Undefined:
        value = None
    data[serialized_name] = value","for e_target in atoms(schema, instance_or_dict):
    value = e_target[2]
    field = e_target[1]
    field_name = e_target[0]
    serialized_name = field.serialized_name or field_name
    if filter_func is not None and filter_func(field_name, value):
        continue
    _export_level = field.get_export_level(context)
    if _export_level == DROP:
        continue
    elif value is not None and value is not Undefined:
        value = _field_converter(field, value, context)
    if value is Undefined:
        if _export_level <= DEFAULT:
            continue
    elif value is None:
        if _export_level <= NOT_NONE:
            continue
    elif field.is_compound and len(value) == 0:
        if _export_level <= NONEMPTY:
            continue
    if value is Undefined:
        value = None
    data[serialized_name] = value

",1,"[['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serialize_none_fields_if_field_says_so'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serialize_none_fields_if_export_loop_says_so'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serialize_print_none_always_gets_you_something']]"
schematics,https://github.com/schematics/schematics/tree/master/schematics/iteration.py,,test_atoms_api_keys_param,"for (field_name, field) in iteritems(schema.fields):
    value = Undefined
    if has_value:
        try:
            value = mapping[field_name]
        except Exception:
            value = Undefined
    atom_tuple = Atom(name=field_name if has_name else None, field=field if has_field else None, value=value)
    if filter is None:
        yield atom_tuple
    elif filter(atom_tuple):
        yield atom_tuple","for e_target in iteritems(schema.fields):
    field = e_target[1]
    field_name = e_target[0]
    value = Undefined
    if has_value:
        try:
            value = mapping[field_name]
        except Exception:
            value = Undefined
    atom_tuple = Atom(name=field_name if has_name else None, field=field if has_field else None, value=value)
    if filter is None:
        yield atom_tuple
    elif filter(atom_tuple):
        yield atom_tuple

",1,"[['https://github.com/schematics/schematics/tree/master/tests/test_private_api.py', 'tests.test_private_api', '', 'test_atoms_api_keys_param']]"
schematics,https://github.com/schematics/schematics/tree/master/schematics/types/serializable.py,,test_serializable_with_type_and_options,"for (name, value) in kwargs.items():
    setattr(serialized_type, name, value)","for e_target in kwargs.items():
    value = e_target[1]
    name = e_target[0]
    setattr(serialized_type, name, value)

",1,"[['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_embedded_models'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_model'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_serializable_name'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_model_to_native'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_model_hide_None'], ['https://github.com/schematics/schematics/tree/master/tests/test_dict_type.py', 'tests.test_dict_type', '', 'test_dict_type_with_model_type_init_with_instance'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_custom_serializable_class'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_type_as_positional_argument'], ['https://github.com/schematics/schematics/tree/master/tests/test_schema.py', 'tests.test_schema', '', 'test_object_model_equivalence'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_setter_override'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_model_when_None'], ['https://github.com/schematics/schematics/tree/master/tests/test_serialize.py', 'tests.test_serialize', '', 'test_serializable_with_type_and_options']]"
schematics,https://github.com/schematics/schematics/tree/master/schematics/types/base.py,,test_multilingualstring_should_validate_regex,"for (locale, localized) in value.items():
    if self.regex is not None and self.regex.match(localized) is None:
        raise ValidationError(self.messages['regex_localized'].format(locale))
    if self.locale_regex is not None and self.locale_regex.match(locale) is None:
        raise ValidationError(self.messages['regex_locale'].format(locale))","for e_target in value.items():
    localized = e_target[1]
    locale = e_target[0]
    if self.regex is not None and self.regex.match(localized) is None:
        raise ValidationError(self.messages['regex_localized'].format(locale))
    if self.locale_regex is not None and self.locale_regex.match(locale) is None:
        raise ValidationError(self.messages['regex_locale'].format(locale))

",1,"[['https://github.com/schematics/schematics/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_multilingualstring_should_validate_regex']]"
pyperf,https://github.com/psf/pyperf/tree/master/pyperf/_bench.py,BenchmarkTests,test_get_total_duration,"for (name, value) in list(self._common_metadata.items()):
    if run._metadata.get(name, None) != value:
        del self._common_metadata[name]","for e_target in list(self._common_metadata.items()):
    value = e_target[1]
    name = e_target[0]
    if run._metadata.get(name, None) != value:
        del self._common_metadata[name]

",1,"[['https://github.com/psf/pyperf/tree/master/pyperf/tests/test_bench.py', 'pyperf.tests.test_bench', 'BenchmarkTests', 'test_add_run'], ['https://github.com/psf/pyperf/tree/master/pyperf/tests/test_bench.py', 'pyperf.tests.test_bench', 'BenchmarkTests', 'test_get_nvalue'], ['https://github.com/psf/pyperf/tree/master/pyperf/tests/test_bench.py', 'pyperf.tests.test_bench', 'BenchmarkTests', 'test_get_dates'], ['https://github.com/psf/pyperf/tree/master/pyperf/tests/test_bench.py', 'pyperf.tests.test_bench', 'BenchmarkTests', 'test_get_total_duration']]"
pyperf,https://github.com/psf/pyperf/tree/master/pyperf/_cli.py,MiscTests,test_format_metadata,"for (name, value) in sorted(metadata.items()):
    value = _format_metadata(name, value)
    lines.append('%s%s: %s' % (prefix, name, value))","for e_target in sorted(metadata.items()):
    value = e_target[1]
    name = e_target[0]
    value = _format_metadata(name, value)
    lines.append('%s%s: %s' % (prefix, name, value))

",1,"[['https://github.com/psf/pyperf/tree/master/pyperf/tests/test_misc.py', 'pyperf.tests.test_misc', 'MiscTests', 'test_format_metadata']]"
langdetect,https://github.com/Mimino666/langdetect/tree/master/langdetect/utils/lang_profile.py,LangProfileText,test_add,"for (key, count) in list(six.iteritems(self.freq)):
    if count <= threshold:
        self.n_words[len(key) - 1] -= count
        del self.freq[key]
    elif self.ROMAN_CHAR_RE.match(key):
        roman += count","for e_target in list(six.iteritems(self.freq)):
    count = e_target[1]
    key = e_target[0]
    if count <= threshold:
        self.n_words[len(key) - 1] -= count
        del self.freq[key]
    elif self.ROMAN_CHAR_RE.match(key):
        roman += count

",1,"[['https://github.com/Mimino666/langdetect/tree/master/langdetect/tests/utils/test_lang_profile.py', 'langdetect.tests.utils.test_lang_profile', 'LangProfileText', 'test_omit_less_freq_illegally'], ['https://github.com/Mimino666/langdetect/tree/master/langdetect/tests/utils/test_lang_profile.py', 'langdetect.tests.utils.test_lang_profile', 'LangProfileText', 'test_omit_less_freq'], ['https://github.com/Mimino666/langdetect/tree/master/langdetect/tests/utils/test_lang_profile.py', 'langdetect.tests.utils.test_lang_profile', 'LangProfileText', 'test_add']]"
langdetect,https://github.com/Mimino666/langdetect/tree/master/langdetect/utils/lang_profile.py,LangProfileText,test_add,"for (key, count) in list(six.iteritems(self.freq)):
    if self.ROMAN_SUBSTR_RE.match(key):
        self.n_words[len(key) - 1] -= count
        del self.freq[key]","for e_target in list(six.iteritems(self.freq)):
    count = e_target[1]
    key = e_target[0]
    if self.ROMAN_SUBSTR_RE.match(key):
        self.n_words[len(key) - 1] -= count
        del self.freq[key]

",1,"[['https://github.com/Mimino666/langdetect/tree/master/langdetect/tests/utils/test_lang_profile.py', 'langdetect.tests.utils.test_lang_profile', 'LangProfileText', 'test_omit_less_freq_illegally'], ['https://github.com/Mimino666/langdetect/tree/master/langdetect/tests/utils/test_lang_profile.py', 'langdetect.tests.utils.test_lang_profile', 'LangProfileText', 'test_omit_less_freq'], ['https://github.com/Mimino666/langdetect/tree/master/langdetect/tests/utils/test_lang_profile.py', 'langdetect.tests.utils.test_lang_profile', 'LangProfileText', 'test_add']]"
webpy,https://github.com/webpy/webpy/tree/master/web/http.py,ApplicationTest,test_changequery,"for (k, v) in iteritems(kw):
    if v is None:
        query.pop(k, None)
    else:
        query[k] = v","for e_target in iteritems(kw):
    v = e_target[1]
    k = e_target[0]
    if v is None:
        query.pop(k, None)
    else:
        query[k] = v

",1,"[['https://github.com/webpy/webpy/tree/master/tests/test_application.py', 'tests.test_application', 'ApplicationTest', 'test_changequery']]"
octodns,https://github.com/octodns/octodns/tree/master/octodns/provider/selectel.py,TestSelectelProvider,test_populate,"for (name, types) in values.items():
    for (_type, records) in types.items():
        data_for = getattr(self, f'_data_for_{_type}')
        data = data_for(_type, records)
        record = Record.new(zone, name, data, source=self, lenient=lenient)
        zone.add_record(record)","for e_target in values.items():
    types = e_target[1]
    name = e_target[0]
    for (_type, records) in types.items():
        data_for = getattr(self, f'_data_for_{_type}')
        data = data_for(_type, records)
        record = Record.new(zone, name, data, source=self, lenient=lenient)
        zone.add_record(record)

",1,"[['https://github.com/octodns/octodns/tree/master/tests/test_octodns_provider_selectel.py', 'tests.test_octodns_provider_selectel', 'TestSelectelProvider', 'test_populate_invalid_record'], ['https://github.com/octodns/octodns/tree/master/tests/test_octodns_provider_selectel.py', 'tests.test_octodns_provider_selectel', 'TestSelectelProvider', 'test_populate']]"
octodns,https://github.com/octodns/octodns/tree/master/octodns/provider/selectel.py,TestSelectelProvider,test_populate,"for (_type, records) in types.items():
    data_for = getattr(self, f'_data_for_{_type}')
    data = data_for(_type, records)
    record = Record.new(zone, name, data, source=self, lenient=lenient)
    zone.add_record(record)","for e_target in types.items():
    records = e_target[1]
    _type = e_target[0]
    data_for = getattr(self, f'_data_for_{_type}')
    data = data_for(_type, records)
    record = Record.new(zone, name, data, source=self, lenient=lenient)
    zone.add_record(record)

",1,"[['https://github.com/octodns/octodns/tree/master/tests/test_octodns_provider_selectel.py', 'tests.test_octodns_provider_selectel', 'TestSelectelProvider', 'test_populate_invalid_record'], ['https://github.com/octodns/octodns/tree/master/tests/test_octodns_provider_selectel.py', 'tests.test_octodns_provider_selectel', 'TestSelectelProvider', 'test_populate']]"
octodns,https://github.com/octodns/octodns/tree/master/octodns/provider/plan.py,TestPlanLogger,test_create,"for (target, plan) in plans:
    if plan.desired.name != current_zone:
        current_zone = plan.desired.name
        buf.write(hr)
        buf.write('* ')
        buf.write(current_zone)
        buf.write('\n')
        buf.write(hr)
    buf.write('* ')
    buf.write(target.id)
    buf.write(' (')
    buf.write(str(target))
    buf.write(')\n*   ')
    if plan.exists is False:
        buf.write('Create ')
        buf.write(str(plan.desired))
        buf.write('\n*   ')
    for change in plan.changes:
        buf.write(change.__repr__(leader='* '))
        buf.write('\n*   ')
    buf.write('Summary: ')
    buf.write(str(plan))
    buf.write('\n')","for e_target in plans:
    plan = e_target[1]
    target = e_target[0]
    if plan.desired.name != current_zone:
        current_zone = plan.desired.name
        buf.write(hr)
        buf.write('* ')
        buf.write(current_zone)
        buf.write('\n')
        buf.write(hr)
    buf.write('* ')
    buf.write(target.id)
    buf.write(' (')
    buf.write(str(target))
    buf.write(')\n*   ')
    if plan.exists is False:
        buf.write('Create ')
        buf.write(str(plan.desired))
        buf.write('\n*   ')
    for change in plan.changes:
        buf.write(change.__repr__(leader='* '))
        buf.write('\n*   ')
    buf.write('Summary: ')
    buf.write(str(plan))
    buf.write('\n')

",1,"[['https://github.com/octodns/octodns/tree/master/tests/test_octodns_plan.py', 'tests.test_octodns_plan', 'TestPlanLogger', 'test_create']]"
octodns,https://github.com/octodns/octodns/tree/master/octodns/provider/plan.py,TestPlanMarkdown,test_empty,"for (target, plan) in plans:
    if plan.desired.name != current_zone:
        current_zone = plan.desired.name
        fh.write('## ')
        fh.write(current_zone)
        fh.write('\n\n')
    fh.write('### ')
    fh.write(target.id)
    fh.write('\n\n')
    fh.write('| Operation | Name | Type | TTL | Value | Source |\n|--|--|--|--|--|--|\n')
    if plan.exists is False:
        fh.write('| Create | ')
        fh.write(str(plan.desired))
        fh.write(' | | | | |\n')
    for change in plan.changes:
        existing = change.existing
        new = change.new
        record = change.record
        fh.write('| ')
        fh.write(change.__class__.__name__)
        fh.write(' | ')
        fh.write(record.name)
        fh.write(' | ')
        fh.write(record._type)
        fh.write(' | ')
        if existing:
            fh.write(str(existing.ttl))
            fh.write(' | ')
            fh.write(_value_stringifier(existing, '; '))
            fh.write(' | |\n')
            if new:
                fh.write('| | | | ')
        if new:
            fh.write(str(new.ttl))
            fh.write(' | ')
            fh.write(_value_stringifier(new, '; '))
            fh.write(' | ')
            if new.source:
                fh.write(new.source.id)
            fh.write(' |\n')
    fh.write('\nSummary: ')
    fh.write(str(plan))
    fh.write('\n\n')","for e_target in plans:
    plan = e_target[1]
    target = e_target[0]
    if plan.desired.name != current_zone:
        current_zone = plan.desired.name
        fh.write('## ')
        fh.write(current_zone)
        fh.write('\n\n')
    fh.write('### ')
    fh.write(target.id)
    fh.write('\n\n')
    fh.write('| Operation | Name | Type | TTL | Value | Source |\n|--|--|--|--|--|--|\n')
    if plan.exists is False:
        fh.write('| Create | ')
        fh.write(str(plan.desired))
        fh.write(' | | | | |\n')
    for change in plan.changes:
        existing = change.existing
        new = change.new
        record = change.record
        fh.write('| ')
        fh.write(change.__class__.__name__)
        fh.write(' | ')
        fh.write(record.name)
        fh.write(' | ')
        fh.write(record._type)
        fh.write(' | ')
        if existing:
            fh.write(str(existing.ttl))
            fh.write(' | ')
            fh.write(_value_stringifier(existing, '; '))
            fh.write(' | |\n')
            if new:
                fh.write('| | | | ')
        if new:
            fh.write(str(new.ttl))
            fh.write(' | ')
            fh.write(_value_stringifier(new, '; '))
            fh.write(' | ')
            if new.source:
                fh.write(new.source.id)
            fh.write(' |\n')
    fh.write('\nSummary: ')
    fh.write(str(plan))
    fh.write('\n\n')

",1,"[['https://github.com/octodns/octodns/tree/master/tests/test_octodns_plan.py', 'tests.test_octodns_plan', 'TestPlanMarkdown', 'test_simple'], ['https://github.com/octodns/octodns/tree/master/tests/test_octodns_plan.py', 'tests.test_octodns_plan', 'TestPlanMarkdown', 'test_empty']]"
octodns,https://github.com/octodns/octodns/tree/master/octodns/provider/plan.py,TestPlanHtml,test_simple,"for (target, plan) in plans:
    if plan.desired.name != current_zone:
        current_zone = plan.desired.name
        fh.write('<h2>')
        fh.write(current_zone)
        fh.write('</h2>\n')
    fh.write('<h3>')
    fh.write(target.id)
    fh.write('</h3>\n<table>\n  <tr>\n    <th>Operation</th>\n    <th>Name</th>\n    <th>Type</th>\n    <th>TTL</th>\n    <th>Value</th>\n    <th>Source</th>\n  </tr>\n')
    if plan.exists is False:
        fh.write('  <tr>\n    <td>Create</td>\n    <td colspan=5>')
        fh.write(str(plan.desired))
        fh.write('</td>\n  </tr>\n')
    for change in plan.changes:
        existing = change.existing
        new = change.new
        record = change.record
        fh.write('  <tr>\n    <td>')
        fh.write(change.__class__.__name__)
        fh.write('</td>\n    <td>')
        fh.write(record.name)
        fh.write('</td>\n    <td>')
        fh.write(record._type)
        fh.write('</td>\n')
        if existing:
            fh.write('    <td>')
            fh.write(str(existing.ttl))
            fh.write('</td>\n    <td>')
            fh.write(_value_stringifier(existing, '<br/>'))
            fh.write('</td>\n    <td></td>\n  </tr>\n')
            if new:
                fh.write('  <tr>\n    <td colspan=3></td>\n')
        if new:
            fh.write('    <td>')
            fh.write(str(new.ttl))
            fh.write('</td>\n    <td>')
            fh.write(_value_stringifier(new, '<br/>'))
            fh.write('</td>\n    <td>')
            if new.source:
                fh.write(new.source.id)
            fh.write('</td>\n  </tr>\n')
    fh.write('  <tr>\n    <td colspan=6>Summary: ')
    fh.write(str(plan))
    fh.write('</td>\n  </tr>\n</table>\n')","for e_target in plans:
    plan = e_target[1]
    target = e_target[0]
    if plan.desired.name != current_zone:
        current_zone = plan.desired.name
        fh.write('<h2>')
        fh.write(current_zone)
        fh.write('</h2>\n')
    fh.write('<h3>')
    fh.write(target.id)
    fh.write('</h3>\n<table>\n  <tr>\n    <th>Operation</th>\n    <th>Name</th>\n    <th>Type</th>\n    <th>TTL</th>\n    <th>Value</th>\n    <th>Source</th>\n  </tr>\n')
    if plan.exists is False:
        fh.write('  <tr>\n    <td>Create</td>\n    <td colspan=5>')
        fh.write(str(plan.desired))
        fh.write('</td>\n  </tr>\n')
    for change in plan.changes:
        existing = change.existing
        new = change.new
        record = change.record
        fh.write('  <tr>\n    <td>')
        fh.write(change.__class__.__name__)
        fh.write('</td>\n    <td>')
        fh.write(record.name)
        fh.write('</td>\n    <td>')
        fh.write(record._type)
        fh.write('</td>\n')
        if existing:
            fh.write('    <td>')
            fh.write(str(existing.ttl))
            fh.write('</td>\n    <td>')
            fh.write(_value_stringifier(existing, '<br/>'))
            fh.write('</td>\n    <td></td>\n  </tr>\n')
            if new:
                fh.write('  <tr>\n    <td colspan=3></td>\n')
        if new:
            fh.write('    <td>')
            fh.write(str(new.ttl))
            fh.write('</td>\n    <td>')
            fh.write(_value_stringifier(new, '<br/>'))
            fh.write('</td>\n    <td>')
            if new.source:
                fh.write(new.source.id)
            fh.write('</td>\n  </tr>\n')
    fh.write('  <tr>\n    <td colspan=6>Summary: ')
    fh.write(str(plan))
    fh.write('</td>\n  </tr>\n</table>\n')

",1,"[['https://github.com/octodns/octodns/tree/master/tests/test_octodns_plan.py', 'tests.test_octodns_plan', 'TestPlanHtml', 'test_empty'], ['https://github.com/octodns/octodns/tree/master/tests/test_octodns_plan.py', 'tests.test_octodns_plan', 'TestPlanHtml', 'test_simple']]"
octodns,https://github.com/octodns/octodns/tree/master/octodns/record/geo.py,TestRecordGeoCodes,test_country_to_code,"for (continent, countries) in geo_data.items():
    if country in countries:
        return f'{continent}-{country}'","for e_target in geo_data.items():
    countries = e_target[1]
    continent = e_target[0]
    if country in countries:
        return f'{continent}-{country}'

",1,"[['https://github.com/octodns/octodns/tree/master/tests/test_octodns_record_geo.py', 'tests.test_octodns_record_geo', 'TestRecordGeoCodes', 'test_country_to_code']]"
troposphere,https://github.com/cloudtools/troposphere/tree/master/troposphere/codebuild.py,TestCodeBuildFilters,test_filter_no_filtergroup,"for (counti, elem) in enumerate(filter_groups):
    if not isinstance(elem, list):
        self._raise_type('FilterGroups[{}]'.format(counti), filter_groups[counti], list)
    for (countj, hook) in enumerate(filter_groups[counti]):
        if not isinstance(hook, WebhookFilter):
            self._raise_type('FilterGroups[{}][{}]'.format(counti, countj), hook, WebhookFilter)","for e_target in enumerate(filter_groups):
    elem = e_target[1]
    counti = e_target[0]
    if not isinstance(elem, list):
        self._raise_type('FilterGroups[{}]'.format(counti), filter_groups[counti], list)
    for (countj, hook) in enumerate(filter_groups[counti]):
        if not isinstance(hook, WebhookFilter):
            self._raise_type('FilterGroups[{}][{}]'.format(counti, countj), hook, WebhookFilter)

",1,"[['https://github.com/cloudtools/troposphere/tree/master/tests/test_codebuild.py', 'tests.test_codebuild', 'TestCodeBuildFilters', 'test_filter_not_list'], ['https://github.com/cloudtools/troposphere/tree/master/tests/test_codebuild.py', 'tests.test_codebuild', 'TestCodeBuildFilters', 'test_filter_no_filtergroup']]"
troposphere,https://github.com/cloudtools/troposphere/tree/master/troposphere/codebuild.py,TestCodeBuildFilters,test_filter_no_filtergroup,"for (countj, hook) in enumerate(filter_groups[counti]):
    if not isinstance(hook, WebhookFilter):
        self._raise_type('FilterGroups[{}][{}]'.format(counti, countj), hook, WebhookFilter)","for e_target in enumerate(filter_groups[counti]):
    hook = e_target[1]
    countj = e_target[0]
    if not isinstance(hook, WebhookFilter):
        self._raise_type('FilterGroups[{}][{}]'.format(counti, countj), hook, WebhookFilter)

",1,"[['https://github.com/cloudtools/troposphere/tree/master/tests/test_codebuild.py', 'tests.test_codebuild', 'TestCodeBuildFilters', 'test_filter_not_list'], ['https://github.com/cloudtools/troposphere/tree/master/tests/test_codebuild.py', 'tests.test_codebuild', 'TestCodeBuildFilters', 'test_filter_no_filtergroup']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/utils.py,,test_ensembler_use_component_preds,"for (name, component_list) in pipeline.component_graph.component_dict.items():
    new_component_list = []
    new_component_name = _make_new_component_name(model_family, name, model_family_idx)
    for (i, item) in enumerate(component_list):
        if i == 0:
            fitted_comp = handle_component_class(item)
            new_component_list.append(fitted_comp)
            parameters[new_component_name] = pipeline.parameters.get(name, {})
        elif isinstance(item, str) and item not in ['X', 'y']:
            new_component_list.append(_make_new_component_name(model_family, item, model_family_idx))
        elif isinstance(item, str) and item == 'y':
            if is_classification(problem_type):
                new_component_list.append('Label Encoder.y')
            else:
                new_component_list.append('y')
        else:
            new_component_list.append(item)
        if i != 0 and item.endswith('.y'):
            ensemble_y = _make_new_component_name(model_family, item, model_family_idx)
    component_graph[new_component_name] = new_component_list
    final_component = new_component_name","for e_target in pipeline.component_graph.component_dict.items():
    component_list = e_target[1]
    name = e_target[0]
    new_component_list = []
    new_component_name = _make_new_component_name(model_family, name, model_family_idx)
    for (i, item) in enumerate(component_list):
        if i == 0:
            fitted_comp = handle_component_class(item)
            new_component_list.append(fitted_comp)
            parameters[new_component_name] = pipeline.parameters.get(name, {})
        elif isinstance(item, str) and item not in ['X', 'y']:
            new_component_list.append(_make_new_component_name(model_family, item, model_family_idx))
        elif isinstance(item, str) and item == 'y':
            if is_classification(problem_type):
                new_component_list.append('Label Encoder.y')
            else:
                new_component_list.append('y')
        else:
            new_component_list.append(item)
        if i != 0 and item.endswith('.y'):
            ensemble_y = _make_new_component_name(model_family, item, model_family_idx)
    component_graph[new_component_name] = new_component_list
    final_component = new_component_name

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_classifier.py', 'evalml.tests.component_tests.test_stacked_ensemble_classifier', '', 'test_ensembler_use_component_preds_multi'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_classifier.py', 'evalml.tests.component_tests.test_stacked_ensemble_classifier', '', 'test_ensembler_use_component_preds_binary'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_classifier.py', 'evalml.tests.component_tests.test_stacked_ensemble_classifier', '', 'test_ensembler_str_and_classes'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_regressor.py', 'evalml.tests.component_tests.test_stacked_ensemble_regressor', '', 'test_stacked_same_model_family'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_classifier.py', 'evalml.tests.component_tests.test_stacked_ensemble_classifier', '', 'test_stacked_ensemble_keep_estimator_parameters'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_regressor.py', 'evalml.tests.component_tests.test_stacked_ensemble_regressor', '', 'test_ensembler_str_and_classes'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_regressor.py', 'evalml.tests.component_tests.test_stacked_ensemble_regressor', '', 'test_ensembler_use_component_preds']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/utils.py,,test_ensembler_use_component_preds,"for (i, item) in enumerate(component_list):
    if i == 0:
        fitted_comp = handle_component_class(item)
        new_component_list.append(fitted_comp)
        parameters[new_component_name] = pipeline.parameters.get(name, {})
    elif isinstance(item, str) and item not in ['X', 'y']:
        new_component_list.append(_make_new_component_name(model_family, item, model_family_idx))
    elif isinstance(item, str) and item == 'y':
        if is_classification(problem_type):
            new_component_list.append('Label Encoder.y')
        else:
            new_component_list.append('y')
    else:
        new_component_list.append(item)
    if i != 0 and item.endswith('.y'):
        ensemble_y = _make_new_component_name(model_family, item, model_family_idx)","for e_target in enumerate(component_list):
    item = e_target[1]
    i = e_target[0]
    if i == 0:
        fitted_comp = handle_component_class(item)
        new_component_list.append(fitted_comp)
        parameters[new_component_name] = pipeline.parameters.get(name, {})
    elif isinstance(item, str) and item not in ['X', 'y']:
        new_component_list.append(_make_new_component_name(model_family, item, model_family_idx))
    elif isinstance(item, str) and item == 'y':
        if is_classification(problem_type):
            new_component_list.append('Label Encoder.y')
        else:
            new_component_list.append('y')
    else:
        new_component_list.append(item)
    if i != 0 and item.endswith('.y'):
        ensemble_y = _make_new_component_name(model_family, item, model_family_idx)

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_classifier.py', 'evalml.tests.component_tests.test_stacked_ensemble_classifier', '', 'test_ensembler_use_component_preds_multi'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_classifier.py', 'evalml.tests.component_tests.test_stacked_ensemble_classifier', '', 'test_ensembler_use_component_preds_binary'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_classifier.py', 'evalml.tests.component_tests.test_stacked_ensemble_classifier', '', 'test_ensembler_str_and_classes'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_regressor.py', 'evalml.tests.component_tests.test_stacked_ensemble_regressor', '', 'test_stacked_same_model_family'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_classifier.py', 'evalml.tests.component_tests.test_stacked_ensemble_classifier', '', 'test_stacked_ensemble_keep_estimator_parameters'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_regressor.py', 'evalml.tests.component_tests.test_stacked_ensemble_regressor', '', 'test_ensembler_str_and_classes'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_stacked_ensemble_regressor.py', 'evalml.tests.component_tests.test_stacked_ensemble_regressor', '', 'test_ensembler_use_component_preds']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/utils.py,,test_make_pipeline_from_multiple_graphs_with_sampler,"for (name, component_list) in pipeline.component_graph.component_dict.items():
    new_component_list = []
    new_component_name = _make_new_component_name(component_pipeline_name, name, name_idx, sub_pipeline_name)
    for (i, item) in enumerate(component_list):
        if i == 0:
            fitted_comp = handle_component_class(item)
            new_component_list.append(fitted_comp)
            parameters[new_component_name] = pipeline.parameters.get(name, {})
        elif isinstance(item, str) and item not in ['X', 'y']:
            new_component_list.append(_make_new_component_name(component_pipeline_name, item, name_idx, sub_pipeline_name))
            if i != 0 and item.endswith('.y'):
                final_y = _make_new_component_name(component_pipeline_name, item, name_idx, sub_pipeline_name)
        elif isinstance(item, str) and item == 'y':
            if is_classification(problem_type):
                new_component_list.append('Label Encoder.y')
            else:
                new_component_list.append('y')
        else:
            new_component_list.append(item)
    component_graph[new_component_name] = new_component_list
    final_component = new_component_name","for e_target in pipeline.component_graph.component_dict.items():
    component_list = e_target[1]
    name = e_target[0]
    new_component_list = []
    new_component_name = _make_new_component_name(component_pipeline_name, name, name_idx, sub_pipeline_name)
    for (i, item) in enumerate(component_list):
        if i == 0:
            fitted_comp = handle_component_class(item)
            new_component_list.append(fitted_comp)
            parameters[new_component_name] = pipeline.parameters.get(name, {})
        elif isinstance(item, str) and item not in ['X', 'y']:
            new_component_list.append(_make_new_component_name(component_pipeline_name, item, name_idx, sub_pipeline_name))
            if i != 0 and item.endswith('.y'):
                final_y = _make_new_component_name(component_pipeline_name, item, name_idx, sub_pipeline_name)
        elif isinstance(item, str) and item == 'y':
            if is_classification(problem_type):
                new_component_list.append('Label Encoder.y')
            else:
                new_component_list.append('y')
        else:
            new_component_list.append(item)
    component_graph[new_component_name] = new_component_list
    final_component = new_component_name

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_pipeline_utils.py', 'evalml.tests.pipeline_tests.test_pipeline_utils', '', 'test_make_pipeline_from_multiple_graphs_with_sampler']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/utils.py,,test_make_pipeline_from_multiple_graphs_with_sampler,"for (i, item) in enumerate(component_list):
    if i == 0:
        fitted_comp = handle_component_class(item)
        new_component_list.append(fitted_comp)
        parameters[new_component_name] = pipeline.parameters.get(name, {})
    elif isinstance(item, str) and item not in ['X', 'y']:
        new_component_list.append(_make_new_component_name(component_pipeline_name, item, name_idx, sub_pipeline_name))
        if i != 0 and item.endswith('.y'):
            final_y = _make_new_component_name(component_pipeline_name, item, name_idx, sub_pipeline_name)
    elif isinstance(item, str) and item == 'y':
        if is_classification(problem_type):
            new_component_list.append('Label Encoder.y')
        else:
            new_component_list.append('y')
    else:
        new_component_list.append(item)","for e_target in enumerate(component_list):
    item = e_target[1]
    i = e_target[0]
    if i == 0:
        fitted_comp = handle_component_class(item)
        new_component_list.append(fitted_comp)
        parameters[new_component_name] = pipeline.parameters.get(name, {})
    elif isinstance(item, str) and item not in ['X', 'y']:
        new_component_list.append(_make_new_component_name(component_pipeline_name, item, name_idx, sub_pipeline_name))
        if i != 0 and item.endswith('.y'):
            final_y = _make_new_component_name(component_pipeline_name, item, name_idx, sub_pipeline_name)
    elif isinstance(item, str) and item == 'y':
        if is_classification(problem_type):
            new_component_list.append('Label Encoder.y')
        else:
            new_component_list.append('y')
    else:
        new_component_list.append(item)

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_pipeline_utils.py', 'evalml.tests.pipeline_tests.test_pipeline_utils', '', 'test_make_pipeline_from_multiple_graphs_with_sampler']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/pipeline_base.py,,test_make_component_dict_from_component_list,"for (idx, component) in enumerate(component_list):
    component_class = handle_component_class(component)
    component_name = component_class.name
    if component_name in seen:
        component_name = f'{component_name}_{idx}'
    seen.add(component_name)
    components_with_names.append((component_name, component_class))","for e_target in enumerate(component_list):
    component = e_target[1]
    idx = e_target[0]
    component_class = handle_component_class(component)
    component_name = component_class.name
    if component_name in seen:
        component_name = f'{component_name}_{idx}'
    seen.add(component_name)
    components_with_names.append((component_name, component_class))

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_pipelines.py', 'evalml.tests.pipeline_tests.test_pipelines', '', 'test_make_component_dict_from_component_list_with_duplicate_names'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_pipelines.py', 'evalml.tests.pipeline_tests.test_pipelines', '', 'test_make_component_dict_from_component_list']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/pipeline_base.py,,test_make_component_dict_from_component_list,"for (component_name, component_class) in components_with_names:
    component_dict[component_name] = [component_class, most_recent_features, most_recent_target]
    if component_class.modifies_target:
        most_recent_target = f'{component_name}.y'
    if component_class.modifies_features:
        most_recent_features = f'{component_name}.x'","for e_target in components_with_names:
    component_class = e_target[1]
    component_name = e_target[0]
    component_dict[component_name] = [component_class, most_recent_features, most_recent_target]
    if component_class.modifies_target:
        most_recent_target = f'{component_name}.y'
    if component_class.modifies_features:
        most_recent_features = f'{component_name}.x'

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_pipelines.py', 'evalml.tests.pipeline_tests.test_pipelines', '', 'test_make_component_dict_from_component_list_with_duplicate_names'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_pipelines.py', 'evalml.tests.pipeline_tests.test_pipelines', '', 'test_make_component_dict_from_component_list']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/component_graph.py,,test_bad_instantiate_can_reinstantiate,"for (component_name, component_class) in self.component_instances.items():
    component_parameters = parameters.get(component_name, {})
    if inspect.isclass(component_class):
        try:
            new_component = component_class(**component_parameters, random_seed=self.random_seed)
        except (ValueError, TypeError) as e:
            self._is_instantiated = False
            err = 'Error received when instantiating component {} with the following arguments {}'.format(component_name, component_parameters)
            raise ValueError(err) from e
        component_instances[component_name] = new_component
    elif isinstance(component_class, ComponentBase):
        component_instances[component_name] = component_class","for e_target in self.component_instances.items():
    component_class = e_target[1]
    component_name = e_target[0]
    component_parameters = parameters.get(component_name, {})
    if inspect.isclass(component_class):
        try:
            new_component = component_class(**component_parameters, random_seed=self.random_seed)
        except (ValueError, TypeError) as e:
            self._is_instantiated = False
            err = 'Error received when instantiating component {} with the following arguments {}'.format(component_name, component_parameters)
            raise ValueError(err) from e
        component_instances[component_name] = new_component
    elif isinstance(component_class, ComponentBase):
        component_instances[component_name] = component_class

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_with_X_y_inputs_X'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_equality'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_evaluation_plumbing'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_init_instantiated'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_predict_empty_graph'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_instantiate_with_parameters'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_transform'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_pipelines.py', 'evalml.tests.pipeline_tests.test_pipelines', '', 'test_component_graph_pipeline_initialized'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_parents'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_transform_with_target_transformer'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_get_component'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_preserves_ltypes_created_during_pipeline_evaluation'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_get_inputs_with_sampler'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_reinstantiate'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_iteration'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_fit_and_transform_all_but_final'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_with_X_y_inputs_y'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_get_last_component'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_component_graph_dataset_with_target_imputer'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_get_estimators'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/pipeline_tests/test_component_graph.py', 'evalml.tests.pipeline_tests.test_component_graph', '', 'test_bad_instantiate_can_reinstantiate']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/components/utils.py,,test_make_balancing_dictionary_errors,"for (index, value) in ratios.items():
    if value < sampling_ratio:
        class_dic[index] = sample_amount
    else:
        class_dic[index] = value_counts[index]","for e_target in ratios.items():
    value = e_target[1]
    index = e_target[0]
    if value < sampling_ratio:
        class_dic[index] = sample_amount
    else:
        class_dic[index] = value_counts[index]

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/component_tests/test_utils.py', 'evalml.tests.component_tests.test_utils', '', 'test_make_balancing_dictionary_errors']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/model_understanding/decision_boundary.py,,test_find_confusion_matrix_values,"for (i, thresh_val) in enumerate(ranges[1:]):
    num_fn += pos_skew[i]
    num_tn += neg_skew[i]
    num_tp = total_pos - num_fn
    num_fp = total_neg - num_tn
    val_list = [num_tp, num_tn, num_fp, num_fn]
    thresh_conf_matrix_list.append(val_list)
    for (k, v) in objective_dict.items():
        obj_val = v[1](val_list)
        if obj_val > v[0]['objective score']:
            v[0]['objective score'] = obj_val
            v[0]['threshold value'] = thresh_val
    if num_fn == total_pos and num_tn == total_pos and (i < len(ranges) - 1):
        v_extension = [val_list for _ in range(i + 1, len(ranges) - 1)]
        thresh_conf_matrix_list.extend(v_extension)
        break","for e_target in enumerate(ranges[1:]):
    thresh_val = e_target[1]
    i = e_target[0]
    num_fn += pos_skew[i]
    num_tn += neg_skew[i]
    num_tp = total_pos - num_fn
    num_fp = total_neg - num_tn
    val_list = [num_tp, num_tn, num_fp, num_fn]
    thresh_conf_matrix_list.append(val_list)
    for (k, v) in objective_dict.items():
        obj_val = v[1](val_list)
        if obj_val > v[0]['objective score']:
            v[0]['objective score'] = obj_val
            v[0]['threshold value'] = thresh_val
    if num_fn == total_pos and num_tn == total_pos and (i < len(ranges) - 1):
        v_extension = [val_list for _ in range(i + 1, len(ranges) - 1)]
        thresh_conf_matrix_list.extend(v_extension)
        break

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_decision_boundary.py', 'evalml.tests.model_understanding_tests.test_decision_boundary', '', 'test_find_confusion_matrix_values']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/model_understanding/decision_boundary.py,,test_find_confusion_matrix_values,"for (k, v) in objective_dict.items():
    obj_val = v[1](val_list)
    if obj_val > v[0]['objective score']:
        v[0]['objective score'] = obj_val
        v[0]['threshold value'] = thresh_val","for e_target in objective_dict.items():
    v = e_target[1]
    k = e_target[0]
    obj_val = v[1](val_list)
    if obj_val > v[0]['objective score']:
        v[0]['objective score'] = obj_val
        v[0]['threshold value'] = thresh_val

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_decision_boundary.py', 'evalml.tests.model_understanding_tests.test_decision_boundary', '', 'test_find_confusion_matrix_values']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/model_understanding/graphs.py,,test_partial_dependence_scale_error,"for (n, label) in enumerate(ind_preds):
    for (i, sample) in enumerate(label):
        ind_df = pd.DataFrame(sample.reshape((-1, sample.shape[-1])))
        ind_df.columns = values[1]
        ind_df.index = values[0]
        if n == 0:
            ind_data.append(ind_df)
        else:
            ind_data[i] = pd.concat([ind_data[i], ind_df])","for e_target in enumerate(ind_preds):
    label = e_target[1]
    n = e_target[0]
    for (i, sample) in enumerate(label):
        ind_df = pd.DataFrame(sample.reshape((-1, sample.shape[-1])))
        ind_df.columns = values[1]
        ind_df.index = values[0]
        if n == 0:
            ind_data.append(ind_df)
        else:
            ind_data[i] = pd.concat([ind_data[i], ind_df])

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_partial_dependence.py', 'evalml.tests.model_understanding_tests.test_partial_dependence', '', 'test_partial_dependence_not_fitted'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_partial_dependence.py', 'evalml.tests.model_understanding_tests.test_partial_dependence', '', 'test_partial_dependence_respect_grid_resolution'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_partial_dependence.py', 'evalml.tests.model_understanding_tests.test_partial_dependence', '', 'test_partial_dependence_baseline'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_partial_dependence.py', 'evalml.tests.model_understanding_tests.test_partial_dependence', '', 'test_partial_dependence_scale_error']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/model_understanding/graphs.py,,test_partial_dependence_scale_error,"for (i, sample) in enumerate(label):
    ind_df = pd.DataFrame(sample.reshape((-1, sample.shape[-1])))
    ind_df.columns = values[1]
    ind_df.index = values[0]
    if n == 0:
        ind_data.append(ind_df)
    else:
        ind_data[i] = pd.concat([ind_data[i], ind_df])","for e_target in enumerate(label):
    sample = e_target[1]
    i = e_target[0]
    ind_df = pd.DataFrame(sample.reshape((-1, sample.shape[-1])))
    ind_df.columns = values[1]
    ind_df.index = values[0]
    if n == 0:
        ind_data.append(ind_df)
    else:
        ind_data[i] = pd.concat([ind_data[i], ind_df])

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_partial_dependence.py', 'evalml.tests.model_understanding_tests.test_partial_dependence', '', 'test_partial_dependence_not_fitted'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_partial_dependence.py', 'evalml.tests.model_understanding_tests.test_partial_dependence', '', 'test_partial_dependence_respect_grid_resolution'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_partial_dependence.py', 'evalml.tests.model_understanding_tests.test_partial_dependence', '', 'test_partial_dependence_baseline'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/test_partial_dependence.py', 'evalml.tests.model_understanding_tests.test_partial_dependence', '', 'test_partial_dependence_scale_error']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/model_understanding/prediction_explanations/_algorithms.py,,test_create_dictionary_exception,"for (feature_name, column_index) in zip(feature_names, range(explainer_values.shape[1])):
    mapping[feature_name] = explainer_values[:, column_index].tolist()","for e_target in zip(feature_names, range(explainer_values.shape[1])):
    column_index = e_target[1]
    feature_name = e_target[0]
    mapping[feature_name] = explainer_values[:, column_index].tolist()

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/model_understanding_tests/prediction_explanations_tests/test_algorithms.py', 'evalml.tests.model_understanding_tests.prediction_explanations_tests.test_algorithms', '', 'test_create_dictionary_exception']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/utils/cli_utils.py,,test_print_sys_info,"for (title, stat) in sys_info:
    logger.info('{title}: {stat}'.format(title=title, stat=stat))","for e_target in sys_info:
    stat = e_target[1]
    title = e_target[0]
    logger.info('{title}: {stat}'.format(title=title, stat=stat))

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/utils_tests/test_cli_utils.py', 'evalml.tests.utils_tests.test_cli_utils', '', 'test_print_sys_info']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/utils/cli_utils.py,,test_print_deps_info,"for (package, version) in installed_packages.items():
    logger.info('{package}: {version}'.format(package=package, version=version))","for e_target in installed_packages.items():
    version = e_target[1]
    package = e_target[0]
    logger.info('{package}: {version}'.format(package=package, version=version))

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/utils_tests/test_cli_utils.py', 'evalml.tests.utils_tests.test_cli_utils', '', 'test_print_deps_info']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/automl/engine/engine_base.py,,test_train_and_score_pipelines_error,"for (level, message) in self.logs:
    method = logger_method[level]
    method(message)","for e_target in self.logs:
    message = e_target[1]
    level = e_target[0]
    method = logger_method[level]
    method(message)

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/automl_tests/test_engine_base.py', 'evalml.tests.automl_tests.test_engine_base', '', 'test_job_logger_warning_and_error_messages'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/automl_tests/test_engine_base.py', 'evalml.tests.automl_tests.test_engine_base', '', 'test_train_and_score_pipelines_error']]"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/preprocessing/data_splitters/time_series_split.py,,test_time_series_split_n_splits_too_big,"for (train, test) in self._splitter.split(**split_kwargs):
    yield (train, test)","for e_target in self._splitter.split(**split_kwargs):
    test = e_target[1]
    train = e_target[0]
    yield (train, test)

",1,"[['https://github.com/alteryx/evalml/tree/master/evalml/tests/automl_tests/test_time_series_split.py', 'evalml.tests.automl_tests.test_time_series_split', '', 'test_time_series_split_init'], ['https://github.com/alteryx/evalml/tree/master/evalml/tests/automl_tests/test_time_series_split.py', 'evalml.tests.automl_tests.test_time_series_split', '', 'test_time_series_split_n_splits_too_big']]"
yake,https://github.com/LIAAD/yake/tree/master/yake/yake.py,,test_n1_EN,"for (h, candResult) in resultSet:
    dist = self.dedu_function(cand.unique_kw, candResult.unique_kw)
    if dist > self.dedupLim:
        toadd = False
        break","for e_target in resultSet:
    candResult = e_target[1]
    h = e_target[0]
    dist = self.dedu_function(cand.unique_kw, candResult.unique_kw)
    if dist > self.dedupLim:
        toadd = False
        break

",1,"[['https://github.com/LIAAD/yake/tree/master/tests/test_yake.py', 'tests.test_yake', '', 'test_phraseless_example'], ['https://github.com/LIAAD/yake/tree/master/tests/test_yake.py', 'tests.test_yake', '', 'test_n3_EN'], ['https://github.com/LIAAD/yake/tree/master/tests/test_yake.py', 'tests.test_yake', '', 'test_n3_PT'], ['https://github.com/LIAAD/yake/tree/master/tests/test_yake.py', 'tests.test_yake', '', 'test_null_and_blank_example'], ['https://github.com/LIAAD/yake/tree/master/tests/test_yake.py', 'tests.test_yake', '', 'test_n1_EN']]"
beartype,https://github.com/beartype/beartype/tree/master/beartype/_decor/_code/_pep/_pephint.py,,test_pep_code_check_hint,"for (hint_child_index, hint_child) in enumerate(hint_childs_pep):
    func_curr_code += PEP484_CODE_HINT_UNION_CHILD_PEP_format(hint_child_placeholder=_enqueue_hint_child(pith_curr_var_name if hint_childs_nonpep or hint_child_index else pith_curr_assign_expr))","for e_target in enumerate(hint_childs_pep):
    hint_child = e_target[1]
    hint_child_index = e_target[0]
    func_curr_code += PEP484_CODE_HINT_UNION_CHILD_PEP_format(hint_child_placeholder=_enqueue_hint_child(pith_curr_var_name if hint_childs_nonpep or hint_child_index else pith_curr_assign_expr))

",1,"[['https://github.com/beartype/beartype/tree/master/beartype_test/a00_unit/a90_decor/code/pep/test_codepephint.py', 'beartype_test.a00_unit.a90_decor.code.pep.test_codepephint', '', 'test_pep_code_check_hint']]"
beartype,https://github.com/beartype/beartype/tree/master/beartype/_decor/_code/_pep/_pephint.py,,test_pep_code_check_hint,"for (hint_child_index, hint_child) in enumerate(hint_childs):
    if is_hint_ignorable(hint_child):
        continue
    func_curr_code += PEP484585_CODE_HINT_TUPLE_FIXED_NONEMPTY_CHILD_format(hint_child_placeholder=_enqueue_hint_child(PEP484585_CODE_HINT_TUPLE_FIXED_NONEMPTY_PITH_CHILD_EXPR_format(pith_curr_var_name=pith_curr_var_name, pith_child_index=hint_child_index)))","for e_target in enumerate(hint_childs):
    hint_child = e_target[1]
    hint_child_index = e_target[0]
    if is_hint_ignorable(hint_child):
        continue
    func_curr_code += PEP484585_CODE_HINT_TUPLE_FIXED_NONEMPTY_CHILD_format(hint_child_placeholder=_enqueue_hint_child(PEP484585_CODE_HINT_TUPLE_FIXED_NONEMPTY_PITH_CHILD_EXPR_format(pith_curr_var_name=pith_curr_var_name, pith_child_index=hint_child_index)))

",1,"[['https://github.com/beartype/beartype/tree/master/beartype_test/a00_unit/a90_decor/code/pep/test_codepephint.py', 'beartype_test.a00_unit.a90_decor.code.pep.test_codepephint', '', 'test_pep_code_check_hint']]"
pampy,https://github.com/santinic/pampy/tree/master/pampy/pampy.py,IterableTests,test_match_asymmetric,"for (pkey, pval) in pattern.items():
    if pkey not in still_usable_pattern_keys:
        continue
    matched_left_and_right = False
    for (vkey, vval) in value.items():
        if vkey not in still_usable_value_keys:
            continue
        if pkey not in still_usable_pattern_keys:
            continue
        (key_matched, key_extracted) = match_value(pkey, vkey)
        if key_matched:
            (value_matched, value_extracted) = match_value(pval, vval)
            if value_matched:
                total_extracted += key_extracted + value_extracted
                matched_left_and_right = True
                still_usable_pattern_keys.remove(pkey)
                still_usable_value_keys.remove(vkey)
                break
    if not matched_left_and_right:
        return (False, [])","for e_target in pattern.items():
    pval = e_target[1]
    pkey = e_target[0]
    if pkey not in still_usable_pattern_keys:
        continue
    matched_left_and_right = False
    for (vkey, vval) in value.items():
        if vkey not in still_usable_value_keys:
            continue
        if pkey not in still_usable_pattern_keys:
            continue
        (key_matched, key_extracted) = match_value(pkey, vkey)
        if key_matched:
            (value_matched, value_extracted) = match_value(pval, vval)
            if value_matched:
                total_extracted += key_extracted + value_extracted
                matched_left_and_right = True
                still_usable_pattern_keys.remove(pkey)
                still_usable_value_keys.remove(vkey)
                break
    if not matched_left_and_right:
        return (False, [])

",1,"[['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_match_dict_ordering'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_multi_underscore_ambiguous'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_exclude_previously_used_keys'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_match_dict'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_match_nested'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_match_asymmetric']]"
pampy,https://github.com/santinic/pampy/tree/master/pampy/pampy.py,IterableTests,test_match_asymmetric,"for (vkey, vval) in value.items():
    if vkey not in still_usable_value_keys:
        continue
    if pkey not in still_usable_pattern_keys:
        continue
    (key_matched, key_extracted) = match_value(pkey, vkey)
    if key_matched:
        (value_matched, value_extracted) = match_value(pval, vval)
        if value_matched:
            total_extracted += key_extracted + value_extracted
            matched_left_and_right = True
            still_usable_pattern_keys.remove(pkey)
            still_usable_value_keys.remove(vkey)
            break","for e_target in value.items():
    vval = e_target[1]
    vkey = e_target[0]
    if vkey not in still_usable_value_keys:
        continue
    if pkey not in still_usable_pattern_keys:
        continue
    (key_matched, key_extracted) = match_value(pkey, vkey)
    if key_matched:
        (value_matched, value_extracted) = match_value(pval, vval)
        if value_matched:
            total_extracted += key_extracted + value_extracted
            matched_left_and_right = True
            still_usable_pattern_keys.remove(pkey)
            still_usable_value_keys.remove(vkey)
            break

",1,"[['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_match_dict_ordering'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_multi_underscore_ambiguous'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_exclude_previously_used_keys'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_match_dict'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_match_nested'], ['https://github.com/santinic/pampy/tree/master/tests/test_dict.py', 'tests.test_dict', 'IterableTests', 'test_match_asymmetric']]"
graphite-api,https://github.com/brutasse/graphite-api/tree/master/graphite_api/functions.py,FunctionsTest,test_keep_last_value,"for (i, value) in enumerate(series):
    series[i] = value
    if i == 0:
        continue
    if value is None:
        consecutiveNones += 1
    else:
        if 0 < consecutiveNones <= limit:
            for index in range(i - consecutiveNones, i):
                series[index] = series[i - consecutiveNones - 1]
        consecutiveNones = 0","for e_target in enumerate(series):
    value = e_target[1]
    i = e_target[0]
    series[i] = value
    if i == 0:
        continue
    if value is None:
        consecutiveNones += 1
    else:
        if 0 < consecutiveNones <= limit:
            for index in range(i - consecutiveNones, i):
                series[index] = series[i - consecutiveNones - 1]
        consecutiveNones = 0

",1,"[['https://github.com/brutasse/graphite-api/tree/master/tests/test_functions.py', 'tests.test_functions', 'FunctionsTest', 'test_keep_last_value']]"
graphite-api,https://github.com/brutasse/graphite-api/tree/master/graphite_api/_vendor/whisper.py,WhisperFinderTest,test_terminal_globstar,"for (secondsPerPoint, points) in archiveList:
    archiveInfo = struct.pack(archiveInfoFormat, archiveOffsetPointer, secondsPerPoint, points)
    fh.write(archiveInfo)
    archiveOffsetPointer += points * pointSize","for e_target in archiveList:
    points = e_target[1]
    secondsPerPoint = e_target[0]
    archiveInfo = struct.pack(archiveInfoFormat, archiveOffsetPointer, secondsPerPoint, points)
    fh.write(archiveInfo)
    archiveOffsetPointer += points * pointSize

",1,"[['https://github.com/brutasse/graphite-api/tree/master/tests/test_finders.py', 'tests.test_finders', 'WhisperFinderTest', 'test_multiple_globstars'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_finders.py', 'tests.test_finders', 'WhisperFinderTest', 'test_gzipped_whisper_finder'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_finders.py', 'tests.test_finders', 'WhisperFinderTest', 'test_whisper_finder'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_finders.py', 'tests.test_finders', 'WhisperFinderTest', 'test_globstar'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_finders.py', 'tests.test_finders', 'WhisperFinderTest', 'test_terminal_globstar']]"
graphite-api,https://github.com/brutasse/graphite-api/tree/master/graphite_api/render/glyph.py,glyphStandaloneFunctionTest,test_format_units_val_None_defaults,"for (prefix, size) in UnitSystems[system]:
    if condition(v, size, step):
        v2 = v / size
        if v2 - math.floor(v2) < 1e-11 and v > 1:
            v2 = float(math.floor(v2))
        if units:
            prefix = '%s%s' % (prefix, units)
        return (v2, prefix)","for e_target in UnitSystems[system]:
    size = e_target[1]
    prefix = e_target[0]
    if condition(v, size, step):
        v2 = v / size
        if v2 - math.floor(v2) < 1e-11 and v > 1:
            v2 = float(math.floor(v2))
        if units:
            prefix = '%s%s' % (prefix, units)
        return (v2, prefix)

",1,"[['https://github.com/brutasse/graphite-api/tree/master/tests/test_render_glyph.py', 'tests.test_render_glyph', 'glyphStandaloneFunctionTest', 'test_format_units_v_None_si'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_render_glyph.py', 'tests.test_render_glyph', 'glyphStandaloneFunctionTest', 'test_format_units_defaults'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_render_glyph.py', 'tests.test_render_glyph', 'glyphStandaloneFunctionTest', 'test_format_units_v_None_si_units'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_render_glyph.py', 'tests.test_render_glyph', 'glyphStandaloneFunctionTest', 'test_format_units_v_step_si_units'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_render_glyph.py', 'tests.test_render_glyph', 'glyphStandaloneFunctionTest', 'test_format_units_v_step_si'], ['https://github.com/brutasse/graphite-api/tree/master/tests/test_render_glyph.py', 'tests.test_render_glyph', 'glyphStandaloneFunctionTest', 'test_format_units_val_None_defaults']]"
elodie,https://github.com/jmathai/elodie/tree/master/elodie/localstorage.py,,test_get_all,"for (checksum, path) in self.hash_db.items():
    yield (checksum, path)","for e_target in self.hash_db.items():
    path = e_target[1]
    checksum = e_target[0]
    yield (checksum, path)

",1,"[['https://github.com/jmathai/elodie/tree/master/elodie/tests/localstorage_test.py', 'elodie.tests.localstorage_test', '', 'test_get_all_empty'], ['https://github.com/jmathai/elodie/tree/master/elodie/tests/localstorage_test.py', 'elodie.tests.localstorage_test', '', 'test_get_all']]"
mlens,https://github.com/flennerhag/mlens/tree/master/mlens/externals/sklearn/base.py,,test_check_ensemble_build_no_lc,"for (name, param) in six.iteritems(new_object_params):
    new_object_params[name] = clone(param, safe=False)","for e_target in six.iteritems(new_object_params):
    param = e_target[1]
    name = e_target[0]
    new_object_params[name] = clone(param, safe=False)

",1,"[['https://github.com/flennerhag/mlens/tree/master/mlens/estimators/tests/test_layer.py', 'mlens.estimators.tests.test_layer', '', 'test_layer_clone'], ['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_checks.py', 'mlens.utils.tests.test_checks', '', 'test_check_ensemble_build_lc_none_no_raise_'], ['https://github.com/flennerhag/mlens/tree/master/mlens/parallel/tests/test_d_wrapper.py', 'mlens.parallel.tests.test_d_wrapper', '', 'test_clone'], ['https://github.com/flennerhag/mlens/tree/master/mlens/estimators/tests/test_transformer.py', 'mlens.estimators.tests.test_transformer', '', 'test_learner_clone'], ['https://github.com/flennerhag/mlens/tree/master/mlens/estimators/tests/test_learner.py', 'mlens.estimators.tests.test_learner', '', 'test_learner_clone'], ['https://github.com/flennerhag/mlens/tree/master/mlens/ensemble/tests/test_base.py', 'mlens.ensemble.tests.test_base', '', 'test_clone'], ['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_checks.py', 'mlens.utils.tests.test_checks', '', 'test_check_ensemble_build_lc_none'], ['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_checks.py', 'mlens.utils.tests.test_checks', '', 'test_check_ensemble_build_no_lc']]"
mlens,https://github.com/flennerhag/mlens/tree/master/mlens/utils/formatting.py,,test_formatting_list,"for (name, instance) in named_instances:
    if name in duplicates:
        current_name_count = name_count[name]
        name_count[name] += 1
        name += '-%d' % current_name_count
    out.append((name, instance))","for e_target in named_instances:
    instance = e_target[1]
    name = e_target[0]
    if name in duplicates:
        current_name_count = name_count[name]
        name_count[name] += 1
        name += '-%d' % current_name_count
    out.append((name, instance))

",1,"[['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_dummy.py', 'mlens.utils.tests.test_dummy', '', 'test_estimator_lists'], ['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_formatting.py', 'mlens.utils.tests.test_formatting', '', 'test_formatting_list']]"
mlens,https://github.com/flennerhag/mlens/tree/master/mlens/utils/formatting.py,,test_formatting_list,"for (case, instance_list) in sorted(instances_dict.items()):
    case = '-'.join(case.lower().split())
    if not instance_list:
        vacuous.append((case, instance_list))
        continue
    for val in instance_list:
        instances.append(val)
        if isinstance(val, (list, tuple, set)):
            val = val[1]
        case_map[val] = case","for e_target in sorted(instances_dict.items()):
    instance_list = e_target[1]
    case = e_target[0]
    case = '-'.join(case.lower().split())
    if not instance_list:
        vacuous.append((case, instance_list))
        continue
    for val in instance_list:
        instances.append(val)
        if isinstance(val, (list, tuple, set)):
            val = val[1]
        case_map[val] = case

",1,"[['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_dummy.py', 'mlens.utils.tests.test_dummy', '', 'test_estimator_lists'], ['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_formatting.py', 'mlens.utils.tests.test_formatting', '', 'test_formatting_list']]"
mlens,https://github.com/flennerhag/mlens/tree/master/mlens/utils/formatting.py,,test_formatting_list,"for (name, instance) in out:
    case = case_map[instance]
    if case not in nested_out:
        nested_out[case] = list()
    nested_out[case].append((name, instance))","for e_target in out:
    instance = e_target[1]
    name = e_target[0]
    case = case_map[instance]
    if case not in nested_out:
        nested_out[case] = list()
    nested_out[case].append((name, instance))

",1,"[['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_dummy.py', 'mlens.utils.tests.test_dummy', '', 'test_estimator_lists'], ['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_formatting.py', 'mlens.utils.tests.test_formatting', '', 'test_formatting_list']]"
mlens,https://github.com/flennerhag/mlens/tree/master/mlens/utils/formatting.py,,test_formatting_list,"for (k, v) in vacuous:
    nested_out[k] = v","for e_target in vacuous:
    v = e_target[1]
    k = e_target[0]
    nested_out[k] = v

",1,"[['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_dummy.py', 'mlens.utils.tests.test_dummy', '', 'test_estimator_lists'], ['https://github.com/flennerhag/mlens/tree/master/mlens/utils/tests/test_formatting.py', 'mlens.utils.tests.test_formatting', '', 'test_formatting_list']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_split_node_of_node_without_backend_raises_error,"for (i, edge) in enumerate(left_edges):
    left_node.add_edge(edge, i)
    edge.update_axis(left_axes_order[i], node, i, left_node)","for e_target in enumerate(left_edges):
    edge = e_target[1]
    i = e_target[0]
    left_node.add_edge(edge, i)
    edge.update_axis(left_axes_order[i], node, i, left_node)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/network_operations_test.py', 'tensornetwork.tests.network_operations_test', '', 'test_split_node_of_node_without_backend_raises_error']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_split_node_of_node_without_backend_raises_error,"for (i, edge) in enumerate(right_edges):
    right_node.add_edge(edge, i + 1)
    edge.update_axis(right_axes_order[i], node, i + 1, right_node)","for e_target in enumerate(right_edges):
    edge = e_target[1]
    i = e_target[0]
    right_node.add_edge(edge, i + 1)
    edge.update_axis(right_axes_order[i], node, i + 1, right_node)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/network_operations_test.py', 'tensornetwork.tests.network_operations_test', '', 'test_split_node_of_node_without_backend_raises_error']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_split_node_qr_of_node_without_backend_raises_error,"for (i, edge) in enumerate(left_edges):
    left_node.add_edge(edge, i)
    edge.update_axis(left_axes_order[i], node, i, left_node)","for e_target in enumerate(left_edges):
    edge = e_target[1]
    i = e_target[0]
    left_node.add_edge(edge, i)
    edge.update_axis(left_axes_order[i], node, i, left_node)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/network_operations_test.py', 'tensornetwork.tests.network_operations_test', '', 'test_split_node_qr_of_node_without_backend_raises_error']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_split_node_qr_of_node_without_backend_raises_error,"for (i, edge) in enumerate(right_edges):
    right_node.add_edge(edge, i + 1)
    edge.update_axis(right_axes_order[i], node, i + 1, right_node)","for e_target in enumerate(right_edges):
    edge = e_target[1]
    i = e_target[0]
    right_node.add_edge(edge, i + 1)
    edge.update_axis(right_axes_order[i], node, i + 1, right_node)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/network_operations_test.py', 'tensornetwork.tests.network_operations_test', '', 'test_split_node_qr_of_node_without_backend_raises_error']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_split_node_rq_of_node_without_backend_raises_error,"for (i, edge) in enumerate(left_edges):
    left_node.add_edge(edge, i)
    edge.update_axis(left_axes_order[i], node, i, left_node)","for e_target in enumerate(left_edges):
    edge = e_target[1]
    i = e_target[0]
    left_node.add_edge(edge, i)
    edge.update_axis(left_axes_order[i], node, i, left_node)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/network_operations_test.py', 'tensornetwork.tests.network_operations_test', '', 'test_split_node_rq_of_node_without_backend_raises_error']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_split_node_rq_of_node_without_backend_raises_error,"for (i, edge) in enumerate(right_edges):
    right_node.add_edge(edge, i + 1)
    edge.update_axis(right_axes_order[i], node, i + 1, right_node)","for e_target in enumerate(right_edges):
    edge = e_target[1]
    i = e_target[0]
    right_node.add_edge(edge, i + 1)
    edge.update_axis(right_axes_order[i], node, i + 1, right_node)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/network_operations_test.py', 'tensornetwork.tests.network_operations_test', '', 'test_split_node_rq_of_node_without_backend_raises_error']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_split_node_full_svd_of_node_without_backend_raises_error,"for (i, edge) in enumerate(left_edges):
    left_node.add_edge(edge, i)
    edge.update_axis(left_axes_order[i], node, i, left_node)","for e_target in enumerate(left_edges):
    edge = e_target[1]
    i = e_target[0]
    left_node.add_edge(edge, i)
    edge.update_axis(left_axes_order[i], node, i, left_node)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/network_operations_test.py', 'tensornetwork.tests.network_operations_test', '', 'test_split_node_full_svd_of_node_without_backend_raises_error']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_split_node_full_svd_of_node_without_backend_raises_error,"for (i, edge) in enumerate(right_edges):
    right_node.add_edge(edge, i + 1)
    edge.update_axis(right_axes_order[i], node, i + 1, right_node)","for e_target in enumerate(right_edges):
    edge = e_target[1]
    i = e_target[0]
    right_node.add_edge(edge, i + 1)
    edge.update_axis(right_axes_order[i], node, i + 1, right_node)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/network_operations_test.py', 'tensornetwork.tests.network_operations_test', '', 'test_split_node_full_svd_of_node_without_backend_raises_error']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_serial_exclude_non_network_edges,"for (i, node) in enumerate(nodes):
    node_id_dict[node] = i
    network_dict['nodes'].append({'id': i, 'attributes': node.to_serial_dict()})","for e_target in enumerate(nodes):
    node = e_target[1]
    i = e_target[0]
    node_id_dict[node] = i
    network_dict['nodes'].append({'id': i, 'attributes': node.to_serial_dict()})

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_with_bindings'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_non_str_keys'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_basic_serial'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_exlcuded_node_serial'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_non_edge_values'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_exclude_non_network_edges']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_serial_exclude_non_network_edges,"for (i, edge) in enumerate(edges):
    edge_id_dict[edge] = i
    node_ids = [node_id_dict.get(n) for n in edge.get_nodes()]
    attributes = edge.to_serial_dict()
    attributes['axes'] = [a if node_ids[j] is not None else None for (j, a) in enumerate(attributes['axes'])]
    edge_dict = {'id': i, 'node_ids': node_ids, 'attributes': attributes}
    network_dict['edges'].append(edge_dict)","for e_target in enumerate(edges):
    edge = e_target[1]
    i = e_target[0]
    edge_id_dict[edge] = i
    node_ids = [node_id_dict.get(n) for n in edge.get_nodes()]
    attributes = edge.to_serial_dict()
    attributes['axes'] = [a if node_ids[j] is not None else None for (j, a) in enumerate(attributes['axes'])]
    edge_dict = {'id': i, 'node_ids': node_ids, 'attributes': attributes}
    network_dict['edges'].append(edge_dict)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_with_bindings'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_non_str_keys'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_basic_serial'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_exlcuded_node_serial'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_non_edge_values'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_exclude_non_network_edges']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_serial_exclude_non_network_edges,"for (k, v) in network_dict.get('edge_binding', {}).items():
    for e_id in v:
        edge_binding[k] = edge_binding.get(k, ()) + (edge_lookup[e_id],)","for e_target in network_dict.get('edge_binding', {}).items():
    v = e_target[1]
    k = e_target[0]
    for e_id in v:
        edge_binding[k] = edge_binding.get(k, ()) + (edge_lookup[e_id],)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_basic_serial'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_exlcuded_node_serial'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_with_bindings'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_exclude_non_network_edges']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/network_operations.py,,test_serial_exclude_non_network_edges,"for (node, axis) in zip(e_nodes, axes):
    if node is not None:
        node.add_edge(edge, axis, override=True)","for e_target in zip(e_nodes, axes):
    axis = e_target[1]
    node = e_target[0]
    if node is not None:
        node.add_edge(edge, axis, override=True)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_basic_serial'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_exlcuded_node_serial'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_with_bindings'], ['https://github.com/google/TensorNetwork/tree/master/tensornetwork/tests/serialize_test.py', 'tensornetwork.tests.serialize_test', '', 'test_serial_exclude_non_network_edges']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg.py,,test_diag_raises,"for (n, block) in enumerate(blocks):
    label = labels[np.nonzero(unique == charges[n])[0][0]]
    data[block] = np.ravel(np.diag(tensor.data[np.nonzero(lookup == label)[0]]))","for e_target in enumerate(blocks):
    block = e_target[1]
    n = e_target[0]
    label = labels[np.nonzero(unique == charges[n])[0][0]]
    data[block] = np.ravel(np.diag(tensor.data[np.nonzero(lookup == label)[0]]))

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg_test.py', 'tensornetwork.block_sparse.linalg_test', '', 'test_diag_raises']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg.py,,test_svd_raises,"for (n, block) in enumerate(blocks):
    out = np.linalg.svd(np.reshape(matrix.data[block], shapes[:, n]), full_matrices, compute_uv, hermitian)
    if compute_uv:
        u_blocks.append(out[0])
        singvals.append(out[1])
        v_blocks.append(out[2])
    else:
        singvals.append(out)","for e_target in enumerate(blocks):
    block = e_target[1]
    n = e_target[0]
    out = np.linalg.svd(np.reshape(matrix.data[block], shapes[:, n]), full_matrices, compute_uv, hermitian)
    if compute_uv:
        u_blocks.append(out[0])
        singvals.append(out[1])
        v_blocks.append(out[2])
    else:
        singvals.append(out)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg_test.py', 'tensornetwork.block_sparse.linalg_test', '', 'test_svd_raises']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg.py,,test_eigh_raises,"for (n, block) in enumerate(blocks):
    (e, v) = np.linalg.eigh(np.reshape(matrix.data[block], shapes[:, n]), UPLO)
    eigvals.append(e)
    v_blocks.append(v)","for e_target in enumerate(blocks):
    block = e_target[1]
    n = e_target[0]
    (e, v) = np.linalg.eigh(np.reshape(matrix.data[block], shapes[:, n]), UPLO)
    eigvals.append(e)
    v_blocks.append(v)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg_test.py', 'tensornetwork.block_sparse.linalg_test', '', 'test_eigh_raises']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg.py,,test_eig_raises,"for (n, block) in enumerate(blocks):
    (e, v) = np.linalg.eig(np.reshape(matrix.data[block], shapes[:, n]))
    eigvals.append(e)
    v_blocks.append(v)","for e_target in enumerate(blocks):
    block = e_target[1]
    n = e_target[0]
    (e, v) = np.linalg.eig(np.reshape(matrix.data[block], shapes[:, n]))
    eigvals.append(e)
    v_blocks.append(v)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg_test.py', 'tensornetwork.block_sparse.linalg_test', '', 'test_eig_raises']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg.py,,test_inv_raises,"for (n, block) in enumerate(blocks):
    data[block] = np.ravel(np.linalg.inv(np.reshape(matrix.data[block], shapes[:, n])).T)","for e_target in enumerate(blocks):
    block = e_target[1]
    n = e_target[0]
    data[block] = np.ravel(np.linalg.inv(np.reshape(matrix.data[block], shapes[:, n])).T)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg_test.py', 'tensornetwork.block_sparse.linalg_test', '', 'test_inv_raises']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg.py,,test_pinv_raises,"for (n, block) in enumerate(blocks):
    data[block] = np.ravel(np.linalg.pinv(np.reshape(matrix.data[block], shapes[:, n]), rcond=rcond, hermitian=hermitian).T)","for e_target in enumerate(blocks):
    block = e_target[1]
    n = e_target[0]
    data[block] = np.ravel(np.linalg.pinv(np.reshape(matrix.data[block], shapes[:, n]), rcond=rcond, hermitian=hermitian).T)

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/linalg_test.py', 'tensornetwork.block_sparse.linalg_test', '', 'test_pinv_raises']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/charge.py,,test_reduce_charges_2,"for (n, ct) in enumerate(charge_types):
    comb_charges[n] = ct.fuse(charges_A[:, n], charges_B[:, n])[:, None]","for e_target in enumerate(charge_types):
    ct = e_target[1]
    n = e_target[0]
    comb_charges[n] = ct.fuse(charges_A[:, n], charges_B[:, n])[:, None]

",1,"[['https://github.com/google/TensorNetwork/tree/master/tensornetwork/block_sparse/blocksparse_utils_test.py', 'tensornetwork.block_sparse.blocksparse_utils_test', '', 'test_reduce_charges_2']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/examples/fft/fft.py,,test_fft,"for (k, t) in enumerate(targets):
    incoming_state = state[t]
    receiving_port = op_node[k]
    output_port = op_node[k + len(targets)]
    incoming_state ^ receiving_port
    state[t] = output_port","for e_target in enumerate(targets):
    t = e_target[1]
    k = e_target[0]
    incoming_state = state[t]
    receiving_port = op_node[k]
    output_port = op_node[k + len(targets)]
    incoming_state ^ receiving_port
    state[t] = output_port

",1,"[['https://github.com/google/TensorNetwork/tree/master/examples/fft/fft_test.py', 'examples.fft.fft_test', '', 'test_fft']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork.py,,test_solutions,"for (i, var) in enumerate(clause):
    copy_tensor_node = tn.CopyNode(3, 2)
    clause_node[i] ^ copy_tensor_node[0]
    var_edges[abs(var) - 1] ^ copy_tensor_node[1]
    var_edges[abs(var) - 1] = copy_tensor_node[2]","for e_target in enumerate(clause):
    var = e_target[1]
    i = e_target[0]
    copy_tensor_node = tn.CopyNode(3, 2)
    clause_node[i] ^ copy_tensor_node[0]
    var_edges[abs(var) - 1] ^ copy_tensor_node[1]
    var_edges[abs(var) - 1] = copy_tensor_node[2]

",1,"[['https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork_test.py', 'examples.sat.sat_tensornetwork_test', '', 'test_solutions']]"
TensorNetwork,https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork.py,,test_sanity_check,"for (edge1, edge2) in zip(var_edges1, var_edges2):
    edge1 ^ edge2","for e_target in zip(var_edges1, var_edges2):
    edge2 = e_target[1]
    edge1 = e_target[0]
    edge1 ^ edge2

",1,"[['https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork_test.py', 'examples.sat.sat_tensornetwork_test', '', 'test_four_variables'], ['https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork_test.py', 'examples.sat.sat_tensornetwork_test', '', 'test_four_variables_four_clauses'], ['https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork_test.py', 'examples.sat.sat_tensornetwork_test', '', 'test_many_clauses'], ['https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork_test.py', 'examples.sat.sat_tensornetwork_test', '', 'test_single_variable'], ['https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork_test.py', 'examples.sat.sat_tensornetwork_test', '', 'test_dual_clauses'], ['https://github.com/google/TensorNetwork/tree/master/examples/sat/sat_tensornetwork_test.py', 'examples.sat.sat_tensornetwork_test', '', 'test_sanity_check']]"
sheetfu,https://github.com/socialpoint-labs/sheetfu/tree/master/sheetfu/helpers.py,TestA1ColumnToCoordinateColumn,test_convert_letter_to_multiple_high_letters,"for (i, letter) in enumerate(letters_string):
    letter_index = string.ascii_uppercase.index(letter.capitalize()) + index_to_row_offset
    power = len(letters_string) - (i + 1)
    number_of_columns = letter_index * math.pow(len(string.ascii_uppercase), power)
    column_number += number_of_columns","for e_target in enumerate(letters_string):
    letter = e_target[1]
    i = e_target[0]
    letter_index = string.ascii_uppercase.index(letter.capitalize()) + index_to_row_offset
    power = len(letters_string) - (i + 1)
    number_of_columns = letter_index * math.pow(len(string.ascii_uppercase), power)
    column_number += number_of_columns

",1,"[['https://github.com/socialpoint-labs/sheetfu/tree/master/tests/test_a1_converters.py', 'tests.test_a1_converters', 'TestA1ColumnToCoordinateColumn', 'test_convert_letter_to_multiple_letters'], ['https://github.com/socialpoint-labs/sheetfu/tree/master/tests/test_a1_converters.py', 'tests.test_a1_converters', 'TestA1ColumnToCoordinateColumn', 'test_convert_letter_to_column'], ['https://github.com/socialpoint-labs/sheetfu/tree/master/tests/test_a1_converters.py', 'tests.test_a1_converters', 'TestA1ColumnToCoordinateColumn', 'test_convert_letter_to_multiple_very_high_letters'], ['https://github.com/socialpoint-labs/sheetfu/tree/master/tests/test_a1_converters.py', 'tests.test_a1_converters', 'TestA1ColumnToCoordinateColumn', 'test_convert_letter_to_multiple_high_letters']]"
policy_sentry,https://github.com/salesforce/policy_sentry/tree/master/policy_sentry/querying/actions.py,QueryActionsTestCase,test_get_action_data,"for (this_action_name, this_action_data) in service_prefix_data['privileges'].items():
    condition_keys = []
    dependent_actions = []
    rows = []
    rows.clear()
    if action_name == '*':
        for resource_type_entry in this_action_data['resource_types']:
            rows.append(this_action_data['resource_types'][resource_type_entry])
    else:
        for resource_type_entry in this_action_data['resource_types']:
            if this_action_name.lower() == action_name.lower():
                rows.append(this_action_data['resource_types'][resource_type_entry])
    for row in rows:
        resource_arn_format = '*'
        if row['dependent_actions']:
            dependent_actions.extend(row['dependent_actions'])
        for (service_resource_name, service_resource_data) in service_prefix_data['resources'].items():
            if row['resource_type'] == '':
                continue
            if row['resource_type'].strip('*') == service_resource_data['resource']:
                resource_arn_format = service_resource_data.get('arn', '*')
                condition_keys = service_resource_data.get('condition_keys')
                break
        temp_dict = {'action': f""{service_prefix_data['prefix']}:{this_action_name}"", 'description': this_action_data['description'], 'access_level': this_action_data['access_level'], 'api_documentation_link': this_action_data.get('api_documentation_link'), 'resource_arn_format': resource_arn_format, 'condition_keys': condition_keys, 'dependent_actions': dependent_actions}
        results.append(temp_dict)","for e_target in service_prefix_data['privileges'].items():
    this_action_data = e_target[1]
    this_action_name = e_target[0]
    condition_keys = []
    dependent_actions = []
    rows = []
    rows.clear()
    if action_name == '*':
        for resource_type_entry in this_action_data['resource_types']:
            rows.append(this_action_data['resource_types'][resource_type_entry])
    else:
        for resource_type_entry in this_action_data['resource_types']:
            if this_action_name.lower() == action_name.lower():
                rows.append(this_action_data['resource_types'][resource_type_entry])
    for row in rows:
        resource_arn_format = '*'
        if row['dependent_actions']:
            dependent_actions.extend(row['dependent_actions'])
        for (service_resource_name, service_resource_data) in service_prefix_data['resources'].items():
            if row['resource_type'] == '':
                continue
            if row['resource_type'].strip('*') == service_resource_data['resource']:
                resource_arn_format = service_resource_data.get('arn', '*')
                condition_keys = service_resource_data.get('condition_keys')
                break
        temp_dict = {'action': f""{service_prefix_data['prefix']}:{this_action_name}"", 'description': this_action_data['description'], 'access_level': this_action_data['access_level'], 'api_documentation_link': this_action_data.get('api_documentation_link'), 'resource_arn_format': resource_arn_format, 'condition_keys': condition_keys, 'dependent_actions': dependent_actions}
        results.append(temp_dict)

",1,"[['https://github.com/salesforce/policy_sentry/tree/master/test/querying/test_query_actions.py', 'test.querying.test_query_actions', 'QueryActionsTestCase', 'test_get_action_data']]"
policy_sentry,https://github.com/salesforce/policy_sentry/tree/master/policy_sentry/querying/actions.py,QueryActionsTestCase,test_get_action_data,"for (service_resource_name, service_resource_data) in service_prefix_data['resources'].items():
    if row['resource_type'] == '':
        continue
    if row['resource_type'].strip('*') == service_resource_data['resource']:
        resource_arn_format = service_resource_data.get('arn', '*')
        condition_keys = service_resource_data.get('condition_keys')
        break","for e_target in service_prefix_data['resources'].items():
    service_resource_data = e_target[1]
    service_resource_name = e_target[0]
    if row['resource_type'] == '':
        continue
    if row['resource_type'].strip('*') == service_resource_data['resource']:
        resource_arn_format = service_resource_data.get('arn', '*')
        condition_keys = service_resource_data.get('condition_keys')
        break

",1,"[['https://github.com/salesforce/policy_sentry/tree/master/test/querying/test_query_actions.py', 'test.querying.test_query_actions', 'QueryActionsTestCase', 'test_get_action_data']]"
policy_sentry,https://github.com/salesforce/policy_sentry/tree/master/policy_sentry/querying/conditions.py,QueryConditionsTestCase,test_get_condition_key_details,"for (condition_name, condition_data) in service_prefix_data['conditions'].items():
    if is_condition_key_match(condition_data['condition'], condition_key_name):
        output = {'name': condition_data['condition'], 'description': condition_data['description'], 'condition_value_type': condition_data['type'].lower()}
        return output","for e_target in service_prefix_data['conditions'].items():
    condition_data = e_target[1]
    condition_name = e_target[0]
    if is_condition_key_match(condition_data['condition'], condition_key_name):
        output = {'name': condition_data['condition'], 'description': condition_data['description'], 'condition_value_type': condition_data['type'].lower()}
        return output

",1,"[['https://github.com/salesforce/policy_sentry/tree/master/test/querying/test_query_conditions.py', 'test.querying.test_query_conditions', 'QueryConditionsTestCase', 'test_get_condition_key_details']]"
policy_sentry,https://github.com/salesforce/policy_sentry/tree/master/policy_sentry/querying/arns.py,QueryArnsTestCase,test_get_arn_data,"for (resource_name, resource_data) in service_prefix_data['resources'].items():
    if resource_data['resource'].lower() == resource_type_name.lower():
        output = {'resource_type_name': resource_data['resource'], 'raw_arn': resource_data['arn'], 'condition_keys': resource_data['condition_keys']}
        results.append(output)","for e_target in service_prefix_data['resources'].items():
    resource_data = e_target[1]
    resource_name = e_target[0]
    if resource_data['resource'].lower() == resource_type_name.lower():
        output = {'resource_type_name': resource_data['resource'], 'raw_arn': resource_data['arn'], 'condition_keys': resource_data['condition_keys']}
        results.append(output)

",1,"[['https://github.com/salesforce/policy_sentry/tree/master/test/querying/test_query_arns.py', 'test.querying.test_query_arns', 'QueryArnsTestCase', 'test_get_arn_data']]"
xlwt,https://github.com/python-excel/xlwt/tree/master/xlwt/UnicodeUtils.py,TestUpack,test_upack2rt,"for (s, fontx) in rt:
    if not isinstance(s, six.text_type):
        s = s.decode(encoding)
    us += s
    if fontx is not None:
        fr += pack('<HH', offset, fontx)
    offset += len(s.encode('utf_16_le')) // 2","for e_target in rt:
    fontx = e_target[1]
    s = e_target[0]
    if not isinstance(s, six.text_type):
        s = s.decode(encoding)
    us += s
    if fontx is not None:
        fr += pack('<HH', offset, fontx)
    offset += len(s.encode('utf_16_le')) // 2

",1,"[['https://github.com/python-excel/xlwt/tree/master/tests/test_unicodeutils.py', 'tests.test_unicodeutils', 'TestUpack', 'test_upack2rt']]"
xlwt,https://github.com/python-excel/xlwt/tree/master/xlwt/BIFFRecords.py,TestSharedStringTable,test_shared_string_table,"for (idx, s) in data:
    if self._tally[idx] == 0:
        s = ''
    if isinstance(s, six.string_types):
        self._add_to_sst(s)
    else:
        self._add_rt_to_sst(s)","for e_target in data:
    s = e_target[1]
    idx = e_target[0]
    if self._tally[idx] == 0:
        s = ''
    if isinstance(s, six.string_types):
        self._add_to_sst(s)
    else:
        self._add_rt_to_sst(s)

",1,"[['https://github.com/python-excel/xlwt/tree/master/tests/test_biff_records.py', 'tests.test_biff_records', 'TestSharedStringTable', 'test_shared_string_table']]"
xlwt,https://github.com/python-excel/xlwt/tree/master/xlwt/CompoundDoc.py,TestXlsDoc,test_build_header,"for (i, SAT_sect_num) in zip(range(0, 109), self.SAT_sect):
    MSAT_1st[i] = SAT_sect_num","for e_target in zip(range(0, 109), self.SAT_sect):
    SAT_sect_num = e_target[1]
    i = e_target[0]
    MSAT_1st[i] = SAT_sect_num

",1,"[['https://github.com/python-excel/xlwt/tree/master/tests/test_compound_doc.py', 'tests.test_compound_doc', 'TestXlsDoc', 'test_build_sat'], ['https://github.com/python-excel/xlwt/tree/master/tests/test_compound_doc.py', 'tests.test_compound_doc', 'TestXlsDoc', 'test_build_header']]"
Deep-Reinforcement-Learning-Hands-On,https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/tree/master/Chapter18/lib/model.py,TestEncoding,test_encoding,"for (idx, (state, who_move)) in enumerate(zip(state_lists, who_moves_lists)):
    _encode_list_state(batch[idx], state, who_move)","for e_target in enumerate(zip(state_lists, who_moves_lists)):
    who_move = e_target[1][1]
    state = e_target[1][0]
    idx = e_target[0]
    _encode_list_state(batch[idx], state, who_move)

",1,"[['https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/tree/master/Chapter18/tests/test_model.py', 'Chapter18.tests.test_model', 'TestEncoding', 'test_encoding']]"
quandl-python,https://github.com/quandl/quandl-python/tree/master/quandl/util.py,UtilTest,test_convert_to_dates,"for (k, v) in list(dic_or_list.items()):
    dic_or_list[k] = Util.convert_to_dates(v)","for e_target in list(dic_or_list.items()):
    v = e_target[1]
    k = e_target[0]
    dic_or_list[k] = Util.convert_to_dates(v)

",1,"[['https://github.com/quandl/quandl-python/tree/master/test/test_util.py', 'test.test_util', 'UtilTest', 'test_convert_to_dates']]"
quandl-python,https://github.com/quandl/quandl-python/tree/master/quandl/util.py,UtilTest,test_convert_to_dates,"for (idx, v) in enumerate(dic_or_list):
    dic_or_list[idx] = Util.convert_to_dates(v)","for e_target in enumerate(dic_or_list):
    v = e_target[1]
    idx = e_target[0]
    dic_or_list[idx] = Util.convert_to_dates(v)

",1,"[['https://github.com/quandl/quandl-python/tree/master/test/test_util.py', 'test.test_util', 'UtilTest', 'test_convert_to_dates']]"
httpx,https://github.com/encode/httpx/tree/master/httpx/_models.py,,test_url_copywith_raw_path,"for (key, value) in kwargs.items():
    if key not in allowed:
        message = f'{key!r} is an invalid keyword argument for copy_with()'
        raise TypeError(message)
    if value is not None and (not isinstance(value, allowed[key])):
        expected = allowed[key].__name__
        seen = type(value).__name__
        message = f'Argument {key!r} must be {expected} but got {seen}'
        raise TypeError(message)","for e_target in kwargs.items():
    value = e_target[1]
    key = e_target[0]
    if key not in allowed:
        message = f'{key!r} is an invalid keyword argument for copy_with()'
        raise TypeError(message)
    if value is not None and (not isinstance(value, allowed[key])):
        expected = allowed[key].__name__
        seen = type(value).__name__
        message = f'Argument {key!r} must be {expected} but got {seen}'
        raise TypeError(message)

",1,"[['https://github.com/encode/httpx/tree/master/tests/models/test_url.py', 'tests.models.test_url', '', 'test_url_copywith_userinfo_subcomponents'], ['https://github.com/encode/httpx/tree/master/tests/models/test_url.py', 'tests.models.test_url', '', 'test_url'], ['https://github.com/encode/httpx/tree/master/tests/models/test_url.py', 'tests.models.test_url', '', 'test_url_copywith_query'], ['https://github.com/encode/httpx/tree/master/tests/models/test_url.py', 'tests.models.test_url', '', 'test_url_copywith_netloc'], ['https://github.com/encode/httpx/tree/master/tests/models/test_url.py', 'tests.models.test_url', '', 'test_url_copywith_invalid_component'], ['https://github.com/encode/httpx/tree/master/tests/models/test_url.py', 'tests.models.test_url', '', 'test_url_copywith_authority_subcomponents'], ['https://github.com/encode/httpx/tree/master/tests/models/test_url.py', 'tests.models.test_url', '', 'test_url_copywith_urlencoded_path'], ['https://github.com/encode/httpx/tree/master/tests/models/test_url.py', 'tests.models.test_url', '', 'test_url_copywith_raw_path']]"
httpx,https://github.com/encode/httpx/tree/master/httpx/_models.py,,test_headers,"for (_, key, value) in self._list:
    str_key = key.decode(self.encoding)
    str_value = value.decode(self.encoding)
    if str_key in values_dict:
        values_dict[str_key] += f', {str_value}'
    else:
        values_dict[str_key] = str_value","for e_target in self._list:
    value = e_target[2]
    key = e_target[1]
    _ = e_target[0]
    str_key = key.decode(self.encoding)
    str_value = value.decode(self.encoding)
    if str_key in values_dict:
        values_dict[str_key] += f', {str_value}'
    else:
        values_dict[str_key] = str_value

",1,"[['https://github.com/encode/httpx/tree/master/tests/models/test_headers.py', 'tests.models.test_headers', '', 'test_headers_insert_retains_ordering'], ['https://github.com/encode/httpx/tree/master/tests/models/test_headers.py', 'tests.models.test_headers', '', 'test_headers_insert_appends_if_new'], ['https://github.com/encode/httpx/tree/master/tests/models/test_headers.py', 'tests.models.test_headers', '', 'test_headers']]"
fairlearn,https://github.com/fairlearn/fairlearn/tree/master/fairlearn/show_versions.py,,test_smoke,"for (k, stat) in sys_info.items():
    print('{k:>10}: {stat}'.format(k=k, stat=stat))","for e_target in sys_info.items():
    stat = e_target[1]
    k = e_target[0]
    print('{k:>10}: {stat}'.format(k=k, stat=stat))

",1,"[['https://github.com/fairlearn/fairlearn/tree/master/test/unit/test_show_versions.py', 'test.unit.test_show_versions', '', 'test_smoke']]"
fairlearn,https://github.com/fairlearn/fairlearn/tree/master/fairlearn/show_versions.py,,test_smoke,"for (k, stat) in deps_info.items():
    print('{k:>10}: {stat}'.format(k=k, stat=stat))","for e_target in deps_info.items():
    stat = e_target[1]
    k = e_target[0]
    print('{k:>10}: {stat}'.format(k=k, stat=stat))

",1,"[['https://github.com/fairlearn/fairlearn/tree/master/test/unit/test_show_versions.py', 'test.unit.test_show_versions', '', 'test_smoke']]"
fairlearn,https://github.com/fairlearn/fairlearn/tree/master/fairlearn/postprocessing/_tradeoff_curve_utilities.py,,test_calculate_tradeoff_points,"for (operation_string, counts) in operations:
    x = METRIC_DICT[x_metric](counts)
    y = METRIC_DICT[y_metric](counts)
    operation = ThresholdOperation(operation_string, threshold)
    x_list.append(x)
    y_list.append(y)
    operation_list.append(operation)","for e_target in operations:
    counts = e_target[1]
    operation_string = e_target[0]
    x = METRIC_DICT[x_metric](counts)
    y = METRIC_DICT[y_metric](counts)
    operation = ThresholdOperation(operation_string, threshold)
    x_list.append(x)
    y_list.append(y)
    operation_list.append(operation)

",1,"[['https://github.com/fairlearn/fairlearn/tree/master/test/unit/postprocessing/test_curve_utilities.py', 'test.unit.postprocessing.test_curve_utilities', '', 'test_calculate_tradeoff_points']]"
fairlearn,https://github.com/fairlearn/fairlearn/tree/master/fairlearn/metrics/_group_metric_set.py,TestProcessSensitiveFeatures,test_result_is_sorted,"for (column_name, column) in sensitive_features.items():
    nxt = dict()
    nxt[_FEATURE_BIN_NAME] = column_name
    np_column = _convert_to_ndarray_and_squeeze(column)
    le = preprocessing.LabelEncoder()
    nxt[_BIN_VECTOR] = [int(x) for x in list(le.fit_transform(np_column))]
    nxt[_BIN_LABELS] = [str(x) for x in le.classes_]
    unsorted_features.append(nxt)","for e_target in sensitive_features.items():
    column = e_target[1]
    column_name = e_target[0]
    nxt = dict()
    nxt[_FEATURE_BIN_NAME] = column_name
    np_column = _convert_to_ndarray_and_squeeze(column)
    le = preprocessing.LabelEncoder()
    nxt[_BIN_VECTOR] = [int(x) for x in list(le.fit_transform(np_column))]
    nxt[_BIN_LABELS] = [str(x) for x in le.classes_]
    unsorted_features.append(nxt)

",1,"[['https://github.com/fairlearn/fairlearn/tree/master/test/unit/metrics/test_create_group_metric_set.py', 'test.unit.metrics.test_create_group_metric_set', 'TestProcessSensitiveFeatures', 'test_result_is_sorted']]"
fairlearn,https://github.com/fairlearn/fairlearn/tree/master/fairlearn/metrics/_function_container.py,,test_generate_sample_params_for_mask,"for (name, value) in self.sample_params_.items():
    curr_sample_params[name] = value[mask]","for e_target in self.sample_params_.items():
    value = e_target[1]
    name = e_target[0]
    curr_sample_params[name] = value[mask]

",1,"[['https://github.com/fairlearn/fairlearn/tree/master/test/unit/metrics/test_function_container.py', 'test.unit.metrics.test_function_container', '', 'test_generate_sample_params_for_mask']]"
pony,https://github.com/ponyorm/pony/tree/master/pony/orm/core.py,TestPrefetching,test_16,"for (sql, stat) in iteritems(database._dblocal.stats):
    global_stat = setdefault(sql, stat)
    if global_stat is not stat:
        global_stat.merge(stat)","for e_target in iteritems(database._dblocal.stats):
    stat = e_target[1]
    sql = e_target[0]
    global_stat = setdefault(sql, stat)
    if global_stat is not stat:
        global_stat.merge(stat)

",1,"[['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_prefetching.py', 'pony.orm.tests.test_prefetching', 'TestPrefetching', 'test_17'], ['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_prefetching.py', 'pony.orm.tests.test_prefetching', 'TestPrefetching', 'test_19'], ['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_prefetching.py', 'pony.orm.tests.test_prefetching', 'TestPrefetching', 'test_18'], ['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_cascade_delete.py', 'pony.orm.tests.test_cascade_delete', 'TestCascade', 'test_2'], ['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_cascade_delete.py', 'pony.orm.tests.test_cascade_delete', 'TestCascade', 'test_1'], ['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_prefetching.py', 'pony.orm.tests.test_prefetching', 'TestPrefetching', 'test_14'], ['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_prefetching.py', 'pony.orm.tests.test_prefetching', 'TestPrefetching', 'test_15'], ['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_prefetching.py', 'pony.orm.tests.test_prefetching', 'TestPrefetching', 'test_13'], ['https://github.com/ponyorm/pony/tree/master/pony/orm/tests/test_prefetching.py', 'pony.orm.tests.test_prefetching', 'TestPrefetching', 'test_16']]"
google-maps-services-python,https://github.com/googlemaps/google-maps-services-python/tree/master/googlemaps/convert.py,ConvertTest,test_components,"for (k, v) in arg.items():
    for item in as_list(v):
        yield ('%s:%s' % (k, item))","for e_target in arg.items():
    v = e_target[1]
    k = e_target[0]
    for item in as_list(v):
        yield ('%s:%s' % (k, item))

",1,"[['https://github.com/googlemaps/google-maps-services-python/tree/master/tests/test_convert.py', 'tests.test_convert', 'ConvertTest', 'test_components']]"
ecs,https://github.com/elastic/ecs/tree/master/scripts/schema/finalizer.py,TestSchemaFinalizer,test_calculate_final_values,"for (schema_name, reuse_entries) in self_nestings.items():
    schema = fields[schema_name]
    ensure_valid_reuse(schema)
    reused_fields = copy.deepcopy(schema['fields'])
    set_original_fieldset(reused_fields, schema_name)
    for reuse_entry in reuse_entries:
        nest_as = reuse_entry['as']
        new_field_details = copy.deepcopy(schema['field_details'])
        new_field_details['name'] = nest_as
        new_field_details['original_fieldset'] = schema_name
        new_field_details['intermediate'] = True
        if reuse_entry['at'] != schema_name:
            destination_fields = field_group_at_path(reuse_entry['at'], fields)
        else:
            destination_fields = schema['fields']
        destination_fields[nest_as] = {'field_details': new_field_details, 'fields': copy.deepcopy(reused_fields)}
        append_reused_here(schema, reuse_entry, fields[schema_name])","for e_target in self_nestings.items():
    reuse_entries = e_target[1]
    schema_name = e_target[0]
    schema = fields[schema_name]
    ensure_valid_reuse(schema)
    reused_fields = copy.deepcopy(schema['fields'])
    set_original_fieldset(reused_fields, schema_name)
    for reuse_entry in reuse_entries:
        nest_as = reuse_entry['as']
        new_field_details = copy.deepcopy(schema['field_details'])
        new_field_details['name'] = nest_as
        new_field_details['original_fieldset'] = schema_name
        new_field_details['intermediate'] = True
        if reuse_entry['at'] != schema_name:
            destination_fields = field_group_at_path(reuse_entry['at'], fields)
        else:
            destination_fields = schema['fields']
        destination_fields[nest_as] = {'field_details': new_field_details, 'fields': copy.deepcopy(reused_fields)}
        append_reused_here(schema, reuse_entry, fields[schema_name])

",1,"[['https://github.com/elastic/ecs/tree/master/scripts/tests/unit/test_schema_finalizer.py', 'scripts.tests.unit.test_schema_finalizer', 'TestSchemaFinalizer', 'test_perform_reuse_with_foreign_reuse_and_self_reuse'], ['https://github.com/elastic/ecs/tree/master/scripts/tests/unit/test_schema_finalizer.py', 'scripts.tests.unit.test_schema_finalizer', 'TestSchemaFinalizer', 'test_calculate_final_values']]"
ecs,https://github.com/elastic/ecs/tree/master/scripts/schema/finalizer.py,TestSchemaFinalizer,test_calculate_final_values,"for (schema_name, reuse_entries) in foreign_reuses[order].items():
    schema = fields[schema_name]
    for reuse_entry in reuse_entries:
        nest_as = reuse_entry['as']
        destination_schema_name = reuse_entry['full'].split('.')[0]
        destination_schema = fields[destination_schema_name]
        ensure_valid_reuse(schema, destination_schema)
        new_field_details = copy.deepcopy(schema['field_details'])
        new_field_details['name'] = nest_as
        new_field_details['original_fieldset'] = schema_name
        new_field_details['intermediate'] = True
        reused_fields = copy.deepcopy(schema['fields'])
        set_original_fieldset(reused_fields, schema_name)
        destination_fields = field_group_at_path(reuse_entry['at'], fields)
        destination_fields[nest_as] = {'field_details': new_field_details, 'fields': reused_fields}
        append_reused_here(schema, reuse_entry, destination_schema)","for e_target in foreign_reuses[order].items():
    reuse_entries = e_target[1]
    schema_name = e_target[0]
    schema = fields[schema_name]
    for reuse_entry in reuse_entries:
        nest_as = reuse_entry['as']
        destination_schema_name = reuse_entry['full'].split('.')[0]
        destination_schema = fields[destination_schema_name]
        ensure_valid_reuse(schema, destination_schema)
        new_field_details = copy.deepcopy(schema['field_details'])
        new_field_details['name'] = nest_as
        new_field_details['original_fieldset'] = schema_name
        new_field_details['intermediate'] = True
        reused_fields = copy.deepcopy(schema['fields'])
        set_original_fieldset(reused_fields, schema_name)
        destination_fields = field_group_at_path(reuse_entry['at'], fields)
        destination_fields[nest_as] = {'field_details': new_field_details, 'fields': reused_fields}
        append_reused_here(schema, reuse_entry, destination_schema)

",1,"[['https://github.com/elastic/ecs/tree/master/scripts/tests/unit/test_schema_finalizer.py', 'scripts.tests.unit.test_schema_finalizer', 'TestSchemaFinalizer', 'test_perform_reuse_with_foreign_reuse_and_self_reuse'], ['https://github.com/elastic/ecs/tree/master/scripts/tests/unit/test_schema_finalizer.py', 'scripts.tests.unit.test_schema_finalizer', 'TestSchemaFinalizer', 'test_calculate_final_values']]"
KL-Loss,https://github.com/yihui-he/KL-Loss/tree/master/detectron/core/config.py,TestCfg,test_merge_cfg_from_list,"for (full_key, v) in zip(cfg_list[0::2], cfg_list[1::2]):
    if _key_is_deprecated(full_key):
        continue
    if _key_is_renamed(full_key):
        _raise_key_rename_error(full_key)
    key_list = full_key.split('.')
    d = __C
    for subkey in key_list[:-1]:
        assert subkey in d, 'Non-existent key: {}'.format(full_key)
        d = d[subkey]
    subkey = key_list[-1]
    assert subkey in d, 'Non-existent key: {}'.format(full_key)
    value = _decode_cfg_value(v)
    value = _check_and_coerce_cfg_value_type(value, d[subkey], subkey, full_key)
    d[subkey] = value","for e_target in zip(cfg_list[0::2], cfg_list[1::2]):
    v = e_target[1]
    full_key = e_target[0]
    if _key_is_deprecated(full_key):
        continue
    if _key_is_renamed(full_key):
        _raise_key_rename_error(full_key)
    key_list = full_key.split('.')
    d = __C
    for subkey in key_list[:-1]:
        assert subkey in d, 'Non-existent key: {}'.format(full_key)
        d = d[subkey]
    subkey = key_list[-1]
    assert subkey in d, 'Non-existent key: {}'.format(full_key)
    value = _decode_cfg_value(v)
    value = _check_and_coerce_cfg_value_type(value, d[subkey], subkey, full_key)
    d[subkey] = value

",1,"[['https://github.com/yihui-he/KL-Loss/tree/master/detectron/tests/test_cfg.py', 'detectron.tests.test_cfg', 'TestCfg', 'test_renamed_key_from_list'], ['https://github.com/yihui-he/KL-Loss/tree/master/detectron/tests/test_cfg.py', 'detectron.tests.test_cfg', 'TestCfg', 'test_deprecated_key_from_list'], ['https://github.com/yihui-he/KL-Loss/tree/master/detectron/tests/test_cfg.py', 'detectron.tests.test_cfg', 'TestCfg', 'test_merge_cfg_from_list']]"
lifetimes,https://github.com/CamDavidsonPilon/lifetimes/tree/master/lifetimes/utils.py,,test_expected_cumulative_transactions_date_index,"for (i, period) in enumerate(date_periods):
    if i % freq_multiplier == 0 and i > 0:
        times = np.array([d.n for d in period - first_trans_size.index])
        times = times[times > 0].astype(float) / freq_multiplier
        expected_trans_agg = model.expected_number_of_purchases_up_to_time(times)
        mask = first_trans_size.index < period
        expected_trans = sum(expected_trans_agg * first_trans_size[mask])
        pred_cum_transactions.append(expected_trans)","for e_target in enumerate(date_periods):
    period = e_target[1]
    i = e_target[0]
    if i % freq_multiplier == 0 and i > 0:
        times = np.array([d.n for d in period - first_trans_size.index])
        times = times[times > 0].astype(float) / freq_multiplier
        expected_trans_agg = model.expected_number_of_purchases_up_to_time(times)
        mask = first_trans_size.index < period
        expected_trans = sum(expected_trans_agg * first_trans_size[mask])
        pred_cum_transactions.append(expected_trans)

",1,"[['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_expected_cumulative_transactions_dedups_inside_a_time_period'], ['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_expected_cumulative_transactions_date_index']]"
lifetimes,https://github.com/CamDavidsonPilon/lifetimes/tree/master/lifetimes/plotting.py,TestPlotting,test_plot_frequency_recency_matrix,"for (i, recency) in enumerate(np.arange(max_recency + 1)):
    for (j, frequency) in enumerate(np.arange(max_frequency + 1)):
        Z[i, j] = model.conditional_expected_number_of_purchases_up_to_time(T, frequency, recency, max_recency)","for e_target in enumerate(np.arange(max_recency + 1)):
    recency = e_target[1]
    i = e_target[0]
    for (j, frequency) in enumerate(np.arange(max_frequency + 1)):
        Z[i, j] = model.conditional_expected_number_of_purchases_up_to_time(T, frequency, recency, max_recency)

",1,"[['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_plotting.py', 'tests.test_plotting', 'TestPlotting', 'test_plot_frequency_recency_matrix_max_frequency'], ['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_plotting.py', 'tests.test_plotting', 'TestPlotting', 'test_plot_frequency_recency_matrix_max_recency'], ['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_plotting.py', 'tests.test_plotting', 'TestPlotting', 'test_plot_frequency_recency_matrix_max_frequency_max_recency'], ['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_plotting.py', 'tests.test_plotting', 'TestPlotting', 'test_plot_frequency_recency_matrix']]"
lifetimes,https://github.com/CamDavidsonPilon/lifetimes/tree/master/lifetimes/plotting.py,TestPlotting,test_plot_frequency_recency_matrix,"for (j, frequency) in enumerate(np.arange(max_frequency + 1)):
    Z[i, j] = model.conditional_expected_number_of_purchases_up_to_time(T, frequency, recency, max_recency)","for e_target in enumerate(np.arange(max_frequency + 1)):
    frequency = e_target[1]
    j = e_target[0]
    Z[i, j] = model.conditional_expected_number_of_purchases_up_to_time(T, frequency, recency, max_recency)

",1,"[['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_plotting.py', 'tests.test_plotting', 'TestPlotting', 'test_plot_frequency_recency_matrix_max_frequency'], ['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_plotting.py', 'tests.test_plotting', 'TestPlotting', 'test_plot_frequency_recency_matrix_max_recency'], ['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_plotting.py', 'tests.test_plotting', 'TestPlotting', 'test_plot_frequency_recency_matrix_max_frequency_max_recency'], ['https://github.com/CamDavidsonPilon/lifetimes/tree/master/tests/test_plotting.py', 'tests.test_plotting', 'TestPlotting', 'test_plot_frequency_recency_matrix']]"
pyCraft,https://github.com/ammaraskar/pyCraft/tree/master/minecraft/networking/types/basic.py,SerializationTest,test_varint,"for (max_value, size) in VARINT_SIZE_TABLE.items():
    if value < max_value:
        return size","for e_target in VARINT_SIZE_TABLE.items():
    size = e_target[1]
    max_value = e_target[0]
    if value < max_value:
        return size

",1,"[['https://github.com/ammaraskar/pyCraft/tree/master/tests/test_serialization.py', 'tests.test_serialization', 'SerializationTest', 'test_varint']]"
pycoin,https://github.com/richardkiss/pycoin/tree/master/pycoin/message/make_parser_and_packer.py,MessageTest,test_make_parser_and_packer,"for (name, type) in pairs:
    if type[0] == '[':
        streamer.stream_struct('I', f, len(kwargs[name]))
        for v in kwargs[name]:
            if not isinstance(v, (tuple, list)):
                v = [v]
            streamer.stream_struct(type[1:-1], f, *v)
    else:
        streamer.stream_struct(type, f, kwargs[name])","for e_target in pairs:
    type = e_target[1]
    name = e_target[0]
    if type[0] == '[':
        streamer.stream_struct('I', f, len(kwargs[name]))
        for v in kwargs[name]:
            if not isinstance(v, (tuple, list)):
                v = [v]
            streamer.stream_struct(type[1:-1], f, *v)
    else:
        streamer.stream_struct(type, f, kwargs[name])

",1,"[['https://github.com/richardkiss/pycoin/tree/master/tests/message_test.py', 'tests.message_test', 'MessageTest', 'test_make_parser_and_packer']]"
pycoin,https://github.com/richardkiss/pycoin/tree/master/pycoin/blockchain/BlockChain.py,BlockchainTestCase,test_basic,"for (idx, h) in enumerate(old_path):
    op = ('remove', self.block_for_hash(h), size - idx - 1)
    ops.append(op)
    del self.hash_to_index_lookup[h]","for e_target in enumerate(old_path):
    h = e_target[1]
    idx = e_target[0]
    op = ('remove', self.block_for_hash(h), size - idx - 1)
    ops.append(op)
    del self.hash_to_index_lookup[h]

",1,"[['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_large'], ['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_callback'], ['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_chain_locking'], ['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_fork'], ['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_basic']]"
pycoin,https://github.com/richardkiss/pycoin/tree/master/pycoin/blockchain/BlockChain.py,BlockchainTestCase,test_basic,"for (idx, h) in reversed(list(enumerate(new_path))):
    op = ('add', self.block_for_hash(h), size - idx - 1)
    ops.append(op)
    self.hash_to_index_lookup[h] = size - idx - 1","for e_target in reversed(list(enumerate(new_path))):
    h = e_target[1]
    idx = e_target[0]
    op = ('add', self.block_for_hash(h), size - idx - 1)
    ops.append(op)
    self.hash_to_index_lookup[h] = size - idx - 1

",1,"[['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_large'], ['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_callback'], ['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_chain_locking'], ['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_fork'], ['https://github.com/richardkiss/pycoin/tree/master/tests/blockchain_test.py', 'tests.blockchain_test', 'BlockchainTestCase', 'test_basic']]"
stackimpact-python,https://github.com/stackimpact/stackimpact-python/tree/master/stackimpact/metric.py,MetricTestCase,test_profile_depth,"for (name, child) in self.children.items():
    child_depth = child.depth()
    if child_depth > max_depth:
        max_depth = child_depth","for e_target in self.children.items():
    child = e_target[1]
    name = e_target[0]
    child_depth = child.depth()
    if child_depth > max_depth:
        max_depth = child_depth

",1,"[['https://github.com/stackimpact/stackimpact-python/tree/master/tests/metric_test.py', 'tests.metric_test', 'MetricTestCase', 'test_profile_depth']]"
xar,https://github.com/facebookincubator/xar/tree/master/xar/py_util.py,PyUtilTest,test_wheel_copy_installation,"for (record, record_hash, record_size) in self.records():
    src_record = os.path.normpath(os.path.join(src_root, record))
    (kind, prefix) = self._determine_kind(src_root, src_paths, dst_paths, src_record)
    rel_record = src_record[len(prefix) + 1:]
    dst_record = os.path.join(dst_paths[kind], rel_record)
    new_record = os.path.relpath(dst_record, dst_root)
    dst_records.writerow((new_record, record_hash, record_size))
    if dst_record == dst_records_path:
        continue
    if os.path.exists(dst_record) and (not force):
        if not does_sha256_match(dst_record, record_hash):
            raise self.Error(""'%s' already exists"" % dst_record)
    xar_util.safe_mkdir(os.path.dirname(dst_record))
    shutil.copy2(src_record, dst_record)","for e_target in self.records():
    record_size = e_target[2]
    record_hash = e_target[1]
    record = e_target[0]
    src_record = os.path.normpath(os.path.join(src_root, record))
    (kind, prefix) = self._determine_kind(src_root, src_paths, dst_paths, src_record)
    rel_record = src_record[len(prefix) + 1:]
    dst_record = os.path.join(dst_paths[kind], rel_record)
    new_record = os.path.relpath(dst_record, dst_root)
    dst_records.writerow((new_record, record_hash, record_size))
    if dst_record == dst_records_path:
        continue
    if os.path.exists(dst_record) and (not force):
        if not does_sha256_match(dst_record, record_hash):
            raise self.Error(""'%s' already exists"" % dst_record)
    xar_util.safe_mkdir(os.path.dirname(dst_record))
    shutil.copy2(src_record, dst_record)

",1,"[['https://github.com/facebookincubator/xar/tree/master/xar/tests/py_util_test.py', 'xar.tests.py_util_test', 'PyUtilTest', 'test_wheel_copy_installation']]"
xar,https://github.com/facebookincubator/xar/tree/master/xar/xar_util.py,XarUtilTest,test_xar_factory,"for (key, val) in self.xar_header.items():
    headers.append('%s=""%s""' % (key, str(val).replace('""', ' ')))","for e_target in self.xar_header.items():
    val = e_target[1]
    key = e_target[0]
    headers.append('%s=""%s""' % (key, str(val).replace('""', ' ')))

",1,"[['https://github.com/facebookincubator/xar/tree/master/xar/tests/xar_util_test.py', 'xar.tests.xar_util_test', 'XarUtilTest', 'test_long_header'], ['https://github.com/facebookincubator/xar/tree/master/xar/tests/xar_util_test.py', 'xar.tests.xar_util_test', 'XarUtilTest', 'test_mksquashfs_options'], ['https://github.com/facebookincubator/xar/tree/master/xar/tests/xar_util_test.py', 'xar.tests.xar_util_test', 'XarUtilTest', 'test_xar_factory']]"
xar,https://github.com/facebookincubator/xar/tree/master/xar/xar_util.py,XarUtilTest,test_partition_files,"for (dirpath, _dirnames, filenames) in os.walk(staging.path()):
    relative_dirname = dirpath[len(source_dir) + 1:]
    if not relative_dirname:
        relative_depth = 1
    else:
        relative_depth = 2 + relative_dirname.count('/')
    for filename in filenames:
        (_, extension) = os.path.splitext(filename)
        dest_base = extension_destinations.get(extension, None)
        if dest_base is None:
            continue
        relative_path = os.path.join(relative_dirname, filename)
        source_path = staging.absolute(relative_path)
        dest_base.staging.move(source_path, relative_path)
        dependency_mountpoint = dest_base.uuid
        staging_symlink = os.path.join('../' * relative_depth, dependency_mountpoint, relative_path)
        logging.info('%s %s' % (staging_symlink, source_path))
        staging.symlink(staging_symlink, relative_path)","for e_target in os.walk(staging.path()):
    filenames = e_target[2]
    _dirnames = e_target[1]
    dirpath = e_target[0]
    relative_dirname = dirpath[len(source_dir) + 1:]
    if not relative_dirname:
        relative_depth = 1
    else:
        relative_depth = 2 + relative_dirname.count('/')
    for filename in filenames:
        (_, extension) = os.path.splitext(filename)
        dest_base = extension_destinations.get(extension, None)
        if dest_base is None:
            continue
        relative_path = os.path.join(relative_dirname, filename)
        source_path = staging.absolute(relative_path)
        dest_base.staging.move(source_path, relative_path)
        dependency_mountpoint = dest_base.uuid
        staging_symlink = os.path.join('../' * relative_depth, dependency_mountpoint, relative_path)
        logging.info('%s %s' % (staging_symlink, source_path))
        staging.symlink(staging_symlink, relative_path)

",1,"[['https://github.com/facebookincubator/xar/tree/master/xar/tests/xar_util_test.py', 'xar.tests.xar_util_test', 'XarUtilTest', 'test_partition_files']]"
pattern,https://github.com/clips/pattern/tree/master/pattern/metrics.py,TestProfiling,test_confustion_matrix,"for (document, b1) in documents:
    b2 = classify(document)
    if b1 and b2:
        TP += 1
    elif not b1 and (not b2):
        TN += 1
    elif not b1 and b2:
        FP += 1
    elif b1 and (not b2):
        FN += 1","for e_target in documents:
    b1 = e_target[1]
    document = e_target[0]
    b2 = classify(document)
    if b1 and b2:
        TP += 1
    elif not b1 and (not b2):
        TN += 1
    elif not b1 and b2:
        FP += 1
    elif b1 and (not b2):
        FN += 1

",1,"[['https://github.com/clips/pattern/tree/master/test/test_metrics.py', 'test.test_metrics', 'TestProfiling', 'test_confustion_matrix']]"
detect-secrets,https://github.com/Yelp/detect-secrets/tree/master/detect_secrets/core/secrets_collection.py,TestTrim,test_deleted_secret,"for (filename, secret) in self:
    output[filename].append(secret.json())","for e_target in self:
    secret = e_target[1]
    filename = e_target[0]
    output[filename].append(secret.json())

",1,"[['https://github.com/Yelp/detect-secrets/tree/master/tests/core/secrets_collection_test.py', 'tests.core.secrets_collection_test', 'TestTrim', 'test_deleted_secret']]"
detect-secrets,https://github.com/Yelp/detect-secrets/tree/master/detect_secrets/core/baseline.py,TestLineNumberChanges,test_does_not_modify_slim_baseline,"for (filename, secret_list) in cast(Dict[str, List[Dict[str, Any]]], output['results']).items():
    for secret_dict in secret_list:
        secret_dict.pop('line_number')","for e_target in cast(Dict[str, List[Dict[str, Any]]], output['results']).items():
    secret_list = e_target[1]
    filename = e_target[0]
    for secret_dict in secret_list:
        secret_dict.pop('line_number')

",1,"[['https://github.com/Yelp/detect-secrets/tree/master/tests/pre_commit_hook_test.py', 'tests.pre_commit_hook_test', 'TestModifiesBaselineFromVersionChange', 'test_maintains_labelled_data'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/core/baseline_test.py', 'tests.core.baseline_test', '', 'test_load_and_output'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/audit/audit_test.py', 'tests.audit.audit_test', '', 'test_fails_if_no_line_numbers_found'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/main_test.py', 'tests.main_test', 'TestScan', 'test_saves_to_baseline'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/pre_commit_hook_test.py', 'tests.pre_commit_hook_test', 'TestLineNumberChanges', 'test_does_not_modify_slim_baseline']]"
detect-secrets,https://github.com/Yelp/detect-secrets/tree/master/detect_secrets/core/scan.py,TestGetFilesToScan,test_should_scan_specific_non_tracked_file,"for (path_root, _, filenames) in iterator:
    for filename in filenames:
        relative_path = get_relative_path(root=root or os.getcwd(), path=os.path.join(path_root, filename))
        if not relative_path:
            continue
        if valid_paths is True or relative_path in cast(Set[str], valid_paths):
            yield relative_path","for e_target in iterator:
    filenames = e_target[2]
    _ = e_target[1]
    path_root = e_target[0]
    for filename in filenames:
        relative_path = get_relative_path(root=root or os.getcwd(), path=os.path.join(path_root, filename))
        if not relative_path:
            continue
        if valid_paths is True or relative_path in cast(Set[str], valid_paths):
            yield relative_path

",1,"[['https://github.com/Yelp/detect-secrets/tree/master/tests/core/scan_test.py', 'tests.core.scan_test', 'TestGetFilesToScan', 'test_should_scan_tracked_files_in_directory'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/core/scan_test.py', 'tests.core.scan_test', 'TestGetFilesToScan', 'test_should_scan_all_files_in_directory_if_flag_is_provided'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/core/scan_test.py', 'tests.core.scan_test', 'TestGetFilesToScan', 'test_handles_each_path_separately'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/core/scan_test.py', 'tests.core.scan_test', 'TestGetFilesToScan', 'test_handles_multiple_directories'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/core/scan_test.py', 'tests.core.scan_test', 'TestGetFilesToScan', 'test_should_scan_specific_non_tracked_file']]"
detect-secrets,https://github.com/Yelp/detect-secrets/tree/master/detect_secrets/core/plugins/util.py,,test_default_plugins_initialized,"for (classname, config) in get_settings().plugins.items():
    if 'path' not in config:
        continue
    filename = config['path'][len('file://'):]
    for plugin_class in get_plugins_from_file(filename):
        output[cast(BasePlugin, plugin_class).secret_type] = plugin_class","for e_target in get_settings().plugins.items():
    config = e_target[1]
    classname = e_target[0]
    if 'path' not in config:
        continue
    filename = config['path'][len('file://'):]
    for plugin_class in get_plugins_from_file(filename):
        output[cast(BasePlugin, plugin_class).secret_type] = plugin_class

",1,"[['https://github.com/Yelp/detect-secrets/tree/master/tests/core/usage/baseline_usage_test.py', 'tests.core.usage.baseline_usage_test', '', 'test_baseline_optional'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/core/usage/scan_usage_test.py', 'tests.core.usage.scan_usage_test', '', 'test_force_use_all_plugins'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/plugins/base_test.py', 'tests.plugins.base_test', '', 'test_ensure_all_plugins_have_unique_secret_types'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/core/usage/scan_usage_test.py', 'tests.core.usage.scan_usage_test', '', 'test_default_plugins_initialized']]"
detect-secrets,https://github.com/Yelp/detect-secrets/tree/master/detect_secrets/filters/allowlist.py,,test_nextline_exclusivity,"for (payload, regexes) in zip([line, context.previous_line], _get_allowlist_regexes_for_file(filename)):
    for regex in regexes:
        if regex.search(payload):
            return True","for e_target in zip([line, context.previous_line], _get_allowlist_regexes_for_file(filename)):
    regexes = e_target[1]
    payload = e_target[0]
    for regex in regexes:
        if regex.search(payload):
            return True

",1,"[['https://github.com/Yelp/detect-secrets/tree/master/tests/filters/allowlist_filter_test.py', 'tests.filters.allowlist_filter_test', '', 'test_backwards_compatibility'], ['https://github.com/Yelp/detect-secrets/tree/master/tests/filters/allowlist_filter_test.py', 'tests.filters.allowlist_filter_test', '', 'test_nextline_exclusivity']]"
skidl,https://github.com/devbisme/skidl/tree/master/skidl/part.py,,test_package_7,"for (attr, name, do_str_match) in search_params:
    parts.extend(filter_list(circuit.parts, do_str_match=do_str_match, **{attr: name}))","for e_target in search_params:
    do_str_match = e_target[2]
    name = e_target[1]
    attr = e_target[0]
    parts.extend(filter_list(circuit.parts, do_str_match=do_str_match, **{attr: name}))

",1,"[['https://github.com/devbisme/skidl/tree/master/tests/test_part.py', 'tests.test_part', '', 'test_part_2'], ['https://github.com/devbisme/skidl/tree/master/tests/test_package.py', 'tests.test_package', '', 'test_package_7']]"
skidl,https://github.com/devbisme/skidl/tree/master/skidl/bus.py,,test_bus_get_pull_1,"for (attr, name, do_str_match) in search_params:
    buses = filter_list(circuit.buses, do_str_match=do_str_match, **{attr: name})
    if buses:
        return list_or_scalar(buses)","for e_target in search_params:
    do_str_match = e_target[2]
    name = e_target[1]
    attr = e_target[0]
    buses = filter_list(circuit.buses, do_str_match=do_str_match, **{attr: name})
    if buses:
        return list_or_scalar(buses)

",1,"[['https://github.com/devbisme/skidl/tree/master/tests/test_bus.py', 'tests.test_bus', '', 'test_bus_get_pull_1']]"
skidl,https://github.com/devbisme/skidl/tree/master/skidl/net.py,,test_net_get_pull_1,"for (attr, name, do_str_match) in search_params:
    nets = filter_list(circuit.nets, do_str_match=do_str_match, **{attr: name})
    try:
        return nets[0]
    except IndexError:
        pass","for e_target in search_params:
    do_str_match = e_target[2]
    name = e_target[1]
    attr = e_target[0]
    nets = filter_list(circuit.nets, do_str_match=do_str_match, **{attr: name})
    try:
        return nets[0]
    except IndexError:
        pass

",1,"[['https://github.com/devbisme/skidl/tree/master/tests/test_net.py', 'tests.test_net', '', 'test_net_get_pull_1']]"
joblib,https://github.com/joblib/joblib/tree/master/joblib/memory.py,,test_dummy_store_backend,"for (backend_key, backend_obj) in _STORE_BACKENDS.items():
    if backend == backend_key:
        obj = backend_obj()","for e_target in _STORE_BACKENDS.items():
    backend_obj = e_target[1]
    backend_key = e_target[0]
    if backend == backend_key:
        obj = backend_obj()

",1,"[['https://github.com/joblib/joblib/tree/master/joblib/test/test_memory.py', 'joblib.test.test_memory', '', 'test_warning_on_unknown_location_type'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_memory.py', 'joblib.test.test_memory', '', 'test_instanciate_incomplete_store_backend'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_memory.py', 'joblib.test.test_memory', '', 'test_instanciate_store_backend_with_pathlib_path'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_memory.py', 'joblib.test.test_memory', '', 'test_dummy_store_backend']]"
joblib,https://github.com/joblib/joblib/tree/master/joblib/numpy_pickle.py,,test_file_handle_persistence_compressed_mmap,"for (name, compressor) in _COMPRESSORS.items():
    if filename.endswith(compressor.extension):
        compress_method = name","for e_target in _COMPRESSORS.items():
    compressor = e_target[1]
    name = e_target[0]
    if filename.endswith(compressor.extension):
        compress_method = name

",1,"[['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_value_error'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_pickle_in_socket'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_parallel.py', 'joblib.test.test_parallel', '', 'test_memmap_with_big_offset'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_compressed_pickle_dump_and_load'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_memmap_persistence'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_file_handle_persistence'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_pathlib'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_masked_array_persistence'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_file_handle_persistence_in_memory_mmap'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_numpy_persistence_bufferred_array_compression'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_file_handle_persistence_mmap'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_in_memory_persistence'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_memmap_persistence_mixed_dtypes'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_lz4_compression'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_non_contiguous_array_pickling'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_pickle_highest_protocol'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_numpy_subclass'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_load_memmap_with_big_offset'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_compress_mmap_mode_warning'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_numpy_pickle.py', 'joblib.test.test_numpy_pickle', '', 'test_file_handle_persistence_compressed_mmap']]"
joblib,https://github.com/joblib/joblib/tree/master/joblib/func_inspect.py,,test_filter_args_2,"for (arg_position, arg_name) in enumerate(arg_names):
    if arg_position < len(args):
        if arg_name not in arg_kwonlyargs:
            arg_dict[arg_name] = args[arg_position]
        else:
            raise ValueError(""Keyword-only parameter '%s' was passed as positional parameter for %s:\n     %s was called."" % (arg_name, _signature_str(name, arg_sig), _function_called_str(name, args, kwargs)))
    else:
        position = arg_position - len(arg_names)
        if arg_name in kwargs:
            arg_dict[arg_name] = kwargs[arg_name]
        else:
            try:
                arg_dict[arg_name] = arg_defaults[position]
            except (IndexError, KeyError) as e:
                raise ValueError('Wrong number of arguments for %s:\n     %s was called.' % (_signature_str(name, arg_sig), _function_called_str(name, args, kwargs))) from e","for e_target in enumerate(arg_names):
    arg_name = e_target[1]
    arg_position = e_target[0]
    if arg_position < len(args):
        if arg_name not in arg_kwonlyargs:
            arg_dict[arg_name] = args[arg_position]
        else:
            raise ValueError(""Keyword-only parameter '%s' was passed as positional parameter for %s:\n     %s was called."" % (arg_name, _signature_str(name, arg_sig), _function_called_str(name, args, kwargs)))
    else:
        position = arg_position - len(arg_names)
        if arg_name in kwargs:
            arg_dict[arg_name] = kwargs[arg_name]
        else:
            try:
                arg_dict[arg_name] = arg_defaults[position]
            except (IndexError, KeyError) as e:
                raise ValueError('Wrong number of arguments for %s:\n     %s was called.' % (_signature_str(name, arg_sig), _function_called_str(name, args, kwargs))) from e

",1,"[['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_filter_args_edge_cases'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_filter_args_method'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_hashing.py', 'joblib.test.test_hashing', '', 'test_bound_methods_hash'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_filter_args_no_kwargs_mutation'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_hashing.py', 'joblib.test.test_hashing', '', 'test_bound_cached_methods_hash'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_bound_methods'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_filter_args_2']]"
joblib,https://github.com/joblib/joblib/tree/master/joblib/func_inspect.py,,test_filter_args_2,"for (arg_name, arg_value) in sorted(kwargs.items()):
    if arg_name in arg_dict:
        arg_dict[arg_name] = arg_value
    elif arg_varkw is not None:
        varkwargs[arg_name] = arg_value
    else:
        raise TypeError(""Ignore list for %s() contains an unexpected keyword argument '%s'"" % (name, arg_name))","for e_target in sorted(kwargs.items()):
    arg_value = e_target[1]
    arg_name = e_target[0]
    if arg_name in arg_dict:
        arg_dict[arg_name] = arg_value
    elif arg_varkw is not None:
        varkwargs[arg_name] = arg_value
    else:
        raise TypeError(""Ignore list for %s() contains an unexpected keyword argument '%s'"" % (name, arg_name))

",1,"[['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_filter_args_edge_cases'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_filter_args_method'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_hashing.py', 'joblib.test.test_hashing', '', 'test_bound_methods_hash'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_filter_args_no_kwargs_mutation'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_hashing.py', 'joblib.test.test_hashing', '', 'test_bound_cached_methods_hash'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_bound_methods'], ['https://github.com/joblib/joblib/tree/master/joblib/test/test_func_inspect.py', 'joblib.test.test_func_inspect', '', 'test_filter_args_2']]"
django-environ,https://github.com/joke2k/django-environ/tree/master/environ/environ.py,,test_postgres_complex_db_name_parsing,"for (k, v) in parse_qs(url.query).items():
    if k.upper() in cls._DB_BASE_OPTIONS:
        config.update({k.upper(): _cast(v[0])})
    else:
        config_options.update({k: _cast_int(v[0])})","for e_target in parse_qs(url.query).items():
    v = e_target[1]
    k = e_target[0]
    if k.upper() in cls._DB_BASE_OPTIONS:
        config.update({k.upper(): _cast(v[0])})
    else:
        config_options.update({k: _cast_int(v[0])})

",1,"[['https://github.com/joke2k/django-environ/tree/master/tests/test_db.py', 'tests.test_db', '', 'test_database_options_parsing'], ['https://github.com/joke2k/django-environ/tree/master/tests/test_db.py', 'tests.test_db', '', 'test_memory_sqlite_url_warns_about_netloc'], ['https://github.com/joke2k/django-environ/tree/master/tests/test_db.py', 'tests.test_db', '', 'test_postgres_complex_db_name_parsing']]"
pydantic,https://github.com/samuelcolvin/pydantic/tree/master/pydantic/utils.py,,test_deep_update_is_not_mutating,"for (k, v) in updating_mapping.items():
    if k in updated_mapping and isinstance(updated_mapping[k], dict) and isinstance(v, dict):
        updated_mapping[k] = deep_update(updated_mapping[k], v)
    else:
        updated_mapping[k] = v","for e_target in updating_mapping.items():
    v = e_target[1]
    k = e_target[0]
    if k in updated_mapping and isinstance(updated_mapping[k], dict) and isinstance(v, dict):
        updated_mapping[k] = deep_update(updated_mapping[k], v)
    else:
        updated_mapping[k] = v

",1,"[['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_deep_update_is_not_mutating']]"
pydantic,https://github.com/samuelcolvin/pydantic/tree/master/pydantic/utils.py,,test_path_type,"for (method, name) in path_types.items():
    if getattr(p, method)():
        return name","for e_target in path_types.items():
    name = e_target[1]
    method = e_target[0]
    if getattr(p, method)():
        return name

",1,"[['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_path_type_unknown'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_path_type']]"
pydantic,https://github.com/samuelcolvin/pydantic/tree/master/pydantic/utils.py,,test_all_identical,"for (left_item, right_item) in zip_longest(left, right, fillvalue=_EMPTY):
    if left_item is not right_item:
        return False","for e_target in zip_longest(left, right, fillvalue=_EMPTY):
    right_item = e_target[1]
    left_item = e_target[0]
    if left_item is not right_item:
        return False

",1,"[['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_all_identical']]"
pydantic,https://github.com/samuelcolvin/pydantic/tree/master/pydantic/typing.py,,test_resolve_annotations_no_module,"for (name, value) in raw_annotations.items():
    if isinstance(value, str):
        if (3, 10) > sys.version_info >= (3, 9, 8) or sys.version_info >= (3, 10, 1):
            value = ForwardRef(value, is_argument=False, is_class=True)
        elif sys.version_info >= (3, 7):
            value = ForwardRef(value, is_argument=False)
        else:
            value = ForwardRef(value)
    try:
        value = _eval_type(value, base_globals, None)
    except NameError:
        pass
    annotations[name] = value","for e_target in raw_annotations.items():
    value = e_target[1]
    name = e_target[0]
    if isinstance(value, str):
        if (3, 10) > sys.version_info >= (3, 9, 8) or sys.version_info >= (3, 10, 1):
            value = ForwardRef(value, is_argument=False, is_class=True)
        elif sys.version_info >= (3, 7):
            value = ForwardRef(value, is_argument=False)
        else:
            value = ForwardRef(value)
    try:
        value = _eval_type(value, base_globals, None)
    except NameError:
        pass
    annotations[name] = value

",1,"[['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_resolve_annotations_no_module']]"
pydantic,https://github.com/samuelcolvin/pydantic/tree/master/pydantic/main.py,,test_custom_config_extras,"for (f_name, f_def) in field_definitions.items():
    if not is_valid_field(f_name):
        warnings.warn(f'fields may not start with an underscore, ignoring ""{f_name}""', RuntimeWarning)
    if isinstance(f_def, tuple):
        try:
            (f_annotation, f_value) = f_def
        except ValueError as e:
            raise ConfigError('field definitions should either be a tuple of (<type>, <default>) or just a default value, unfortunately this means tuples as default values are not allowed') from e
    else:
        (f_annotation, f_value) = (None, f_def)
    if f_annotation:
        annotations[f_name] = f_annotation
    fields[f_name] = f_value","for e_target in field_definitions.items():
    f_def = e_target[1]
    f_name = e_target[0]
    if not is_valid_field(f_name):
        warnings.warn(f'fields may not start with an underscore, ignoring ""{f_name}""', RuntimeWarning)
    if isinstance(f_def, tuple):
        try:
            (f_annotation, f_value) = f_def
        except ValueError as e:
            raise ConfigError('field definitions should either be a tuple of (<type>, <default>) or just a default value, unfortunately this means tuples as default values are not allowed') from e
    else:
        (f_annotation, f_value) = (None, f_def)
    if f_annotation:
        annotations[f_name] = f_annotation
    fields[f_name] = f_value

",1,"[['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_inheritance_validators_all'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_custom_config'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_create_model_pickle'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_invalid_name'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_create_model'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_funky_name'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_field_wrong_tuple'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_config_and_base'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_repeat_base_usage'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_create_model_usage'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_inheritance_validators'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_model_signature.py', 'tests.test_model_signature', '', 'test_invalid_identifiers_signature'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_forward_ref.py', 'tests.test_forward_ref', '', 'test_forward_ref_with_create_model'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_custom_config_inherits'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_inheritance_validators_always'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_inheritance'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_dynamic_and_static'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_config_field_info_create_model'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_create_model.py', 'tests.test_create_model', '', 'test_custom_config_extras']]"
pydantic,https://github.com/samuelcolvin/pydantic/tree/master/pydantic/main.py,,test_return_errors_error,"for (name, field) in model.__fields__.items():
    value = input_data.get(field.alias, _missing)
    using_name = False
    if value is _missing and config.allow_population_by_field_name and field.alt_alias:
        value = input_data.get(field.name, _missing)
        using_name = True
    if value is _missing:
        if field.required:
            errors.append(ErrorWrapper(MissingError(), loc=field.alias))
            continue
        value = field.get_default()
        if not config.validate_all and (not field.validate_always):
            values[name] = value
            continue
    else:
        fields_set.add(name)
        if check_extra:
            names_used.add(field.name if using_name else field.alias)
    (v_, errors_) = field.validate(value, values, loc=field.alias, cls=cls_)
    if isinstance(errors_, ErrorWrapper):
        errors.append(errors_)
    elif isinstance(errors_, list):
        errors.extend(errors_)
    else:
        values[name] = v_","for e_target in model.__fields__.items():
    field = e_target[1]
    name = e_target[0]
    value = input_data.get(field.alias, _missing)
    using_name = False
    if value is _missing and config.allow_population_by_field_name and field.alt_alias:
        value = input_data.get(field.name, _missing)
        using_name = True
    if value is _missing:
        if field.required:
            errors.append(ErrorWrapper(MissingError(), loc=field.alias))
            continue
        value = field.get_default()
        if not config.validate_all and (not field.validate_always):
            values[name] = value
            continue
    else:
        fields_set.add(name)
        if check_extra:
            names_used.add(field.name if using_name else field.alias)
    (v_, errors_) = field.validate(value, values, loc=field.alias, cls=cls_)
    if isinstance(errors_, ErrorWrapper):
        errors.append(errors_)
    elif isinstance(errors_, list):
        errors.extend(errors_)
    else:
        values[name] = v_

",1,"[['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_edge_cases.py', 'tests.test_edge_cases', '', 'test_return_errors_ok'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_edge_cases.py', 'tests.test_edge_cases', '', 'test_return_errors_error']]"
pydantic,https://github.com/samuelcolvin/pydantic/tree/master/pydantic/main.py,,test_return_errors_error,"for (skip_on_failure, validator) in model.__post_root_validators__:
    if skip_on_failure and errors:
        continue
    try:
        values = validator(cls_, values)
    except (ValueError, TypeError, AssertionError) as exc:
        errors.append(ErrorWrapper(exc, loc=ROOT_KEY))","for e_target in model.__post_root_validators__:
    validator = e_target[1]
    skip_on_failure = e_target[0]
    if skip_on_failure and errors:
        continue
    try:
        values = validator(cls_, values)
    except (ValueError, TypeError, AssertionError) as exc:
        errors.append(ErrorWrapper(exc, loc=ROOT_KEY))

",1,"[['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_edge_cases.py', 'tests.test_edge_cases', '', 'test_return_errors_ok'], ['https://github.com/samuelcolvin/pydantic/tree/master/tests/test_edge_cases.py', 'tests.test_edge_cases', '', 'test_return_errors_error']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/pack.py,WritePackTests,test_write_pack_object,"for (i, byte) in enumerate(bytes[1:]):
    size += (byte & 127) << i * 7 + 4","for e_target in enumerate(bytes[1:]):
    byte = e_target[1]
    i = e_target[0]
    size += (byte & 127) << i * 7 + 4

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_pack.py', 'dulwich.tests.test_pack', 'WritePackTests', 'test_write_pack_object']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/config.py,ConfigFileTests,test_write_to_file_subsection,"for (section, values) in self._values.items():
    try:
        (section_name, subsection_name) = section
    except ValueError:
        (section_name,) = section
        subsection_name = None
    if subsection_name is None:
        f.write(b'[' + section_name + b']\n')
    else:
        f.write(b'[' + section_name + b' ""' + subsection_name + b'""]\n')
    for (key, value) in values.items():
        if value is True:
            value = b'true'
        elif value is False:
            value = b'false'
        else:
            value = _format_string(value)
        f.write(b'\t' + key + b' = ' + value + b'\n')","for e_target in self._values.items():
    values = e_target[1]
    section = e_target[0]
    try:
        (section_name, subsection_name) = section
    except ValueError:
        (section_name,) = section
        subsection_name = None
    if subsection_name is None:
        f.write(b'[' + section_name + b']\n')
    else:
        f.write(b'[' + section_name + b' ""' + subsection_name + b'""]\n')
    for (key, value) in values.items():
        if value is True:
            value = b'true'
        elif value is False:
            value = b'false'
        else:
            value = _format_string(value)
        f.write(b'\t' + key + b' = ' + value + b'\n')

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_config.py', 'dulwich.tests.test_config', 'ConfigFileTests', 'test_write_to_file_empty'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_config.py', 'dulwich.tests.test_config', 'ConfigFileTests', 'test_write_to_file_section'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_config.py', 'dulwich.tests.test_config', 'ConfigFileTests', 'test_set_hash_gets_quoted'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_config.py', 'dulwich.tests.test_config', 'ConfigFileTests', 'test_write_to_file_subsection']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/config.py,ConfigFileTests,test_write_to_file_subsection,"for (key, value) in values.items():
    if value is True:
        value = b'true'
    elif value is False:
        value = b'false'
    else:
        value = _format_string(value)
    f.write(b'\t' + key + b' = ' + value + b'\n')","for e_target in values.items():
    value = e_target[1]
    key = e_target[0]
    if value is True:
        value = b'true'
    elif value is False:
        value = b'false'
    else:
        value = _format_string(value)
    f.write(b'\t' + key + b' = ' + value + b'\n')

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_config.py', 'dulwich.tests.test_config', 'ConfigFileTests', 'test_write_to_file_empty'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_config.py', 'dulwich.tests.test_config', 'ConfigFileTests', 'test_write_to_file_section'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_config.py', 'dulwich.tests.test_config', 'ConfigFileTests', 'test_set_hash_gets_quoted'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_config.py', 'dulwich.tests.test_config', 'ConfigFileTests', 'test_write_to_file_subsection']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/ignore.py,TranslateTests,test_translate,"for (i, segment) in enumerate(pat.split(b'/')):
    if segment == b'**':
        res += b'(/.*)?'
        continue
    else:
        res += (re.escape(b'/') if i > 0 else b'') + _translate_segment(segment)","for e_target in enumerate(pat.split(b'/')):
    segment = e_target[1]
    i = e_target[0]
    if segment == b'**':
        res += b'(/.*)?'
        continue
    else:
        res += (re.escape(b'/') if i > 0 else b'') + _translate_segment(segment)

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_ignore.py', 'dulwich.tests.test_ignore', 'TranslateTests', 'test_translate']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/index.py,ReadIndexDictTests,test_simple_write,"for (name, entry) in read_index(f):
    ret[name] = entry","for e_target in read_index(f):
    entry = e_target[1]
    name = e_target[0]
    ret[name] = entry

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_index.py', 'dulwich.tests.test_index', 'ReadIndexDictTests', 'test_simple_write']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/refs.py,CheckRefFormatTests,test_valid,"for (i, c) in enumerate(refname):
    if ord(refname[i:i + 1]) < 32 or c in BAD_REF_CHARS:
        return False","for e_target in enumerate(refname):
    c = e_target[1]
    i = e_target[0]
    if ord(refname[i:i + 1]) < 32 or c in BAD_REF_CHARS:
        return False

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_refs.py', 'dulwich.tests.test_refs', 'CheckRefFormatTests', 'test_invalid'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_refs.py', 'dulwich.tests.test_refs', 'CheckRefFormatTests', 'test_valid']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/bundle.py,BundleTests,test_roundtrip_bundle,"for (obj_id, comment) in bundle.prerequisites:
    f.write(b'-%s %s\n' % (obj_id, comment.encode('utf-8')))","for e_target in bundle.prerequisites:
    comment = e_target[1]
    obj_id = e_target[0]
    f.write(b'-%s %s\n' % (obj_id, comment.encode('utf-8')))

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_bundle.py', 'dulwich.tests.test_bundle', 'BundleTests', 'test_roundtrip_bundle']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/bundle.py,BundleTests,test_roundtrip_bundle,"for (ref, obj_id) in bundle.references.items():
    f.write(b'%s %s\n' % (obj_id, ref))","for e_target in bundle.references.items():
    obj_id = e_target[1]
    ref = e_target[0]
    f.write(b'%s %s\n' % (obj_id, ref))

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_bundle.py', 'dulwich.tests.test_bundle', 'BundleTests', 'test_roundtrip_bundle']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/bundle.py,BundleTests,test_roundtrip_bundle,"for (key, value) in bundle.capabilities.items():
    f.write(b'@' + key.encode('utf-8'))
    if value is not None:
        f.write(b'=' + value.encode('utf-8'))
    f.write(b'\n')","for e_target in bundle.capabilities.items():
    value = e_target[1]
    key = e_target[0]
    f.write(b'@' + key.encode('utf-8'))
    if value is not None:
        f.write(b'=' + value.encode('utf-8'))
    f.write(b'\n')

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_bundle.py', 'dulwich.tests.test_bundle', 'BundleTests', 'test_roundtrip_bundle']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/porcelain.py,CloneTests,test_bare_local_with_checkout,"for (key, target) in fetch_result.symrefs.items():
    r.refs.set_symbolic_ref(key, target)","for e_target in fetch_result.symrefs.items():
    target = e_target[1]
    key = e_target[0]
    r.refs.set_symbolic_ref(key, target)

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'PushTests', 'test_simple'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'PushTests', 'test_diverged'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_no_head_no_checkout_outstream_errstream_autofallback'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_simple_local_with_checkout'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_fetch_symref'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'PushTests', 'test_delete'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'FetchTests', 'test_simple'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'FetchTests', 'test_with_remote_name'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_simple_local'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_no_head_no_checkout'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_bare_local_with_checkout']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/archive.py,ArchiveTests,test_empty,"for (entry_abspath, entry) in _walk_tree(store, tree, prefix):
    try:
        blob = store[entry.sha]
    except KeyError:
        continue
    data = ChunkedBytesIO(blob.chunked)
    info = tarfile.TarInfo()
    info.name = entry_abspath.decode('ascii')
    info.size = blob.raw_length()
    info.mode = entry.mode
    info.mtime = mtime
    tar.addfile(info, data)
    yield buf.getvalue()
    buf.truncate(0)
    buf.seek(0)","for e_target in _walk_tree(store, tree, prefix):
    entry = e_target[1]
    entry_abspath = e_target[0]
    try:
        blob = store[entry.sha]
    except KeyError:
        continue
    data = ChunkedBytesIO(blob.chunked)
    info = tarfile.TarInfo()
    info.name = entry_abspath.decode('ascii')
    info.size = blob.raw_length()
    info.mode = entry.mode
    info.mtime = mtime
    tar.addfile(info, data)
    yield buf.getvalue()
    buf.truncate(0)
    buf.seek(0)

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_archive.py', 'dulwich.tests.test_archive', 'ArchiveTests', 'test_empty']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/patch.py,DiffTests,test_tree_diff_submodule,"for ((oldpath, newpath), (oldmode, newmode), (oldsha, newsha)) in changes:
    write_object_diff(f, store, (oldpath, oldmode, oldsha), (newpath, newmode, newsha), diff_binary=diff_binary)","for e_target in changes:
    newsha = e_target[2][1]
    oldsha = e_target[2][0]
    newmode = e_target[1][1]
    oldmode = e_target[1][0]
    newpath = e_target[0][1]
    oldpath = e_target[0][0]
    write_object_diff(f, store, (oldpath, oldmode, oldsha), (newpath, newmode, newsha), diff_binary=diff_binary)

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_patch.py', 'dulwich.tests.test_patch', 'DiffTests', 'test_tree_diff'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_patch.py', 'dulwich.tests.test_patch', 'DiffTests', 'test_tree_diff_submodule']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/reflog.py,ReflogDropTests,test_drop_entry_with_rewrite,"for (_, entry) in log[inverse_index:]:
    f.write(format_reflog_line(entry.old_sha, entry.new_sha, entry.committer, entry.timestamp, entry.timezone, entry.message))","for e_target in log[inverse_index:]:
    entry = e_target[1]
    _ = e_target[0]
    f.write(format_reflog_line(entry.old_sha, entry.new_sha, entry.committer, entry.timestamp, entry.timezone, entry.message))

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_reflog.py', 'dulwich.tests.test_reflog', 'ReflogDropTests', 'test_drop_entry'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_reflog.py', 'dulwich.tests.test_reflog', 'ReflogDropTests', 'test_drop_entry_with_rewrite']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/diff_tree.py,ResetTests,test_hard_head,"for (entry1, entry2) in entries:
    if entry1 == entry2 and (not want_unchanged):
        continue
    entry1 = _skip_tree(entry1, include_trees)
    entry2 = _skip_tree(entry2, include_trees)
    if entry1 != _NULL_ENTRY and entry2 != _NULL_ENTRY:
        if stat.S_IFMT(entry1.mode) != stat.S_IFMT(entry2.mode) and (not change_type_same):
            yield TreeChange.delete(entry1)
            entry1 = _NULL_ENTRY
            change_type = CHANGE_ADD
        elif entry1 == entry2:
            change_type = CHANGE_UNCHANGED
        else:
            change_type = CHANGE_MODIFY
    elif entry1 != _NULL_ENTRY:
        change_type = CHANGE_DELETE
    elif entry2 != _NULL_ENTRY:
        change_type = CHANGE_ADD
    else:
        continue
    yield TreeChange(change_type, entry1, entry2)","for e_target in entries:
    entry2 = e_target[1]
    entry1 = e_target[0]
    if entry1 == entry2 and (not want_unchanged):
        continue
    entry1 = _skip_tree(entry1, include_trees)
    entry2 = _skip_tree(entry2, include_trees)
    if entry1 != _NULL_ENTRY and entry2 != _NULL_ENTRY:
        if stat.S_IFMT(entry1.mode) != stat.S_IFMT(entry2.mode) and (not change_type_same):
            yield TreeChange.delete(entry1)
            entry1 = _NULL_ENTRY
            change_type = CHANGE_ADD
        elif entry1 == entry2:
            change_type = CHANGE_UNCHANGED
        else:
            change_type = CHANGE_MODIFY
    elif entry1 != _NULL_ENTRY:
        change_type = CHANGE_DELETE
    elif entry2 != _NULL_ENTRY:
        change_type = CHANGE_ADD
    else:
        continue
    yield TreeChange(change_type, entry1, entry2)

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'PushTests', 'test_simple'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'ResetTests', 'test_hard_commit'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'ResetTests', 'test_hard_head']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/object_store.py,DiffTests,test_tree_diff,"for (obj, path) in objects:
    self.add_object(obj)","for e_target in objects:
    path = e_target[1]
    obj = e_target[0]
    self.add_object(obj)

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_patch.py', 'dulwich.tests.test_patch', 'DiffTests', 'test_object_diff_bin_blob'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_patch.py', 'dulwich.tests.test_patch', 'DiffTests', 'test_tree_diff_submodule'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_patch.py', 'dulwich.tests.test_patch', 'DiffTests', 'test_object_diff_bin_blob_force'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_patch.py', 'dulwich.tests.test_patch', 'DiffTests', 'test_object_diff_blob'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_patch.py', 'dulwich.tests.test_patch', 'DiffTests', 'test_tree_diff']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/repo.py,CreateRepositoryTests,test_create_memory,"for (refname, sha) in refs.items():
    ret.refs.add_if_new(refname, sha)","for e_target in refs.items():
    sha = e_target[1]
    refname = e_target[0]
    ret.refs.add_if_new(refname, sha)

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_server.py', 'dulwich.tests.test_server', 'DictBackendTests', 'test_nonexistant'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_server.py', 'dulwich.tests.test_server', 'DictBackendTests', 'test_bad_repo_path'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_server.py', 'dulwich.tests.test_server', 'ServeCommandTests', 'test_receive_pack'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_repository.py', 'dulwich.tests.test_repository', 'BuildRepoRootTests', 'test_commit_config_identity_in_memoryrepo'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_repository.py', 'dulwich.tests.test_repository', 'MemoryRepoTests', 'test_set_description'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_repository.py', 'dulwich.tests.test_repository', 'CreateRepositoryTests', 'test_create_memory']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/tests/utils.py,TreeChangesTest,test_tree_changes_for_merge_octopus_delete,"for (name, value) in attrs.items():
    if name == 'id':
        sha = FixedSha(value)
        obj.sha = lambda : sha
    else:
        setattr(obj, name, value)","for e_target in attrs.items():
    value = e_target[1]
    name = e_target[0]
    if name == 'id':
        sha = FixedSha(value)
        obj.sha = lambda : sha
    else:
        setattr(obj, name, value)

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'ShaFileCopyTests', 'test_blob_copy'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_simple_local_with_checkout'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_to_tree'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'ShaFileSerializeTests', 'test_tag_serialize'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_octopus_no_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_changes_with_renames'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_paths_max_entries'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_changes_one_parent'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_swap'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'ShaFileSerializeTests', 'test_tree_serialize'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_add_exact_rename_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_modify_rename_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_complex'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_follow_rename'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_rename_threshold'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_one_to_one_ordering'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'ShaFileCopyTests', 'test_tree_copy'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_add_add_same_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_no_renames'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_rename_swap'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_paths_subtree'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_follow_rename_remove_path'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_modify_contents'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_no_checkout_with_bare'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'TagSerializeTests', 'test_serialize_none_message'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_utils.py', 'dulwich.tests.test_utils', 'BuildCommitGraphTest', 'test_trees'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_find_copies_harder_with_rewrites'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'CommitSerializationTests', 'test_serialize_mergetags'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_modify_modify_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkEntryTest', 'test_filter_with_merge'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkEntryTest', 'test_all_changes'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_add_delete'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_similarity_score'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_paths_merge'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_max_files'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'ShaFileCopyTests', 'test_tag_copy'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'TagSerializeTests', 'test_serialize_simple'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_web.py', 'dulwich.tests.test_web', 'DumbHandlersTestCase', 'test_get_loose_object_error'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_no_changes'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_change_type'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_rename_detector'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_many_to_many'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_modify_no_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'ShaFileSerializeTests', 'test_tag_serialize_time_error'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_copy_change_mode'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_no_head_no_checkout'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_delete_no_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_simple_local'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_octopus_modify_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkEntryTest', 'test_all_with_merge'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'CommitSerializationTests', 'test_serialize_mergetag'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_rename_many_to_one'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_no_head_no_checkout_outstream_errstream_autofallback'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_rewrite_threshold'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_modify_mode'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_rename_one_to_one'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_rename_and_different_type'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'CommitSerializationTests', 'test_deserialize_mergetag'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_prune'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'ShaFileSerializeTests', 'test_blob_serialize'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_bare_local_with_checkout'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_similarity_score_cache'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_porcelain.py', 'dulwich.tests.test_porcelain', 'CloneTests', 'test_fetch_symref'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_add_no_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_add_content_rename_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_rename_split_different_type'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_one_to_one'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_copy_modify'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_gitlink'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py', 'dulwich.tests.test_objects', 'CommitSerializationTests', 'test_deserialize_mergetags'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_add_modify_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_rename_one_to_many'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkEntryTest', 'test_filter_changes'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_many_to_one'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_delete_delete_conflict'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_web.py', 'dulwich.tests.test_web', 'DumbHandlersTestCase', 'test_get_info_refs'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_changes_multiple_parents'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_want_unchanged'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_find_copies_harder_content'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_name_order'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_walk.py', 'dulwich.tests.test_walk', 'WalkerTest', 'test_paths'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_find_copies_harder_exact'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_exact_rename_many_to_many'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_change_type_same'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_one_to_many'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_content_rename_with_more_deletions'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'RenameDetectionTest', 'test_reuse_detector'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_web.py', 'dulwich.tests.test_web', 'DumbHandlersTestCase', 'test_get_loose_object'], ['https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_diff_tree.py', 'dulwich.tests.test_diff_tree', 'TreeChangesTest', 'test_tree_changes_for_merge_octopus_delete']]"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/contrib/release_robot.py,GetRecentTagsTest,test_get_recent_tags,"for (key, value) in refs.items():
    key = key.decode('utf-8')
    obj = project.get_object(value)
    if u'tags' not in key:
        continue
    (_, tag) = key.rsplit(u'/', 1)
    try:
        commit = obj.object
    except AttributeError:
        commit = obj
        tag_meta = None
    else:
        tag_meta = (datetime.datetime(*time.gmtime(obj.tag_time)[:6]), obj.id.decode('utf-8'), obj.name.decode('utf-8'))
        commit = project.get_object(commit[1])
    tags[tag] = [datetime.datetime(*time.gmtime(commit.commit_time)[:6]), commit.id.decode('utf-8'), commit.author.decode('utf-8'), tag_meta]","for e_target in refs.items():
    value = e_target[1]
    key = e_target[0]
    key = key.decode('utf-8')
    obj = project.get_object(value)
    if u'tags' not in key:
        continue
    (_, tag) = key.rsplit(u'/', 1)
    try:
        commit = obj.object
    except AttributeError:
        commit = obj
        tag_meta = None
    else:
        tag_meta = (datetime.datetime(*time.gmtime(obj.tag_time)[:6]), obj.id.decode('utf-8'), obj.name.decode('utf-8'))
        commit = project.get_object(commit[1])
    tags[tag] = [datetime.datetime(*time.gmtime(commit.commit_time)[:6]), commit.id.decode('utf-8'), commit.author.decode('utf-8'), tag_meta]

",1,"[['https://github.com/dulwich/dulwich/tree/master/dulwich/contrib/test_release_robot.py', 'dulwich.contrib.test_release_robot', 'GetRecentTagsTest', 'test_get_recent_tags']]"
docker-py,https://github.com/docker/docker-py/tree/master/docker/types/services.py,ServicePortsTest,test_convert_service_ports_with_protocol_and_mode,"for (k, v) in ports.items():
    port_spec = {'Protocol': 'tcp', 'PublishedPort': k}
    if isinstance(v, tuple):
        port_spec['TargetPort'] = v[0]
        if len(v) >= 2 and v[1] is not None:
            port_spec['Protocol'] = v[1]
        if len(v) == 3:
            port_spec['PublishMode'] = v[2]
        if len(v) > 3:
            raise ValueError('Service port configuration can have at most 3 elements: (target_port, protocol, mode)')
    else:
        port_spec['TargetPort'] = v
    result.append(port_spec)","for e_target in ports.items():
    v = e_target[1]
    k = e_target[0]
    port_spec = {'Protocol': 'tcp', 'PublishedPort': k}
    if isinstance(v, tuple):
        port_spec['TargetPort'] = v[0]
        if len(v) >= 2 and v[1] is not None:
            port_spec['Protocol'] = v[1]
        if len(v) == 3:
            port_spec['PublishMode'] = v[2]
        if len(v) > 3:
            raise ValueError('Service port configuration can have at most 3 elements: (target_port, protocol, mode)')
    else:
        port_spec['TargetPort'] = v
    result.append(port_spec)

",1,"[['https://github.com/docker/docker-py/tree/master/tests/unit/dockertypes_test.py', 'tests.unit.dockertypes_test', 'ServicePortsTest', 'test_convert_service_ports_multiple'], ['https://github.com/docker/docker-py/tree/master/tests/unit/dockertypes_test.py', 'tests.unit.dockertypes_test', 'ServicePortsTest', 'test_convert_service_ports_simple'], ['https://github.com/docker/docker-py/tree/master/tests/unit/dockertypes_test.py', 'tests.unit.dockertypes_test', 'ServicePortsTest', 'test_convert_service_ports_invalid'], ['https://github.com/docker/docker-py/tree/master/tests/unit/dockertypes_test.py', 'tests.unit.dockertypes_test', 'ServicePortsTest', 'test_convert_service_ports_with_protocol'], ['https://github.com/docker/docker-py/tree/master/tests/unit/dockertypes_test.py', 'tests.unit.dockertypes_test', 'ServicePortsTest', 'test_convert_service_ports_no_protocol_and_mode'], ['https://github.com/docker/docker-py/tree/master/tests/unit/dockertypes_test.py', 'tests.unit.dockertypes_test', 'ServicePortsTest', 'test_convert_service_ports_with_protocol_and_mode']]"
docker-py,https://github.com/docker/docker-py/tree/master/docker/utils/utils.py,ConverVolumeBindsTest,test_convert_volume_binds_empty,"for (k, v) in binds.items():
    if isinstance(k, bytes):
        k = k.decode('utf-8')
    if isinstance(v, dict):
        if 'ro' in v and 'mode' in v:
            raise ValueError('Binding cannot contain both ""ro"" and ""mode"": {}'.format(repr(v)))
        bind = v['bind']
        if isinstance(bind, bytes):
            bind = bind.decode('utf-8')
        if 'ro' in v:
            mode = 'ro' if v['ro'] else 'rw'
        elif 'mode' in v:
            mode = v['mode']
        else:
            mode = 'rw'
        result.append(f'{k}:{bind}:{mode}')
    else:
        if isinstance(v, bytes):
            v = v.decode('utf-8')
        result.append(f'{k}:{v}:rw')","for e_target in binds.items():
    v = e_target[1]
    k = e_target[0]
    if isinstance(k, bytes):
        k = k.decode('utf-8')
    if isinstance(v, dict):
        if 'ro' in v and 'mode' in v:
            raise ValueError('Binding cannot contain both ""ro"" and ""mode"": {}'.format(repr(v)))
        bind = v['bind']
        if isinstance(bind, bytes):
            bind = bind.decode('utf-8')
        if 'ro' in v:
            mode = 'ro' if v['ro'] else 'rw'
        elif 'mode' in v:
            mode = v['mode']
        else:
            mode = 'rw'
        result.append(f'{k}:{bind}:{mode}')
    else:
        if isinstance(v, bytes):
            v = v.decode('utf-8')
        result.append(f'{k}:{v}:rw')

",1,"[['https://github.com/docker/docker-py/tree/master/tests/unit/utils_test.py', 'tests.unit.utils_test', 'ConverVolumeBindsTest', 'test_convert_volume_binds_no_mode'], ['https://github.com/docker/docker-py/tree/master/tests/unit/utils_test.py', 'tests.unit.utils_test', 'ConverVolumeBindsTest', 'test_convert_volume_binds_list'], ['https://github.com/docker/docker-py/tree/master/tests/unit/utils_test.py', 'tests.unit.utils_test', 'ConverVolumeBindsTest', 'test_convert_volume_binds_compact'], ['https://github.com/docker/docker-py/tree/master/tests/unit/utils_test.py', 'tests.unit.utils_test', 'ConverVolumeBindsTest', 'test_convert_volume_binds_unicode_bytes_input'], ['https://github.com/docker/docker-py/tree/master/tests/unit/utils_test.py', 'tests.unit.utils_test', 'ConverVolumeBindsTest', 'test_convert_volume_binds_unicode_unicode_input'], ['https://github.com/docker/docker-py/tree/master/tests/unit/utils_test.py', 'tests.unit.utils_test', 'ConverVolumeBindsTest', 'test_convert_volume_binds_complete'], ['https://github.com/docker/docker-py/tree/master/tests/unit/utils_test.py', 'tests.unit.utils_test', 'ConverVolumeBindsTest', 'test_convert_volume_binds_empty']]"
docker-py,https://github.com/docker/docker-py/tree/master/docker/context/api.py,BaseContextTest,test_default_in_context_list,"for (dirname, dirnames, fnames) in os.walk(get_meta_dir()):
    for filename in fnames + dirnames:
        if filename == METAFILE:
            try:
                data = json.load(open(os.path.join(dirname, filename)))
                names.append(data['Name'])
            except Exception as e:
                raise errors.ContextException('Failed to load metafile {}: {}'.format(filename, e))","for e_target in os.walk(get_meta_dir()):
    fnames = e_target[2]
    dirnames = e_target[1]
    dirname = e_target[0]
    for filename in fnames + dirnames:
        if filename == METAFILE:
            try:
                data = json.load(open(os.path.join(dirname, filename)))
                names.append(data['Name'])
            except Exception as e:
                raise errors.ContextException('Failed to load metafile {}: {}'.format(filename, e))

",1,"[['https://github.com/docker/docker-py/tree/master/tests/unit/context_test.py', 'tests.unit.context_test', 'BaseContextTest', 'test_default_in_context_list']]"
ubelt,https://github.com/Erotemic/ubelt/tree/master/ubelt/util_dict.py,,test_group_items_callable,"for (key, item) in pair_list:
    id_to_items[key].append(item)","for e_target in pair_list:
    item = e_target[1]
    key = e_target[0]
    id_to_items[key].append(item)

",1,"[['https://github.com/Erotemic/ubelt/tree/master/tests/test_dict.py', 'tests.test_dict', '', 'test_group_items_callable']]"
ubelt,https://github.com/Erotemic/ubelt/tree/master/ubelt/util_dict.py,,test_dict_hist_ordered,"for (item, weight) in zip(items, weights):
    hist_[item] += weight","for e_target in zip(items, weights):
    weight = e_target[1]
    item = e_target[0]
    hist_[item] += weight

",1,"[['https://github.com/Erotemic/ubelt/tree/master/tests/test_dict.py', 'tests.test_dict', '', 'test_dict_hist_ordered']]"
ubelt,https://github.com/Erotemic/ubelt/tree/master/ubelt/orderedset.py,,test_remove,"for (k, v) in self.map.items():
    if v >= i:
        self.map[k] = v - 1","for e_target in self.map.items():
    v = e_target[1]
    k = e_target[0]
    if v >= i:
        self.map[k] = v - 1

",1,"[['https://github.com/Erotemic/ubelt/tree/master/tests/test_orderedset.py', 'tests.test_orderedset', '', 'test_remove']]"
finta,https://github.com/peerchemist/finta/tree/master/finta/finta.py,,test_kama,"for (s, ma, price) in zip(sc.iteritems(), sma.shift().iteritems(), ohlc[column].iteritems()):
    try:
        kama.append(kama[-1] + s[1] * (price[1] - kama[-1]))
    except (IndexError, TypeError):
        if pd.notnull(ma[1]):
            kama.append(ma[1] + s[1] * (price[1] - ma[1]))
        else:
            kama.append(None)","for e_target in zip(sc.iteritems(), sma.shift().iteritems(), ohlc[column].iteritems()):
    price = e_target[2]
    ma = e_target[1]
    s = e_target[0]
    try:
        kama.append(kama[-1] + s[1] * (price[1] - kama[-1]))
    except (IndexError, TypeError):
        if pd.notnull(ma[1]):
            kama.append(ma[1] + s[1] * (price[1] - ma[1]))
        else:
            kama.append(None)

",1,"[['https://github.com/peerchemist/finta/tree/master/tests/test_unit.py', 'tests.test_unit', '', 'test_kama']]"
simpleai,https://github.com/simpleai-team/simpleai/tree/master/simpleai/search/arc.py,TestAllArcs,test_adds_pairs_in_both_directions,"for (neighbors, constraint) in constraints:
    if len(neighbors) == 2:
        (x, y) = neighbors
        list(map(arcs.add, ((x, y), (y, x))))","for e_target in constraints:
    constraint = e_target[1]
    neighbors = e_target[0]
    if len(neighbors) == 2:
        (x, y) = neighbors
        list(map(arcs.add, ((x, y), (y, x))))

",1,"[['https://github.com/simpleai-team/simpleai/tree/master/tests/search/test_arc_concistency.py', 'tests.search.test_arc_concistency', 'TestAllArcs', 'test_constraints_with_more_than_2_neighbors_arent_added'], ['https://github.com/simpleai-team/simpleai/tree/master/tests/search/test_arc_concistency.py', 'tests.search.test_arc_concistency', 'TestAllArcs', 'test_adds_pairs_in_both_directions']]"
simpleai,https://github.com/simpleai-team/simpleai/tree/master/simpleai/search/csp.py,TestCsp,test_find_conflicts,"for (neighbors, constraint) in problem.constraints:
    if all((n in assignment for n in neighbors)):
        if not _call_constraint(assignment, neighbors, constraint):
            conflicts.append((neighbors, constraint))","for e_target in problem.constraints:
    constraint = e_target[1]
    neighbors = e_target[0]
    if all((n in assignment for n in neighbors)):
        if not _call_constraint(assignment, neighbors, constraint):
            conflicts.append((neighbors, constraint))

",1,"[['https://github.com/simpleai-team/simpleai/tree/master/tests/search/test_csp.py', 'tests.search.test_csp', 'TestCsp', 'test_find_conflicts_with_added_variable'], ['https://github.com/simpleai-team/simpleai/tree/master/tests/search/test_csp.py', 'tests.search.test_csp', 'TestCsp', 'test_find_conflicts']]"
dupeguru,https://github.com/arsenetar/dupeguru/tree/master/hscommon/util.py,,test_multi_replace,"for (r_from, r_to) in [r for r in replace if r[0] in s]:
    s = s.replace(r_from, r_to)","for e_target in [r for r in replace if r[0] in s]:
    r_to = e_target[1]
    r_from = e_target[0]
    s = s.replace(r_from, r_to)

",1,"[['https://github.com/arsenetar/dupeguru/tree/master/hscommon/tests/util_test.py', 'hscommon.tests.util_test', '', 'test_multi_replace']]"
dupeguru,https://github.com/arsenetar/dupeguru/tree/master/hscommon/gui/selectable_list.py,,test_search_by_prefix,"for (index, s) in enumerate(self):
    if s.lower().startswith(prefix):
        return index","for e_target in enumerate(self):
    s = e_target[1]
    index = e_target[0]
    if s.lower().startswith(prefix):
        return index

",1,"[['https://github.com/arsenetar/dupeguru/tree/master/hscommon/tests/selectable_list_test.py', 'hscommon.tests.selectable_list_test', '', 'test_search_by_prefix']]"
dupeguru,https://github.com/arsenetar/dupeguru/tree/master/core/ignore.py,,test_filter,"for (first, second) in self:
    if func(first, second):
        filtered.ignore(first, second)","for e_target in self:
    second = e_target[1]
    first = e_target[0]
    if func(first, second):
        filtered.ignore(first, second)

",1,"[['https://github.com/arsenetar/dupeguru/tree/master/core/tests/ignore_test.py', 'core.tests.ignore_test', '', 'test_filter']]"
dupeguru,https://github.com/arsenetar/dupeguru/tree/master/core/directories.py,,test_save_and_load,"for (p, s) in self.states.items():
    if p.is_parent_of(path) and len(p) > prevlen:
        prevlen = len(p)
        state = s","for e_target in self.states.items():
    s = e_target[1]
    p = e_target[0]
    if p.is_parent_of(path) and len(p) > prevlen:
        prevlen = len(p)
        state = s

",1,"[['https://github.com/arsenetar/dupeguru/tree/master/core/tests/directories_test.py', 'core.tests.directories_test', '', 'test_save_and_load']]"
guessit,https://github.com/guessit-io/guessit/tree/master/guessit/options.py,,test_merge_configurations_deep,"for (option, value) in options.items():
    merge_option_value(option, value, merged)","for e_target in options.items():
    value = e_target[1]
    option = e_target[0]
    merge_option_value(option, value, merged)

",1,"[['https://github.com/guessit-io/guessit/tree/master/guessit/test/test_options.py', 'guessit.test.test_options', '', 'test_merge_configurations_lists'], ['https://github.com/guessit-io/guessit/tree/master/guessit/test/test_options.py', 'guessit.test.test_options', '', 'test_merge_configurations'], ['https://github.com/guessit-io/guessit/tree/master/guessit/test/test_options.py', 'guessit.test.test_options', '', 'test_merge_configurations_pristine_properties_deep'], ['https://github.com/guessit-io/guessit/tree/master/guessit/test/test_options.py', 'guessit.test.test_options', '', 'test_merge_configurations_pristine_properties'], ['https://github.com/guessit-io/guessit/tree/master/guessit/test/test_options.py', 'guessit.test.test_options', '', 'test_merge_configurations_pristine_all'], ['https://github.com/guessit-io/guessit/tree/master/guessit/test/test_options.py', 'guessit.test.test_options', '', 'test_merge_configurations_pristine_properties2'], ['https://github.com/guessit-io/guessit/tree/master/guessit/test/test_options.py', 'guessit.test.test_options', '', 'test_merge_configurations_deep']]"
elasticdl,https://github.com/sql-machine-learning/elasticdl/tree/master/elasticdl/python/common/hash_utils.py,HashUtilTest,test_scatter_embedding_vector,"for (i, item_id) in enumerate(indices_list):
    ps_id = int_to_id(item_id, bucket_num)
    if ps_id not in ps_ids:
        ps_ids[ps_id] = [(i, item_id)]
    else:
        ps_ids[ps_id].append((i, item_id))","for e_target in enumerate(indices_list):
    item_id = e_target[1]
    i = e_target[0]
    ps_id = int_to_id(item_id, bucket_num)
    if ps_id not in ps_ids:
        ps_ids[ps_id] = [(i, item_id)]
    else:
        ps_ids[ps_id].append((i, item_id))

",1,"[['https://github.com/sql-machine-learning/elasticdl/tree/master/elasticdl/python/tests/hash_utils_test.py', 'elasticdl.python.tests.hash_utils_test', 'HashUtilTest', 'test_scatter_embedding_vector']]"
elasticdl,https://github.com/sql-machine-learning/elasticdl/tree/master/elasticdl/python/common/hash_utils.py,HashUtilTest,test_scatter_embedding_vector,"for (ps_id, i_item_id) in ps_ids.items():
    i = [v[0] for v in i_item_id]
    item_id = [v[1] for v in i_item_id]
    results[ps_id] = (values[i, :], item_id)","for e_target in ps_ids.items():
    i_item_id = e_target[1]
    ps_id = e_target[0]
    i = [v[0] for v in i_item_id]
    item_id = [v[1] for v in i_item_id]
    results[ps_id] = (values[i, :], item_id)

",1,"[['https://github.com/sql-machine-learning/elasticdl/tree/master/elasticdl/python/tests/hash_utils_test.py', 'elasticdl.python.tests.hash_utils_test', 'HashUtilTest', 'test_scatter_embedding_vector']]"
fuck-coding-interviews,https://github.com/vinta/fuck-coding-interviews/tree/master/data_structures/graphs/adjacency_map_directed_weighted_graph.py,TestCase,test_find_shortest_path_dijkstra,"for (neighbor, weight) in self.outgoing_edges[v].items():
    if neighbor not in visited:
        nei_distance = v_distance + weight
        if nei_distance < distances[neighbor]:
            distances[neighbor] = nei_distance
            previous[neighbor] = v
            heapq.heappush(min_heap, (distances[neighbor], neighbor))","for e_target in self.outgoing_edges[v].items():
    weight = e_target[1]
    neighbor = e_target[0]
    if neighbor not in visited:
        nei_distance = v_distance + weight
        if nei_distance < distances[neighbor]:
            distances[neighbor] = nei_distance
            previous[neighbor] = v
            heapq.heappush(min_heap, (distances[neighbor], neighbor))

",1,"[['https://github.com/vinta/fuck-coding-interviews/tree/master/data_structures/graphs/tests/test_adjacency_map_directed_weighted_graph.py', 'data_structures.graphs.tests.test_adjacency_map_directed_weighted_graph', 'TestCase', 'test_find_shortest_path_dijkstra']]"
lookatme,https://github.com/d0c-s4vage/lookatme/tree/master/tests/utils.py,,test_lists,"for (idx, row) in enumerate(rendered):
    if full_strip:
        stripped = row_text(row).strip()
    else:
        stripped = row_text(row).rstrip()
    if idx >= len(correct_render):
        assert stripped == b''
    else:
        assert correct_render[idx] == stripped","for e_target in enumerate(rendered):
    row = e_target[1]
    idx = e_target[0]
    if full_strip:
        stripped = row_text(row).strip()
    else:
        stripped = row_text(row).rstrip()
    if idx >= len(correct_render):
        assert stripped == b''
    else:
        assert correct_render[idx] == stripped

",1,"[['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_block_quote'], ['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_hrule'], ['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_table'], ['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_numbered_lists'], ['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_code'], ['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_lists_with_newline'], ['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_code_yaml'], ['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_headings'], ['https://github.com/d0c-s4vage/lookatme/tree/master/tests/test_markdown.py', 'tests.test_markdown', '', 'test_lists']]"
dominate,https://github.com/Knio/dominate/tree/master/dominate/dom_tag.py,,test_attributes,"for (attr, value) in d.items():
    c.set_attribute(*dom_tag.clean_pair(attr, value))","for e_target in d.items():
    value = e_target[1]
    attr = e_target[0]
    c.set_attribute(*dom_tag.clean_pair(attr, value))

",1,"[['https://github.com/Knio/dominate/tree/master/tests/test_svg.py', 'tests.test_svg', '', 'test_filters'], ['https://github.com/Knio/dominate/tree/master/tests/test_html.py', 'tests.test_html', '', 'test_attributes']]"
MuGo,https://github.com/brilee/MuGo/tree/master//load_data_sets.py,TestDataSetHelpers,test_onehot,"for (i, coord) in enumerate(coords):
    output[i, utils.flatten_coords(coord)] = 1","for e_target in enumerate(coords):
    coord = e_target[1]
    i = e_target[0]
    output[i, utils.flatten_coords(coord)] = 1

",1,"[['https://github.com/brilee/MuGo/tree/master/tests/test_datasets.py', 'tests.test_datasets', 'TestDataSetHelpers', 'test_onehot']]"
MuGo,https://github.com/brilee/MuGo/tree/master//features.py,TestFeatureExtraction,test_recent_moves_feature,"for (i, player_move) in enumerate(reversed(position.recent[-P:])):
    (_, move) = player_move
    if move is not None:
        onehot_features[move[0], move[1], i] = 1","for e_target in enumerate(reversed(position.recent[-P:])):
    player_move = e_target[1]
    i = e_target[0]
    (_, move) = player_move
    if move is not None:
        onehot_features[move[0], move[1], i] = 1

",1,"[['https://github.com/brilee/MuGo/tree/master/tests/test_features.py', 'tests.test_features', 'TestFeatureExtraction', 'test_recent_moves_feature']]"
pydash,https://github.com/dgilland/pydash/tree/master/src/pydash/collections.py,,test_curry_arity_max_from_func,"for (index, item) in iterable:
    result = callit(iteratee, result, item, index, argcount=argcount)","for e_target in iterable:
    item = e_target[1]
    index = e_target[0]
    result = callit(iteratee, result, item, index, argcount=argcount)

",1,"[['https://github.com/dgilland/pydash/tree/master/tests/test_functions.py', 'tests.test_functions', '', 'test_curry_arity_max_from_func']]"
envelopes,https://github.com/tomekwojcik/envelopes/tree/master/envelopes/envelope.py,Test_Envelope,test_to_mime_message_unicode,"for (key, value) in self._headers.items():
    msg[key] = self._header(value)","for e_target in self._headers.items():
    value = e_target[1]
    key = e_target[0]
    msg[key] = self._header(value)

",1,"[['https://github.com/tomekwojcik/envelopes/tree/master/tests/test_envelope.py', 'tests.test_envelope', 'Test_Envelope', 'test_to_mime_message_with_data'], ['https://github.com/tomekwojcik/envelopes/tree/master/tests/test_envelope.py', 'tests.test_envelope', 'Test_Envelope', 'test_to_mime_message_with_no_data'], ['https://github.com/tomekwojcik/envelopes/tree/master/tests/test_envelope.py', 'tests.test_envelope', 'Test_Envelope', 'test_to_mime_message_with_many_to_addresses'], ['https://github.com/tomekwojcik/envelopes/tree/master/tests/test_envelope.py', 'tests.test_envelope', 'Test_Envelope', 'test_to_mime_message_unicode']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/test/tools.py,,test_invalid_benchmark_tree,"for (i, value) in enumerate(values):
    mapping = {'version': i, 'dummy_value': value}
    copy_template(template_path, project_path, dvcs, mapping)
    dvcs.commit('Revision {0}'.format(i))
    dvcs.tag(i)","for e_target in enumerate(values):
    value = e_target[1]
    i = e_target[0]
    mapping = {'version': i, 'dummy_value': value}
    copy_template(template_path, project_path, dvcs, mapping)
    dvcs.commit('Revision {0}'.format(i))
    dvcs.tag(i)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_import_failure_retry'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_install_success'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_conf_inside_benchmarks_dir'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_benchmark_param_selection'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_install_env_matrix_values'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_hg'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_custom_commands'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_code_extraction'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_run_spec'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_git'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_installed_commit_hash'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_find_benchmarks_cwd_imports'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_publish.py', 'test.test_publish', '', 'test_publish'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_build_isolation'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_git_annotated_tag_date'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_invalid_benchmark_tree']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/test/tools.py,,test_invalid_benchmark_tree,"for (start_commit, branch_name, values) in extra_branches:
    dvcs.checkout(branch_name, start_commit)
    for (i, value) in enumerate(values):
        mapping = {'version': '{0}'.format(i), 'dummy_value': value}
        copy_template(template_path, project_path, dvcs, mapping)
        dvcs.commit('Revision {0}.{1}'.format(branch_name, i))","for e_target in extra_branches:
    values = e_target[2]
    branch_name = e_target[1]
    start_commit = e_target[0]
    dvcs.checkout(branch_name, start_commit)
    for (i, value) in enumerate(values):
        mapping = {'version': '{0}'.format(i), 'dummy_value': value}
        copy_template(template_path, project_path, dvcs, mapping)
        dvcs.commit('Revision {0}.{1}'.format(branch_name, i))

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_import_failure_retry'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_install_success'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_conf_inside_benchmarks_dir'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_benchmark_param_selection'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_install_env_matrix_values'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_hg'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_custom_commands'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_code_extraction'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_run_spec'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_git'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_installed_commit_hash'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_find_benchmarks_cwd_imports'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_publish.py', 'test.test_publish', '', 'test_publish'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_build_isolation'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_git_annotated_tag_date'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_invalid_benchmark_tree']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/test/tools.py,,test_invalid_benchmark_tree,"for (i, value) in enumerate(values):
    mapping = {'version': '{0}'.format(i), 'dummy_value': value}
    copy_template(template_path, project_path, dvcs, mapping)
    dvcs.commit('Revision {0}.{1}'.format(branch_name, i))","for e_target in enumerate(values):
    value = e_target[1]
    i = e_target[0]
    mapping = {'version': '{0}'.format(i), 'dummy_value': value}
    copy_template(template_path, project_path, dvcs, mapping)
    dvcs.commit('Revision {0}.{1}'.format(branch_name, i))

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_import_failure_retry'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_install_success'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_conf_inside_benchmarks_dir'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_benchmark_param_selection'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_install_env_matrix_values'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_hg'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_custom_commands'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_code_extraction'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_run_spec'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_git'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_installed_commit_hash'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_find_benchmarks_cwd_imports'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_publish.py', 'test.test_publish', '', 'test_publish'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test_build_isolation'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_repo.py', 'test.test_repo', '', 'test_repo_git_annotated_tag_date'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_benchmarks.py', 'test.test_benchmarks', '', 'test_invalid_benchmark_tree']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/environment.py,,test__parse_matrix,"for (t, m) in matrices:
    for (key, value) in m.items():
        result[t, key] = value","for e_target in matrices:
    m = e_target[1]
    t = e_target[0]
    for (key, value) in m.items():
        result[t, key] = value

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test__parse_matrix_invalid'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test__parse_matrix_legacy'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test__parse_matrix']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/environment.py,,test__parse_matrix,"for (key, value) in m.items():
    result[t, key] = value","for e_target in m.items():
    value = e_target[1]
    key = e_target[0]
    result[t, key] = value

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test__parse_matrix_invalid'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test__parse_matrix_legacy'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test__parse_matrix']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/environment.py,,test__parse_matrix_entries,"for ((key_type, key), value) in entries.items():
    if key_type == 'python':
        python = value
    elif key_type == 'env':
        tagged_env_vars['build', key] = value
    elif key_type == 'env_nobuild':
        tagged_env_vars['nobuild', key] = value
    elif key_type == 'req':
        requirements[key] = value
    else:
        raise ValueError('Invalid matrix key type {0}'.format(key))","for e_target in entries.items():
    value = e_target[1]
    key = e_target[0][1]
    key_type = e_target[0][0]
    if key_type == 'python':
        python = value
    elif key_type == 'env':
        tagged_env_vars['build', key] = value
    elif key_type == 'env_nobuild':
        tagged_env_vars['nobuild', key] = value
    elif key_type == 'req':
        requirements[key] = value
    else:
        raise ValueError('Invalid matrix key type {0}'.format(key))

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_environment.py', 'test.test_environment', '', 'test__parse_matrix_entries']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/step_detect.py,,test_zero_weight,"for (j, x) in enumerate(y):
    if x is None or x != x:
        continue
    if w is not None and w[j] is not None and (w[j] <= 0):
        continue
    index_map[len(y_filtered)] = j
    y_filtered.append(x)","for e_target in enumerate(y):
    x = e_target[1]
    j = e_target[0]
    if x is None or x != x:
        continue
    if w is not None and w[j] is not None and (w[j] <= 0):
        continue
    index_map[len(y_filtered)] = j
    y_filtered.append(x)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_weighted'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_zero_weight']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/step_detect.py,,test_zero_weight,"for (r, v, d) in zip(right, values, dists):
    steps.append((index_map[l], index_map[r - 1] + 1, v, min(y_filtered[l:r]), abs(d / (r - l))))
    l = r","for e_target in zip(right, values, dists):
    d = e_target[2]
    v = e_target[1]
    r = e_target[0]
    steps.append((index_map[l], index_map[r - 1] + 1, v, min(y_filtered[l:r]), abs(d / (r - l))))
    l = r

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_weighted'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_zero_weight']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/step_detect.py,,test_regression_min_size,"for (l, r, cur_v, cur_min, cur_err) in reversed(steps):
    threshold_step = max(cur_err, thresholded_best_err, threshold * cur_v)
    if thresholded_best_v > cur_v + threshold_step:
        if r - l < min_size:
            short_prev = (thresholded_best_v, thresholded_best_err)
        regression_pos.append((r - 1, prev_l, cur_v, best_v))
        thresholded_best_v = cur_v
        thresholded_best_err = cur_err
    elif short_prev is not None:
        if short_prev[0] <= cur_v + threshold_step:
            regression_pos.pop()
            (thresholded_best_v, thresholded_best_err) = short_prev
        short_prev = None
    prev_l = l
    if cur_v < best_v:
        best_v = cur_v","for e_target in reversed(steps):
    cur_err = e_target[4]
    cur_min = e_target[3]
    cur_v = e_target[2]
    r = e_target[1]
    l = e_target[0]
    threshold_step = max(cur_err, thresholded_best_err, threshold * cur_v)
    if thresholded_best_v > cur_v + threshold_step:
        if r - l < min_size:
            short_prev = (thresholded_best_v, thresholded_best_err)
        regression_pos.append((r - 1, prev_l, cur_v, best_v))
        thresholded_best_v = cur_v
        thresholded_best_err = cur_err
    elif short_prev is not None:
        if short_prev[0] <= cur_v + threshold_step:
            regression_pos.pop()
            (thresholded_best_v, thresholded_best_err) = short_prev
        short_prev = None
    prev_l = l
    if cur_v < best_v:
        best_v = cur_v

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_regression_threshold'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_regression_min_size']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/step_detect.py,,test_autocorrelated,"for (r, v) in zip(rights, values):
    for (yv, wv) in zip(y[l:r], w[l:r]):
        E = yv - v
        s += abs(E - rho * E_prev) * wv
        E_prev = E
    l = r","for e_target in zip(rights, values):
    v = e_target[1]
    r = e_target[0]
    for (yv, wv) in zip(y[l:r], w[l:r]):
        E = yv - v
        s += abs(E - rho * E_prev) * wv
        E_prev = E
    l = r

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_zero_variance'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_autocorrelated']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/step_detect.py,,test_autocorrelated,"for (yv, wv) in zip(y[l:r], w[l:r]):
    E = yv - v
    s += abs(E - rho * E_prev) * wv
    E_prev = E","for e_target in zip(y[l:r], w[l:r]):
    wv = e_target[1]
    yv = e_target[0]
    E = yv - v
    s += abs(E - rho * E_prev) * wv
    E_prev = E

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_zero_variance'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_step_detect.py', 'test.test_step_detect', '', 'test_autocorrelated']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/results.py,,test_rm,"for (root, filename, machine_name) in iter_results_paths(results):
    try:
        yield Results.load(os.path.join(root, filename), machine_name=machine_name)
    except util.UserError as exc:
        log.warning(six.text_type(exc))","for e_target in iter_results_paths(results):
    machine_name = e_target[2]
    filename = e_target[1]
    root = e_target[0]
    try:
        yield Results.load(os.path.join(root, filename), machine_name=machine_name)
    except util.UserError as exc:
        log.warning(six.text_type(exc))

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_iter_results'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_rm.py', 'test.test_rm', '', 'test_rm']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/results.py,,test_get_result_hash_from_prefix,"for (root, filename, r_machine_name) in iter_results_paths(path):
    if r_machine_name != machine_name:
        log.warning(""Skipping results '{0}': machine name is not '{1}'"".format(os.path.join(root, filename), machine_name))
        continue
    results_commit = filename.split('-')[0]
    cmp_len = min(len(commit_prefix), len(results_commit))
    if results_commit[:cmp_len] == commit_prefix[:cmp_len]:
        commits.add(results_commit)","for e_target in iter_results_paths(path):
    r_machine_name = e_target[2]
    filename = e_target[1]
    root = e_target[0]
    if r_machine_name != machine_name:
        log.warning(""Skipping results '{0}': machine name is not '{1}'"".format(os.path.join(root, filename), machine_name))
        continue
    results_commit = filename.split('-')[0]
    cmp_len = min(len(commit_prefix), len(results_commit))
    if results_commit[:cmp_len] == commit_prefix[:cmp_len]:
        commits.add(results_commit)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_get_result_hash_from_prefix']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/results.py,,test_table_formatting,"for (j, values) in enumerate(itertools.product(*row_params)):
    row_results = [util.human_value(x[0], benchmark['unit'], err=x[1]) for x in result[j * column_items:(j + 1) * column_items]]
    row = [_format_param_value(value) for value in values] + row_results
    rows.append(row)","for e_target in enumerate(itertools.product(*row_params)):
    values = e_target[1]
    j = e_target[0]
    row_results = [util.human_value(x[0], benchmark['unit'], err=x[1]) for x in result[j * column_items:(j + 1) * column_items]]
    row = [_format_param_value(value) for value in values] + row_results
    rows.append(row)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_table_formatting']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/results.py,,test_results,"for (name, key_values) in six.iteritems(d['results']):
    for (key, value) in zip(d['result_columns'], key_values):
        key_dict = simple_keys.get(key)
        if key_dict is not None:
            key_dict[name] = value
            continue
        elif key.startswith('stats_'):
            if value is not None:
                if name not in obj._stats:
                    obj._stats[name] = [{} for _ in value]
                stats_key = key[6:]
                for (j, v) in enumerate(value):
                    if v is not None:
                        obj._stats[name][j][stats_key] = v
        else:
            raise KeyError('unknown data key {}'.format(key))
    for key_dict in simple_keys.values():
        key_dict.setdefault(name, None)
    obj._stats.setdefault(name, None)","for e_target in six.iteritems(d['results']):
    key_values = e_target[1]
    name = e_target[0]
    for (key, value) in zip(d['result_columns'], key_values):
        key_dict = simple_keys.get(key)
        if key_dict is not None:
            key_dict[name] = value
            continue
        elif key.startswith('stats_'):
            if value is not None:
                if name not in obj._stats:
                    obj._stats[name] = [{} for _ in value]
                stats_key = key[6:]
                for (j, v) in enumerate(value):
                    if v is not None:
                        obj._stats[name][j][stats_key] = v
        else:
            raise KeyError('unknown data key {}'.format(key))
    for key_dict in simple_keys.values():
        key_dict.setdefault(name, None)
    obj._stats.setdefault(name, None)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_set_commit_hash'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_backward_compat_load'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_results']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/results.py,,test_results,"for (key, value) in zip(d['result_columns'], key_values):
    key_dict = simple_keys.get(key)
    if key_dict is not None:
        key_dict[name] = value
        continue
    elif key.startswith('stats_'):
        if value is not None:
            if name not in obj._stats:
                obj._stats[name] = [{} for _ in value]
            stats_key = key[6:]
            for (j, v) in enumerate(value):
                if v is not None:
                    obj._stats[name][j][stats_key] = v
    else:
        raise KeyError('unknown data key {}'.format(key))","for e_target in zip(d['result_columns'], key_values):
    value = e_target[1]
    key = e_target[0]
    key_dict = simple_keys.get(key)
    if key_dict is not None:
        key_dict[name] = value
        continue
    elif key.startswith('stats_'):
        if value is not None:
            if name not in obj._stats:
                obj._stats[name] = [{} for _ in value]
            stats_key = key[6:]
            for (j, v) in enumerate(value):
                if v is not None:
                    obj._stats[name][j][stats_key] = v
    else:
        raise KeyError('unknown data key {}'.format(key))

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_set_commit_hash'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_backward_compat_load'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_results']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/results.py,,test_results,"for (j, v) in enumerate(value):
    if v is not None:
        obj._stats[name][j][stats_key] = v","for e_target in enumerate(value):
    v = e_target[1]
    j = e_target[0]
    if v is not None:
        obj._stats[name][j][stats_key] = v

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_set_commit_hash'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_backward_compat_load'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_results.py', 'test.test_results', '', 'test_results']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/graph.py,,test_graph_steps,"for (j, item) in enumerate(self._steps):
    if not isinstance(item, list):
        self._steps[j] = item.get()","for e_target in enumerate(self._steps):
    item = e_target[1]
    j = e_target[0]
    if not isinstance(item, list):
        self._steps[j] = item.get()

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test_graph_steps']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/graph.py,,test_summary_graph_loop,"for (x, y) in val:
    graph.add_data_point(x, y)","for e_target in val:
    y = e_target[1]
    x = e_target[0]
    graph.add_data_point(x, y)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test_graph_single'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test_summary_graph'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test_graph_multi'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test_summary_graph_loop']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/graph.py,,test__fill_missing_data,"for (i, v) in enumerate(y):
    if not is_na(v):
        gap_size = i - prev_idx - 1
        if 0 < gap_size <= max_gap_size and (not is_na(prev)):
            for k in range(1, gap_size + 1):
                filled[prev_idx + k] = (v * k + (gap_size + 1 - k) * prev) / (gap_size + 1)
        prev = v
        prev_idx = i","for e_target in enumerate(y):
    v = e_target[1]
    i = e_target[0]
    if not is_na(v):
        gap_size = i - prev_idx - 1
        if 0 < gap_size <= max_gap_size and (not is_na(prev)):
            for k in range(1, gap_size + 1):
                filled[prev_idx + k] = (v * k + (gap_size + 1 - k) * prev) / (gap_size + 1)
        prev = v
        prev_idx = i

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test__fill_missing_data']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/graph.py,,test__combine_graph_data,"for (dataset, graph) in zip(datasets, graphs):
    for (k, v, dv) in dataset:
        i = x_idx[k]
        if graph.scalar_series:
            v = [v]
        for (j, y) in enumerate(v):
            ys[pos + j][i] = y
    pos += graph.n_series","for e_target in zip(datasets, graphs):
    graph = e_target[1]
    dataset = e_target[0]
    for (k, v, dv) in dataset:
        i = x_idx[k]
        if graph.scalar_series:
            v = [v]
        for (j, y) in enumerate(v):
            ys[pos + j][i] = y
    pos += graph.n_series

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test__combine_graph_data']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/graph.py,,test__combine_graph_data,"for (k, v, dv) in dataset:
    i = x_idx[k]
    if graph.scalar_series:
        v = [v]
    for (j, y) in enumerate(v):
        ys[pos + j][i] = y","for e_target in dataset:
    dv = e_target[2]
    v = e_target[1]
    k = e_target[0]
    i = x_idx[k]
    if graph.scalar_series:
        v = [v]
    for (j, y) in enumerate(v):
        ys[pos + j][i] = y

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test__combine_graph_data']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/graph.py,,test__combine_graph_data,"for (j, y) in enumerate(v):
    ys[pos + j][i] = y","for e_target in enumerate(v):
    y = e_target[1]
    j = e_target[0]
    ys[pos + j][i] = y

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_graph.py', 'test.test_graph', '', 'test__combine_graph_data']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/runner.py,,test_skip_param_selection,"for (name, benchmark) in six.iteritems(benchmarks):
    log.step()
    log.warning('{0} skipped'.format(name))
    started_at = datetime.datetime.utcnow()
    r = fail_benchmark(benchmark)
    results.add_result(benchmark, r, selected_idx=benchmarks.benchmark_selection.get(name), started_at=started_at)","for e_target in six.iteritems(benchmarks):
    benchmark = e_target[1]
    name = e_target[0]
    log.step()
    log.warning('{0} skipped'.format(name))
    started_at = datetime.datetime.utcnow()
    r = fail_benchmark(benchmark)
    results.add_result(benchmark, r, selected_idx=benchmarks.benchmark_selection.get(name), started_at=started_at)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_skip_param_selection']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/runner.py,,test_quick,"for (name, benchmark) in sorted(six.iteritems(benchmarks)):
    key = benchmark.get('setup_cache_key')
    setup_cache_timeout[key] = max(benchmark.get('setup_cache_timeout', benchmark['timeout']), setup_cache_timeout.get(key, 0))
    benchmark_order.setdefault(key, []).append((name, benchmark))
    max_rounds = max(max_rounds, get_rounds(benchmark))
    cache_users.setdefault(key, set()).add(name)","for e_target in sorted(six.iteritems(benchmarks)):
    benchmark = e_target[1]
    name = e_target[0]
    key = benchmark.get('setup_cache_key')
    setup_cache_timeout[key] = max(benchmark.get('setup_cache_timeout', benchmark['timeout']), setup_cache_timeout.get(key, 0))
    benchmark_order.setdefault(key, []).append((name, benchmark))
    max_rounds = max(max_rounds, get_rounds(benchmark))
    cache_users.setdefault(key, set()).add(name)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_run_benchmarks'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_timeraw_benchmark'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_quick']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/runner.py,,test_quick,"for (name, benchmark, setup_cache_key, is_final) in iter_run_items():
    selected_idx = benchmarks.benchmark_selection.get(name)
    started_at = datetime.datetime.utcnow()
    if name in failed_benchmarks:
        if is_final:
            partial_info_time = None
            log.info(name, reserve_space=True)
            log_benchmark_result(results, benchmark, show_stderr=show_stderr)
        continue
    if setup_cache_key is None:
        cache_dir = None
    elif setup_cache_key in cache_dirs:
        cache_dir = cache_dirs[setup_cache_key]
    elif setup_cache_key not in failed_setup_cache:
        partial_info_time = None
        log.info('Setting up {0}'.format(setup_cache_key), reserve_space=True)
        params_str = json.dumps({'cpu_affinity': extra_params.get('cpu_affinity')})
        (cache_dir, stderr) = spawner.create_setup_cache(name, setup_cache_timeout[setup_cache_key], params_str)
        if cache_dir is not None:
            log.add_padded('ok')
            cache_dirs[setup_cache_key] = cache_dir
        else:
            log.add_padded('failed')
            if stderr and show_stderr:
                with log.indent():
                    log.error(stderr)
            failed_setup_cache[setup_cache_key] = stderr
        duration = (datetime.datetime.utcnow() - started_at).total_seconds()
        results.set_setup_cache_duration(setup_cache_key, duration)
        started_at = datetime.datetime.utcnow()
    if setup_cache_key in failed_setup_cache:
        partial_info_time = None
        log.warning('{0} skipped (setup_cache failed)'.format(name))
        stderr = 'asv: setup_cache failed\n\n{}'.format(failed_setup_cache[setup_cache_key])
        res = fail_benchmark(benchmark, stderr=stderr)
        results.add_result(benchmark, res, selected_idx=selected_idx, started_at=started_at, record_samples=record_samples)
        failed_benchmarks.add(name)
        continue
    cur_extra_params = extra_params
    if name in previous_result_keys:
        cur_extra_params = []
        prev_stats = results.get_result_stats(name, benchmark['params'])
        for s in prev_stats:
            if s is None or 'number' not in s:
                p = extra_params
            else:
                p = dict(extra_params)
                p['number'] = s['number']
            cur_extra_params.append(p)
    if is_final:
        partial_info_time = None
        log.info(name, reserve_space=True)
    elif partial_info_time is None or time.time() > partial_info_time + 30:
        partial_info_time = time.time()
        log.info('Running ({0}--)'.format(name))
    res = run_benchmark(benchmark, spawner, profile=profile, selected_idx=selected_idx, extra_params=cur_extra_params, cwd=cache_dir)
    ended_at = datetime.datetime.utcnow()
    if name in benchmark_durations:
        benchmark_durations[name] += (ended_at - started_at).total_seconds()
    else:
        benchmark_durations[name] = (ended_at - started_at).total_seconds()
    results.add_result(benchmark, res, selected_idx=selected_idx, started_at=started_at, duration=benchmark_durations[name], record_samples=not is_final or record_samples, append_samples=name in previous_result_keys)
    previous_result_keys.add(name)
    if all((r is None for r in res.result)):
        failed_benchmarks.add(name)
    if is_final:
        partial_info_time = None
        log_benchmark_result(results, benchmark, show_stderr=show_stderr)
    else:
        log.add('.')
    if cache_dir is not None and is_final:
        cache_users[setup_cache_key].remove(name)
        if not cache_users[setup_cache_key]:
            util.long_path_rmtree(cache_dir, True)
            del cache_dirs[setup_cache_key]","for e_target in iter_run_items():
    is_final = e_target[3]
    setup_cache_key = e_target[2]
    benchmark = e_target[1]
    name = e_target[0]
    selected_idx = benchmarks.benchmark_selection.get(name)
    started_at = datetime.datetime.utcnow()
    if name in failed_benchmarks:
        if is_final:
            partial_info_time = None
            log.info(name, reserve_space=True)
            log_benchmark_result(results, benchmark, show_stderr=show_stderr)
        continue
    if setup_cache_key is None:
        cache_dir = None
    elif setup_cache_key in cache_dirs:
        cache_dir = cache_dirs[setup_cache_key]
    elif setup_cache_key not in failed_setup_cache:
        partial_info_time = None
        log.info('Setting up {0}'.format(setup_cache_key), reserve_space=True)
        params_str = json.dumps({'cpu_affinity': extra_params.get('cpu_affinity')})
        (cache_dir, stderr) = spawner.create_setup_cache(name, setup_cache_timeout[setup_cache_key], params_str)
        if cache_dir is not None:
            log.add_padded('ok')
            cache_dirs[setup_cache_key] = cache_dir
        else:
            log.add_padded('failed')
            if stderr and show_stderr:
                with log.indent():
                    log.error(stderr)
            failed_setup_cache[setup_cache_key] = stderr
        duration = (datetime.datetime.utcnow() - started_at).total_seconds()
        results.set_setup_cache_duration(setup_cache_key, duration)
        started_at = datetime.datetime.utcnow()
    if setup_cache_key in failed_setup_cache:
        partial_info_time = None
        log.warning('{0} skipped (setup_cache failed)'.format(name))
        stderr = 'asv: setup_cache failed\n\n{}'.format(failed_setup_cache[setup_cache_key])
        res = fail_benchmark(benchmark, stderr=stderr)
        results.add_result(benchmark, res, selected_idx=selected_idx, started_at=started_at, record_samples=record_samples)
        failed_benchmarks.add(name)
        continue
    cur_extra_params = extra_params
    if name in previous_result_keys:
        cur_extra_params = []
        prev_stats = results.get_result_stats(name, benchmark['params'])
        for s in prev_stats:
            if s is None or 'number' not in s:
                p = extra_params
            else:
                p = dict(extra_params)
                p['number'] = s['number']
            cur_extra_params.append(p)
    if is_final:
        partial_info_time = None
        log.info(name, reserve_space=True)
    elif partial_info_time is None or time.time() > partial_info_time + 30:
        partial_info_time = time.time()
        log.info('Running ({0}--)'.format(name))
    res = run_benchmark(benchmark, spawner, profile=profile, selected_idx=selected_idx, extra_params=cur_extra_params, cwd=cache_dir)
    ended_at = datetime.datetime.utcnow()
    if name in benchmark_durations:
        benchmark_durations[name] += (ended_at - started_at).total_seconds()
    else:
        benchmark_durations[name] = (ended_at - started_at).total_seconds()
    results.add_result(benchmark, res, selected_idx=selected_idx, started_at=started_at, duration=benchmark_durations[name], record_samples=not is_final or record_samples, append_samples=name in previous_result_keys)
    previous_result_keys.add(name)
    if all((r is None for r in res.result)):
        failed_benchmarks.add(name)
    if is_final:
        partial_info_time = None
        log_benchmark_result(results, benchmark, show_stderr=show_stderr)
    else:
        log.add('.')
    if cache_dir is not None and is_final:
        cache_users[setup_cache_key].remove(name)
        if not cache_users[setup_cache_key]:
            util.long_path_rmtree(cache_dir, True)
            del cache_dirs[setup_cache_key]

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_run_benchmarks'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_timeraw_benchmark'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_quick']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/runner.py,,test_quick,"for (setup_cache_key, benchmark_set) in six.iteritems(benchmark_order):
    for (name, benchmark) in benchmark_set:
        log.step()
        rounds = get_rounds(benchmark)
        if run_round > rounds:
            if not append_samples and run_round == run_rounds[-1] and (name in existing_results):
                selected_idx = benchmarks.benchmark_selection.get(name)
                results.remove_samples(name, selected_idx)
            continue
        is_final = run_round == 1
        yield (name, benchmark, setup_cache_key, is_final)","for e_target in six.iteritems(benchmark_order):
    benchmark_set = e_target[1]
    setup_cache_key = e_target[0]
    for (name, benchmark) in benchmark_set:
        log.step()
        rounds = get_rounds(benchmark)
        if run_round > rounds:
            if not append_samples and run_round == run_rounds[-1] and (name in existing_results):
                selected_idx = benchmarks.benchmark_selection.get(name)
                results.remove_samples(name, selected_idx)
            continue
        is_final = run_round == 1
        yield (name, benchmark, setup_cache_key, is_final)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_run_benchmarks'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_timeraw_benchmark'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_quick']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/runner.py,,test_quick,"for (name, benchmark, setup_cache_key, is_final) in iter_run_items():
    if name in failed_benchmarks:
        continue
    selected_idx = benchmarks.benchmark_selection.get(name)
    started_at = datetime.datetime.utcnow()
    res = fail_benchmark(benchmark, stderr=stderr)
    results.add_result(benchmark, res, selected_idx=selected_idx, started_at=started_at, record_samples=record_samples)
    failed_benchmarks.add(name)","for e_target in iter_run_items():
    is_final = e_target[3]
    setup_cache_key = e_target[2]
    benchmark = e_target[1]
    name = e_target[0]
    if name in failed_benchmarks:
        continue
    selected_idx = benchmarks.benchmark_selection.get(name)
    started_at = datetime.datetime.utcnow()
    res = fail_benchmark(benchmark, stderr=stderr)
    results.add_result(benchmark, res, selected_idx=selected_idx, started_at=started_at, record_samples=record_samples)
    failed_benchmarks.add(name)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_run_benchmarks'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_timeraw_benchmark'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_quick']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/runner.py,,test_quick,"for (name, benchmark) in benchmark_set:
    log.step()
    rounds = get_rounds(benchmark)
    if run_round > rounds:
        if not append_samples and run_round == run_rounds[-1] and (name in existing_results):
            selected_idx = benchmarks.benchmark_selection.get(name)
            results.remove_samples(name, selected_idx)
        continue
    is_final = run_round == 1
    yield (name, benchmark, setup_cache_key, is_final)","for e_target in benchmark_set:
    benchmark = e_target[1]
    name = e_target[0]
    log.step()
    rounds = get_rounds(benchmark)
    if run_round > rounds:
        if not append_samples and run_round == run_rounds[-1] and (name in existing_results):
            selected_idx = benchmarks.benchmark_selection.get(name)
            results.remove_samples(name, selected_idx)
        continue
    is_final = run_round == 1
    yield (name, benchmark, setup_cache_key, is_final)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_run_benchmarks'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_timeraw_benchmark'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_runner.py', 'test.test_runner', '', 'test_quick']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/console.py,,test_write_with_fallback,"for (key, val) in _unicode_translations.iteritems():
    s = s.replace(unichr(key), val)","for e_target in _unicode_translations.iteritems():
    val = e_target[1]
    key = e_target[0]
    s = s.replace(unichr(key), val)

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_console.py', 'test.test_console', '', 'test_write_with_fallback']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/statistics.py,,test_quantile_ci_small,"for (k, yp) in enumerate(y):
    F += binom_pmf(n, k, q)
    if F <= pa:
        a = yp
    if F >= pb:
        b = yp
        break","for e_target in enumerate(y):
    yp = e_target[1]
    k = e_target[0]
    F += binom_pmf(n, k, q)
    if F <= pa:
        a = yp
    if F >= pb:
        b = yp
        break

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_statistics.py', 'test.test_statistics', '', 'test_quantile_ci'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_statistics.py', 'test.test_statistics', '', 'test_quantile_ci_r'], ['https://github.com/airspeed-velocity/asv/tree/master/test/test_statistics.py', 'test.test_statistics', '', 'test_quantile_ci_small']]"
asv,https://github.com/airspeed-velocity/asv/tree/master/asv/commands/run.py,,test_format_durations,"for (j, (name, duration)) in enumerate(items):
    if j >= num_durations:
        rows.append(['...', '...'])
        break
    rows.append([name, util.human_time(duration)])","for e_target in enumerate(items):
    duration = e_target[1][1]
    name = e_target[1][0]
    j = e_target[0]
    if j >= num_durations:
        rows.append(['...', '...'])
        break
    rows.append([name, util.human_time(duration)])

",1,"[['https://github.com/airspeed-velocity/asv/tree/master/test/test_run.py', 'test.test_run', '', 'test_format_durations']]"
proselint,https://github.com/amperser/proselint/tree/master//app.py,TestLint,test_errors_sorted,"for (i, e) in enumerate(job.result):
    app.logger.debug(e)
    errors.append({'check': e[0], 'message': e[1], 'line': e[2], 'column': e[3], 'start': e[4], 'end': e[5], 'extent': e[5] - e[4], 'severity': e[7], 'replacements': e[8], 'source_name': '', 'source_url': ''})","for e_target in enumerate(job.result):
    e = e_target[1]
    i = e_target[0]
    app.logger.debug(e)
    errors.append({'check': e[0], 'message': e[1], 'line': e[2], 'column': e[3], 'start': e[4], 'end': e[5], 'extent': e[5] - e[4], 'severity': e[7], 'replacements': e[8], 'source_name': '', 'source_url': ''})

",1,"[['https://github.com/amperser/proselint/tree/master/tests/test_tools.py', 'tests.test_tools', 'TestLint', 'test_on_no_newlines'], ['https://github.com/amperser/proselint/tree/master/tests/test_tools.py', 'tests.test_tools', 'TestLint', 'test_errors_sorted']]"
proselint,https://github.com/amperser/proselint/tree/master/proselint/tools.py,,test_deepmerge_dicts,"for (key, value) in dict2.items():
    if isinstance(value, dict):
        result[key] = deepmerge_dicts(result[key] or {}, value)
    else:
        result[key] = value","for e_target in dict2.items():
    value = e_target[1]
    key = e_target[0]
    if isinstance(value, dict):
        result[key] = deepmerge_dicts(result[key] or {}, value)
    else:
        result[key] = value

",1,"[['https://github.com/amperser/proselint/tree/master/tests/test_config_flag.py', 'tests.test_config_flag', '', 'test_deepmerge_dicts']]"
proselint,https://github.com/amperser/proselint/tree/master/proselint/command_line.py,Test__delete_compiled_python_files,test__remove_dir,"for (path, _, files) in os.walk(os.getcwd()):
    for fname in [f for f in files if os.path.splitext(f)[1] == '.pyc']:
        try:
            os.remove(os.path.join(path, fname))
        except OSError:
            pass","for e_target in os.walk(os.getcwd()):
    files = e_target[2]
    _ = e_target[1]
    path = e_target[0]
    for fname in [f for f in files if os.path.splitext(f)[1] == '.pyc']:
        try:
            os.remove(os.path.join(path, fname))
        except OSError:
            pass

",1,"[['https://github.com/amperser/proselint/tree/master/tests/test_clear_cache.py', 'tests.test_clear_cache', 'Test__delete_compiled_python_files', 'test_delete_pyc_file'], ['https://github.com/amperser/proselint/tree/master/tests/test_clear_cache.py', 'tests.test_clear_cache', 'Test__delete_compiled_python_files', 'test_on_oserror'], ['https://github.com/amperser/proselint/tree/master/tests/test_clear_cache.py', 'tests.test_clear_cache', 'Test__delete_compiled_python_files', 'test_files_not_deleted'], ['https://github.com/amperser/proselint/tree/master/tests/test_clear_cache.py', 'tests.test_clear_cache', 'Test__delete_compiled_python_files', 'test_no_permission'], ['https://github.com/amperser/proselint/tree/master/tests/test_clear_cache.py', 'tests.test_clear_cache', 'Test__delete_compiled_python_files', 'test_files_not_found'], ['https://github.com/amperser/proselint/tree/master/tests/test_clear_cache.py', 'tests.test_clear_cache', 'Test__delete_compiled_python_files', 'test__remove_dir']]"
pefile,https://github.com/erocarrera/pefile/tree/master//pefile.py,Test_pefile,test_pe_image_regression_test,"for (idx, vinfo_entry) in enumerate(self.VS_VERSIONINFO):
    if len(self.VS_VERSIONINFO) > 1:
        dump.add_header(f'Version Information {idx + 1}')
    else:
        dump.add_header('Version Information')
    if vinfo_entry is not None:
        dump.add_lines(vinfo_entry.dump())
    dump.add_newline()
    if hasattr(self, 'VS_FIXEDFILEINFO'):
        dump.add_lines(self.VS_FIXEDFILEINFO[idx].dump())
        dump.add_newline()
    if hasattr(self, 'FileInfo') and len(self.FileInfo) > idx:
        for entry in self.FileInfo[idx]:
            dump.add_lines(entry.dump())
            dump.add_newline()
            if hasattr(entry, 'StringTable'):
                for st_entry in entry.StringTable:
                    [dump.add_line('  ' + line) for line in st_entry.dump()]
                    dump.add_line('  LangID: {0}'.format(st_entry.LangID.decode(encoding, 'backslashreplace_')))
                    dump.add_newline()
                    for str_entry in sorted(list(st_entry.entries.items())):
                        dump.add_line('    {0}: {1}'.format(str_entry[0].decode(encoding, 'backslashreplace_'), str_entry[1].decode(encoding, 'backslashreplace_')))
                dump.add_newline()
            elif hasattr(entry, 'Var'):
                for var_entry in entry.Var:
                    if hasattr(var_entry, 'entry'):
                        [dump.add_line('  ' + line) for line in var_entry.dump()]
                        dump.add_line('    {0}: {1}'.format(list(var_entry.entry.keys())[0].decode('utf-8', 'backslashreplace_'), list(var_entry.entry.values())[0]))
                dump.add_newline()","for e_target in enumerate(self.VS_VERSIONINFO):
    vinfo_entry = e_target[1]
    idx = e_target[0]
    if len(self.VS_VERSIONINFO) > 1:
        dump.add_header(f'Version Information {idx + 1}')
    else:
        dump.add_header('Version Information')
    if vinfo_entry is not None:
        dump.add_lines(vinfo_entry.dump())
    dump.add_newline()
    if hasattr(self, 'VS_FIXEDFILEINFO'):
        dump.add_lines(self.VS_FIXEDFILEINFO[idx].dump())
        dump.add_newline()
    if hasattr(self, 'FileInfo') and len(self.FileInfo) > idx:
        for entry in self.FileInfo[idx]:
            dump.add_lines(entry.dump())
            dump.add_newline()
            if hasattr(entry, 'StringTable'):
                for st_entry in entry.StringTable:
                    [dump.add_line('  ' + line) for line in st_entry.dump()]
                    dump.add_line('  LangID: {0}'.format(st_entry.LangID.decode(encoding, 'backslashreplace_')))
                    dump.add_newline()
                    for str_entry in sorted(list(st_entry.entries.items())):
                        dump.add_line('    {0}: {1}'.format(str_entry[0].decode(encoding, 'backslashreplace_'), str_entry[1].decode(encoding, 'backslashreplace_')))
                dump.add_newline()
            elif hasattr(entry, 'Var'):
                for var_entry in entry.Var:
                    if hasattr(var_entry, 'entry'):
                        [dump.add_line('  ' + line) for line in var_entry.dump()]
                        dump.add_line('    {0}: {1}'.format(list(var_entry.entry.keys())[0].decode('utf-8', 'backslashreplace_'), list(var_entry.entry.values())[0]))
                dump.add_newline()

",1,"[['https://github.com/erocarrera/pefile/tree/master/tests/pefile_test.py', 'tests.pefile_test', 'Test_pefile', 'test_pe_image_regression_test']]"
pefile,https://github.com/erocarrera/pefile/tree/master//pefile.py,Test_pefile,test_pe_image_regression_test,"for (idx, res_string) in list(sorted(resource_id.directory.strings.items())):
    dump.add_line('{0:6d}: {1}'.format(idx, res_string.encode('unicode-escape', 'backslashreplace').decode('ascii')), 12)","for e_target in list(sorted(resource_id.directory.strings.items())):
    res_string = e_target[1]
    idx = e_target[0]
    dump.add_line('{0:6d}: {1}'.format(idx, res_string.encode('unicode-escape', 'backslashreplace').decode('ascii')), 12)

",1,"[['https://github.com/erocarrera/pefile/tree/master/tests/pefile_test.py', 'tests.pefile_test', 'Test_pefile', 'test_pe_image_regression_test']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/fingerprint.py,TestTransitiveFingerprint,test_analyse_cooperation_ratio,"for (_, row) in df.iterrows():
    (opponent_index, player_history) = (row['Opponent index'], row['Actions'])
    if opponent_index in cooperation_rates:
        cooperation_rates[opponent_index].append(did_c(player_history))
    else:
        cooperation_rates[opponent_index] = [did_c(player_history)]","for e_target in df.iterrows():
    row = e_target[1]
    _ = e_target[0]
    (opponent_index, player_history) = (row['Opponent index'], row['Actions'])
    if opponent_index in cooperation_rates:
        cooperation_rates[opponent_index].append(did_c(player_history))
    else:
        cooperation_rates[opponent_index] = [did_c(player_history)]

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_fingerprint.py', 'axelrod.tests.unit.test_fingerprint', 'TestTransitiveFingerprint', 'test_analyse_cooperation_ratio']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/fingerprint.py,TestTransitiveFingerprint,test_analyse_cooperation_ratio,"for (index, rates) in cooperation_rates.items():
    cooperation_rates[index] = np.mean(rates, axis=0)","for e_target in cooperation_rates.items():
    rates = e_target[1]
    index = e_target[0]
    cooperation_rates[index] = np.mean(rates, axis=0)

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_fingerprint.py', 'axelrod.tests.unit.test_fingerprint', 'TestTransitiveFingerprint', 'test_analyse_cooperation_ratio']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/result_set.py,TestResultSet,test_summarise,"for (i, player) in enumerate(self.normalised_state_distribution):
    counts = []
    for state in states:
        p = sum([opp[state] for (j, opp) in enumerate(player) if i != j])
        counts.append(p)
    try:
        counts = [c / sum(counts) for c in counts]
    except ZeroDivisionError:
        counts = [0 for c in counts]
    state_prob.append(counts)","for e_target in enumerate(self.normalised_state_distribution):
    player = e_target[1]
    i = e_target[0]
    counts = []
    for state in states:
        p = sum([opp[state] for (j, opp) in enumerate(player) if i != j])
        counts.append(p)
    try:
        counts = [c / sum(counts) for c in counts]
    except ZeroDivisionError:
        counts = [0 for c in counts]
    state_prob.append(counts)

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_resultset.py', 'axelrod.tests.unit.test_resultset', 'TestResultSet', 'test_summarise']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/result_set.py,TestResultSet,test_summarise,"for (rank, i) in enumerate(self.ranking):
    data = list(summary_measures[i]) + state_prob[i] + state_to_C_prob[i]
    summary_data.append(self.player(rank, *data))","for e_target in enumerate(self.ranking):
    i = e_target[1]
    rank = e_target[0]
    data = list(summary_measures[i]) + state_prob[i] + state_to_C_prob[i]
    summary_data.append(self.player(rank, *data))

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_resultset.py', 'axelrod.tests.unit.test_resultset', 'TestResultSet', 'test_summarise']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/result_set.py,TestCreateCounterDict,test_basic_use,"for (key, value) in df.loc[player_index, opponent_index].items():
    if value > 0:
        counter[key_map[key]] = value","for e_target in df.loc[player_index, opponent_index].items():
    value = e_target[1]
    key = e_target[0]
    if value > 0:
        counter[key_map[key]] = value

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_resultset.py', 'axelrod.tests.unit.test_resultset', 'TestCreateCounterDict', 'test_basic_use']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/plot.py,TestPlot,test_stackplot_with_passed_axes,"for (i, n) in enumerate(self.result_set.ranked_names):
    x = -0.01
    y = (i + 0.5) * 1 / self.result_set.num_players
    ax.annotate(n, xy=(x, y), xycoords=trans, clip_on=False, va='center', ha='right', fontsize=5)
    ticks.append(y)","for e_target in enumerate(self.result_set.ranked_names):
    n = e_target[1]
    i = e_target[0]
    x = -0.01
    y = (i + 0.5) * 1 / self.result_set.num_players
    ax.annotate(n, xy=(x, y), xycoords=trans, clip_on=False, va='center', ha='right', fontsize=5)
    ticks.append(y)

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_plot.py', 'axelrod.tests.unit.test_plot', 'TestPlot', 'test_stackplot'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_plot.py', 'axelrod.tests.unit.test_plot', 'TestPlot', 'test_stackplot_with_passed_axes']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/moran.py,TestMoranProcess,test_fps,"for (i, x) in enumerate(csums):
    if x >= r:
        break","for e_target in enumerate(csums):
    x = e_target[1]
    i = e_target[0]
    if x >= r:
        break

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_moran.py', 'axelrod.tests.unit.test_moran', 'TestMoranProcess', 'test_fps']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/_strategy_utils.py,TestDetectCycle,test_cycle_that_never_fully_repeats_returns_none,"for (j, elem) in enumerate(history_tail):
    if elem != cycle[j % len(cycle)]:
        has_cycle = False
        break","for e_target in enumerate(history_tail):
    elem = e_target[1]
    j = e_target[0]
    if elem != cycle[j % len(cycle)]:
        has_cycle = False
        break

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_strategy_utils.py', 'axelrod.tests.unit.test_strategy_utils', 'TestDetectCycle', 'test_finds_cycle'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_strategy_utils.py', 'axelrod.tests.unit.test_strategy_utils', 'TestDetectCycle', 'test_cycle_greater_than_max_size_returns_none'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/strategies/test_calculator.py', 'axelrod.tests.strategies.test_calculator', 'TestCalculator', 'test_edge_case_calculator_sees_cycles_of_size_ten'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_strategy_utils.py', 'axelrod.tests.unit.test_strategy_utils', 'TestDetectCycle', 'test_no_cycle'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_strategy_utils.py', 'axelrod.tests.unit.test_strategy_utils', 'TestDetectCycle', 'test_min_size_greater_than_two_times_max_size_has_no_effect'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/strategies/test_cycler.py', 'axelrod.tests.strategies.test_cycler', 'TestAntiCycler', 'test_has_no_cycles'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_strategy_utils.py', 'axelrod.tests.unit.test_strategy_utils', 'TestDetectCycle', 'test_regression_test_can_detect_cycle_that_is_repeated_exactly_once'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_strategy_utils.py', 'axelrod.tests.unit.test_strategy_utils', 'TestDetectCycle', 'test_cycle_will_be_at_least_min_size'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_strategy_utils.py', 'axelrod.tests.unit.test_strategy_utils', 'TestDetectCycle', 'test_min_size_greater_than_two_times_history_tail_returns_none'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/strategies/test_calculator.py', 'axelrod.tests.strategies.test_calculator', 'TestCalculator', 'test_edge_case_calculator_ignores_cycles_gt_len_ten'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_strategy_utils.py', 'axelrod.tests.unit.test_strategy_utils', 'TestDetectCycle', 'test_cycle_that_never_fully_repeats_returns_none']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/interaction_utils.py,TestMatch,test_read_interactions_from_file,"for (_, d) in tqdm.tqdm(groupby):
    key = tuple(d[['Player index', 'Opponent index']].iloc[0])
    value = list(map(str_to_actions, zip(*d['Actions'])))
    pairs_to_interactions[key].append(value)","for e_target in tqdm.tqdm(groupby):
    d = e_target[1]
    _ = e_target[0]
    key = tuple(d[['Player index', 'Opponent index']].iloc[0])
    value = list(map(str_to_actions, zip(*d['Actions'])))
    pairs_to_interactions[key].append(value)

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_interaction_utils.py', 'axelrod.tests.unit.test_interaction_utils', 'TestMatch', 'test_read_interactions_from_file']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/compute_finite_state_machine_memory.py,TestGetMemoryFromTransitions,test_fortress_4,"for (x, y) in [(x, y) for x in all_memits for y in all_memits]:
    if x == y and x.state == y.state:
        continue
    if x != y:
        continue
    pair_nodes.add(ordered_memit_tuple(x, y))
    for x_successor in memit_edges[x]:
        for y_successor in memit_edges[y]:
            if x_successor == y_successor:
                pair_edges[ordered_memit_tuple(x, y)].add(ordered_memit_tuple(x_successor, y_successor))","for e_target in [(x, y) for x in all_memits for y in all_memits]:
    y = e_target[1]
    x = e_target[0]
    if x == y and x.state == y.state:
        continue
    if x != y:
        continue
    pair_nodes.add(ordered_memit_tuple(x, y))
    for x_successor in memit_edges[x]:
        for y_successor in memit_edges[y]:
            if x_successor == y_successor:
                pair_edges[ordered_memit_tuple(x, y)].add(ordered_memit_tuple(x_successor, y_successor))

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_transient_state'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_four_state_memory_two'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_tit_for_five_tat'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_fortress_3'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_three_state_tft'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_two_state_tft'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_complex_cooperator'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/strategies/test_finite_state_machines.py', 'axelrod.tests.strategies.test_finite_state_machines', 'TestFSMPlayer', 'test_memory'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_two_state_inf_memory'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_evolved_fsm_4'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_two_state_memory_two'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_cooperator'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_tit_for_two_tat'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_tit_for_tat'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_disconnected_graph'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_infinite_memory_transient_state'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_compute_finite_state_machine_memory.py', 'axelrod.tests.unit.test_compute_finite_state_machine_memory', 'TestGetMemoryFromTransitions', 'test_fortress_4']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/eigen.py,FunctionCases,test_2x2_matrix,"for (i, vector) in enumerate(_power_iteration(mat, initial=initial)):
    if i > maximum_iterations:
        break
    if _squared_error(vector, last) < max_error:
        break
    last = vector","for e_target in enumerate(_power_iteration(mat, initial=initial)):
    vector = e_target[1]
    i = e_target[0]
    if i > maximum_iterations:
        break
    if _squared_error(vector, last) < max_error:
        break
    last = vector

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_eigen.py', 'axelrod.tests.unit.test_eigen', 'FunctionCases', 'test_zero_matrix'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_eigen.py', 'axelrod.tests.unit.test_eigen', 'FunctionCases', 'test_identity_matrices'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_eigen.py', 'axelrod.tests.unit.test_eigen', 'FunctionCases', 'test_3x3_matrix'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_eigen.py', 'axelrod.tests.unit.test_eigen', 'FunctionCases', 'test_4x4_matrix'], ['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_eigen.py', 'axelrod.tests.unit.test_eigen', 'FunctionCases', 'test_2x2_matrix']]"
Axelrod,https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/strategies/_filters.py,TestFilters,test_passes_filterset,"for (_filter, filter_function) in filter_functions.items():
    if filterset.get(_filter, None) is not None:
        kwargs = filter_function.kwargs
        kwargs['player'] = strategy()
        kwargs['value'] = filterset[_filter]
        passes_filters.append(filter_function.function(**kwargs))","for e_target in filter_functions.items():
    filter_function = e_target[1]
    _filter = e_target[0]
    if filterset.get(_filter, None) is not None:
        kwargs = filter_function.kwargs
        kwargs['player'] = strategy()
        kwargs['value'] = filterset[_filter]
        passes_filters.append(filter_function.function(**kwargs))

",1,"[['https://github.com/Axelrod-Python/Axelrod/tree/master/axelrod/tests/unit/test_filters.py', 'axelrod.tests.unit.test_filters', 'TestFilters', 'test_passes_filterset']]"
fgmk,https://github.com/ericoporto/fgmk/tree/master/fgmk/ff/write_file.py,,test_fwriteKeyVals,"for (k, v) in sorted_data:
    f.write('\n' + '    ' * indent + '""' + k + '""' + ': ')
    fwriteKeyVals(v, f, indent + 1)
    if sorted_data[-1][0] != k:
        f.write(',')","for e_target in sorted_data:
    v = e_target[1]
    k = e_target[0]
    f.write('\n' + '    ' * indent + '""' + k + '""' + ': ')
    fwriteKeyVals(v, f, indent + 1)
    if sorted_data[-1][0] != k:
        f.write(',')

",1,"[['https://github.com/ericoporto/fgmk/tree/master/tests/test_write_file.py', 'tests.test_write_file', '', 'test_fwriteKeyVals']]"
dnsrecon,https://github.com/darkoperator/dnsrecon/tree/master//dnsrecon.py,Test_dnsrecon,test_se_result_process,"for (type_, name_, address_or_target_) in res.get_ip(se_entry):
    if type_ not in ['A', 'CNAME']:
        continue
    print_status(f'\t {type_} {name_} {address_or_target_}')
    resolved_se_entry = {'type': type_, 'name': name_}
    if type_ == 'A':
        resolved_se_entry['address'] = address_or_target_
    elif type_ == 'CNAME':
        resolved_se_entry['target'] = address_or_target_
    resolved_se_entries.append(resolved_se_entry)","for e_target in res.get_ip(se_entry):
    address_or_target_ = e_target[2]
    name_ = e_target[1]
    type_ = e_target[0]
    if type_ not in ['A', 'CNAME']:
        continue
    print_status(f'\t {type_} {name_} {address_or_target_}')
    resolved_se_entry = {'type': type_, 'name': name_}
    if type_ == 'A':
        resolved_se_entry['address'] = address_or_target_
    elif type_ == 'CNAME':
        resolved_se_entry['target'] = address_or_target_
    resolved_se_entries.append(resolved_se_entry)

",1,"[['https://github.com/darkoperator/dnsrecon/tree/master/tests/test_dnsrecon.py', 'tests.test_dnsrecon', 'Test_dnsrecon', 'test_se_result_process']]"
nmigen,https://github.com/m-labs/nmigen/tree/master/nmigen/_toolchain/cxx.py,ToolchainCxxTestCase,test_include,"for (cxx_filename, cxx_source) in cxx_sources.items():
    with open(cxx_filename, 'w') as f:
        f.write(cxx_source)","for e_target in cxx_sources.items():
    cxx_source = e_target[1]
    cxx_filename = e_target[0]
    with open(cxx_filename, 'w') as f:
        f.write(cxx_source)

",1,"[['https://github.com/m-labs/nmigen/tree/master/tests/test_toolchain_cxx.py', 'tests.test_toolchain_cxx', 'ToolchainCxxTestCase', 'test_simple'], ['https://github.com/m-labs/nmigen/tree/master/tests/test_toolchain_cxx.py', 'tests.test_toolchain_cxx', 'ToolchainCxxTestCase', 'test_filename'], ['https://github.com/m-labs/nmigen/tree/master/tests/test_toolchain_cxx.py', 'tests.test_toolchain_cxx', 'ToolchainCxxTestCase', 'test_macro'], ['https://github.com/m-labs/nmigen/tree/master/tests/test_toolchain_cxx.py', 'tests.test_toolchain_cxx', 'ToolchainCxxTestCase', 'test_include']]"
nmigen,https://github.com/m-labs/nmigen/tree/master/nmigen/hdl/dsl.py,DSLTestCase,test_lower,"for (signal, domain) in self._driving.items():
    fragment.add_driver(signal, domain)","for e_target in self._driving.items():
    domain = e_target[1]
    signal = e_target[0]
    fragment.add_driver(signal, domain)

",1,"[['https://github.com/m-labs/nmigen/tree/master/tests/test_hdl_dsl.py', 'tests.test_hdl_dsl', 'DSLTestCase', 'test_FSM_basic'], ['https://github.com/m-labs/nmigen/tree/master/tests/test_hdl_dsl.py', 'tests.test_hdl_dsl', 'DSLTestCase', 'test_sample_domain'], ['https://github.com/m-labs/nmigen/tree/master/tests/test_hdl_dsl.py', 'tests.test_hdl_dsl', 'DSLTestCase', 'test_lower']]"
nmigen,https://github.com/m-labs/nmigen/tree/master/nmigen/hdl/ir.py,FragmentGeneratedTestCase,test_find_subfragment,"for (subfragment, name) in self.subfragments:
    if name == name_or_index:
        return subfragment","for e_target in self.subfragments:
    name = e_target[1]
    subfragment = e_target[0]
    if name == name_or_index:
        return subfragment

",1,"[['https://github.com/m-labs/nmigen/tree/master/tests/test_hdl_ir.py', 'tests.test_hdl_ir', 'FragmentGeneratedTestCase', 'test_find_subfragment_wrong'], ['https://github.com/m-labs/nmigen/tree/master/tests/test_hdl_ir.py', 'tests.test_hdl_ir', 'FragmentGeneratedTestCase', 'test_find_subfragment']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/deprecator.py,,test__add_dep_doc,"for (line_no, line) in enumerate(old_lines):
    if line.strip():
        new_lines.append(line)
    else:
        break","for e_target in enumerate(old_lines):
    line = e_target[1]
    line_no = e_target[0]
    if line.strip():
        new_lines.append(line)
    else:
        break

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_deprecator.py', 'nibabel.tests.test_deprecator', '', 'test__add_dep_doc']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/affines.py,,test_append_diag,"for (i, el) in enumerate(steps):
    aff_plus[old_n_out + i, old_n_in + i] = el","for e_target in enumerate(steps):
    el = e_target[1]
    i = e_target[0]
    aff_plus[old_n_out + i, old_n_in + i] = el

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_affines.py', 'nibabel.tests.test_affines', '', 'test_append_diag']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/orientations.py,,test_ornt_transform,"for (end_in_idx, (end_out_idx, end_flip)) in enumerate(end_ornt):
    for (start_in_idx, (start_out_idx, start_flip)) in enumerate(start_ornt):
        if end_out_idx == start_out_idx:
            if start_flip == end_flip:
                flip = 1
            else:
                flip = -1
            result[start_in_idx, :] = [end_in_idx, flip]
            break
    else:
        raise ValueError('Unable to find out axis %d in start_ornt' % end_out_idx)","for e_target in enumerate(end_ornt):
    end_flip = e_target[1][1]
    end_out_idx = e_target[1][0]
    end_in_idx = e_target[0]
    for (start_in_idx, (start_out_idx, start_flip)) in enumerate(start_ornt):
        if end_out_idx == start_out_idx:
            if start_flip == end_flip:
                flip = 1
            else:
                flip = -1
            result[start_in_idx, :] = [end_in_idx, flip]
            break
    else:
        raise ValueError('Unable to find out axis %d in start_ornt' % end_out_idx)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_orientations.py', 'nibabel.tests.test_orientations', '', 'test_ornt_transform']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/orientations.py,,test_ornt_transform,"for (start_in_idx, (start_out_idx, start_flip)) in enumerate(start_ornt):
    if end_out_idx == start_out_idx:
        if start_flip == end_flip:
            flip = 1
        else:
            flip = -1
        result[start_in_idx, :] = [end_in_idx, flip]
        break
else:
    raise ValueError('Unable to find out axis %d in start_ornt' % end_out_idx)","for e_target in enumerate(start_ornt):
    start_flip = e_target[1][1]
    start_out_idx = e_target[1][0]
    start_in_idx = e_target[0]
    if end_out_idx == start_out_idx:
        if start_flip == end_flip:
            flip = 1
        else:
            flip = -1
        result[start_in_idx, :] = [end_in_idx, flip]
        break
else:
    raise ValueError('Unable to find out axis %d in start_ornt' % end_out_idx)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_orientations.py', 'nibabel.tests.test_orientations', '', 'test_ornt_transform']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/orientations.py,,test_apply,"for (ax, flip) in enumerate(ornt[:, 1]):
    if flip == -1:
        t_arr = np.flip(t_arr, axis=ax)","for e_target in enumerate(ornt[:, 1]):
    flip = e_target[1]
    ax = e_target[0]
    if flip == -1:
        t_arr = np.flip(t_arr, axis=ax)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_orientations.py', 'nibabel.tests.test_orientations', '', 'test_apply']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/orientations.py,,test_ornt2axcodes,"for (axno, direction) in np.asarray(ornt):
    if np.isnan(axno):
        axcodes.append(None)
        continue
    axint = int(np.round(axno))
    if axint != axno:
        raise ValueError(f'Non integer axis number {axno:f}')
    elif direction == 1:
        axcode = labels[axint][1]
    elif direction == -1:
        axcode = labels[axint][0]
    else:
        raise ValueError('Direction should be -1 or 1')
    axcodes.append(axcode)","for e_target in np.asarray(ornt):
    direction = e_target[1]
    axno = e_target[0]
    if np.isnan(axno):
        axcodes.append(None)
        continue
    axint = int(np.round(axno))
    if axint != axno:
        raise ValueError(f'Non integer axis number {axno:f}')
    elif direction == 1:
        axcode = labels[axint][1]
    elif direction == -1:
        axcode = labels[axint][0]
    else:
        raise ValueError('Direction should be -1 or 1')
    axcodes.append(axcode)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_orientations.py', 'nibabel.tests.test_orientations', '', 'test_ornt2axcodes']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/orientations.py,,test_axcodes2ornt,"for (code_idx, code) in enumerate(axcodes):
    for (label_idx, codes) in enumerate(labels):
        if code is None:
            continue
        if code in codes:
            if code == codes[0]:
                ornt[code_idx, :] = [label_idx, -1]
            else:
                ornt[code_idx, :] = [label_idx, 1]
            break","for e_target in enumerate(axcodes):
    code = e_target[1]
    code_idx = e_target[0]
    for (label_idx, codes) in enumerate(labels):
        if code is None:
            continue
        if code in codes:
            if code == codes[0]:
                ornt[code_idx, :] = [label_idx, -1]
            else:
                ornt[code_idx, :] = [label_idx, 1]
            break

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_orientations.py', 'nibabel.tests.test_orientations', '', 'test_axcodes2ornt']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/orientations.py,,test_axcodes2ornt,"for (label_idx, codes) in enumerate(labels):
    if code is None:
        continue
    if code in codes:
        if code == codes[0]:
            ornt[code_idx, :] = [label_idx, -1]
        else:
            ornt[code_idx, :] = [label_idx, 1]
        break","for e_target in enumerate(labels):
    codes = e_target[1]
    label_idx = e_target[0]
    if code is None:
        continue
    if code in codes:
        if code == codes[0]:
            ornt[code_idx, :] = [label_idx, -1]
        else:
            ornt[code_idx, :] = [label_idx, 1]
        break

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_orientations.py', 'nibabel.tests.test_orientations', '', 'test_axcodes2ornt']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/spatialimages.py,TestAnalyzeHeader,test_supported_types,"for (name, np_types) in np.sctypes.items():
    for np_type in np_types:
        try:
            obj.set_data_dtype(np_type)
        except HeaderDataError:
            continue
        if np.dtype(obj.get_data_dtype()) == np.dtype(np_type):
            supported.append(np_type)","for e_target in np.sctypes.items():
    np_types = e_target[1]
    name = e_target[0]
    for np_type in np_types:
        try:
            obj.set_data_dtype(np_type)
        except HeaderDataError:
            continue
        if np.dtype(obj.get_data_dtype()) == np.dtype(np_type):
            supported.append(np_type)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_round_trip.py', 'nibabel.tests.test_round_trip', '', 'test_round_trip'], ['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_analyze.py', 'nibabel.tests.test_analyze', 'TestAnalyzeImage', 'test_supported_types'], ['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_analyze.py', 'nibabel.tests.test_analyze', 'TestAnalyzeHeader', 'test_supported_types']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/ecat.py,TestEcatMlist,test_mlist_errors,"for (frame_stored, (true_order, _)) in frames_order.items():
    try:
        frame_dict[frame_stored] = trueframenumbers[true_order] + 1
    except IndexError:
        raise IOError('Error in header or mlist order unknown')","for e_target in frames_order.items():
    _ = e_target[1][1]
    true_order = e_target[1][0]
    frame_stored = e_target[0]
    try:
        frame_dict[frame_stored] = trueframenumbers[true_order] + 1
    except IndexError:
        raise IOError('Error in header or mlist order unknown')

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_ecat.py', 'nibabel.tests.test_ecat', 'TestEcatMlist', 'test_mlist_errors']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/volumeutils.py,,test_add_codes,"for (field_ind, field_name) in enumerate(self.fields):
    self.__dict__[field_name][alias] = code_syns[field_ind]","for e_target in enumerate(self.fields):
    field_name = e_target[1]
    field_ind = e_target[0]
    self.__dict__[field_name][alias] = code_syns[field_ind]

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_recoder.py', 'nibabel.tests.test_recoder', '', 'test_add_codes']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/filename_parser.py,,test_filenames,"for (name, ext) in types_exts:
    if name == direct_set_name:
        tfns[name] = template_fname
        continue
    fname = filename
    if ext:
        fname += proc_ext(ext)
    if ignored:
        fname += ignored
    tfns[name] = fname","for e_target in types_exts:
    ext = e_target[1]
    name = e_target[0]
    if name == direct_set_name:
        tfns[name] = template_fname
        continue
    fname = filename
    if ext:
        fname += proc_ext(ext)
    if ignored:
        fname += ignored
    tfns[name] = fname

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_filename_parser.py', 'nibabel.tests.test_filename_parser', '', 'test_filenames']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/filename_parser.py,,test_parse_filename,"for (name, ext) in types_exts:
    if ext and endswith(filename, ext):
        extpos = -len(ext)
        found_ext = filename[extpos:]
        filename = filename[:extpos]
        guessed_name = name
        break
else:
    (filename, found_ext) = os.path.splitext(filename)","for e_target in types_exts:
    ext = e_target[1]
    name = e_target[0]
    if ext and endswith(filename, ext):
        extpos = -len(ext)
        found_ext = filename[extpos:]
        filename = filename[:extpos]
        guessed_name = name
        break
else:
    (filename, found_ext) = os.path.splitext(filename)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_filename_parser.py', 'nibabel.tests.test_filename_parser', '', 'test_parse_filename']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/fileslice.py,,test_canonical_slicers,"for (i, slicer) in enumerate(sliceobj):
    if slicer is None:
        can_slicers.append(None)
        continue
    if slicer == Ellipsis:
        remaining = sliceobj[i + 1:]
        if Ellipsis in remaining:
            raise ValueError('More than one Ellipsis in slicing expression')
        real_remaining = [r for r in remaining if r is not None]
        n_ellided = n_dim - n_real - len(real_remaining)
        can_slicers.extend((slice(None),) * n_ellided)
        n_real += n_ellided
        continue
    dim_len = shape[n_real]
    n_real += 1
    try:
        slicer = int(slicer)
    except TypeError:
        if slicer != slice(None):
            if slicer.stop == dim_len and slicer.start in (None, 0) and (slicer.step in (None, 1)):
                slicer = slice(None)
    else:
        if slicer < 0:
            slicer = dim_len + slicer
        elif check_inds and slicer >= dim_len:
            raise ValueError('Integer index %d to large' % slicer)
    can_slicers.append(slicer)","for e_target in enumerate(sliceobj):
    slicer = e_target[1]
    i = e_target[0]
    if slicer is None:
        can_slicers.append(None)
        continue
    if slicer == Ellipsis:
        remaining = sliceobj[i + 1:]
        if Ellipsis in remaining:
            raise ValueError('More than one Ellipsis in slicing expression')
        real_remaining = [r for r in remaining if r is not None]
        n_ellided = n_dim - n_real - len(real_remaining)
        can_slicers.extend((slice(None),) * n_ellided)
        n_real += n_ellided
        continue
    dim_len = shape[n_real]
    n_real += 1
    try:
        slicer = int(slicer)
    except TypeError:
        if slicer != slice(None):
            if slicer.stop == dim_len and slicer.start in (None, 0) and (slicer.step in (None, 1)):
                slicer = slice(None)
    else:
        if slicer < 0:
            slicer = dim_len + slicer
        elif check_inds and slicer >= dim_len:
            raise ValueError('Integer index %d to large' % slicer)
    can_slicers.append(slicer)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_fileslice.py', 'nibabel.tests.test_fileslice', '', 'test_canonical_slicers']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/fileslice.py,,test_read_segments_lock,"for (offset, length) in segments:
    with lock:
        fileobj.seek(offset)
        bytes.write(fileobj.read(length))","for e_target in segments:
    length = e_target[1]
    offset = e_target[0]
    with lock:
        fileobj.seek(offset)
        bytes.write(fileobj.read(length))

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_fileslice.py', 'nibabel.tests.test_fileslice', '', 'test_read_segments'], ['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_fileslice.py', 'nibabel.tests.test_fileslice', '', 'test_read_segments_lock']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/rstutils.py,,test_rst_table,"for (row_no, row_name) in enumerate(row_names):
    row_vals = [row_val_fmt.format(row_str) for row_str in row_str_list[row_no]]
    row_line = down_starter + down_joiner.join([row_name] + row_vals) + down_ender
    table_strs.append(row_line)","for e_target in enumerate(row_names):
    row_name = e_target[1]
    row_no = e_target[0]
    row_vals = [row_val_fmt.format(row_str) for row_str in row_str_list[row_no]]
    row_line = down_starter + down_joiner.join([row_name] + row_vals) + down_ender
    table_strs.append(row_line)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_rstutils.py', 'nibabel.tests.test_rstutils', '', 'test_rst_table']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/funcs.py,,test_concat,"for (i, img) in enumerate(images):
    if len(img.shape) != n_dim:
        raise ValueError(f'Image {i} has {len(img.shape)} dimensions, image 0 has {n_dim}')
    if not np.all(np.array(img.shape)[idx_mask] == masked_shape):
        raise ValueError(f'shape {img.shape} for image {i} not compatible with first image shape {shape0} with axis == {axis}')
    if check_affines and (not np.all(img.affine == affine)):
        raise ValueError(f'Affine for image {i} does not match affine for first image')
    out_data[i] = np.asanyarray(img.dataobj)","for e_target in enumerate(images):
    img = e_target[1]
    i = e_target[0]
    if len(img.shape) != n_dim:
        raise ValueError(f'Image {i} has {len(img.shape)} dimensions, image 0 has {n_dim}')
    if not np.all(np.array(img.shape)[idx_mask] == masked_shape):
        raise ValueError(f'shape {img.shape} for image {i} not compatible with first image shape {shape0} with axis == {axis}')
    if check_affines and (not np.all(img.affine == affine)):
        raise ValueError(f'Affine for image {i} does not match affine for first image')
    out_data[i] = np.asanyarray(img.dataobj)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_funcs.py', 'nibabel.tests.test_funcs', '', 'test_concat']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/gifti/gifti.py,,test_dataarray_init,"for (k, v) in data_dict.items():
    nv = GiftiNVPairs(k, v)
    meda.data.append(nv)","for e_target in data_dict.items():
    v = e_target[1]
    k = e_target[0]
    nv = GiftiNVPairs(k, v)
    meda.data.append(nv)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/gifti/tests/test_gifti.py', 'nibabel.gifti.tests.test_gifti', '', 'test_dataarray_init']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cifti2/cifti2_axes.py,,test_brain_models,"for (idx_parcel, (parcel_name, bm)) in enumerate(named_brain_models):
    all_names.append(parcel_name)
    voxels = bm.voxel[bm.volume_mask]
    if voxels.shape[0] != 0:
        if affine is None:
            affine = bm.affine
            volume_shape = bm.volume_shape
        elif not np.allclose(affine, bm.affine) or volume_shape != bm.volume_shape:
            raise ValueError('Can not combine brain models defined in different volumes into a single Parcel axis')
    all_voxels[idx_parcel] = voxels
    vertices = {}
    for (name, _, bm_part) in bm.iter_structures():
        if name in bm.nvertices.keys():
            if name in nvertices.keys() and nvertices[name] != bm.nvertices[name]:
                raise ValueError(f'Got multiple conflicting number of vertices for surface structure {name}')
            nvertices[name] = bm.nvertices[name]
            vertices[name] = bm_part.vertex
    all_vertices[idx_parcel] = vertices","for e_target in enumerate(named_brain_models):
    bm = e_target[1][1]
    parcel_name = e_target[1][0]
    idx_parcel = e_target[0]
    all_names.append(parcel_name)
    voxels = bm.voxel[bm.volume_mask]
    if voxels.shape[0] != 0:
        if affine is None:
            affine = bm.affine
            volume_shape = bm.volume_shape
        elif not np.allclose(affine, bm.affine) or volume_shape != bm.volume_shape:
            raise ValueError('Can not combine brain models defined in different volumes into a single Parcel axis')
    all_voxels[idx_parcel] = voxels
    vertices = {}
    for (name, _, bm_part) in bm.iter_structures():
        if name in bm.nvertices.keys():
            if name in nvertices.keys() and nvertices[name] != bm.nvertices[name]:
                raise ValueError(f'Got multiple conflicting number of vertices for surface structure {name}')
            nvertices[name] = bm.nvertices[name]
            vertices[name] = bm_part.vertex
    all_vertices[idx_parcel] = vertices

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cifti2/tests/test_axes.py', 'nibabel.cifti2.tests.test_axes', '', 'test_brain_models']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cifti2/cifti2_axes.py,,test_brain_models,"for (name, _, bm_part) in bm.iter_structures():
    if name in bm.nvertices.keys():
        if name in nvertices.keys() and nvertices[name] != bm.nvertices[name]:
            raise ValueError(f'Got multiple conflicting number of vertices for surface structure {name}')
        nvertices[name] = bm.nvertices[name]
        vertices[name] = bm_part.vertex","for e_target in bm.iter_structures():
    bm_part = e_target[2]
    _ = e_target[1]
    name = e_target[0]
    if name in bm.nvertices.keys():
        if name in nvertices.keys() and nvertices[name] != bm.nvertices[name]:
            raise ValueError(f'Got multiple conflicting number of vertices for surface structure {name}')
        nvertices[name] = bm.nvertices[name]
        vertices[name] = bm_part.vertex

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cifti2/tests/test_axes.py', 'nibabel.cifti2.tests.test_axes', '', 'test_brain_models']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/diff.py,,test_get_data_diff,"for (i, d1) in enumerate(data[:-1]):
    diffs1 = [None] * (i + 1)
    for (j, d2) in enumerate(data[i + 1:], i + 1):
        if d1.shape == d2.shape:
            abs_diff = np.abs(d1 - d2)
            mean_abs = (np.abs(d1) + np.abs(d2)) * 0.5
            candidates = np.logical_or(mean_abs != 0, abs_diff != 0)
            if max_abs:
                candidates[abs_diff <= max_abs] = False
            max_abs_diff = np.max(abs_diff)
            if np.any(candidates):
                rel_diff = abs_diff[candidates] / mean_abs[candidates]
                if max_rel:
                    sub_thr = rel_diff <= max_rel
                    candidates[tuple((indexes[sub_thr] for indexes in np.where(candidates)))] = False
                max_rel_diff = np.max(rel_diff)
            else:
                max_rel_diff = 0
            if np.any(candidates):
                diff_rec = OrderedDict()
                diff_rec['abs'] = max_abs_diff.astype(dtype)
                diff_rec['rel'] = max_rel_diff.astype(dtype)
                diffs1.append(diff_rec)
            else:
                diffs1.append(None)
        else:
            diffs1.append({'CMP': 'incompat'})
    if any(diffs1):
        diffs['DATA(diff %d:)' % (i + 1)] = diffs1","for e_target in enumerate(data[:-1]):
    d1 = e_target[1]
    i = e_target[0]
    diffs1 = [None] * (i + 1)
    for (j, d2) in enumerate(data[i + 1:], i + 1):
        if d1.shape == d2.shape:
            abs_diff = np.abs(d1 - d2)
            mean_abs = (np.abs(d1) + np.abs(d2)) * 0.5
            candidates = np.logical_or(mean_abs != 0, abs_diff != 0)
            if max_abs:
                candidates[abs_diff <= max_abs] = False
            max_abs_diff = np.max(abs_diff)
            if np.any(candidates):
                rel_diff = abs_diff[candidates] / mean_abs[candidates]
                if max_rel:
                    sub_thr = rel_diff <= max_rel
                    candidates[tuple((indexes[sub_thr] for indexes in np.where(candidates)))] = False
                max_rel_diff = np.max(rel_diff)
            else:
                max_rel_diff = 0
            if np.any(candidates):
                diff_rec = OrderedDict()
                diff_rec['abs'] = max_abs_diff.astype(dtype)
                diff_rec['rel'] = max_rel_diff.astype(dtype)
                diffs1.append(diff_rec)
            else:
                diffs1.append(None)
        else:
            diffs1.append({'CMP': 'incompat'})
    if any(diffs1):
        diffs['DATA(diff %d:)' % (i + 1)] = diffs1

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/tests/test_utils.py', 'nibabel.cmdline.tests.test_utils', '', 'test_get_data_diff']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/diff.py,,test_get_data_diff,"for (j, d2) in enumerate(data[i + 1:], i + 1):
    if d1.shape == d2.shape:
        abs_diff = np.abs(d1 - d2)
        mean_abs = (np.abs(d1) + np.abs(d2)) * 0.5
        candidates = np.logical_or(mean_abs != 0, abs_diff != 0)
        if max_abs:
            candidates[abs_diff <= max_abs] = False
        max_abs_diff = np.max(abs_diff)
        if np.any(candidates):
            rel_diff = abs_diff[candidates] / mean_abs[candidates]
            if max_rel:
                sub_thr = rel_diff <= max_rel
                candidates[tuple((indexes[sub_thr] for indexes in np.where(candidates)))] = False
            max_rel_diff = np.max(rel_diff)
        else:
            max_rel_diff = 0
        if np.any(candidates):
            diff_rec = OrderedDict()
            diff_rec['abs'] = max_abs_diff.astype(dtype)
            diff_rec['rel'] = max_rel_diff.astype(dtype)
            diffs1.append(diff_rec)
        else:
            diffs1.append(None)
    else:
        diffs1.append({'CMP': 'incompat'})","for e_target in enumerate(data[i + 1:], i + 1):
    d2 = e_target[1]
    j = e_target[0]
    if d1.shape == d2.shape:
        abs_diff = np.abs(d1 - d2)
        mean_abs = (np.abs(d1) + np.abs(d2)) * 0.5
        candidates = np.logical_or(mean_abs != 0, abs_diff != 0)
        if max_abs:
            candidates[abs_diff <= max_abs] = False
        max_abs_diff = np.max(abs_diff)
        if np.any(candidates):
            rel_diff = abs_diff[candidates] / mean_abs[candidates]
            if max_rel:
                sub_thr = rel_diff <= max_rel
                candidates[tuple((indexes[sub_thr] for indexes in np.where(candidates)))] = False
            max_rel_diff = np.max(rel_diff)
        else:
            max_rel_diff = 0
        if np.any(candidates):
            diff_rec = OrderedDict()
            diff_rec['abs'] = max_abs_diff.astype(dtype)
            diff_rec['rel'] = max_rel_diff.astype(dtype)
            diffs1.append(diff_rec)
        else:
            diffs1.append(None)
    else:
        diffs1.append({'CMP': 'incompat'})

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/tests/test_utils.py', 'nibabel.cmdline.tests.test_utils', '', 'test_get_data_diff']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/diff.py,,test_display_diff,"for (i, f) in enumerate(files, 1):
    output += '%d:%s' % (i, filename_width.format(os.path.basename(f)))","for e_target in enumerate(files, 1):
    f = e_target[1]
    i = e_target[0]
    output += '%d:%s' % (i, filename_width.format(os.path.basename(f)))

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/tests/test_utils.py', 'nibabel.cmdline.tests.test_utils', '', 'test_display_diff']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/diff.py,,test_display_diff,"for (key, value) in diff.items():
    output += field_width.format(key)
    for item in value:
        if isinstance(item, dict):
            item_str = ', '.join(('%s: %s' % i for i in item.items()))
        elif item is None:
            item_str = '-'
        else:
            item_str = str(item)
        item_str = re.sub('^[ \t]+', '<', item_str)
        item_str = re.sub('[ \t]+$', '>', item_str)
        item_str = re.sub('[\x00]', '?', item_str)
        output += value_width.format(item_str)
    output += '\n'","for e_target in diff.items():
    value = e_target[1]
    key = e_target[0]
    output += field_width.format(key)
    for item in value:
        if isinstance(item, dict):
            item_str = ', '.join(('%s: %s' % i for i in item.items()))
        elif item is None:
            item_str = '-'
        else:
            item_str = str(item)
        item_str = re.sub('^[ \t]+', '<', item_str)
        item_str = re.sub('[ \t]+$', '>', item_str)
        item_str = re.sub('[\x00]', '?', item_str)
        output += value_width.format(item_str)
    output += '\n'

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/tests/test_utils.py', 'nibabel.cmdline.tests.test_utils', '', 'test_display_diff']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/utils.py,,test_table2string,"for (i, table_) in enumerate(table):
    table[i] += [''] * (nelements_max - len(table_))","for e_target in enumerate(table):
    table_ = e_target[1]
    i = e_target[0]
    table[i] += [''] * (nelements_max - len(table_))

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/tests/test_utils.py', 'nibabel.cmdline.tests.test_utils', '', 'test_table2string']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/utils.py,,test_table2string,"for (i, table_) in enumerate(table):
    string_ = ''
    for (j, item) in enumerate(table_):
        item = str(item)
        if item.startswith('@'):
            align = item[1]
            item = item[2:]
            if align not in ['l', 'r', 'c', 'w']:
                raise ValueError(f'Unknown alignment {align}. Known are l,r,c')
        else:
            align = 'c'
        nspacesl = max(ceil((col_width[j] - len(item)) / 2.0), 0)
        nspacesr = max(col_width[j] - nspacesl - len(item), 0)
        if align in ['w', 'c']:
            pass
        elif align == 'l':
            (nspacesl, nspacesr) = (0, nspacesl + nspacesr)
        elif align == 'r':
            (nspacesl, nspacesr) = (nspacesl + nspacesr, 0)
        else:
            raise RuntimeError(f'Should not get here with align={align}')
        string_ += '%%%ds%%s%%%ds ' % (nspacesl, nspacesr) % ('', item, '')
    string += string_.rstrip() + '\n'","for e_target in enumerate(table):
    table_ = e_target[1]
    i = e_target[0]
    string_ = ''
    for (j, item) in enumerate(table_):
        item = str(item)
        if item.startswith('@'):
            align = item[1]
            item = item[2:]
            if align not in ['l', 'r', 'c', 'w']:
                raise ValueError(f'Unknown alignment {align}. Known are l,r,c')
        else:
            align = 'c'
        nspacesl = max(ceil((col_width[j] - len(item)) / 2.0), 0)
        nspacesr = max(col_width[j] - nspacesl - len(item), 0)
        if align in ['w', 'c']:
            pass
        elif align == 'l':
            (nspacesl, nspacesr) = (0, nspacesl + nspacesr)
        elif align == 'r':
            (nspacesl, nspacesr) = (nspacesl + nspacesr, 0)
        else:
            raise RuntimeError(f'Should not get here with align={align}')
        string_ += '%%%ds%%s%%%ds ' % (nspacesl, nspacesr) % ('', item, '')
    string += string_.rstrip() + '\n'

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/tests/test_utils.py', 'nibabel.cmdline.tests.test_utils', '', 'test_table2string']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/utils.py,,test_table2string,"for (j, item) in enumerate(table_):
    item = str(item)
    if item.startswith('@'):
        align = item[1]
        item = item[2:]
        if align not in ['l', 'r', 'c', 'w']:
            raise ValueError(f'Unknown alignment {align}. Known are l,r,c')
    else:
        align = 'c'
    nspacesl = max(ceil((col_width[j] - len(item)) / 2.0), 0)
    nspacesr = max(col_width[j] - nspacesl - len(item), 0)
    if align in ['w', 'c']:
        pass
    elif align == 'l':
        (nspacesl, nspacesr) = (0, nspacesl + nspacesr)
    elif align == 'r':
        (nspacesl, nspacesr) = (nspacesl + nspacesr, 0)
    else:
        raise RuntimeError(f'Should not get here with align={align}')
    string_ += '%%%ds%%s%%%ds ' % (nspacesl, nspacesr) % ('', item, '')","for e_target in enumerate(table_):
    item = e_target[1]
    j = e_target[0]
    item = str(item)
    if item.startswith('@'):
        align = item[1]
        item = item[2:]
        if align not in ['l', 'r', 'c', 'w']:
            raise ValueError(f'Unknown alignment {align}. Known are l,r,c')
    else:
        align = 'c'
    nspacesl = max(ceil((col_width[j] - len(item)) / 2.0), 0)
    nspacesr = max(col_width[j] - nspacesl - len(item), 0)
    if align in ['w', 'c']:
        pass
    elif align == 'l':
        (nspacesl, nspacesr) = (0, nspacesl + nspacesr)
    elif align == 'r':
        (nspacesl, nspacesr) = (nspacesl + nspacesr, 0)
    else:
        raise RuntimeError(f'Should not get here with align={align}')
    string_ += '%%%ds%%s%%%ds ' % (nspacesl, nspacesr) % ('', item, '')

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/cmdline/tests/test_utils.py', 'nibabel.cmdline.tests.test_utils', '', 'test_table2string']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/trk.py,TestTRK,test_write_optional_header_fields,"for (name, slice_) in data_per_point_slice.items():
    tractogram.data_per_point[name] = scalars[:, slice_]","for e_target in data_per_point_slice.items():
    slice_ = e_target[1]
    name = e_target[0]
    tractogram.data_per_point[name] = scalars[:, slice_]

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_write_LPS_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_file_with_wrong_information'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_complex_file_in_big_endian'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_empty_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_simple_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_str'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_write_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_complex_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_tractogram_file_properties'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_too_many_scalars_and_properties'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_empty_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_trk_version_1'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_complex_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_simple_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_optional_header_fields']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/trk.py,TestTRK,test_write_optional_header_fields,"for (name, slice_) in data_per_streamline_slice.items():
    tractogram.data_per_streamline[name] = properties[:, slice_]","for e_target in data_per_streamline_slice.items():
    slice_ = e_target[1]
    name = e_target[0]
    tractogram.data_per_streamline[name] = properties[:, slice_]

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_write_LPS_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_file_with_wrong_information'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_complex_file_in_big_endian'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_empty_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_simple_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_str'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_write_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_complex_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_tractogram_file_properties'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_too_many_scalars_and_properties'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_empty_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_trk_version_1'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_complex_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_simple_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_optional_header_fields']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/trk.py,TestTRK,test_write_optional_header_fields,"for (pts, scals, props) in cls._read(fileobj, hdr):
    items = data_per_point_slice.items()
    data_for_points = dict(((k, scals[:, v]) for (k, v) in items))
    items = data_per_streamline_slice.items()
    data_for_streamline = dict(((k, props[v]) for (k, v) in items))
    yield TractogramItem(pts, data_for_streamline, data_for_points)","for e_target in cls._read(fileobj, hdr):
    props = e_target[2]
    scals = e_target[1]
    pts = e_target[0]
    items = data_per_point_slice.items()
    data_for_points = dict(((k, scals[:, v]) for (k, v) in items))
    items = data_per_streamline_slice.items()
    data_for_streamline = dict(((k, props[v]) for (k, v) in items))
    yield TractogramItem(pts, data_for_streamline, data_for_points)

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_write_LPS_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_file_with_wrong_information'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_complex_file_in_big_endian'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_empty_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_simple_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_str'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_write_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_complex_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_tractogram_file_properties'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_too_many_scalars_and_properties'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_empty_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_trk_version_1'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_complex_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_load_simple_file'], ['https://github.com/nipy/nibabel/tree/master/nibabel/streamlines/tests/test_trk.py', 'nibabel.streamlines.tests.test_trk', 'TestTRK', 'test_write_optional_header_fields']]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/testing/helpers.py,TestAnalyzeImage,test_no_finite_values,"for (name, fileholder) in file_map.items():
    fileholder.fileobj = BytesIO()
    fileholder.pos = 0","for e_target in file_map.items():
    fileholder = e_target[1]
    name = e_target[0]
    fileholder.fileobj = BytesIO()
    fileholder.pos = 0

",1,"[['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_nifti1.py', 'nibabel.tests.test_nifti1', 'TestNifti1Image', 'test_offset_errors'], ['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_analyze.py', 'nibabel.tests.test_analyze', 'TestAnalyzeImage', 'test_offset_to_zero'], ['https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_analyze.py', 'nibabel.tests.test_analyze', 'TestAnalyzeImage', 'test_no_finite_values']]"
dnspython,https://github.com/rthalley/dnspython/tree/master/tests/util.py,ConstantsTestCase,test_rdata_constants,"for (flag, value) in attr.__members__.items():
    eq_callback(getattr(module, flag), value)","for e_target in attr.__members__.items():
    value = e_target[1]
    flag = e_target[0]
    eq_callback(getattr(module, flag), value)

",1,"[['https://github.com/rthalley/dnspython/tree/master/tests/test_constants.py', 'tests.test_constants', 'ConstantsTestCase', 'test_edns_constants'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_constants.py', 'tests.test_constants', 'ConstantsTestCase', 'test_message_constants'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_constants.py', 'tests.test_constants', 'ConstantsTestCase', 'test_dnssec_constants'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_constants.py', 'tests.test_constants', 'ConstantsTestCase', 'test_flags_constants'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_constants.py', 'tests.test_constants', 'ConstantsTestCase', 'test_rdata_constants']]"
dnspython,https://github.com/rthalley/dnspython/tree/master/dns/immutable.py,ImmutableTestCase,test_constify,"for (k, v) in o.items():
    cdict[k] = constify(v)","for e_target in o.items():
    v = e_target[1]
    k = e_target[0]
    cdict[k] = constify(v)

",1,"[['https://github.com/rthalley/dnspython/tree/master/tests/test_immutable.py', 'tests.test_immutable', 'ImmutableTestCase', 'test_constify']]"
dnspython,https://github.com/rthalley/dnspython/tree/master/dns/tsigkeyring.py,TSIGKeyRingTestCase,test_from_text,"for (name, value) in textring.items():
    name = dns.name.from_text(name)
    if isinstance(value, str):
        keyring[name] = dns.tsig.Key(name, value).secret
    else:
        (algorithm, secret) = value
        keyring[name] = dns.tsig.Key(name, secret, algorithm)","for e_target in textring.items():
    value = e_target[1]
    name = e_target[0]
    name = dns.name.from_text(name)
    if isinstance(value, str):
        keyring[name] = dns.tsig.Key(name, value).secret
    else:
        (algorithm, secret) = value
        keyring[name] = dns.tsig.Key(name, secret, algorithm)

",1,"[['https://github.com/rthalley/dnspython/tree/master/tests/test_tsigkeyring.py', 'tests.test_tsigkeyring', 'TSIGKeyRingTestCase', 'test_from_and_to_text'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_tsigkeyring.py', 'tests.test_tsigkeyring', 'TSIGKeyRingTestCase', 'test_from_alt_text'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_renderer.py', 'tests.test_renderer', 'RendererTestCase', 'test_tsig'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_tsigkeyring.py', 'tests.test_tsigkeyring', 'TSIGKeyRingTestCase', 'test_from_old_text'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_tsigkeyring.py', 'tests.test_tsigkeyring', 'TSIGKeyRingTestCase', 'test_old_from_and_to_text'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_update.py', 'tests.test_update', 'UpdateTestCase', 'test_TSIG'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_resolution.py', 'tests.test_resolution', 'ResolutionTestCase', 'test_next_request_TSIG'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_renderer.py', 'tests.test_renderer', 'RendererTestCase', 'test_multi_tsig'], ['https://github.com/rthalley/dnspython/tree/master/tests/test_tsigkeyring.py', 'tests.test_tsigkeyring', 'TSIGKeyRingTestCase', 'test_from_text']]"
cleanlab,https://github.com/cleanlab/cleanlab/tree/master/cleanlab/pruning.py,,test_prune_on_small_data,"for (i, pred_label) in enumerate(pred):
    if multi_label and np.all(pred_label == s[i]) or (not multi_label and pred_label == s[i]):
        label_errors_mask[i] = False","for e_target in enumerate(pred):
    pred_label = e_target[1]
    i = e_target[0]
    if multi_label and np.all(pred_label == s[i]) or (not multi_label and pred_label == s[i]):
        label_errors_mask[i] = False

",1,"[['https://github.com/cleanlab/cleanlab/tree/master/tests/test_latent_estimation_and_pruning.py', 'tests.test_latent_estimation_and_pruning', '', 'test_pruning_order_method'], ['https://github.com/cleanlab/cleanlab/tree/master/tests/test_latent_estimation_and_pruning.py', 'tests.test_latent_estimation_and_pruning', '', 'test_get_noise_indices_multi_label'], ['https://github.com/cleanlab/cleanlab/tree/master/tests/test_latent_estimation_and_pruning.py', 'tests.test_latent_estimation_and_pruning', '', 'test_exact_prune_count'], ['https://github.com/cleanlab/cleanlab/tree/master/tests/test_latent_estimation_and_pruning.py', 'tests.test_latent_estimation_and_pruning', '', 'test_prune_on_small_data']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/scanner/scanners/iam_rules_scanner.py,IamRulesScannerTest,test_add_bucket_ancestor_bindings_same_role_different_members,"for (resource, _, bindings) in policy_data:
    if resource.type == 'bucket':
        bucket_data.append((resource, bindings))","for e_target in policy_data:
    bindings = e_target[2]
    _ = e_target[1]
    resource = e_target[0]
    if resource.type == 'bucket':
        bucket_data.append((resource, bindings))

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_success'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_nothing_found'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_with_2_ancestor_lines'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_success_no_dups'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_with_wrong_ancestors'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_same_role_different_members']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/scanner/scanners/iam_rules_scanner.py,IamRulesScannerTest,test_add_bucket_ancestor_bindings_same_role_different_members,"for (bucket, bucket_bindings) in bucket_data:
    all_ancestor_bindings = []
    for (resource, _, bindings) in policy_data:
        if resource.full_name == bucket.full_name:
            continue
        if bucket.full_name.find(resource.full_name):
            continue
        all_ancestor_bindings.append(bindings)
    for ancestor_bindings in all_ancestor_bindings:
        for ancestor_binding in ancestor_bindings:
            if ancestor_binding.role_name not in storage_iam_roles:
                continue
            if ancestor_binding in bucket_bindings:
                continue
            for bucket_binding in bucket_bindings:
                if bucket_binding.role_name == ancestor_binding.role_name:
                    bucket_binding.merge_members(ancestor_binding)
                    break
            else:
                bucket_bindings.append(ancestor_binding)","for e_target in bucket_data:
    bucket_bindings = e_target[1]
    bucket = e_target[0]
    all_ancestor_bindings = []
    for (resource, _, bindings) in policy_data:
        if resource.full_name == bucket.full_name:
            continue
        if bucket.full_name.find(resource.full_name):
            continue
        all_ancestor_bindings.append(bindings)
    for ancestor_bindings in all_ancestor_bindings:
        for ancestor_binding in ancestor_bindings:
            if ancestor_binding.role_name not in storage_iam_roles:
                continue
            if ancestor_binding in bucket_bindings:
                continue
            for bucket_binding in bucket_bindings:
                if bucket_binding.role_name == ancestor_binding.role_name:
                    bucket_binding.merge_members(ancestor_binding)
                    break
            else:
                bucket_bindings.append(ancestor_binding)

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_success'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_nothing_found'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_with_2_ancestor_lines'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_success_no_dups'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_with_wrong_ancestors'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_same_role_different_members']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/scanner/scanners/iam_rules_scanner.py,IamRulesScannerTest,test_add_bucket_ancestor_bindings_same_role_different_members,"for (resource, _, bindings) in policy_data:
    if resource.full_name == bucket.full_name:
        continue
    if bucket.full_name.find(resource.full_name):
        continue
    all_ancestor_bindings.append(bindings)","for e_target in policy_data:
    bindings = e_target[2]
    _ = e_target[1]
    resource = e_target[0]
    if resource.full_name == bucket.full_name:
        continue
    if bucket.full_name.find(resource.full_name):
        continue
    all_ancestor_bindings.append(bindings)

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_success'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_nothing_found'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_with_2_ancestor_lines'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_success_no_dups'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_with_wrong_ancestors'], ['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/iam_rules_scanner_test.py', 'tests.scanner.scanners.iam_rules_scanner_test', 'IamRulesScannerTest', 'test_add_bucket_ancestor_bindings_same_role_different_members']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/scanner/scanners/firewall_rules_scanner.py,FirewallRulesScannerTest,test_retrieve,"for (cnt, i) in enumerate(data_access.scanner_iter(session, 'firewall')):
    count = cnt
    firewall_data_for_scanner = json.loads(i.data)
    firewall_data_for_scanner['project_id'] = i.parent.name
    firewall_data_for_scanner['full_name'] = i.full_name
    project_policies[i.parent.name].append(firewall_rule.FirewallRule.from_dict(firewall_dict=firewall_data_for_scanner, project_id=i.parent.name, validate=True))","for e_target in enumerate(data_access.scanner_iter(session, 'firewall')):
    i = e_target[1]
    cnt = e_target[0]
    count = cnt
    firewall_data_for_scanner = json.loads(i.data)
    firewall_data_for_scanner['project_id'] = i.parent.name
    firewall_data_for_scanner['full_name'] = i.full_name
    project_policies[i.parent.name].append(firewall_rule.FirewallRule.from_dict(firewall_dict=firewall_data_for_scanner, project_id=i.parent.name, validate=True))

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/scanner/scanners/firewall_rules_scanner_test.py', 'tests.scanner.scanners.firewall_rules_scanner_test', 'FirewallRulesScannerTest', 'test_retrieve']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/notifier/notifiers/slack_webhook.py,SlackWebhooknotifierTest,test_dump_slack_output_for_string_returns_string,"for (key, value) in sorted(data.items()):
    output += '\t' * indent + '*' + str(key) + '*:'
    if isinstance(value, dict):
        output += '\n' + self._dump_slack_output(value, indent + 1) + '\n'
    else:
        if not value:
            value = 'n/a'
        output += '\t' * (indent + 1) + '`' + str(value) + '`\n'","for e_target in sorted(data.items()):
    value = e_target[1]
    key = e_target[0]
    output += '\t' * indent + '*' + str(key) + '*:'
    if isinstance(value, dict):
        output += '\n' + self._dump_slack_output(value, indent + 1) + '\n'
    else:
        if not value:
            value = 'n/a'
        output += '\t' * (indent + 1) + '`' + str(value) + '`\n'

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/notifier/notifiers/slack_webhook_test.py', 'tests.notifier.notifiers.slack_webhook_test', 'SlackWebhooknotifierTest', 'test_dump_slack_output_for_string_returns_string']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/services/utils.py,ServerUtilsTest,test_get_resources_from_full_name,"for (resource_id, resource_type) in zip(resource_iter, resource_iter):
    yield (resource_type, resource_id)","for e_target in zip(resource_iter, resource_iter):
    resource_type = e_target[1]
    resource_id = e_target[0]
    yield (resource_type, resource_id)

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/services/utils_test.py', 'tests.services.utils_test', 'ServerUtilsTest', 'test_get_resources_from_full_name']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/common/gcp_type/resource_util.py,BillingAccountTest,test_get_billing_account_ancestors,"for (resource_type, resource_id) in utils.get_resources_from_full_name(full_name):
    resource_ancestors.append(create_resource(resource_id, resource_type))","for e_target in utils.get_resources_from_full_name(full_name):
    resource_id = e_target[1]
    resource_type = e_target[0]
    resource_ancestors.append(create_resource(resource_id, resource_type))

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/common/gcp_type/billing_account_test.py', 'tests.common.gcp_type.billing_account_test', 'BillingAccountTest', 'test_get_billing_account_ancestors']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/common/gcp_type/iam_policy.py,IamPolicyTest,test_audit_config_merge_succeeds,"for (service_name, log_configs) in other.service_configs.items():
    if service_name not in self.service_configs:
        self.service_configs[service_name] = {}
    service_config = self.service_configs[service_name]
    for (log_type, exemptions) in log_configs.items():
        service_config[log_type] = exemptions.union(service_config.get(log_type, set()))","for e_target in other.service_configs.items():
    log_configs = e_target[1]
    service_name = e_target[0]
    if service_name not in self.service_configs:
        self.service_configs[service_name] = {}
    service_config = self.service_configs[service_name]
    for (log_type, exemptions) in log_configs.items():
        service_config[log_type] = exemptions.union(service_config.get(log_type, set()))

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/common/gcp_type/iam_policy_test.py', 'tests.common.gcp_type.iam_policy_test', 'IamPolicyTest', 'test_audit_config_merge_succeeds']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/common/gcp_type/iam_policy.py,IamPolicyTest,test_audit_config_merge_succeeds,"for (log_type, exemptions) in log_configs.items():
    service_config[log_type] = exemptions.union(service_config.get(log_type, set()))","for e_target in log_configs.items():
    exemptions = e_target[1]
    log_type = e_target[0]
    service_config[log_type] = exemptions.union(service_config.get(log_type, set()))

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/common/gcp_type/iam_policy_test.py', 'tests.common.gcp_type.iam_policy_test', 'IamPolicyTest', 'test_audit_config_merge_succeeds']]"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/common/util/relationship.py,RelationshipUtilTest,test_get_resource_ancestors_from_full_name,"for (resource_type, resource_id) in resources:
    if resource_type == starting_resource.type and resource_id == starting_resource.id:
        continue
    new_resource = resource_util.create_resource(resource_id, resource_type)
    if new_resource:
        ancestor_resources.append(new_resource)","for e_target in resources:
    resource_id = e_target[1]
    resource_type = e_target[0]
    if resource_type == starting_resource.type and resource_id == starting_resource.id:
        continue
    new_resource = resource_util.create_resource(resource_id, resource_type)
    if new_resource:
        ancestor_resources.append(new_resource)

",1,"[['https://github.com/forseti-security/forseti-security/tree/master/tests/common/util/relationship_test.py', 'tests.common.util.relationship_test', 'RelationshipUtilTest', 'test_get_resource_ancestors_from_full_name']]"
errbot,https://github.com/errbotio/errbot/tree/master/errbot/utils.py,,test_find_plugin_roots,"for (root, dirnames, filenames) in os.walk(path, followlinks=True):
    for filename in fnmatch.filter(filenames, file_sig):
        dir_to_add = os.path.dirname(os.path.join(root, filename))
        relative = os.path.relpath(os.path.realpath(dir_to_add), os.path.realpath(path))
        for subelement in relative.split(os.path.sep):
            if subelement in ('.', '..'):
                continue
            if subelement.startswith('.') or subelement == '__pycache__':
                log.debug('Ignore %s.', dir_to_add)
                break
        else:
            roots.append(dir_to_add)","for e_target in os.walk(path, followlinks=True):
    filenames = e_target[2]
    dirnames = e_target[1]
    root = e_target[0]
    for filename in fnmatch.filter(filenames, file_sig):
        dir_to_add = os.path.dirname(os.path.join(root, filename))
        relative = os.path.relpath(os.path.realpath(dir_to_add), os.path.realpath(path))
        for subelement in relative.split(os.path.sep):
            if subelement in ('.', '..'):
                continue
            if subelement.startswith('.') or subelement == '__pycache__':
                log.debug('Ignore %s.', dir_to_add)
                break
        else:
            roots.append(dir_to_add)

",1,"[['https://github.com/errbotio/errbot/tree/master/tests/plugin_management_test.py', 'tests.plugin_management_test', '', 'test_find_plugin_roots']]"
sen,https://github.com/TomasTomecek/sen/tree/master/sen/tui/widgets/table.py,,test_assemble_rows_long_text,"for (idx, item) in enumerate(row):
    if idx in ignore_columns:
        row_widgets.append(item)
    else:
        row_widgets.append((max_lengths[idx], item))","for e_target in enumerate(row):
    item = e_target[1]
    idx = e_target[0]
    if idx in ignore_columns:
        row_widgets.append(item)
    else:
        row_widgets.append((max_lengths[idx], item))

",1,"[['https://github.com/TomasTomecek/sen/tree/master/tests/test_widgets.py', 'tests.test_widgets', '', 'test_assemble_rows_long_text']]"
meta-dataset,https://github.com/google-research/meta-dataset/tree/master/meta_dataset/data/imagenet_specification.py,SplitCreationTest,test_toy_root_proposer,"for (s, leaves) in spanning_leaves_sorted:
    num_leaves = len(leaves)
    low_limit_valid = desired_num_valid_classes - margin
    high_limit_valid = desired_num_valid_classes + margin
    if low_limit_valid < num_leaves and num_leaves < high_limit_valid:
        valid_candidates.append(s)
    low_limit_test = desired_num_test_classes - margin
    high_limit_test = desired_num_test_classes + margin
    if low_limit_test < num_leaves and num_leaves < high_limit_test:
        test_candidates.append(s)","for e_target in spanning_leaves_sorted:
    leaves = e_target[1]
    s = e_target[0]
    num_leaves = len(leaves)
    low_limit_valid = desired_num_valid_classes - margin
    high_limit_valid = desired_num_valid_classes + margin
    if low_limit_valid < num_leaves and num_leaves < high_limit_valid:
        valid_candidates.append(s)
    low_limit_test = desired_num_test_classes - margin
    high_limit_test = desired_num_test_classes + margin
    if low_limit_test < num_leaves and num_leaves < high_limit_test:
        test_candidates.append(s)

",1,"[['https://github.com/google-research/meta-dataset/tree/master/meta_dataset/data/imagenet_specification_test.py', 'meta_dataset.data.imagenet_specification_test', 'SplitCreationTest', 'test_toy_root_proposer']]"
mechanize,https://github.com/python-mechanize/mechanize/tree/master/mechanize/_headersutil.py,HeaderTests,test_join_header_words,"for (k, v) in pairs:
    if v is not None:
        if not re.search('^\\w+$', v):
            v = join_escape_re.sub('\\\\\\1', v)
            v = '""%s""' % v
        if k is None:
            k = v
        else:
            k = '%s=%s' % (k, v)
    attr.append(k)","for e_target in pairs:
    v = e_target[1]
    k = e_target[0]
    if v is not None:
        if not re.search('^\\w+$', v):
            v = join_escape_re.sub('\\\\\\1', v)
            v = '""%s""' % v
        if k is None:
            k = v
        else:
            k = '%s=%s' % (k, v)
    attr.append(k)

",1,"[['https://github.com/python-mechanize/mechanize/tree/master/test/test_headers.py', 'test.test_headers', 'HeaderTests', 'test_roundtrip'], ['https://github.com/python-mechanize/mechanize/tree/master/test/test_headers.py', 'test.test_headers', 'HeaderTests', 'test_join_header_words']]"
dynaconf,https://github.com/rochacbruno/dynaconf/tree/master/dynaconf/loaders/env_loader.py,,test_write,"for (key, value) in settings_data.items():
    quote_mode = isinstance(value, str) and (value.startswith(""'"") or value.startswith('""')) or isinstance(value, (list, dict))
    dotenv_cli.set_key(str(settings_path), key, str(value), quote_mode='always' if quote_mode else 'none')","for e_target in settings_data.items():
    value = e_target[1]
    key = e_target[0]
    quote_mode = isinstance(value, str) and (value.startswith(""'"") or value.startswith('""')) or isinstance(value, (list, dict))
    dotenv_cli.set_key(str(settings_path), key, str(value), quote_mode='always' if quote_mode else 'none')

",1,"[['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_env_loader.py', 'tests.test_env_loader', '', 'test_write']]"
dynaconf,https://github.com/rochacbruno/dynaconf/tree/master/dynaconf/vendor_src/dotenv/cli.py,,test_extract_json,"for (k, v) in dotenv_as_dict.items():
    click.echo('%s=%s' % (k, v))","for e_target in dotenv_as_dict.items():
    v = e_target[1]
    k = e_target[0]
    click.echo('%s=%s' % (k, v))

",1,"[['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_keys_are_equal'], ['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_extract_json']]"
dynaconf,https://github.com/rochacbruno/dynaconf/tree/master/dynaconf/utils/parse_conf.py,,test_del_raises_on_unwrap,"for (k, v) in data.items():
    _parsed[k] = parse_conf_data(v, tomlfy=tomlfy, box_settings=box_settings)","for e_target in data.items():
    v = e_target[1]
    k = e_target[0]
    _parsed[k] = parse_conf_data(v, tomlfy=tomlfy, box_settings=box_settings)

",1,"[['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_merge_dict_with_meta_values'], ['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_tomlfy'], ['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_meta_values'], ['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_disable_cast'], ['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_evaluate_lazy_format_decorator'], ['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_cast_bool'], ['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_del_raises_on_unwrap']]"
dynaconf,https://github.com/rochacbruno/dynaconf/tree/master/dynaconf/vendor/dotenv/cli.py,,test_extract_json,"for (C, D) in B.items():
    click.echo(_D % (C, D))","for e_target in B.items():
    D = e_target[1]
    C = e_target[0]
    click.echo(_D % (C, D))

",1,"[['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_keys_are_equal'], ['https://github.com/rochacbruno/dynaconf/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_extract_json']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/reports/graphs.py,TestPlotHistograms,test_specify_column_inds,"for (col_ind, ax) in zip(inds_to_graph, axs):
    col_profiler = profiler.profile[col_ind]
    data_compiler = col_profiler.profiles['data_type_profile']
    data_type = data_compiler.selected_data_type
    data_type_profiler = data_compiler._profiles[data_type]
    ax = plot_col_histogram(data_type_profiler, ax=ax, title=str(data_type_profiler.name))
    ax.set(xlabel=None)
    ax.set(ylabel=None)","for e_target in zip(inds_to_graph, axs):
    ax = e_target[1]
    col_ind = e_target[0]
    col_profiler = profiler.profile[col_ind]
    data_compiler = col_profiler.profiles['data_type_profile']
    data_type = data_compiler.selected_data_type
    data_type_profiler = data_compiler._profiles[data_type]
    ax = plot_col_histogram(data_type_profiler, ax=ax, title=str(data_type_profiler.name))
    ax.set(xlabel=None)
    ax.set(ylabel=None)

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/reports/test_graphs.py', 'dataprofiler.tests.reports.test_graphs', 'TestPlotHistograms', 'test_specify_column'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/reports/test_graphs.py', 'dataprofiler.tests.reports.test_graphs', 'TestPlotHistograms', 'test_no_column_plottable'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/reports/test_graphs.py', 'dataprofiler.tests.reports.test_graphs', 'TestPlotHistograms', 'test_bad_inputs'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/reports/test_graphs.py', 'dataprofiler.tests.reports.test_graphs', 'TestPlotHistograms', 'test_empty_profiler'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/reports/test_graphs.py', 'dataprofiler.tests.reports.test_graphs', 'TestPlotHistograms', 'test_no_columns_specified'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/reports/test_graphs.py', 'dataprofiler.tests.reports.test_graphs', 'TestPlotHistograms', 'test_specify_column_inds']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/labelers/data_processing.py,TestStructCharPreprocessor,test_convert_to_unstructured_format,"for (sample, entity) in zip(data, labels):
    if entity != default_label:
        entities.append((start, start + len(sample), entity))
    start += len(sample) + separator_length
    if start < text_len:
        entities.append((start - separator_length, start, 'PAD'))","for e_target in zip(data, labels):
    entity = e_target[1]
    sample = e_target[0]
    if entity != default_label:
        entities.append((start, start + len(sample), entity))
    start += len(sample) + separator_length
    if start < text_len:
        entities.append((start - separator_length, start, 'PAD'))

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_data_processing.py', 'dataprofiler.tests.labelers.test_data_processing', 'TestStructCharPreprocessor', 'test_convert_to_unstructured_format']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/labelers/regex_model.py,TestRegexModel,test_predict,"for (entity_label, entity_patterns) in pre_compiled_patterns.items():
    for i in range(len(entity_patterns)):
        pattern = start_pattern + pre_compiled_patterns[entity_label][i] + end_pattern
        pre_compiled_patterns[entity_label][i] = re.compile(pattern, flags=re_flags)","for e_target in pre_compiled_patterns.items():
    entity_patterns = e_target[1]
    entity_label = e_target[0]
    for i in range(len(entity_patterns)):
        pattern = start_pattern + pre_compiled_patterns[entity_label][i] + end_pattern
        pre_compiled_patterns[entity_label][i] = re.compile(pattern, flags=re_flags)

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_regex_model.py', 'dataprofiler.tests.labelers.test_regex_model', 'TestRegexModel', 'test_predict']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/labelers/regex_model.py,TestRegexModel,test_predict,"for (i, input_string) in enumerate(data):
    if len(predictions) <= i:
        predictions.extend([np.empty((0,))] * len(predictions))
    pred = np.zeros((len(input_string), self.num_labels), dtype=int)
    pred[:, default_ind] = 1
    for (entity_label, entity_patterns) in pre_compiled_patterns.items():
        entity_id = self.label_mapping[entity_label]
        for re_pattern in entity_patterns:
            for each_find in re_pattern.finditer(input_string):
                indices = each_find.span(0)
                pred[indices[0]:indices[1], default_ind] = 0
                pred[indices[0]:indices[1], entity_id] = 1
    if verbose:
        sys.stdout.flush()
        sys.stdout.write('\rData Samples Processed: {:d}   '.format(i + 1))
    predictions[i] = pred","for e_target in enumerate(data):
    input_string = e_target[1]
    i = e_target[0]
    if len(predictions) <= i:
        predictions.extend([np.empty((0,))] * len(predictions))
    pred = np.zeros((len(input_string), self.num_labels), dtype=int)
    pred[:, default_ind] = 1
    for (entity_label, entity_patterns) in pre_compiled_patterns.items():
        entity_id = self.label_mapping[entity_label]
        for re_pattern in entity_patterns:
            for each_find in re_pattern.finditer(input_string):
                indices = each_find.span(0)
                pred[indices[0]:indices[1], default_ind] = 0
                pred[indices[0]:indices[1], entity_id] = 1
    if verbose:
        sys.stdout.flush()
        sys.stdout.write('\rData Samples Processed: {:d}   '.format(i + 1))
    predictions[i] = pred

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_regex_model.py', 'dataprofiler.tests.labelers.test_regex_model', 'TestRegexModel', 'test_predict']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/labelers/regex_model.py,TestRegexModel,test_predict,"for (entity_label, entity_patterns) in pre_compiled_patterns.items():
    entity_id = self.label_mapping[entity_label]
    for re_pattern in entity_patterns:
        for each_find in re_pattern.finditer(input_string):
            indices = each_find.span(0)
            pred[indices[0]:indices[1], default_ind] = 0
            pred[indices[0]:indices[1], entity_id] = 1","for e_target in pre_compiled_patterns.items():
    entity_patterns = e_target[1]
    entity_label = e_target[0]
    entity_id = self.label_mapping[entity_label]
    for re_pattern in entity_patterns:
        for each_find in re_pattern.finditer(input_string):
            indices = each_find.span(0)
            pred[indices[0]:indices[1], default_ind] = 0
            pred[indices[0]:indices[1], entity_id] = 1

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_regex_model.py', 'dataprofiler.tests.labelers.test_regex_model', 'TestRegexModel', 'test_predict']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/labelers/labeler_utils.py,TestEvaluateAccuracy,test_omit_1_class,"for (i, true_labels_row) in enumerate(true_entities_in_index):
    true_labels_padded[i][:len(true_labels_row)] = true_labels_row","for e_target in enumerate(true_entities_in_index):
    true_labels_row = e_target[1]
    i = e_target[0]
    true_labels_padded[i][:len(true_labels_row)] = true_labels_row

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_verbose'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_no_support_classes'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_no_omit_class'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_save_conf_mat'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_omit_2_classes'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_omit_1_class']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/labelers/labeler_utils.py,TestEvaluateAccuracy,test_omit_1_class,"for (key, values) in f1_report.items():
    if key not in ['accuracy', 'macro avg', 'weighted avg', 'micro avg']:
        if values['support']:
            num_labels_with_positive_support += 1","for e_target in f1_report.items():
    values = e_target[1]
    key = e_target[0]
    if key not in ['accuracy', 'macro avg', 'weighted avg', 'micro avg']:
        if values['support']:
            num_labels_with_positive_support += 1

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_verbose'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_no_support_classes'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_no_omit_class'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_save_conf_mat'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_omit_2_classes'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_labeler_utils.py', 'dataprofiler.tests.labelers.test_labeler_utils', 'TestEvaluateAccuracy', 'test_omit_1_class']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/labelers/classification_report_utils.py,TestClassificationReport,test_classification_report,"for (label, scores) in report_dict.items():
    report_dict[label] = dict(zip(headers, [i.item() for i in scores]))","for e_target in report_dict.items():
    scores = e_target[1]
    label = e_target[0]
    report_dict[label] = dict(zip(headers, [i.item() for i in scores]))

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_classification_report_utils.py', 'dataprofiler.tests.labelers.test_classification_report_utils', 'TestClassificationReport', 'test_print_classification_report'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/labelers/test_classification_report_utils.py', 'dataprofiler.tests.labelers.test_classification_report_utils', 'TestClassificationReport', 'test_classification_report']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/profilers/utils.py,TestShuffleInChunks,test_find_diff,"for (key, value1) in dict1.items():
    value2 = dict2.get(key, None)
    if isinstance(value1, list):
        diff[key] = find_diff_of_lists_and_sets(value1, value2)
    elif isinstance(value1, datetime.datetime):
        diff[key] = find_diff_of_dates(value1, value2)
    elif isinstance(value1, str):
        diff[key] = find_diff_of_strings_and_bools(value1, value2)
    else:
        diff[key] = find_diff_of_numbers(value1, value2)","for e_target in dict1.items():
    value1 = e_target[1]
    key = e_target[0]
    value2 = dict2.get(key, None)
    if isinstance(value1, list):
        diff[key] = find_diff_of_lists_and_sets(value1, value2)
    elif isinstance(value1, datetime.datetime):
        diff[key] = find_diff_of_dates(value1, value2)
    elif isinstance(value1, str):
        diff[key] = find_diff_of_strings_and_bools(value1, value2)
    else:
        diff[key] = find_diff_of_numbers(value1, value2)

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/profilers/test_utils.py', 'dataprofiler.tests.profilers.test_utils', 'TestShuffleInChunks', 'test_find_diff']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/profilers/utils.py,TestShuffleInChunks,test_find_diff,"for (key, value) in dict2.items():
    if key not in diff:
        diff[key] = [None, value]","for e_target in dict2.items():
    value = e_target[1]
    key = e_target[0]
    if key not in diff:
        diff[key] = [None, value]

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/profilers/test_utils.py', 'dataprofiler.tests.profilers.test_utils', 'TestShuffleInChunks', 'test_find_diff']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/profilers/profile_builder.py,TestStructuredProfiler,test_diff,"for (key, profile) in self.profiles.items():
    if key in other_profile.profiles:
        comp_diff = self.profiles[key].diff(other_profile.profiles[key], options=options)
        utils.dict_merge(unordered_profile, comp_diff)","for e_target in self.profiles.items():
    profile = e_target[1]
    key = e_target[0]
    if key in other_profile.profiles:
        comp_diff = self.profiles[key].diff(other_profile.profiles[key], options=options)
        utils.dict_merge(unordered_profile, comp_diff)

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/profilers/test_profile_builder.py', 'dataprofiler.tests.profilers.test_profile_builder', 'TestStructuredColProfilerClass', 'test_diff'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/profilers/test_profile_builder.py', 'dataprofiler.tests.profilers.test_profile_builder', 'TestStructuredProfiler', 'test_diff_with_different_schema'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/profilers/test_profile_builder.py', 'dataprofiler.tests.profilers.test_profile_builder', 'TestStructuredProfiler', 'test_diff']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/data_readers/avro_data.py,TestAVRODataClass,test_nested_keys,"for (key, value) in nested_keys.items():
    if type(value) is dict:
        schema_avro_temp = {'name': key, 'type': [{'name': key, 'type': 'record', 'fields': []}, 'null']}
        schema_avro_temp['type'][0] = cls._get_schema_avro(value, schema_avro_temp['type'][0])
        schema_avro['fields'].append(schema_avro_temp)
    else:
        schema_avro['fields'].append({'name': key, 'type': ['string', 'null']})","for e_target in nested_keys.items():
    value = e_target[1]
    key = e_target[0]
    if type(value) is dict:
        schema_avro_temp = {'name': key, 'type': [{'name': key, 'type': 'record', 'fields': []}, 'null']}
        schema_avro_temp['type'][0] = cls._get_schema_avro(value, schema_avro_temp['type'][0])
        schema_avro['fields'].append(schema_avro_temp)
    else:
        schema_avro['fields'].append({'name': key, 'type': ['string', 'null']})

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/data_readers/test_avro_data.py', 'dataprofiler.tests.data_readers.test_avro_data', 'TestAVRODataClass', 'test_nested_keys']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/data_readers/data_utils.py,TestDataReadingWriting,test_nth_loc_detection,"for (id_count, match) in enumerate(r_iter):
    idx = match.start()
    if id_count + 1 == n:
        break","for e_target in enumerate(r_iter):
    match = e_target[1]
    id_count = e_target[0]
    idx = match.start()
    if id_count + 1 == n:
        break

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/data_readers/test_data_utils.py', 'dataprofiler.tests.data_readers.test_data_utils', 'TestDataReadingWriting', 'test_nth_loc_detection']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/validators/base_validators.py,TestDataValidator,test_dask_data_validation,"for (iter_key, value) in known_anomaly_validation.items():
    if len(value) < 1:
        raise Warning(f'Pass at a minimum one value for a specified column (i.e. iter_key variable) -- not both for {iter_key}')","for e_target in known_anomaly_validation.items():
    value = e_target[1]
    iter_key = e_target[0]
    if len(value) < 1:
        raise Warning(f'Pass at a minimum one value for a specified column (i.e. iter_key variable) -- not both for {iter_key}')

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_output'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_empty_config'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_wrong_config'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_dask_data_validation']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/validators/base_validators.py,TestDataValidator,test_dask_data_validation,"for (iter_key, value) in known_anomaly_validation.items():
    self.validation_report[iter_key] = dict()
    df_series = data[iter_key]
    for (sub_key, sub_value) in value.items():
        self.validation_report[iter_key][sub_key] = dict()
        if sub_key not in ['range', 'list']:
            raise TypeError('Range and list only acceptable key values.')
        apply_type = is_in_range if sub_key == 'range' else is_in_list
        if df_type == 'dask':
            temp_results = df_series.apply(apply_type, meta=(iter_key, 'bool'), args=(sub_value,))
            temp_results = temp_results.compute()
            self.validation_report[iter_key][sub_key] = [idx for (idx, val) in enumerate(temp_results.values.tolist()) if val]
        elif df_type == 'pandas':
            temp_results = df_series.apply(apply_type, args=(sub_value,))
            self.validation_report[iter_key][sub_key] = [idx for (idx, val) in temp_results.items() if val]
        else:
            raise ValueError('Dask and Pandas are the only supported dataframe types.')
        del temp_results","for e_target in known_anomaly_validation.items():
    value = e_target[1]
    iter_key = e_target[0]
    self.validation_report[iter_key] = dict()
    df_series = data[iter_key]
    for (sub_key, sub_value) in value.items():
        self.validation_report[iter_key][sub_key] = dict()
        if sub_key not in ['range', 'list']:
            raise TypeError('Range and list only acceptable key values.')
        apply_type = is_in_range if sub_key == 'range' else is_in_list
        if df_type == 'dask':
            temp_results = df_series.apply(apply_type, meta=(iter_key, 'bool'), args=(sub_value,))
            temp_results = temp_results.compute()
            self.validation_report[iter_key][sub_key] = [idx for (idx, val) in enumerate(temp_results.values.tolist()) if val]
        elif df_type == 'pandas':
            temp_results = df_series.apply(apply_type, args=(sub_value,))
            self.validation_report[iter_key][sub_key] = [idx for (idx, val) in temp_results.items() if val]
        else:
            raise ValueError('Dask and Pandas are the only supported dataframe types.')
        del temp_results

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_output'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_empty_config'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_wrong_config'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_dask_data_validation']]"
DataProfiler,https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/validators/base_validators.py,TestDataValidator,test_dask_data_validation,"for (sub_key, sub_value) in value.items():
    self.validation_report[iter_key][sub_key] = dict()
    if sub_key not in ['range', 'list']:
        raise TypeError('Range and list only acceptable key values.')
    apply_type = is_in_range if sub_key == 'range' else is_in_list
    if df_type == 'dask':
        temp_results = df_series.apply(apply_type, meta=(iter_key, 'bool'), args=(sub_value,))
        temp_results = temp_results.compute()
        self.validation_report[iter_key][sub_key] = [idx for (idx, val) in enumerate(temp_results.values.tolist()) if val]
    elif df_type == 'pandas':
        temp_results = df_series.apply(apply_type, args=(sub_value,))
        self.validation_report[iter_key][sub_key] = [idx for (idx, val) in temp_results.items() if val]
    else:
        raise ValueError('Dask and Pandas are the only supported dataframe types.')
    del temp_results","for e_target in value.items():
    sub_value = e_target[1]
    sub_key = e_target[0]
    self.validation_report[iter_key][sub_key] = dict()
    if sub_key not in ['range', 'list']:
        raise TypeError('Range and list only acceptable key values.')
    apply_type = is_in_range if sub_key == 'range' else is_in_list
    if df_type == 'dask':
        temp_results = df_series.apply(apply_type, meta=(iter_key, 'bool'), args=(sub_value,))
        temp_results = temp_results.compute()
        self.validation_report[iter_key][sub_key] = [idx for (idx, val) in enumerate(temp_results.values.tolist()) if val]
    elif df_type == 'pandas':
        temp_results = df_series.apply(apply_type, args=(sub_value,))
        self.validation_report[iter_key][sub_key] = [idx for (idx, val) in temp_results.items() if val]
    else:
        raise ValueError('Dask and Pandas are the only supported dataframe types.')
    del temp_results

",1,"[['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_output'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_empty_config'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_data_validation_wrong_config'], ['https://github.com/capitalone/DataProfiler/tree/master/dataprofiler/tests/validators/test_base_validators.py', 'dataprofiler.tests.validators.test_base_validators', 'TestDataValidator', 'test_dask_data_validation']]"
pudb,https://github.com/inducer/pudb/tree/master/pudb/ui_tools.py,,test_simple,"for (line, line_attr) in zip(txt, attr):
    line_attr = [(aname, l) for (aname, l) in line_attr if l > 0]
    diff = maxcol - text_width(line)
    if diff > 0:
        line += ' ' * diff
        line_attr.append((fill_attr, diff))
    else:
        from urwid.util import rle_subseg
        line = line[:calc_text_pos(line, 0, len(line), maxcol)[0]]
        line_attr = rle_subseg(line_attr, 0, maxcol)
    from urwid.util import apply_target_encoding
    (encoded_line, line_cs) = apply_target_encoding(line)

    def get_byte_line_attr(line, line_attr):
        i = 0
        for (label, column_count) in line_attr:
            byte_count = len(encode_like_urwid(line[i:i + column_count]))
            i += column_count
            yield (label, byte_count)
    line_attr = list(get_byte_line_attr(line, line_attr))
    processed_txt.append(encoded_line)
    processed_attr.append(line_attr)
    processed_cs.append(line_cs)","for e_target in zip(txt, attr):
    line_attr = e_target[1]
    line = e_target[0]
    line_attr = [(aname, l) for (aname, l) in line_attr if l > 0]
    diff = maxcol - text_width(line)
    if diff > 0:
        line += ' ' * diff
        line_attr.append((fill_attr, diff))
    else:
        from urwid.util import rle_subseg
        line = line[:calc_text_pos(line, 0, len(line), maxcol)[0]]
        line_attr = rle_subseg(line_attr, 0, maxcol)
    from urwid.util import apply_target_encoding
    (encoded_line, line_cs) = apply_target_encoding(line)

    def get_byte_line_attr(line, line_attr):
        i = 0
        for (label, column_count) in line_attr:
            byte_count = len(encode_like_urwid(line[i:i + column_count]))
            i += column_count
            yield (label, byte_count)
    line_attr = list(get_byte_line_attr(line, line_attr))
    processed_txt.append(encoded_line)
    processed_attr.append(line_attr)
    processed_cs.append(line_cs)

",1,"[['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_multiple'], ['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_boundary'], ['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_wide_chars'], ['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_byte_boundary'], ['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_simple']]"
pudb,https://github.com/inducer/pudb/tree/master/pudb/ui_tools.py,,test_simple,"for (label, column_count) in line_attr:
    byte_count = len(encode_like_urwid(line[i:i + column_count]))
    i += column_count
    yield (label, byte_count)","for e_target in line_attr:
    column_count = e_target[1]
    label = e_target[0]
    byte_count = len(encode_like_urwid(line[i:i + column_count]))
    i += column_count
    yield (label, byte_count)

",1,"[['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_multiple'], ['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_boundary'], ['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_wide_chars'], ['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_byte_boundary'], ['https://github.com/inducer/pudb/tree/master/test/test_make_canvas.py', 'test.test_make_canvas', '', 'test_simple']]"
PySceneDetect,https://github.com/Breakthrough/PySceneDetect/tree/master/scenedetect/stats_manager.py,,test_load_empty_stats,"for (i, metric_str) in enumerate(row[2:]):
    if metric_str and metric_str != 'None':
        try:
            metric_dict[self._loaded_metrics[i]] = float(metric_str)
        except ValueError:
            raise StatsFileCorrupt('Corrupted value in stats file: %s' % metric_str)","for e_target in enumerate(row[2:]):
    metric_str = e_target[1]
    i = e_target[0]
    if metric_str and metric_str != 'None':
        try:
            metric_dict[self._loaded_metrics[i]] = float(metric_str)
        except ValueError:
            raise StatsFileCorrupt('Corrupted value in stats file: %s' % metric_str)

",1,"[['https://github.com/Breakthrough/PySceneDetect/tree/master/tests/test_stats_manager.py', 'tests.test_stats_manager', '', 'test_load_corrupt_stats'], ['https://github.com/Breakthrough/PySceneDetect/tree/master/tests/test_stats_manager.py', 'tests.test_stats_manager', '', 'test_load_hardcoded_file'], ['https://github.com/Breakthrough/PySceneDetect/tree/master/tests/test_stats_manager.py', 'tests.test_stats_manager', '', 'test_load_hardcoded_file_backwards_compat'], ['https://github.com/Breakthrough/PySceneDetect/tree/master/tests/test_stats_manager.py', 'tests.test_stats_manager', '', 'test_load_empty_stats']]"
filterpy,https://github.com/rlabbe/filterpy/tree/master/filterpy/common/kinematic.py,,test_kinematic,"for (i, x) in enumerate(F.ravel()):
    f = np.eye(dim) * x
    (ix, iy) = (i // dim_x * dim, i % dim_x * dim)
    kf.F[ix:ix + dim, iy:iy + dim] = f","for e_target in enumerate(F.ravel()):
    x = e_target[1]
    i = e_target[0]
    f = np.eye(dim) * x
    (ix, iy) = (i // dim_x * dim, i % dim_x * dim)
    kf.F[ix:ix + dim, iy:iy + dim] = f

",1,"[['https://github.com/rlabbe/filterpy/tree/master/filterpy/common/tests/test_helpers.py', 'filterpy.common.tests.test_helpers', '', 'test_kinematic_filter'], ['https://github.com/rlabbe/filterpy/tree/master/filterpy/common/tests/test_helpers.py', 'filterpy.common.tests.test_helpers', '', 'test_saver_kf'], ['https://github.com/rlabbe/filterpy/tree/master/filterpy/common/tests/test_discretization.py', 'filterpy.common.tests.test_discretization', '', 'test_kinematic']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/tests/optional_attrs.py,,test_optional_attrs,"for (rec, exp_revs) in sorted(rec2revs.items(), key=lambda t: t[0].namespace):
    if prt is not None:
        prt.write('    {SPC} {GO}\n'.format(SPC=spc, GO=str(rec)))
    assert rec.relationship_rev[reltype] == exp_revs
    for related_from in rec.relationship_rev[reltype]:
        if prt is not None:
            prt.write('rev {RELTYPE} {GO}\n'.format(RELTYPE=reltype, GO=str(related_from)))
    if prt is not None:
        prt.write('\n')","for e_target in sorted(rec2revs.items(), key=lambda t: t[0].namespace):
    exp_revs = e_target[1]
    rec = e_target[0]
    if prt is not None:
        prt.write('    {SPC} {GO}\n'.format(SPC=spc, GO=str(rec)))
    assert rec.relationship_rev[reltype] == exp_revs
    for related_from in rec.relationship_rev[reltype]:
        if prt is not None:
            prt.write('rev {RELTYPE} {GO}\n'.format(RELTYPE=reltype, GO=str(related_from)))
    if prt is not None:
        prt.write('\n')

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_optional_relationship.py', 'tests.test_optional_relationship', '', 'test_optional_attrs']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/associations.py,,test_update_association,"for (gene, goids_cur) in assc_orig.items():
    assc[gene] = goids_cur.intersection(goids_dag)","for e_target in assc_orig.items():
    goids_cur = e_target[1]
    gene = e_target[0]
    assc[gene] = goids_cur.intersection(goids_dag)

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_semantic_similarity.py', 'tests.test_semantic_similarity', '', 'test_semantic_similarity'], ['https://github.com/tanghaibao/goatools/tree/master/tests/test_semantic_similarity_best4lex.py', 'tests.test_semantic_similarity_best4lex', '', 'test_semantic_similarity'], ['https://github.com/tanghaibao/goatools/tree/master/tests/test_update_association_compare.py', 'tests.test_update_association_compare', '', 'test_update_association']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/evidence_codes.py,,test_evcode_picker,"for (grp, c2nt) in self.grp2code2nt.items():
    prt.write('    {GRP:19}: {CODES}\n'.format(GRP=grp, CODES=' '.join(c2nt.keys())))","for e_target in self.grp2code2nt.items():
    c2nt = e_target[1]
    grp = e_target[0]
    prt.write('    {GRP:19}: {CODES}\n'.format(GRP=grp, CODES=' '.join(c2nt.keys())))

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_evcode_picker.py', 'tests.test_evcode_picker', '', 'test_evcode_picker']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/test_data/checks.py,,test_get_lowerselect,"for (goid, exp_goids) in exp_a2bset.items():
    act_goids = act_a2bset[goid]
    if act_goids != exp_goids:
        self._err(goid, exp_goids, act_goids)","for e_target in exp_a2bset.items():
    exp_goids = e_target[1]
    goid = e_target[0]
    act_goids = act_a2bset[goid]
    if act_goids != exp_goids:
        self._err(goid, exp_goids, act_goids)

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_get_upper_select.py', 'tests.test_get_upper_select', '', 'test_get_upperselect'], ['https://github.com/tanghaibao/goatools/tree/master/tests/test_get_lower_select.py', 'tests.test_get_lower_select', '', 'test_get_lowerselect']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/gosubdag/plot/plot.py,,test_example,"for (ns_name, ns_res) in ns2goea_results.items():
    fout = fout_img.format(NS=ns_name)
    plt_goea_results(fout, ns_res, **kws)","for e_target in ns2goea_results.items():
    ns_res = e_target[1]
    ns_name = e_target[0]
    fout = fout_img.format(NS=ns_name)
    plt_goea_results(fout, ns_res, **kws)

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_plot_objgoearesults.py', 'tests.test_plot_objgoearesults', '', 'test_example'], ['https://github.com/tanghaibao/goatools/tree/master/tests/test_plot_goids.py', 'tests.test_plot_goids', '', 'test_example']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/anno/update_association.py,,test_remove_assc_goids,"for (geneid, goid_set) in assoc.items():
    rm_gos = goid_set.intersection(broad_goids)
    if rm_gos:
        actuall_removed_goids.update(rm_gos)
        reduced_goids = goid_set.difference(rm_gos)
        if reduced_goids:
            assc_rm[geneid] = reduced_goids
        else:
            actuall_removed_genes.add(geneid)
    else:
        assc_rm[geneid] = goid_set","for e_target in assoc.items():
    goid_set = e_target[1]
    geneid = e_target[0]
    rm_gos = goid_set.intersection(broad_goids)
    if rm_gos:
        actuall_removed_goids.update(rm_gos)
        reduced_goids = goid_set.difference(rm_gos)
        if reduced_goids:
            assc_rm[geneid] = reduced_goids
        else:
            actuall_removed_genes.add(geneid)
    else:
        assc_rm[geneid] = goid_set

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_assc_remove_broad_goids.py', 'tests.test_assc_remove_broad_goids', '', 'test_remove_assc_goids']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/semsim/termwise/wang.py,,test_nb_ss_wang,"for (rel, weight) in self.w_e.items():
    prt.write('        {W:.8f} {REL}\n'.format(W=weight, REL=rel))","for e_target in self.w_e.items():
    weight = e_target[1]
    rel = e_target[0]
    prt.write('        {W:.8f} {REL}\n'.format(W=weight, REL=rel))

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_nb_semantic_similarity_wang.py', 'tests.test_nb_semantic_similarity_wang', '', 'test_nb_ss_wang']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/grouper/wr_sections.py,,test_grouper_d2,"for (hdrgo, usrgos) in self.grprobj.hdrgo2usrgos.items():
    keygos = usrgos.union([hdrgo])
    fout_txt = '{BASE}.txt'.format(BASE=self.grprobj.get_fout_base(hdrgo))
    with open(fout_txt, 'w') as prt:
        prt_goids(keygos, prt=prt)
        sys.stdout.write('  {N:5,} GO IDs WROTE: {TXT}\n'.format(N=len(keygos), TXT=fout_txt))","for e_target in self.grprobj.hdrgo2usrgos.items():
    usrgos = e_target[1]
    hdrgo = e_target[0]
    keygos = usrgos.union([hdrgo])
    fout_txt = '{BASE}.txt'.format(BASE=self.grprobj.get_fout_base(hdrgo))
    with open(fout_txt, 'w') as prt:
        prt_goids(keygos, prt=prt)
        sys.stdout.write('  {N:5,} GO IDs WROTE: {TXT}\n'.format(N=len(keygos), TXT=fout_txt))

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_grprobj.py', 'tests.test_grprobj', '', 'test_grouper_d2']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/grouper/grprobj.py,,test_fnc,"for (section_name, hdrgos_all_lst) in self.hdrobj.sections:
    hdrgos_all_set = set(hdrgos_all_lst)
    hdrgos_act_set = hdrgos_all_set.intersection(hdrgos_act_all)
    if hdrgos_act_set:
        hdrgos_act_secs |= hdrgos_act_set
        hdrgos_act_lst = []
        hdrgos_act_ctr = cx.Counter()
        for hdrgo_p in hdrgos_all_lst:
            if hdrgo_p in hdrgos_act_set and hdrgos_act_ctr[hdrgo_p] == 0:
                hdrgos_act_lst.append(hdrgo_p)
            hdrgos_act_ctr[hdrgo_p] += 1
        sections_hdrgos_act.append((section_name, hdrgos_act_lst))","for e_target in self.hdrobj.sections:
    hdrgos_all_lst = e_target[1]
    section_name = e_target[0]
    hdrgos_all_set = set(hdrgos_all_lst)
    hdrgos_act_set = hdrgos_all_set.intersection(hdrgos_act_all)
    if hdrgos_act_set:
        hdrgos_act_secs |= hdrgos_act_set
        hdrgos_act_lst = []
        hdrgos_act_ctr = cx.Counter()
        for hdrgo_p in hdrgos_all_lst:
            if hdrgo_p in hdrgos_act_set and hdrgos_act_ctr[hdrgo_p] == 0:
                hdrgos_act_lst.append(hdrgo_p)
            hdrgos_act_ctr[hdrgo_p] += 1
        sections_hdrgos_act.append((section_name, hdrgos_act_lst))

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_grpr_get_sections_2d.py', 'tests.test_grpr_get_sections_2d', '', 'test_fnc']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/godag/go_tasks.py,,test_parents_ancestors,"for (goid_main, goterm) in go2obj.items():
    parents_goids = set((o.id for o in goterm.parents))
    for rel in set(goterm.relationship.keys()).intersection(relationships):
        for parent_term in goterm.relationship[rel]:
            parents_goids.add(parent_term.id)
    if parents_goids:
        go2parents[goid_main] = parents_goids","for e_target in go2obj.items():
    goterm = e_target[1]
    goid_main = e_target[0]
    parents_goids = set((o.id for o in goterm.parents))
    for rel in set(goterm.relationship.keys()).intersection(relationships):
        for parent_term in goterm.relationship[rel]:
            parents_goids.add(parent_term.id)
    if parents_goids:
        go2parents[goid_main] = parents_goids

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_parents_ancestors.py', 'tests.test_parents_ancestors', '', 'test_parents_ancestors']]"
goatools,https://github.com/tanghaibao/goatools/tree/master/goatools/godag/go_tasks.py,,test_parents_ancestors,"for (goid_main, goterm) in go2obj.items():
    children_goids = set((o.id for o in goterm.children))
    for rel in set(goterm.relationship_rev.keys()).intersection(relationships):
        for child_term in goterm.relationship_rev[rel]:
            children_goids.add(child_term.id)
    if children_goids:
        go2children[goid_main] = children_goids","for e_target in go2obj.items():
    goterm = e_target[1]
    goid_main = e_target[0]
    children_goids = set((o.id for o in goterm.children))
    for rel in set(goterm.relationship_rev.keys()).intersection(relationships):
        for child_term in goterm.relationship_rev[rel]:
            children_goids.add(child_term.id)
    if children_goids:
        go2children[goid_main] = children_goids

",1,"[['https://github.com/tanghaibao/goatools/tree/master/tests/test_parents_ancestors.py', 'tests.test_parents_ancestors', '', 'test_parents_ancestors']]"
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/test/helper.py,TestInfoExtractor,test_parse_f4m_formats,"for (index, (item_got, item_expected)) in enumerate(zip(got, expected)):
    type_got = type(item_got)
    type_expected = type(item_expected)
    self.assertEqual(type_expected, type_got, 'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (index, field, type_expected, type_got))
    expect_value(self, item_got, item_expected, field)","for e_target in enumerate(zip(got, expected)):
    item_expected = e_target[1][1]
    item_got = e_target[1][0]
    index = e_target[0]
    type_got = type(item_got)
    type_expected = type(item_expected)
    self.assertEqual(type_expected, type_got, 'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (index, field, type_expected, type_got))
    expect_value(self, item_got, item_expected, field)

",1,"[['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_m3u8_formats'], ['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_youtube_chapters.py', 'test.test_youtube_chapters', 'TestYoutubeChapters', 'test_youtube_chapters'], ['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_xspf'], ['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_mpd_formats'], ['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_f4m_formats']]"
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/youtube_dlc/utils.py,TestUtil,test_sanitize_url,"for (mistake, fixup) in COMMON_TYPOS:
    if re.match(mistake, url):
        return re.sub(mistake, fixup, url)","for e_target in COMMON_TYPOS:
    fixup = e_target[1]
    mistake = e_target[0]
    if re.match(mistake, url):
        return re.sub(mistake, fixup, url)

",1,"[['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_utils.py', 'test.test_utils', 'TestUtil', 'test_sanitize_url']]"
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/youtube_dlc/options.py,TestOptions,test_hide_login_info,"for (idx, opt) in enumerate(opts):
    if opt in PRIVATE_OPTS and idx + 1 < len(opts):
        opts[idx + 1] = 'PRIVATE'","for e_target in enumerate(opts):
    opt = e_target[1]
    idx = e_target[0]
    if opt in PRIVATE_OPTS and idx + 1 < len(opts):
        opts[idx + 1] = 'PRIVATE'

",1,"[['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_options.py', 'test.test_options', 'TestOptions', 'test_hide_login_info']]"
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/youtube_dlc/compat.py,TestUtil,test_update_url_query,"for (name, value) in pairs:
    if name in parsed_result:
        parsed_result[name].append(value)
    else:
        parsed_result[name] = [value]","for e_target in pairs:
    value = e_target[1]
    name = e_target[0]
    if name in parsed_result:
        parsed_result[name].append(value)
    else:
        parsed_result[name] = [value]

",1,"[['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_utils.py', 'test.test_utils', 'TestUtil', 'test_update_url_query']]"
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/youtube_dlc/extractor/youtube.py,TestYoutubeChapters,test_youtube_chapters,"for (next_num, (chapter_line, time_point)) in enumerate(chapter_lines, start=1):
    start_time = parse_duration(time_point)
    if start_time is None:
        continue
    if start_time > duration:
        break
    end_time = duration if next_num == len(chapter_lines) else parse_duration(chapter_lines[next_num][1])
    if end_time is None:
        continue
    if end_time > duration:
        end_time = duration
    if start_time > end_time:
        break
    chapter_title = re.sub('<a[^>]+>[^<]+</a>', '', chapter_line).strip(' \t-')
    chapter_title = re.sub('\\s+', ' ', chapter_title)
    chapters.append({'start_time': start_time, 'end_time': end_time, 'title': chapter_title})","for e_target in enumerate(chapter_lines, start=1):
    time_point = e_target[1][1]
    chapter_line = e_target[1][0]
    next_num = e_target[0]
    start_time = parse_duration(time_point)
    if start_time is None:
        continue
    if start_time > duration:
        break
    end_time = duration if next_num == len(chapter_lines) else parse_duration(chapter_lines[next_num][1])
    if end_time is None:
        continue
    if end_time > duration:
        end_time = duration
    if start_time > end_time:
        break
    chapter_title = re.sub('<a[^>]+>[^<]+</a>', '', chapter_line).strip(' \t-')
    chapter_title = re.sub('\\s+', ' ', chapter_title)
    chapters.append({'start_time': start_time, 'end_time': end_time, 'title': chapter_title})

",1,"[['https://github.com/blackjack4494/yt-dlc/tree/master/test/test_youtube_chapters.py', 'test.test_youtube_chapters', 'TestYoutubeChapters', 'test_youtube_chapters']]"
oio-sds,https://github.com/open-io/oio-sds/tree/master/oio/content/content.py,TestContentFunctions,test_ensure_better_quality,"for (current, candidate) in zip(current_chunks, candidates.keys()):
    balance += compare_chunk_quality(current.quality, candidates[candidate])","for e_target in zip(current_chunks, candidates.keys()):
    candidate = e_target[1]
    current = e_target[0]
    balance += compare_chunk_quality(current.quality, candidates[candidate])

",1,"[['https://github.com/open-io/oio-sds/tree/master/tests/unit/content/test_content_functions.py', 'tests.unit.content.test_content_functions', 'TestContentFunctions', 'test_ensure_better_quality_same'], ['https://github.com/open-io/oio-sds/tree/master/tests/unit/content/test_content_functions.py', 'tests.unit.content.test_content_functions', 'TestContentFunctions', 'test_ensure_better_quality']]"
oio-sds,https://github.com/open-io/oio-sds/tree/master/oio/common/storage_functions.py,TestUtils,test_obj_range_to_meta_chunk_range,"for (pos, meta_size) in enumerate(meta_sizes):
    if meta_size <= 0:
        continue
    if found_start:
        meta_chunk_start = 0
    elif obj_start is not None and obj_start >= offset + meta_size:
        offset += meta_size
        continue
    elif obj_start is not None and obj_start < offset + meta_size:
        meta_chunk_start = obj_start - offset
        found_start = True
    else:
        meta_chunk_start = 0
    if obj_end is not None and offset + meta_size > obj_end:
        meta_chunk_end = obj_end - offset
        found_end = True
    elif meta_size > 0:
        meta_chunk_end = meta_size - 1
    meta_chunk_ranges[pos] = (meta_chunk_start, meta_chunk_end)
    if found_end:
        break
    offset += meta_size","for e_target in enumerate(meta_sizes):
    meta_size = e_target[1]
    pos = e_target[0]
    if meta_size <= 0:
        continue
    if found_start:
        meta_chunk_start = 0
    elif obj_start is not None and obj_start >= offset + meta_size:
        offset += meta_size
        continue
    elif obj_start is not None and obj_start < offset + meta_size:
        meta_chunk_start = obj_start - offset
        found_start = True
    else:
        meta_chunk_start = 0
    if obj_end is not None and offset + meta_size > obj_end:
        meta_chunk_end = obj_end - offset
        found_end = True
    elif meta_size > 0:
        meta_chunk_end = meta_size - 1
    meta_chunk_ranges[pos] = (meta_chunk_start, meta_chunk_end)
    if found_end:
        break
    offset += meta_size

",1,"[['https://github.com/open-io/oio-sds/tree/master/tests/unit/api/test_utils.py', 'tests.unit.api.test_utils', 'TestUtils', 'test_obj_range_to_meta_chunk_range']]"
oio-sds,https://github.com/open-io/oio-sds/tree/master/oio/common/fullpath.py,FullpathTest,test_encode,"for (k, v) in locals().items():
    if not v:
        raise ValueError(""Can't encode fullpath: missing %s"" % k)","for e_target in locals().items():
    v = e_target[1]
    k = e_target[0]
    if not v:
        raise ValueError(""Can't encode fullpath: missing %s"" % k)

",1,"[['https://github.com/open-io/oio-sds/tree/master/tests/unit/common/test_fullpath.py', 'tests.unit.common.test_fullpath', 'FullpathTest', 'test_encode_with_utf8_info'], ['https://github.com/open-io/oio-sds/tree/master/tests/unit/common/test_fullpath.py', 'tests.unit.common.test_fullpath', 'FullpathTest', 'test_encode']]"
aeneas,https://github.com/readbeyond/aeneas/tree/master/aeneas/tree.py,TestTree,test_remove_dangling,"for (i, child) in enumerate(self.parent.children):
    if id(child) == id(self):
        self.parent.remove_child(i)
        self.parent = None
        break","for e_target in enumerate(self.parent.children):
    child = e_target[1]
    i = e_target[0]
    if id(child) == id(self):
        self.parent.remove_child(i)
        self.parent = None
        break

",1,"[['https://github.com/readbeyond/aeneas/tree/master/aeneas/tests/test_tree.py', 'aeneas.tests.test_tree', 'TestTree', 'test_remove'], ['https://github.com/readbeyond/aeneas/tree/master/aeneas/tests/test_tree.py', 'aeneas.tests.test_tree', 'TestTree', 'test_remove_dangling']]"
audiogrep,https://github.com/antiboredom/audiogrep/tree/master/audiogrep/audiogrep.py,,test_convert_timestamps,"for (index, line) in enumerate(lines):
    (word, start, end, conf) = line
    if word == '<s>' or word == '<sil>' or word == '</s>':
        if seg_start == -1:
            seg_start = index
            seg_end = -1
        else:
            seg_end = index
        if seg_start > -1 and seg_end > -1:
            words = lines[seg_start + 1:seg_end]
            start = float(lines[seg_start][1])
            end = float(lines[seg_end][1])
            if words:
                sentences.append({'start': start, 'end': end, 'words': words, 'file': f})
            if word == '</s>':
                seg_start = -1
            else:
                seg_start = seg_end
            seg_end = -1","for e_target in enumerate(lines):
    line = e_target[1]
    index = e_target[0]
    (word, start, end, conf) = line
    if word == '<s>' or word == '<sil>' or word == '</s>':
        if seg_start == -1:
            seg_start = index
            seg_end = -1
        else:
            seg_end = index
        if seg_start > -1 and seg_end > -1:
            words = lines[seg_start + 1:seg_end]
            start = float(lines[seg_start][1])
            end = float(lines[seg_end][1])
            if words:
                sentences.append({'start': start, 'end': end, 'words': words, 'file': f})
            if word == '</s>':
                seg_start = -1
            else:
                seg_start = seg_end
            seg_end = -1

",1,"[['https://github.com/antiboredom/audiogrep/tree/master/audiogrep/tests/test_audiogrep.py', 'audiogrep.tests.test_audiogrep', '', 'test_convert_timestamps']]"
mistune,https://github.com/lepture/mistune/tree/master/mistune/directives/toc.py,TestPluginTocAst,test_render_toc_ul,"for (k, text, level) in toc:
    item = '<a href=""#{}"">{}</a>'.format(k, text)
    if not levels:
        s += '<li>' + item
        levels.append(level)
    elif level == levels[-1]:
        s += '</li>\n<li>' + item
    elif level > levels[-1]:
        s += '\n<ul>\n<li>' + item
        levels.append(level)
    else:
        last_level = levels.pop()
        while levels:
            last_level = levels.pop()
            if level == last_level:
                s += '</li>\n</ul>\n</li>\n<li>' + item
                levels.append(level)
                break
            elif level > last_level:
                s += '</li>\n<li>' + item
                levels.append(last_level)
                levels.append(level)
                break
            else:
                s += '</li>\n</ul>\n'
        else:
            levels.append(level)
            s += '</li>\n<li>' + item","for e_target in toc:
    level = e_target[2]
    text = e_target[1]
    k = e_target[0]
    item = '<a href=""#{}"">{}</a>'.format(k, text)
    if not levels:
        s += '<li>' + item
        levels.append(level)
    elif level == levels[-1]:
        s += '</li>\n<li>' + item
    elif level > levels[-1]:
        s += '\n<ul>\n<li>' + item
        levels.append(level)
    else:
        last_level = levels.pop()
        while levels:
            last_level = levels.pop()
            if level == last_level:
                s += '</li>\n</ul>\n</li>\n<li>' + item
                levels.append(level)
                break
            elif level > last_level:
                s += '</li>\n<li>' + item
                levels.append(last_level)
                levels.append(level)
                break
            else:
                s += '</li>\n</ul>\n'
        else:
            levels.append(level)
            s += '</li>\n<li>' + item

",1,"[['https://github.com/lepture/mistune/tree/master/tests/test_toc.py', 'tests.test_toc', 'TestPluginTocAst', 'test_render_toc_ul']]"
authlib,https://github.com/lepture/authlib/tree/master/authlib/common/urls.py,OAuth2SessionTest,test_token_from_fragment,"for (k, v) in params:
    encoded.append((to_bytes(k), to_bytes(v)))","for e_target in params:
    v = e_target[1]
    k = e_target[0]
    encoded.append((to_bytes(k), to_bytes(v)))

",1,"[['https://github.com/lepture/authlib/tree/master/tests/core/test_requests_client/test_oauth2_session.py', 'tests.core.test_requests_client.test_oauth2_session', 'OAuth2SessionTest', 'test_token_from_fragment']]"
stcgal,https://github.com/grigorig/stcgal/tree/master/stcgal/ihex.py,IHEXTests,test_roundtrip,"for (start, data) in sorted(self.areas.items()):
    i = 0
    segbase = 0
    while i < len(data):
        chunk = data[i:i + self.row_bytes]
        addr = start
        newsegbase = segbase
        if self.mode == 8:
            addr = addr & 65535
        elif self.mode == 16:
            t = addr & 65535
            newsegbase = addr - t >> 4
            addr = t
            if newsegbase != segbase:
                output += self.make_line(2, 0, struct.pack('>H', newsegbase))
                segbase = newsegbase
        elif self.mode == 32:
            newsegbase = addr >> 16
            addr = addr & 65535
            if newsegbase != segbase:
                output += self.make_line(4, 0, struct.pack('>H', newsegbase))
                segbase = newsegbase
        output += self.make_line(0, addr, chunk)
        i += self.row_bytes
        start += self.row_bytes","for e_target in sorted(self.areas.items()):
    data = e_target[1]
    start = e_target[0]
    i = 0
    segbase = 0
    while i < len(data):
        chunk = data[i:i + self.row_bytes]
        addr = start
        newsegbase = segbase
        if self.mode == 8:
            addr = addr & 65535
        elif self.mode == 16:
            t = addr & 65535
            newsegbase = addr - t >> 4
            addr = t
            if newsegbase != segbase:
                output += self.make_line(2, 0, struct.pack('>H', newsegbase))
                segbase = newsegbase
        elif self.mode == 32:
            newsegbase = addr >> 16
            addr = addr & 65535
            if newsegbase != segbase:
                output += self.make_line(4, 0, struct.pack('>H', newsegbase))
                segbase = newsegbase
        output += self.make_line(0, addr, chunk)
        i += self.row_bytes
        start += self.row_bytes

",1,"[['https://github.com/grigorig/stcgal/tree/master/tests/test_ihex.py', 'tests.test_ihex', 'IHEXTests', 'test_roundtrip']]"
uncurl,https://github.com/spulec/uncurl/tree/master/uncurl/api.py,,test_parse_curl_with_escaped_newlines,"for (k, v) in sorted(kargs.items()):
    requests_kargs += '{}{}={},\n'.format(BASE_INDENT, k, str(v))","for e_target in sorted(kargs.items()):
    v = e_target[1]
    k = e_target[0]
    requests_kargs += '{}{}={},\n'.format(BASE_INDENT, k, str(v))

",1,"[['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_basic_headers'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_post'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_parse_curl_escaped_unicode_in_cookie'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_basic_get'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_parse_curl_with_request_kargs'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_parse_curl_with_binary_data'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_cookies_dollar_sign'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_cookies'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_parse_curl_with_raw_data'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_post_with_dict_data'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_colon_header'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_parse_curl_with_insecure_flag'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_parse_curl_with_another_binary_data'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_post_with_string_data'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_cookies_lowercase'], ['https://github.com/spulec/uncurl/tree/master/tests/test_api.py', 'tests.test_api', '', 'test_parse_curl_with_escaped_newlines']]"
cubes,https://github.com/DataBrewery/cubes/tree/master/cubes/namespace.py,NamespaceTestCase,test_get_namespace,"for (i, element) in enumerate(path):
    remainder = path[i + 1:]
    if element in namespace.namespaces:
        namespace = namespace.namespaces[element]
        found = True
    else:
        remainder = path[i:]
        break","for e_target in enumerate(path):
    element = e_target[1]
    i = e_target[0]
    remainder = path[i + 1:]
    if element in namespace.namespaces:
        namespace = namespace.namespaces[element]
        found = True
    else:
        remainder = path[i:]
        break

",1,"[['https://github.com/DataBrewery/cubes/tree/master/tests/test_namespace.py', 'tests.test_namespace', 'NamespaceTestCase', 'test_get_namespace_create'], ['https://github.com/DataBrewery/cubes/tree/master/tests/test_namespace.py', 'tests.test_namespace', 'NamespaceTestCase', 'test_get_namespace']]"
crossplane,https://github.com/nginxinc/crossplane/tree/master/crossplane/parser.py,,test_parse_lua_block_tricky,"for (fname, ctx) in includes:
    tokens = lex(fname)
    parsing = {'file': fname, 'status': 'ok', 'errors': [], 'parsed': []}
    try:
        parsing['parsed'] = _parse(parsing, tokens, ctx=ctx)
    except Exception as e:
        _handle_error(parsing, e)
    payload['config'].append(parsing)","for e_target in includes:
    ctx = e_target[1]
    fname = e_target[0]
    tokens = lex(fname)
    parsing = {'file': fname, 'status': 'ok', 'errors': [], 'parsed': []}
    try:
        parsing['parsed'] = _parse(parsing, tokens, ctx=ctx)
    except Exception as e:
        _handle_error(parsing, e)
    payload['config'].append(parsing)

",1,"[['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_parse_missing_semicolon'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_config_without_comments'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_includes_regular'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_includes_single'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_includes_globbed'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_includes_globbed_combined'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_ignore_directives'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_comments_between_args'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_config_with_comments'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_parse_strict'], ['https://github.com/nginxinc/crossplane/tree/master/tests/ext/test_lua.py', 'tests.ext.test_lua', '', 'test_parse_lua_block_simple'], ['https://github.com/nginxinc/crossplane/tree/master/tests/ext/test_lua.py', 'tests.ext.test_lua', '', 'test_parse_lua_block_tricky']]"
crossplane,https://github.com/nginxinc/crossplane/tree/master/crossplane/parser.py,,test_parse_lua_block_tricky,"for (token, lineno, quoted) in tokens:
    comments_in_args = []
    if token == '}' and (not quoted):
        break
    if consume:
        if token == '{' and (not quoted):
            _parse(parsing, tokens, consume=True)
        continue
    directive = token
    if combine:
        stmt = {'file': fname, 'directive': directive, 'line': lineno, 'args': []}
    else:
        stmt = {'directive': directive, 'line': lineno, 'args': []}
    if directive.startswith('#') and (not quoted):
        if comments:
            stmt['directive'] = '#'
            stmt['comment'] = token[1:]
            parsed.append(stmt)
        continue
    args = stmt['args']
    (token, __, quoted) = next(tokens)
    while token not in ('{', ';', '}') or quoted:
        if token.startswith('#') and (not quoted):
            comments_in_args.append(token[1:])
        else:
            stmt['args'].append(token)
        (token, __, quoted) = next(tokens)
    if stmt['directive'] in ignore:
        if token == '{' and (not quoted):
            _parse(parsing, tokens, consume=True)
        continue
    if stmt['directive'] == 'if':
        _prepare_if_args(stmt)
    try:
        analyze(fname=fname, stmt=stmt, term=token, ctx=ctx, strict=strict, check_ctx=check_ctx, check_args=check_args)
    except NgxParserDirectiveError as e:
        if catch_errors:
            _handle_error(parsing, e)
            if e.strerror.endswith(' is not terminated by "";""'):
                if token != '}' and (not quoted):
                    _parse(parsing, tokens, consume=True)
                else:
                    break
            continue
        else:
            raise e
    if not single and stmt['directive'] == 'include':
        pattern = args[0]
        if not os.path.isabs(args[0]):
            pattern = os.path.join(config_dir, args[0])
        stmt['includes'] = []
        if glob.has_magic(pattern):
            fnames = glob.glob(pattern)
            fnames.sort()
        else:
            try:
                open(str(pattern)).close()
                fnames = [pattern]
            except Exception as e:
                fnames = []
                e.lineno = stmt['line']
                if catch_errors:
                    _handle_error(parsing, e)
                else:
                    raise e
        for fname in fnames:
            if fname not in included:
                included[fname] = len(includes)
                includes.append((fname, ctx))
            index = included[fname]
            stmt['includes'].append(index)
    if token == '{' and (not quoted):
        inner = enter_block_ctx(stmt, ctx)
        stmt['block'] = _parse(parsing, tokens, ctx=inner)
    parsed.append(stmt)
    for comment in comments_in_args:
        comment_stmt = {'directive': '#', 'line': stmt['line'], 'args': [], 'comment': comment}
        parsed.append(comment_stmt)","for e_target in tokens:
    quoted = e_target[2]
    lineno = e_target[1]
    token = e_target[0]
    comments_in_args = []
    if token == '}' and (not quoted):
        break
    if consume:
        if token == '{' and (not quoted):
            _parse(parsing, tokens, consume=True)
        continue
    directive = token
    if combine:
        stmt = {'file': fname, 'directive': directive, 'line': lineno, 'args': []}
    else:
        stmt = {'directive': directive, 'line': lineno, 'args': []}
    if directive.startswith('#') and (not quoted):
        if comments:
            stmt['directive'] = '#'
            stmt['comment'] = token[1:]
            parsed.append(stmt)
        continue
    args = stmt['args']
    (token, __, quoted) = next(tokens)
    while token not in ('{', ';', '}') or quoted:
        if token.startswith('#') and (not quoted):
            comments_in_args.append(token[1:])
        else:
            stmt['args'].append(token)
        (token, __, quoted) = next(tokens)
    if stmt['directive'] in ignore:
        if token == '{' and (not quoted):
            _parse(parsing, tokens, consume=True)
        continue
    if stmt['directive'] == 'if':
        _prepare_if_args(stmt)
    try:
        analyze(fname=fname, stmt=stmt, term=token, ctx=ctx, strict=strict, check_ctx=check_ctx, check_args=check_args)
    except NgxParserDirectiveError as e:
        if catch_errors:
            _handle_error(parsing, e)
            if e.strerror.endswith(' is not terminated by "";""'):
                if token != '}' and (not quoted):
                    _parse(parsing, tokens, consume=True)
                else:
                    break
            continue
        else:
            raise e
    if not single and stmt['directive'] == 'include':
        pattern = args[0]
        if not os.path.isabs(args[0]):
            pattern = os.path.join(config_dir, args[0])
        stmt['includes'] = []
        if glob.has_magic(pattern):
            fnames = glob.glob(pattern)
            fnames.sort()
        else:
            try:
                open(str(pattern)).close()
                fnames = [pattern]
            except Exception as e:
                fnames = []
                e.lineno = stmt['line']
                if catch_errors:
                    _handle_error(parsing, e)
                else:
                    raise e
        for fname in fnames:
            if fname not in included:
                included[fname] = len(includes)
                includes.append((fname, ctx))
            index = included[fname]
            stmt['includes'].append(index)
    if token == '{' and (not quoted):
        inner = enter_block_ctx(stmt, ctx)
        stmt['block'] = _parse(parsing, tokens, ctx=inner)
    parsed.append(stmt)
    for comment in comments_in_args:
        comment_stmt = {'directive': '#', 'line': stmt['line'], 'args': [], 'comment': comment}
        parsed.append(comment_stmt)

",1,"[['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_parse_missing_semicolon'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_config_without_comments'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_includes_regular'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_includes_single'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_includes_globbed'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_includes_globbed_combined'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_ignore_directives'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_comments_between_args'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_config_with_comments'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_parse.py', 'tests.test_parse', '', 'test_parse_strict'], ['https://github.com/nginxinc/crossplane/tree/master/tests/ext/test_lua.py', 'tests.ext.test_lua', '', 'test_parse_lua_block_simple'], ['https://github.com/nginxinc/crossplane/tree/master/tests/ext/test_lua.py', 'tests.ext.test_lua', '', 'test_parse_lua_block_tricky']]"
crossplane,https://github.com/nginxinc/crossplane/tree/master/crossplane/lexer.py,,test_lex_lua_block_simple,"for (token, line, quoted) in it:
    yield (token, line, quoted)","for e_target in it:
    quoted = e_target[2]
    line = e_target[1]
    token = e_target[0]
    yield (token, line, quoted)

",1,"[['https://github.com/nginxinc/crossplane/tree/master/tests/test_lex.py', 'tests.test_lex', '', 'test_with_config_comments'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_lex.py', 'tests.test_lex', '', 'test_quoted_right_brace'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_lex.py', 'tests.test_lex', '', 'test_quote_behavior'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_lex.py', 'tests.test_lex', '', 'test_messy_config'], ['https://github.com/nginxinc/crossplane/tree/master/tests/ext/test_lua.py', 'tests.ext.test_lua', '', 'test_lex_lua_block_tricky'], ['https://github.com/nginxinc/crossplane/tree/master/tests/ext/test_lua.py', 'tests.ext.test_lua', '', 'test_lex_lua_block_larger'], ['https://github.com/nginxinc/crossplane/tree/master/tests/test_lex.py', 'tests.test_lex', '', 'test_simple_config'], ['https://github.com/nginxinc/crossplane/tree/master/tests/ext/test_lua.py', 'tests.ext.test_lua', '', 'test_lex_lua_block_simple']]"
ariadne,https://github.com/mirumee/ariadne/tree/master/ariadne/enums.py,,test_attempt_bind_custom_enum_to_wrong_schema_type_raises_error,"for (key, value) in self.values.items():
    if key not in graphql_type.values:
        raise ValueError('Value %s is not defined on enum %s' % (key, self.name))
    graphql_type.values[key].value = value","for e_target in self.values.items():
    value = e_target[1]
    key = e_target[0]
    if key not in graphql_type.values:
        raise ValueError('Value %s is not defined on enum %s' % (key, self.name))
    graphql_type.values[key].value = value

",1,"[['https://github.com/mirumee/ariadne/tree/master/tests/test_enums.py', 'tests.test_enums', '', 'test_attempt_bind_custom_enum_to_undefined_type_raises_error'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_enums.py', 'tests.test_enums', '', 'test_attempt_bind_custom_enum_to_schema_enum_missing_value_raises_error'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_enums.py', 'tests.test_enums', '', 'test_attempt_bind_custom_enum_to_wrong_schema_type_raises_error']]"
ariadne,https://github.com/mirumee/ariadne/tree/master/ariadne/enums.py,,test_find_enum_values_in_schema_for_undefined_and_invalid_values,"for (name, type_) in schema.type_map.items():
    result = enum_values_in_types(type_, name)
    if result is not None:
        yield from result","for e_target in schema.type_map.items():
    type_ = e_target[1]
    name = e_target[0]
    result = enum_values_in_types(type_, name)
    if result is not None:
        yield from result

",1,"[['https://github.com/mirumee/ariadne/tree/master/tests/test_enums.py', 'tests.test_enums', '', 'test_find_enum_values_in_schema_for_undefined_and_invalid_values']]"
ariadne,https://github.com/mirumee/ariadne/tree/master/ariadne/utils.py,,test_lower_case_name_is_not_changed,"for (i, c) in enumerate(lowered_name):
    if i > 0 and (c != graphql_name[i] and graphql_name[i - 1] != '_' and (graphql_name[i - 1] == python_name[-1]) or (i < max_index and graphql_name[i] != lowered_name[i] and (graphql_name[i + 1] == lowered_name[i + 1])) or (c.isdigit() and (not graphql_name[i - 1].isdigit())) or (not c.isdigit() and graphql_name[i - 1].isdigit())):
        python_name += '_'
    python_name += c","for e_target in enumerate(lowered_name):
    c = e_target[1]
    i = e_target[0]
    if i > 0 and (c != graphql_name[i] and graphql_name[i - 1] != '_' and (graphql_name[i - 1] == python_name[-1]) or (i < max_index and graphql_name[i] != lowered_name[i] and (graphql_name[i + 1] == lowered_name[i + 1])) or (c.isdigit() and (not graphql_name[i - 1].isdigit())) or (not c.isdigit() and graphql_name[i - 1].isdigit())):
        python_name += '_'
    python_name += c

",1,"[['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_three_words_pascal_case_name_is_converted'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_two_words_camel_case_name_is_converted'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_two_words_snake_case_name_is_not_changed'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_two_words_pascal_case_name_is_converted'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_no_underscore_added_if_previous_character_is_uppercase'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_three_words_snake_case_name_is_not_changed'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_pascal_case_name_is_lowercased'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_no_underscore_added_if_previous_character_is_an_underscore'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_three_words_camel_case_name_is_converted'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_camel_case_to_snake_case_convertion.py', 'tests.test_camel_case_to_snake_case_convertion', '', 'test_lower_case_name_is_not_changed']]"
ariadne,https://github.com/mirumee/ariadne/tree/master/ariadne/file_uploads.py,,test_files_are_set_in_list_of_inputs_variable,"for (i, operation) in enumerate(operations):
    add_files_to_variables(operation.get('variables'), '{}.variables'.format(i), files_map)","for e_target in enumerate(operations):
    operation = e_target[1]
    i = e_target[0]
    add_files_to_variables(operation.get('variables'), '{}.variables'.format(i), files_map)

",1,"[['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_file_is_set_in_one_operation_variable'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_setting_file_value_in_variables_leaves_other_variables_unchanged'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_file_is_set_in_variable'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_error_is_raised_if_operations_value_is_not_a_list_or_dict'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_files_are_set_in_input_list_variable'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_error_is_raised_if_file_paths_list_item_is_not_a_str'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_files_are_set_in_multiple_variables'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_error_is_raised_if_file_paths_value_is_not_a_list'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_files_are_set_in_list_variable'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_error_is_raised_if_file_described_in_map_is_not_found'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_error_is_raised_if_map_value_is_not_a_list_or_dict'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_single_file_is_set_in_multiple_variables'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_file_is_set_in_list_variable'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_file_is_set_in_input_variable'], ['https://github.com/mirumee/ariadne/tree/master/tests/test_file_uploads.py', 'tests.test_file_uploads', '', 'test_files_are_set_in_list_of_inputs_variable']]"
mitmproxy,https://github.com/mitmproxy/mitmproxy/tree/master/mitmproxy/utils/human.py,,test_pretty_duration,"for (limit, formatter) in formatters:
    if secs >= limit:
        return formatter.format(secs)","for e_target in formatters:
    formatter = e_target[1]
    limit = e_target[0]
    if secs >= limit:
        return formatter.format(secs)

",1,"[['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_human.py', 'test.mitmproxy.utils.test_human', '', 'test_pretty_duration']]"
mitmproxy,https://github.com/mitmproxy/mitmproxy/tree/master/mitmproxy/utils/debug.py,,test_dump_stacks,"for (threadId, stack) in sys._current_frames().items():
    code.append('\n# Thread: %s(%d)' % (id2name.get(threadId, ''), threadId))
    for (filename, lineno, name, line) in traceback.extract_stack(stack):
        code.append('File: ""%s"", line %d, in %s' % (filename, lineno, name))
        if line:
            code.append('  %s' % line.strip())","for e_target in sys._current_frames().items():
    stack = e_target[1]
    threadId = e_target[0]
    code.append('\n# Thread: %s(%d)' % (id2name.get(threadId, ''), threadId))
    for (filename, lineno, name, line) in traceback.extract_stack(stack):
        code.append('File: ""%s"", line %d, in %s' % (filename, lineno, name))
        if line:
            code.append('  %s' % line.strip())

",1,"[['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_debug.py', 'test.mitmproxy.utils.test_debug', '', 'test_dump_stacks']]"
mitmproxy,https://github.com/mitmproxy/mitmproxy/tree/master/mitmproxy/utils/debug.py,,test_dump_stacks,"for (filename, lineno, name, line) in traceback.extract_stack(stack):
    code.append('File: ""%s"", line %d, in %s' % (filename, lineno, name))
    if line:
        code.append('  %s' % line.strip())","for e_target in traceback.extract_stack(stack):
    line = e_target[3]
    name = e_target[2]
    lineno = e_target[1]
    filename = e_target[0]
    code.append('File: ""%s"", line %d, in %s' % (filename, lineno, name))
    if line:
        code.append('  %s' % line.strip())

",1,"[['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_debug.py', 'test.mitmproxy.utils.test_debug', '', 'test_dump_stacks']]"
mitmproxy,https://github.com/mitmproxy/mitmproxy/tree/master/mitmproxy/utils/strutils.py,,test_escape_special_areas,"for (i, x) in enumerate(parts):
    if i % 2:
        x = rex.sub(_move_to_private_code_plane, x)
    buf.write(x)","for e_target in enumerate(parts):
    x = e_target[1]
    i = e_target[0]
    if i % 2:
        x = rex.sub(_move_to_private_code_plane, x)
    buf.write(x)

",1,"[['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_strutils.py', 'test.mitmproxy.utils.test_strutils', '', 'test_escape_special_areas']]"
mitmproxy,https://github.com/mitmproxy/mitmproxy/tree/master/mitmproxy/utils/typecheck.py,,test_check_tuple,"for (i, (x, T)) in enumerate(zip(value, types)):
    check_option_type(f'{name}[{i}]', x, T)","for e_target in enumerate(zip(value, types)):
    T = e_target[1][1]
    x = e_target[1][0]
    i = e_target[0]
    check_option_type(f'{name}[{i}]', x, T)

",1,"[['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_typecheck.py', 'test.mitmproxy.utils.test_typecheck', '', 'test_check_any'], ['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_typecheck.py', 'test.mitmproxy.utils.test_typecheck', '', 'test_check_option_type'], ['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_typecheck.py', 'test.mitmproxy.utils.test_typecheck', '', 'test_check_union'], ['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_typecheck.py', 'test.mitmproxy.utils.test_typecheck', '', 'test_check_sequence'], ['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_typecheck.py', 'test.mitmproxy.utils.test_typecheck', '', 'test_check_io'], ['https://github.com/mitmproxy/mitmproxy/tree/master/test/mitmproxy/utils/test_typecheck.py', 'test.mitmproxy.utils.test_typecheck', '', 'test_check_tuple']]"
xmltodict,https://github.com/martinblech/xmltodict/tree/master//xmltodict.py,DictToXMLTestCase,test_nested,"for (key, value) in input_dict.items():
    _emit(key, value, content_handler, full_document=full_document, **kwargs)","for e_target in input_dict.items():
    value = e_target[1]
    key = e_target[0]
    _emit(key, value, content_handler, full_document=full_document, **kwargs)

",1,"[['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_pretty_print'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_short_empty_elements'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_boolean_unparse'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_no_root_nofulldoc'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_fulldoc'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_root'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_preprocessor_skipkey'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_namespace_support'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_preprocessor'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_encoding'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_simple_cdata'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_multiple_roots_nofulldoc'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_list_expand_iter'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_cdata'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_non_string_value'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_attrib_and_cdata'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_list'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_attrib'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_non_string_attr'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_generator'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_semistructured'], ['https://github.com/martinblech/xmltodict/tree/master/tests/test_dicttoxml.py', 'tests.test_dicttoxml', 'DictToXMLTestCase', 'test_nested']]"
more-itertools,https://github.com/more-itertools/more-itertools/tree/master/more_itertools/recipes.py,TriplewiseTests,test_basic,"for ((a, _), (b, c)) in pairwise(pairwise(iterable)):
    yield (a, b, c)","for e_target in pairwise(pairwise(iterable)):
    c = e_target[1][1]
    b = e_target[1][0]
    _ = e_target[0][1]
    a = e_target[0][0]
    yield (a, b, c)

",1,"[['https://github.com/more-itertools/more-itertools/tree/master/tests/test_recipes.py', 'tests.test_recipes', 'TriplewiseTests', 'test_basic']]"
more-itertools,https://github.com/more-itertools/more-itertools/tree/master/more_itertools/more.py,InterleaveEvenlyTests,test_equal_lengths,"for (i, e) in enumerate(errors):
    if e < 0:
        yield next(iters_secondary[i])
        to_yield -= 1
        errors[i] += delta_primary","for e_target in enumerate(errors):
    e = e_target[1]
    i = e_target[0]
    if e < 0:
        yield next(iters_secondary[i])
        to_yield -= 1
        errors[i] += delta_primary

",1,"[['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_many_iters'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_no_length_raises'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_degenerate_empty'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_proportional'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_not_proportional'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_three_iters'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_degenerate_one'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_argument_mismatch_raises'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_manual_lengths'], ['https://github.com/more-itertools/more-itertools/tree/master/tests/test_more.py', 'tests.test_more', 'InterleaveEvenlyTests', 'test_equal_lengths']]"
budoux,https://github.com/google/budoux/tree/master/scripts/train.py,TestTrain,test_preprocess,"for (i, entry) in enumerate(entries):
    Y[i] = entry[0] == '1'
    for col in entry[1:]:
        if col in feature_index:
            X[i, feature_index[col]] = True
    X[i, -1] = True","for e_target in enumerate(entries):
    entry = e_target[1]
    i = e_target[0]
    Y[i] = entry[0] == '1'
    for col in entry[1:]:
        if col in feature_index:
            X[i, feature_index[col]] = True
    X[i, -1] = True

",1,"[['https://github.com/google/budoux/tree/master/tests/test_train.py', 'tests.test_train', 'TestTrain', 'test_preprocess']]"
milk,https://github.com/luispedro/milk/tree/master/milk/measures/curves.py,,test_precision_recall,"for (i, p) in enumerate(points):
    selected = values >= p
    selected = labels[selected]
    precision_recall[i] = (np.mean(selected), np.sum(selected) / true_pos)","for e_target in enumerate(points):
    p = e_target[1]
    i = e_target[0]
    selected = values >= p
    selected = labels[selected]
    precision_recall[i] = (np.mean(selected), np.sum(selected) / true_pos)

",1,"[['https://github.com/luispedro/milk/tree/master/milk/tests/test_curves.py', 'milk.tests.test_curves', '', 'test_precision_recall']]"
milk,https://github.com/luispedro/milk/tree/master/milk/measures/curves.py,,test_roc,"for (i, p) in enumerate(reversed(points)):
    selected = labels[values >= p]
    roc[i] = (np.sum(~selected) / N, np.sum(selected) / P)","for e_target in enumerate(reversed(points)):
    p = e_target[1]
    i = e_target[0]
    selected = labels[values >= p]
    roc[i] = (np.sum(~selected) / N, np.sum(selected) / P)

",1,"[['https://github.com/luispedro/milk/tree/master/milk/tests/test_measures.py', 'milk.tests.test_measures', '', 'test_roc']]"
astor,https://github.com/berkerpeksag/astor/tree/master/tests/support.py,PublicAPITestCase,test_codegen_from_root,"for (orig_name, module) in orig_modules.items():
    sys.modules[orig_name] = module","for e_target in orig_modules.items():
    module = e_target[1]
    orig_name = e_target[0]
    sys.modules[orig_name] = module

",1,"[['https://github.com/berkerpeksag/astor/tree/master/tests/test_misc.py', 'tests.test_misc', 'PublicAPITestCase', 'test_codegen_from_root']]"
apprise,https://github.com/caronc/apprise/tree/master/apprise/Apprise.py,,test_apprise_config_with_apprise_obj,"for (idx, s) in enumerate(self.servers):
    if isinstance(s, (ConfigBase, AppriseConfig)):
        servers = s.servers()
        if len(servers) > 0:
            offset = prev_offset + len(servers)
            if offset >= index:
                fn = s.pop if isinstance(s, ConfigBase) else s.server_pop
                return fn(index if prev_offset == -1 else index - prev_offset - 1)
    else:
        offset = prev_offset + 1
        if offset == index:
            return self.servers.pop(idx)
    prev_offset = offset","for e_target in enumerate(self.servers):
    s = e_target[1]
    idx = e_target[0]
    if isinstance(s, (ConfigBase, AppriseConfig)):
        servers = s.servers()
        if len(servers) > 0:
            offset = prev_offset + len(servers)
            if offset >= index:
                fn = s.pop if isinstance(s, ConfigBase) else s.server_pop
                return fn(index if prev_offset == -1 else index - prev_offset - 1)
    else:
        offset = prev_offset + 1
        if offset == index:
            return self.servers.pop(idx)
    prev_offset = offset

",1,"[['https://github.com/caronc/apprise/tree/master/test/test_apprise_config.py', 'test.test_apprise_config', '', 'test_apprise_config_with_apprise_obj']]"
apprise,https://github.com/caronc/apprise/tree/master/apprise/plugins/NotifySNS.py,,test_plugin_sns_url_parsing,"for (i, entry) in enumerate(entries):
    result = IS_REGION.match(entry)
    if result:
        secret_access_key = '/'.join(secret_access_key_parts)
        region_name = '{country}-{area}-{no}'.format(country=result.group('country').lower(), area=result.group('area').lower(), no=result.group('no'))
        index = i + 1
        break
    secret_access_key_parts.append(entry)","for e_target in enumerate(entries):
    entry = e_target[1]
    i = e_target[0]
    result = IS_REGION.match(entry)
    if result:
        secret_access_key = '/'.join(secret_access_key_parts)
        region_name = '{country}-{area}-{no}'.format(country=result.group('country').lower(), area=result.group('area').lower(), no=result.group('no'))
        index = i + 1
        break
    secret_access_key_parts.append(entry)

",1,"[['https://github.com/caronc/apprise/tree/master/test/test_plugin_sns.py', 'test.test_plugin_sns', '', 'test_plugin_sns_url_parsing']]"
apprise,https://github.com/caronc/apprise/tree/master/apprise/config/ConfigBase.py,,test_config_base_detect_config_format,"for (line, entry) in enumerate(content, start=1):
    result = valid_line_re.match(entry)
    if not result:
        ConfigBase.logger.error('Undetectable Apprise configuration found based on line {}.'.format(line))
        return None
    if result.group('yaml'):
        config_format = ConfigFormat.YAML
        ConfigBase.logger.debug('Detected YAML configuration based on line {}.'.format(line))
        break
    elif result.group('text'):
        config_format = ConfigFormat.TEXT
        ConfigBase.logger.debug('Detected TEXT configuration based on line {}.'.format(line))
        break
    config_format = ConfigFormat.TEXT","for e_target in enumerate(content, start=1):
    entry = e_target[1]
    line = e_target[0]
    result = valid_line_re.match(entry)
    if not result:
        ConfigBase.logger.error('Undetectable Apprise configuration found based on line {}.'.format(line))
        return None
    if result.group('yaml'):
        config_format = ConfigFormat.YAML
        ConfigBase.logger.debug('Detected YAML configuration based on line {}.'.format(line))
        break
    elif result.group('text'):
        config_format = ConfigFormat.TEXT
        ConfigBase.logger.debug('Detected TEXT configuration based on line {}.'.format(line))
        break
    config_format = ConfigFormat.TEXT

",1,"[['https://github.com/caronc/apprise/tree/master/test/test_config_base.py', 'test.test_config_base', '', 'test_config_base_detect_config_format']]"
deepdiff,https://github.com/seperman/deepdiff/tree/master/deepdiff/serialization.py,TestLoadContet,test_load_path_content_when_unsupported_format,"for (key, value) in row.items():
    value = value.strip()
    for type_ in [int, float, complex]:
        try:
            value = type_(value)
        except Exception:
            pass
        else:
            row[key] = value
            break","for e_target in row.items():
    value = e_target[1]
    key = e_target[0]
    value = value.strip()
    for type_ in [int, float, complex]:
        try:
            value = type_(value)
        except Exception:
            pass
        else:
            row[key] = value
            break

",1,"[['https://github.com/seperman/deepdiff/tree/master/tests/test_serialization.py', 'tests.test_serialization', 'TestLoadContet', 'test_load_path_content_when_unsupported_format']]"
deepdiff,https://github.com/seperman/deepdiff/tree/master/deepdiff/distance.py,TestDeepDistance,test_distance_of_list_sets,"for (key, subitem) in item.items():
    if key in {'iterable_items_added_at_indexes', 'iterable_items_removed_at_indexes'}:
        new_subitem = dict_()
        for (path_, indexes_to_items) in subitem.items():
            used_value_ids = set()
            new_indexes_to_items = dict_()
            for (k, v) in indexes_to_items.items():
                v_id = id(v)
                if v_id not in used_value_ids:
                    used_value_ids.add(v_id)
                    new_indexes_to_items[k] = v
            new_subitem[path_] = new_indexes_to_items
        subitem = new_subitem
    if isinstance(key, strings) and (key.startswith('_') or key == 'deep_distance'):
        continue
    item_id = id(subitem)
    if parents_ids and item_id in parents_ids:
        continue
    parents_ids_added = add_to_frozen_set(parents_ids, item_id)
    length += _get_item_length(subitem, parents_ids_added)","for e_target in item.items():
    subitem = e_target[1]
    key = e_target[0]
    if key in {'iterable_items_added_at_indexes', 'iterable_items_removed_at_indexes'}:
        new_subitem = dict_()
        for (path_, indexes_to_items) in subitem.items():
            used_value_ids = set()
            new_indexes_to_items = dict_()
            for (k, v) in indexes_to_items.items():
                v_id = id(v)
                if v_id not in used_value_ids:
                    used_value_ids.add(v_id)
                    new_indexes_to_items[k] = v
            new_subitem[path_] = new_indexes_to_items
        subitem = new_subitem
    if isinstance(key, strings) and (key.startswith('_') or key == 'deep_distance'):
        continue
    item_id = id(subitem)
    if parents_ids and item_id in parents_ids:
        continue
    parents_ids_added = add_to_frozen_set(parents_ids, item_id)
    length += _get_item_length(subitem, parents_ids_added)

",1,"[['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_when_loops1'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_when_loops2'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_distance_of_the_same_objects'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_custom_class2_loop'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_custom_class1'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_distance_of_list_sets']]"
deepdiff,https://github.com/seperman/deepdiff/tree/master/deepdiff/distance.py,TestDeepDistance,test_distance_of_list_sets,"for (path_, indexes_to_items) in subitem.items():
    used_value_ids = set()
    new_indexes_to_items = dict_()
    for (k, v) in indexes_to_items.items():
        v_id = id(v)
        if v_id not in used_value_ids:
            used_value_ids.add(v_id)
            new_indexes_to_items[k] = v
    new_subitem[path_] = new_indexes_to_items","for e_target in subitem.items():
    indexes_to_items = e_target[1]
    path_ = e_target[0]
    used_value_ids = set()
    new_indexes_to_items = dict_()
    for (k, v) in indexes_to_items.items():
        v_id = id(v)
        if v_id not in used_value_ids:
            used_value_ids.add(v_id)
            new_indexes_to_items[k] = v
    new_subitem[path_] = new_indexes_to_items

",1,"[['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_when_loops1'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_when_loops2'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_distance_of_the_same_objects'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_custom_class2_loop'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_custom_class1'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_distance_of_list_sets']]"
deepdiff,https://github.com/seperman/deepdiff/tree/master/deepdiff/distance.py,TestDeepDistance,test_distance_of_list_sets,"for (k, v) in indexes_to_items.items():
    v_id = id(v)
    if v_id not in used_value_ids:
        used_value_ids.add(v_id)
        new_indexes_to_items[k] = v","for e_target in indexes_to_items.items():
    v = e_target[1]
    k = e_target[0]
    v_id = id(v)
    if v_id not in used_value_ids:
        used_value_ids.add(v_id)
        new_indexes_to_items[k] = v

",1,"[['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_when_loops1'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_when_loops2'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_distance_of_the_same_objects'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_custom_class2_loop'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_get_item_length_custom_class1'], ['https://github.com/seperman/deepdiff/tree/master/tests/test_distance.py', 'tests.test_distance', 'TestDeepDistance', 'test_distance_of_list_sets']]"
deepdiff,https://github.com/seperman/deepdiff/tree/master/deepdiff/helper.py,TestHelper,test_cartesian_product_numpy,"for (i, a) in enumerate(arrays):
    arr[i, ...] = a[idx[:la - i]]","for e_target in enumerate(arrays):
    a = e_target[1]
    i = e_target[0]
    arr[i, ...] = a[idx[:la - i]]

",1,"[['https://github.com/seperman/deepdiff/tree/master/tests/test_helper.py', 'tests.test_helper', 'TestHelper', 'test_cartesian_product_numpy']]"
python-qrcode,https://github.com/lincolnloop/python-qrcode/tree/master/qrcode/release.py,UpdateManpageTests,test_no_change,"for (i, line) in enumerate(lines):
    if not line.startswith('.TH '):
        continue
    parts = re.split('""([^""]*)""', line)
    if len(parts) < 5:
        continue
    changed = parts[3] != data['new_version']
    if changed:
        parts[3] = data['new_version']
        parts[1] = datetime.datetime.now().strftime('%-d %b %Y')
        lines[i] = '""'.join(parts)
    break","for e_target in enumerate(lines):
    line = e_target[1]
    i = e_target[0]
    if not line.startswith('.TH '):
        continue
    parts = re.split('""([^""]*)""', line)
    if len(parts) < 5:
        continue
    changed = parts[3] != data['new_version']
    if changed:
        parts[3] = data['new_version']
        parts[1] = datetime.datetime.now().strftime('%-d %b %Y')
        lines[i] = '""'.join(parts)
    break

",1,"[['https://github.com/lincolnloop/python-qrcode/tree/master/qrcode/tests/test_release.py', 'qrcode.tests.test_release', 'UpdateManpageTests', 'test_invalid_data'], ['https://github.com/lincolnloop/python-qrcode/tree/master/qrcode/tests/test_release.py', 'qrcode.tests.test_release', 'UpdateManpageTests', 'test_not_qrcode'], ['https://github.com/lincolnloop/python-qrcode/tree/master/qrcode/tests/test_release.py', 'qrcode.tests.test_release', 'UpdateManpageTests', 'test_change'], ['https://github.com/lincolnloop/python-qrcode/tree/master/qrcode/tests/test_release.py', 'qrcode.tests.test_release', 'UpdateManpageTests', 'test_no_change']]"
stomp.py,https://github.com/jasonrbriggs/stomp.py/tree/master/stomp/utils.py,TestUtils,test_convert_frame,"for (key, vals) in sorted(frame.headers.items()):
    if vals is None:
        continue
    if type(vals) != tuple:
        vals = (vals,)
    for val in vals:
        lines.append(encode('%s:%s\n' % (key, val)))","for e_target in sorted(frame.headers.items()):
    vals = e_target[1]
    key = e_target[0]
    if vals is None:
        continue
    if type(vals) != tuple:
        vals = (vals,)
    for val in vals:
        lines.append(encode('%s:%s\n' % (key, val)))

",1,"[['https://github.com/jasonrbriggs/stomp.py/tree/master/tests/test_utils.py', 'tests.test_utils', 'TestUtils', 'test_convert_frame']]"
firebase-admin-python,https://github.com/firebase/firebase-admin-python/tree/master/tests/testutils.py,TestFirestore,test_no_project_id,"for (idx, env_var) in enumerate(env_vars):
    gcloud_project = env_values[idx]
    if gcloud_project:
        os.environ[env_var] = gcloud_project","for e_target in enumerate(env_vars):
    env_var = e_target[1]
    idx = e_target[0]
    gcloud_project = env_values[idx]
    if gcloud_project:
        os.environ[env_var] = gcloud_project

",1,"[['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_messaging.py', 'tests.test_messaging', 'TestSend', 'test_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_messaging.py', 'tests.test_messaging', 'TestSendMulticast', 'test_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_project_management.py', 'tests.test_project_management', 'TestIOSApp', 'test_raises_if_app_has_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_ml.py', 'tests.test_ml', 'TestListModels', 'test_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_project_management.py', 'tests.test_project_management', 'TestAndroidApp', 'test_raises_if_app_has_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_ml.py', 'tests.test_ml', 'TestGetModel', 'test_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_ml.py', 'tests.test_ml', 'TestDeleteModel', 'test_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_app.py', 'tests.test_app', 'TestFirebaseApp', 'test_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_instance_id.py', 'tests.test_instance_id', 'TestDeleteInstanceId', 'test_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_messaging.py', 'tests.test_messaging', 'TestSendAll', 'test_no_project_id'], ['https://github.com/firebase/firebase-admin-python/tree/master/tests/test_firestore.py', 'tests.test_firestore', 'TestFirestore', 'test_no_project_id']]"
gaft,https://github.com/PytLab/gaft/tree/master/gaft/operators/crossover/uniform_crossover.py,UniformCrossoverTest,test_cross,"for (i, (g1, g2)) in enumerate(zip(chrom1, chrom2)):
    do_exchange = True if random() < self.pe else False
    if do_exchange:
        (chrom1[i], chrom2[i]) = (g2, g1)","for e_target in enumerate(zip(chrom1, chrom2)):
    g2 = e_target[1][1]
    g1 = e_target[1][0]
    i = e_target[0]
    do_exchange = True if random() < self.pe else False
    if do_exchange:
        (chrom1[i], chrom2[i]) = (g2, g1)

",1,"[['https://github.com/PytLab/gaft/tree/master/gaft/tests/uniform_crossover_test.py', 'gaft.tests.uniform_crossover_test', 'UniformCrossoverTest', 'test_cross']]"
gaft,https://github.com/PytLab/gaft/tree/master/gaft/operators/mutation/flip_bit_mutation.py,FlipBitMutationTest,test_mutate_decimal_indv,"for (i, genome) in enumerate(individual.chromsome):
    no_flip = True if random() > self.pm else False
    if no_flip:
        continue
    if type(individual) is BinaryIndividual:
        individual.chromsome[i] = genome ^ 1
    elif type(individual) is DecimalIndividual:
        (a, b) = individual.ranges[i]
        eps = individual.precisions[i]
        n_intervals = (b - a) // eps
        n = int(uniform(0, n_intervals + 1))
        individual.chromsome[i] = a + n * eps
    else:
        raise TypeError('Wrong individual type: {}'.format(type(individual)))","for e_target in enumerate(individual.chromsome):
    genome = e_target[1]
    i = e_target[0]
    no_flip = True if random() > self.pm else False
    if no_flip:
        continue
    if type(individual) is BinaryIndividual:
        individual.chromsome[i] = genome ^ 1
    elif type(individual) is DecimalIndividual:
        (a, b) = individual.ranges[i]
        eps = individual.precisions[i]
        n_intervals = (b - a) // eps
        n = int(uniform(0, n_intervals + 1))
        individual.chromsome[i] = a + n * eps
    else:
        raise TypeError('Wrong individual type: {}'.format(type(individual)))

",1,"[['https://github.com/PytLab/gaft/tree/master/gaft/tests/flip_bit_mutation_test.py', 'gaft.tests.flip_bit_mutation_test', 'FlipBitMutationTest', 'test_mutate_binary_indv'], ['https://github.com/PytLab/gaft/tree/master/gaft/tests/flip_bit_mutation_test.py', 'gaft.tests.flip_bit_mutation_test', 'FlipBitMutationTest', 'test_mutate_decimal_indv']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/utils.py,,test_recursive_update,"for (k, v) in u.items():
    if isinstance(v, collections.abc.Mapping):
        r = recursive_update(d.get(k, {}), v)
        d[k] = r
    else:
        d[k] = u[k]","for e_target in u.items():
    v = e_target[1]
    k = e_target[0]
    if isinstance(v, collections.abc.Mapping):
        r = recursive_update(d.get(k, {}), v)
        d[k] = r
    else:
        d[k] = u[k]

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_recursive_update']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/utils.py,,test_iterate_flattened_separately,"for (key, value) in sorted(dictionary.items(), key=get_order):
    if is_non_empty_dict(value):
        yield (key, PATHCHANGE)
        for (k, val) in iterate_flattened_separately(value, manually_sorted_keys):
            yield (join_paths(key, k), val)
    else:
        yield (key, value)","for e_target in sorted(dictionary.items(), key=get_order):
    value = e_target[1]
    key = e_target[0]
    if is_non_empty_dict(value):
        yield (key, PATHCHANGE)
        for (k, val) in iterate_flattened_separately(value, manually_sorted_keys):
            yield (join_paths(key, k), val)
    else:
        yield (key, value)

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_iterate_flattened_separately']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/utils.py,,test_iterate_flattened_separately,"for (k, val) in iterate_flattened_separately(value, manually_sorted_keys):
    yield (join_paths(key, k), val)","for e_target in iterate_flattened_separately(value, manually_sorted_keys):
    val = e_target[1]
    k = e_target[0]
    yield (join_paths(key, k), val)

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_iterate_flattened_separately']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/utils.py,,test_iterate_flattened,"for (k, v) in iterate_flattened(d[key]):
    yield (join_paths(key, k), v)","for e_target in iterate_flattened(d[key]):
    v = e_target[1]
    k = e_target[0]
    yield (join_paths(key, k), v)

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_iterate_flattened']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/utils.py,,test_convert_to_nested_dict_nested,"for (k, v) in iterate_flattened(dotted_dict):
    set_by_dotted_path(nested_dict, k, v)","for e_target in iterate_flattened(dotted_dict):
    v = e_target[1]
    k = e_target[0]
    set_by_dotted_path(nested_dict, k, v)

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_convert_to_nested_dict'], ['https://github.com/IDSIA/sacred/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_convert_to_nested_dict_nested']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/ingredient.py,,test_gather_commands,"for (ingredient, _) in self.traverse_ingredients():
    for (command_name, command) in ingredient.commands.items():
        cmd_name = join_paths(ingredient.path, command_name)
        cmd_name = self.post_process_name(cmd_name, ingredient)
        yield (cmd_name, command)","for e_target in self.traverse_ingredients():
    _ = e_target[1]
    ingredient = e_target[0]
    for (command_name, command) in ingredient.commands.items():
        cmd_name = join_paths(ingredient.path, command_name)
        cmd_name = self.post_process_name(cmd_name, ingredient)
        yield (cmd_name, command)

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_ingredients.py', 'tests.test_ingredients', '', 'test_gather_commands']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/ingredient.py,,test_gather_commands,"for (command_name, command) in ingredient.commands.items():
    cmd_name = join_paths(ingredient.path, command_name)
    cmd_name = self.post_process_name(cmd_name, ingredient)
    yield (cmd_name, command)","for e_target in ingredient.commands.items():
    command = e_target[1]
    command_name = e_target[0]
    cmd_name = join_paths(ingredient.path, command_name)
    cmd_name = self.post_process_name(cmd_name, ingredient)
    yield (cmd_name, command)

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_ingredients.py', 'tests.test_ingredients', '', 'test_gather_commands']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/host_info.py,,test_host_info_decorator_with_name,"for (k, v) in all_host_info_gatherers.items():
    try:
        host_info[k] = v()
    except IgnoreHostInfo:
        pass","for e_target in all_host_info_gatherers.items():
    v = e_target[1]
    k = e_target[0]
    try:
        host_info[k] = v()
    except IgnoreHostInfo:
        pass

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_host_info.py', 'tests.test_host_info', '', 'test_host_info_decorator'], ['https://github.com/IDSIA/sacred/tree/master/tests/test_host_info.py', 'tests.test_host_info', '', 'test_get_host_info'], ['https://github.com/IDSIA/sacred/tree/master/tests/test_host_info.py', 'tests.test_host_info', '', 'test_host_info_decorator_with_name']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/observers/file_storage.py,,test_fs_observer_queued_event_creates_rundir,"for (s, _) in ex_info['sources']:
    self.save_file(s)","for e_target in ex_info['sources']:
    _ = e_target[1]
    s = e_target[0]
    self.save_file(s)

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_observers/test_file_storage_observer.py', 'tests.test_observers.test_file_storage_observer', '', 'test_fs_observer_queued_event_creates_rundir']]"
sacred,https://github.com/IDSIA/sacred/tree/master/sacred/config/custom_containers.py,,test_dict_interface_update_with_list_of_items,"for (key, value) in iterable:
    self[key] = value","for e_target in iterable:
    value = e_target[1]
    key = e_target[0]
    self[key] = value

",1,"[['https://github.com/IDSIA/sacred/tree/master/tests/test_config/test_dogmatic_dict.py', 'tests.test_config.test_dogmatic_dict', '', 'test_dict_interface_update_with_dict'], ['https://github.com/IDSIA/sacred/tree/master/tests/test_config/test_dogmatic_dict.py', 'tests.test_config.test_dogmatic_dict', '', 'test_dict_interface_update_with_kwargs'], ['https://github.com/IDSIA/sacred/tree/master/tests/test_config/test_dogmatic_dict.py', 'tests.test_config.test_dogmatic_dict', '', 'test_fixed_value_fixed'], ['https://github.com/IDSIA/sacred/tree/master/tests/test_config/test_dogmatic_dict.py', 'tests.test_config.test_dogmatic_dict', '', 'test_dict_interface_update_with_list_of_items']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/fontBuilder.py,,test_subset_keep_size_drop_empty_stylistic_set,"for (unicodeValue, variationSelector, glyphName) in uvs:
    if cmapping.get(unicodeValue) == glyphName:
        glyphName = None
    if variationSelector not in uvsDict:
        uvsDict[variationSelector] = []
    uvsDict[variationSelector].append((unicodeValue, glyphName))","for e_target in uvs:
    glyphName = e_target[2]
    variationSelector = e_target[1]
    unicodeValue = e_target[0]
    if cmapping.get(unicodeValue) == glyphName:
        glyphName = None
    if variationSelector not in uvsDict:
        uvsDict[variationSelector] = []
    uvsDict[variationSelector].append((unicodeValue, glyphName))

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/fontBuilder/fontBuilder_test.py', 'Tests.fontBuilder.fontBuilder_test', '', 'test_unicodeVariationSequences'], ['https://github.com/fonttools/fonttools/tree/master/Tests/subset/subset_test.py', 'Tests.subset.subset_test', '', 'test_subset_single_pos_format'], ['https://github.com/fonttools/fonttools/tree/master/Tests/subset/subset_test.py', 'Tests.subset.subset_test', '', 'test_subset_keep_size_drop_empty_stylistic_set']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttx.py,TTXTest,test_parseOptions_splitTables,"for (action, input, output) in jobs:
    action(input, output, options)","for e_target in jobs:
    output = e_target[2]
    input = e_target[1]
    action = e_target[0]
    action(input, output, options)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttx/ttx_test.py', 'Tests.ttx.ttx_test', 'TTXTest', 'test_parseOptions_splitGlyphs'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttx/ttx_test.py', 'Tests.ttx.ttx_test', 'TTXTest', 'test_parseOptions_splitTables']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/otlLib/builder.py,BuilderTest,test_buildPairPosClassesSubtable,"for (gc1, gc2) in sorted(pairs):
    coverage.update(gc1)
    classDef1.add(gc1)
    classDef2.add(gc2)","for e_target in sorted(pairs):
    gc2 = e_target[1]
    gc1 = e_target[0]
    coverage.update(gc1)
    classDef1.add(gc1)
    classDef2.add(gc2)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/otlLib/builder_test.py', 'Tests.otlLib.builder_test', 'BuilderTest', 'test_buildPairPosClassesSubtable']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/otlLib/builder.py,ClassDefBuilderTest,test_build_usingClass0,"for (classID, glyphs) in enumerate(self.classes()):
    if classID == 0:
        continue
    for glyph in glyphs:
        glyphClasses[glyph] = classID","for e_target in enumerate(self.classes()):
    glyphs = e_target[1]
    classID = e_target[0]
    if classID == 0:
        continue
    for glyph in glyphs:
        glyphClasses[glyph] = classID

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/otlLib/builder_test.py', 'Tests.otlLib.builder_test', 'ClassDefBuilderTest', 'test_build_notUsingClass0'], ['https://github.com/fonttools/fonttools/tree/master/Tests/otlLib/builder_test.py', 'Tests.otlLib.builder_test', 'ClassDefBuilderTest', 'test_build_usingClass0']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/misc/testTools.py,ColrV1Test,test_traverseEmptyPaintColrLayersNeedsNoLayerList,"for (name, attrs, content) in parsed_xml:
    parseInto.fromXML(name, attrs, content, font)","for e_target in parsed_xml:
    content = e_target[2]
    attrs = e_target[1]
    name = e_target[0]
    parseInto.fromXML(name, attrs, content, font)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/otTables_test.py', 'Tests.ttLib.tables.otTables_test', 'ColrV1Test', 'test_traverseEmptyPaintColrLayersNeedsNoLayerList']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/cu2qu/ufo.py,GlyphsToQuadraticTest,test_incompatible_fonts,"for (font, error) in zip(fonts, max_errors):
    if name in font:
        glyphs.append(font[name])
        cur_max_errors.append(error)","for e_target in zip(fonts, max_errors):
    error = e_target[1]
    font = e_target[0]
    if name in font:
        glyphs.append(font[name])
        cur_max_errors.append(error)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_max_err_em_list'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_max_err_float'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_max_err_em_float'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_max_err_list'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_dump_stats'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_both_max_err_and_max_err_em'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_no_remember_curve_type'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_different_glyphsets'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_modified'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_remember_curve_type'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'FontsToQuadraticTest', 'test_stats'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cu2qu/ufo_test.py', 'Tests.cu2qu.ufo_test', 'GlyphsToQuadraticTest', 'test_incompatible_fonts']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/pens/cu2quPen.py,TestCu2QuPointPen,test__flushContour_restore_starting_point,"for (segment_type, points) in segments:
    if segment_type == 'curve':
        for sub_points in self._split_super_bezier_segments(points):
            (on_curve, smooth, name, kwargs) = sub_points[-1]
            (bcp1, bcp2) = (sub_points[0][0], sub_points[1][0])
            cubic = [prev_on_curve, bcp1, bcp2, on_curve]
            quad = curve_to_quadratic(cubic, self.max_err)
            if self.stats is not None:
                n = str(len(quad) - 2)
                self.stats[n] = self.stats.get(n, 0) + 1
            new_points = [(pt, False, None, {}) for pt in quad[1:-1]]
            new_points.append((on_curve, smooth, name, kwargs))
            new_segments.append(['qcurve', new_points])
            prev_on_curve = sub_points[-1][0]
    else:
        new_segments.append([segment_type, points])
        prev_on_curve = points[-1][0]","for e_target in segments:
    points = e_target[1]
    segment_type = e_target[0]
    if segment_type == 'curve':
        for sub_points in self._split_super_bezier_segments(points):
            (on_curve, smooth, name, kwargs) = sub_points[-1]
            (bcp1, bcp2) = (sub_points[0][0], sub_points[1][0])
            cubic = [prev_on_curve, bcp1, bcp2, on_curve]
            quad = curve_to_quadratic(cubic, self.max_err)
            if self.stats is not None:
                n = str(len(quad) - 2)
                self.stats[n] = self.stats.get(n, 0) + 1
            new_points = [(pt, False, None, {}) for pt in quad[1:-1]]
            new_points.append((on_curve, smooth, name, kwargs))
            new_segments.append(['qcurve', new_points])
            prev_on_curve = sub_points[-1][0]
    else:
        new_segments.append([segment_type, points])
        prev_on_curve = points[-1][0]

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/pens/cu2quPen_test.py', 'Tests.pens.cu2quPen_test', 'TestCu2QuPointPen', 'test__flushContour_restore_starting_point']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/pens/recordingPen.py,RecordingPointPenTest,test_record_and_replay,"for (operator, args, kwargs) in self.value:
    getattr(pointPen, operator)(*args, **kwargs)","for e_target in self.value:
    kwargs = e_target[2]
    args = e_target[1]
    operator = e_target[0]
    getattr(pointPen, operator)(*args, **kwargs)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/pens/recordingPen_test.py', 'Tests.pens.recordingPen_test', 'RecordingPointPenTest', 'test_record_and_replay']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/woff2.py,WOFF2GlyfTableTest,test_roundtrip_glyf_reconstruct_and_transform,"for (glyphID, glyphName) in enumerate(self.glyphOrder):
    glyph = self._decodeGlyph(glyphID)
    glyphs[glyphName] = glyph","for e_target in enumerate(self.glyphOrder):
    glyphName = e_target[1]
    glyphID = e_target[0]
    glyph = self._decodeGlyph(glyphID)
    glyphs[glyphName] = glyph

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_glyf_missing_glyphOrder'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_loca_unpadded'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_loca_padded_2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_glyf_incorrect_glyphOrder'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_roundtrip_glyf_transform_and_reconstruct'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_glyf_padded_4'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_glyf_header_not_enough_data'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_glyf_table_incorrect_size'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_glyf_padded_2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_glyf_unpadded'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_reconstruct_loca_padded_4'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2GlyfTableTest', 'test_roundtrip_glyf_reconstruct_and_transform']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/woff2.py,WOFF2HmtxTableTest,test_reconstruct_monospaced_sidebearings,"for (i, glyphName) in enumerate(glyphOrder):
    if i >= numberOfHMetrics:
        break
    glyph = glyfTable[glyphName]
    xMin = getattr(glyph, 'xMin', 0)
    lsbArray.append(xMin)","for e_target in enumerate(glyphOrder):
    glyphName = e_target[1]
    i = e_target[0]
    if i >= numberOfHMetrics:
        break
    glyph = glyfTable[glyphName]
    xMin = getattr(glyph, 'xMin', 0)
    lsbArray.append(xMin)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_flags_reserved_bits'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_too_much_data'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_no_sidebearings'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_flags_required_bits'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_proportional_sidebearings'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_monospaced_sidebearings']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/woff2.py,WOFF2HmtxTableTest,test_reconstruct_monospaced_sidebearings,"for (i, glyphName) in enumerate(glyphOrder):
    if i < numberOfHMetrics:
        continue
    glyph = glyfTable[glyphName]
    xMin = getattr(glyph, 'xMin', 0)
    leftSideBearingArray.append(xMin)","for e_target in enumerate(glyphOrder):
    glyphName = e_target[1]
    i = e_target[0]
    if i < numberOfHMetrics:
        continue
    glyph = glyfTable[glyphName]
    xMin = getattr(glyph, 'xMin', 0)
    leftSideBearingArray.append(xMin)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_flags_reserved_bits'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_too_much_data'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_no_sidebearings'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_flags_required_bits'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_proportional_sidebearings'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'WOFF2HmtxTableTest', 'test_reconstruct_monospaced_sidebearings']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/woff2.py,MainTest,test_compress_ttf_hmtx_transform,"for (choice, subparser) in subparsers_action.choices.items():
    print(subparser.format_help())","for e_target in subparsers_action.choices.items():
    subparser = e_target[1]
    choice = e_target[0]
    print(subparser.format_help())

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_decompress_ttf'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_recompress_woff2_keeps_flavorData'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_compress_ttf'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_compress_otf'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_compress_ttf_no_glyf_transform'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_decompress_otf'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_compress_ttf_no_glyf_transform_hmtx_transform'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_decompress_output_file'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_compress_output_file'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_no_subcommand_show_help'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/woff2_test.py', 'Tests.ttLib.woff2_test', 'MainTest', 'test_compress_ttf_hmtx_transform']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/removeOverlaps.py,,test_pathops_simplify_bug_workaround,"for (verb, points) in path:
    rounded_path.add(verb, *((round(p[0]), round(p[1])) for p in points))","for e_target in path:
    points = e_target[1]
    verb = e_target[0]
    rounded_path.add(verb, *((round(p[0]), round(p[1])) for p in points))

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/removeOverlaps_test.py', 'Tests.ttLib.removeOverlaps_test', '', 'test_pathops_simplify_bug_workaround']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/S_V_G_.py,,test_decompile_and_compile,"for (doc, startGlyphID, endGlyphID) in self.docList:
    docBytes = tobytes(doc, encoding='utf_8')
    if getattr(self, 'compressed', False) and (not docBytes.startswith(b'\x1f\x8b')):
        import gzip
        bytesIO = BytesIO()
        with gzip.GzipFile(None, 'w', fileobj=bytesIO) as gzipper:
            gzipper.write(docBytes)
        gzipped = bytesIO.getvalue()
        if len(gzipped) < len(docBytes):
            docBytes = gzipped
        del gzipped, bytesIO
    docLength = len(docBytes)
    if docBytes in seenDocs:
        docOffset = seenDocs[docBytes]
    else:
        docOffset = curOffset
        curOffset += docLength
        seenDocs[docBytes] = docOffset
        docList.append(docBytes)
    entry = struct.pack('>HHLL', startGlyphID, endGlyphID, docOffset, docLength)
    entryList.append(entry)","for e_target in self.docList:
    endGlyphID = e_target[2]
    startGlyphID = e_target[1]
    doc = e_target[0]
    docBytes = tobytes(doc, encoding='utf_8')
    if getattr(self, 'compressed', False) and (not docBytes.startswith(b'\x1f\x8b')):
        import gzip
        bytesIO = BytesIO()
        with gzip.GzipFile(None, 'w', fileobj=bytesIO) as gzipper:
            gzipper.write(docBytes)
        gzipped = bytesIO.getvalue()
        if len(gzipped) < len(docBytes):
            docBytes = gzipped
        del gzipped, bytesIO
    docLength = len(docBytes)
    if docBytes in seenDocs:
        docOffset = seenDocs[docBytes]
    else:
        docOffset = curOffset
        curOffset += docLength
        seenDocs[docBytes] = docOffset
        docList.append(docBytes)
    entry = struct.pack('>HHLL', startGlyphID, endGlyphID, docOffset, docLength)
    entryList.append(entry)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/S_V_G__test.py', 'Tests.ttLib.tables.S_V_G__test', '', 'test_round_trip_ttx'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/S_V_G__test.py', 'Tests.ttLib.tables.S_V_G__test', '', 'test_load_from_ttx_and_compile'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/S_V_G__test.py', 'Tests.ttLib.tables.S_V_G__test', '', 'test_decompile_and_compile']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/_f_v_a_r.py,AxisTest,test_toXML,"for (tag, value) in [('AxisTag', self.axisTag), ('Flags', '0x%X' % self.flags), ('MinValue', fl2str(self.minValue, 16)), ('DefaultValue', fl2str(self.defaultValue, 16)), ('MaxValue', fl2str(self.maxValue, 16)), ('AxisNameID', str(self.axisNameID))]:
    writer.begintag(tag)
    writer.write(value)
    writer.endtag(tag)
    writer.newline()","for e_target in [('AxisTag', self.axisTag), ('Flags', '0x%X' % self.flags), ('MinValue', fl2str(self.minValue, 16)), ('DefaultValue', fl2str(self.defaultValue, 16)), ('MaxValue', fl2str(self.maxValue, 16)), ('AxisNameID', str(self.axisNameID))]:
    value = e_target[1]
    tag = e_target[0]
    writer.begintag(tag)
    writer.write(value)
    writer.endtag(tag)
    writer.newline()

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_f_v_a_r_test.py', 'Tests.ttLib.tables._f_v_a_r_test', 'AxisTest', 'test_toXML']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/_f_v_a_r.py,NamedInstanceTest,test_fromXML_withPostScriptName,"for (tag, elementAttrs, _) in filter(lambda t: type(t) is tuple, content):
    if tag == 'coord':
        value = str2fl(elementAttrs['value'], 16)
        self.coordinates[elementAttrs['axis']] = value","for e_target in filter(lambda t: type(t) is tuple, content):
    _ = e_target[2]
    elementAttrs = e_target[1]
    tag = e_target[0]
    if tag == 'coord':
        value = str2fl(elementAttrs['value'], 16)
        self.coordinates[elementAttrs['axis']] = value

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_f_v_a_r_test.py', 'Tests.ttLib.tables._f_v_a_r_test', 'NamedInstanceTest', 'test_fromXML_withoutPostScriptName'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_f_v_a_r_test.py', 'Tests.ttLib.tables._f_v_a_r_test', 'NamedInstanceTest', 'test_fromXML_withPostScriptName']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/otTables.py,SingleSubstTest,test_postRead_format2,"for (inp, alt) in zip(input, alts):
    alternates[inp] = alt.Alternate","for e_target in zip(input, alts):
    alt = e_target[1]
    inp = e_target[0]
    alternates[inp] = alt.Alternate

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/otTables_test.py', 'Tests.ttLib.tables.otTables_test', 'AlternateSubstTest', 'test_postRead_format1'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/otTables_test.py', 'Tests.ttLib.tables.otTables_test', 'LigatureSubstTest', 'test_postRead_format1'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/otTables_test.py', 'Tests.ttLib.tables.otTables_test', 'SingleSubstTest', 'test_postRead_format1'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/otTables_test.py', 'Tests.ttLib.tables.otTables_test', 'MultipleSubstTest', 'test_postRead_format1'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/otTables_test.py', 'Tests.ttLib.tables.otTables_test', 'SingleSubstTest', 'test_postRead_format2']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/otTables.py,,test_splitMarkBasePos,"for (glyphName, markRecord) in zip(oldSubTable.MarkCoverage.glyphs, oldSubTable.MarkArray.MarkRecord):
    if markRecord.Class < oldClassCount:
        oldMarkCoverage.append(glyphName)
        oldMarkRecords.append(markRecord)
    else:
        markRecord.Class -= oldClassCount
        newMarkCoverage.append(glyphName)
        newMarkRecords.append(markRecord)","for e_target in zip(oldSubTable.MarkCoverage.glyphs, oldSubTable.MarkArray.MarkRecord):
    markRecord = e_target[1]
    glyphName = e_target[0]
    if markRecord.Class < oldClassCount:
        oldMarkCoverage.append(glyphName)
        oldMarkRecords.append(markRecord)
    else:
        markRecord.Class -= oldClassCount
        newMarkCoverage.append(glyphName)
        newMarkRecords.append(markRecord)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/otTables_test.py', 'Tests.ttLib.tables.otTables_test', '', 'test_splitMarkBasePos']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/_n_a_m_e.py,NameTableTest,test_findMultilingualNameNoMac,"for (lang, name) in sorted(names.items()):
    if windows:
        windowsName = _makeWindowsName(name, None, lang)
        if windowsName is not None:
            reqNameSet.add((windowsName.string, windowsName.platformID, windowsName.platEncID, windowsName.langID))
    if mac:
        macName = _makeMacName(name, None, lang)
        if macName is not None:
            reqNameSet.add((macName.string, macName.platformID, macName.platEncID, macName.langID))","for e_target in sorted(names.items()):
    name = e_target[1]
    lang = e_target[0]
    if windows:
        windowsName = _makeWindowsName(name, None, lang)
        if windowsName is not None:
            reqNameSet.add((windowsName.string, windowsName.platformID, windowsName.platEncID, windowsName.langID))
    if mac:
        macName = _makeMacName(name, None, lang)
        if macName is not None:
            reqNameSet.add((macName.string, macName.platformID, macName.platEncID, macName.langID))

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_n_a_m_e_test.py', 'Tests.ttLib.tables._n_a_m_e_test', 'NameTableTest', 'test_findMultilingualName'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_n_a_m_e_test.py', 'Tests.ttLib.tables._n_a_m_e_test', 'NameTableTest', 'test_addMultilingualName_minNameID'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_n_a_m_e_test.py', 'Tests.ttLib.tables._n_a_m_e_test', 'NameTableTest', 'test_findMultilingualName_compiled'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_n_a_m_e_test.py', 'Tests.ttLib.tables._n_a_m_e_test', 'NameTableTest', 'test_findMultilingualNameNoMac']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/_n_a_m_e.py,NameTableTest,test_findMultilingualNameNoMac,"for (nameID, nameSet) in sorted(matchingNames.items()):
    if nameSet == reqNameSet:
        return nameID","for e_target in sorted(matchingNames.items()):
    nameSet = e_target[1]
    nameID = e_target[0]
    if nameSet == reqNameSet:
        return nameID

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_n_a_m_e_test.py', 'Tests.ttLib.tables._n_a_m_e_test', 'NameTableTest', 'test_findMultilingualName'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_n_a_m_e_test.py', 'Tests.ttLib.tables._n_a_m_e_test', 'NameTableTest', 'test_addMultilingualName_minNameID'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_n_a_m_e_test.py', 'Tests.ttLib.tables._n_a_m_e_test', 'NameTableTest', 'test_findMultilingualName_compiled'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_n_a_m_e_test.py', 'Tests.ttLib.tables._n_a_m_e_test', 'NameTableTest', 'test_findMultilingualNameNoMac']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/_c_m_a_p.py,CmapSubtableTest,test_getBestCmap,"for (platformID, platEncID) in cmapPreferences:
    cmapSubtable = self.getcmap(platformID, platEncID)
    if cmapSubtable is not None:
        return cmapSubtable.cmap","for e_target in cmapPreferences:
    platEncID = e_target[1]
    platformID = e_target[0]
    cmapSubtable = self.getcmap(platformID, platEncID)
    if cmapSubtable is not None:
        return cmapSubtable.cmap

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_c_m_a_p_test.py', 'Tests.ttLib.tables._c_m_a_p_test', 'CmapSubtableTest', 'test_getBestCmap']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/T_S_I__1.py,,test_decompile_magic_length_last_glyph,"for (indices, isExtra) in zip((indextable.indices, indextable.extra_indices), (False, True)):
    programs = {}
    for (i, (glyphID, textLength, textOffset)) in enumerate(indices):
        if isExtra:
            name = self.extras[glyphID]
        else:
            name = ttFont.getGlyphName(glyphID)
        if textOffset > totalLength:
            self.log.warning('textOffset > totalLength; %r skipped' % name)
            continue
        if textLength < 32768:
            pass
        elif textLength == 32768:
            isLast = i == len(indices) - 1
            if isLast:
                if isExtra:
                    nextTextOffset = totalLength
                else:
                    nextTextOffset = indextable.extra_indices[0][2]
            else:
                nextTextOffset = indices[i + 1][2]
            assert nextTextOffset >= textOffset, 'entries not sorted by offset'
            if nextTextOffset > totalLength:
                self.log.warning('nextTextOffset > totalLength; %r truncated' % name)
                nextTextOffset = totalLength
            textLength = nextTextOffset - textOffset
        else:
            from fontTools import ttLib
            raise ttLib.TTLibError('%r textLength (%d) must not be > 32768' % (name, textLength))
        text = data[textOffset:textOffset + textLength]
        assert len(text) == textLength
        text = tostr(text, encoding='utf-8')
        if text:
            programs[name] = text
    if isExtra:
        self.extraPrograms = programs
    else:
        self.glyphPrograms = programs","for e_target in zip((indextable.indices, indextable.extra_indices), (False, True)):
    isExtra = e_target[1]
    indices = e_target[0]
    programs = {}
    for (i, (glyphID, textLength, textOffset)) in enumerate(indices):
        if isExtra:
            name = self.extras[glyphID]
        else:
            name = ttFont.getGlyphName(glyphID)
        if textOffset > totalLength:
            self.log.warning('textOffset > totalLength; %r skipped' % name)
            continue
        if textLength < 32768:
            pass
        elif textLength == 32768:
            isLast = i == len(indices) - 1
            if isLast:
                if isExtra:
                    nextTextOffset = totalLength
                else:
                    nextTextOffset = indextable.extra_indices[0][2]
            else:
                nextTextOffset = indices[i + 1][2]
            assert nextTextOffset >= textOffset, 'entries not sorted by offset'
            if nextTextOffset > totalLength:
                self.log.warning('nextTextOffset > totalLength; %r truncated' % name)
                nextTextOffset = totalLength
            textLength = nextTextOffset - textOffset
        else:
            from fontTools import ttLib
            raise ttLib.TTLibError('%r textLength (%d) must not be > 32768' % (name, textLength))
        text = data[textOffset:textOffset + textLength]
        assert len(text) == textLength
        text = tostr(text, encoding='utf-8')
        if text:
            programs[name] = text
    if isExtra:
        self.extraPrograms = programs
    else:
        self.glyphPrograms = programs

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_utf8'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_magic_length_non_last'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_invalid_length'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_empty'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_offset_past_end'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_magic_length_last_extra'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_magic_length_last_glyph']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/T_S_I__1.py,,test_decompile_magic_length_last_glyph,"for (i, (glyphID, textLength, textOffset)) in enumerate(indices):
    if isExtra:
        name = self.extras[glyphID]
    else:
        name = ttFont.getGlyphName(glyphID)
    if textOffset > totalLength:
        self.log.warning('textOffset > totalLength; %r skipped' % name)
        continue
    if textLength < 32768:
        pass
    elif textLength == 32768:
        isLast = i == len(indices) - 1
        if isLast:
            if isExtra:
                nextTextOffset = totalLength
            else:
                nextTextOffset = indextable.extra_indices[0][2]
        else:
            nextTextOffset = indices[i + 1][2]
        assert nextTextOffset >= textOffset, 'entries not sorted by offset'
        if nextTextOffset > totalLength:
            self.log.warning('nextTextOffset > totalLength; %r truncated' % name)
            nextTextOffset = totalLength
        textLength = nextTextOffset - textOffset
    else:
        from fontTools import ttLib
        raise ttLib.TTLibError('%r textLength (%d) must not be > 32768' % (name, textLength))
    text = data[textOffset:textOffset + textLength]
    assert len(text) == textLength
    text = tostr(text, encoding='utf-8')
    if text:
        programs[name] = text","for e_target in enumerate(indices):
    textOffset = e_target[1][2]
    textLength = e_target[1][1]
    glyphID = e_target[1][0]
    i = e_target[0]
    if isExtra:
        name = self.extras[glyphID]
    else:
        name = ttFont.getGlyphName(glyphID)
    if textOffset > totalLength:
        self.log.warning('textOffset > totalLength; %r skipped' % name)
        continue
    if textLength < 32768:
        pass
    elif textLength == 32768:
        isLast = i == len(indices) - 1
        if isLast:
            if isExtra:
                nextTextOffset = totalLength
            else:
                nextTextOffset = indextable.extra_indices[0][2]
        else:
            nextTextOffset = indices[i + 1][2]
        assert nextTextOffset >= textOffset, 'entries not sorted by offset'
        if nextTextOffset > totalLength:
            self.log.warning('nextTextOffset > totalLength; %r truncated' % name)
            nextTextOffset = totalLength
        textLength = nextTextOffset - textOffset
    else:
        from fontTools import ttLib
        raise ttLib.TTLibError('%r textLength (%d) must not be > 32768' % (name, textLength))
    text = data[textOffset:textOffset + textLength]
    assert len(text) == textLength
    text = tostr(text, encoding='utf-8')
    if text:
        programs[name] = text

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_utf8'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_magic_length_non_last'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_invalid_length'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_empty'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_offset_past_end'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_magic_length_last_extra'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/T_S_I__1_test.py', 'Tests.ttLib.tables.T_S_I__1_test', '', 'test_decompile_magic_length_last_glyph']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/TupleVariation.py,TupleVariationTest,test_toXML_constants,"for (i, delta) in enumerate(self.coordinates):
    if type(delta) == tuple and len(delta) == 2:
        writer.simpletag('delta', pt=i, x=delta[0], y=delta[1])
        writer.newline()
        wrote_any_deltas = True
    elif type(delta) == int:
        writer.simpletag('delta', cvt=i, value=delta)
        writer.newline()
        wrote_any_deltas = True
    elif delta is not None:
        log.error('bad delta format')
        writer.comment('bad delta #%d' % i)
        writer.newline()
        wrote_any_deltas = True","for e_target in enumerate(self.coordinates):
    delta = e_target[1]
    i = e_target[0]
    if type(delta) == tuple and len(delta) == 2:
        writer.simpletag('delta', pt=i, x=delta[0], y=delta[1])
        writer.newline()
        wrote_any_deltas = True
    elif type(delta) == int:
        writer.simpletag('delta', cvt=i, value=delta)
        writer.newline()
        wrote_any_deltas = True
    elif delta is not None:
        log.error('bad delta format')
        writer.comment('bad delta #%d' % i)
        writer.newline()
        wrote_any_deltas = True

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_toXML_axes_floats'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_toXML_badDeltaFormat'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_toXML_points'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_toXML_allDeltasNone'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_toXML_constants']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/TupleVariation.py,TupleVariationTest,test_compileTupleVariationStore_noVariations,"for (v, p) in zip(variations, pointDatas):
    (thisTuple, thisData) = v.compile(axisTags, sharedTupleIndices, pointData=p)
    tuples.append(thisTuple)
    data.append(thisData)","for e_target in zip(variations, pointDatas):
    p = e_target[1]
    v = e_target[0]
    (thisTuple, thisData) = v.compile(axisTags, sharedTupleIndices, pointData=p)
    tuples.append(thisTuple)
    data.append(thisData)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_compileTupleVariationStore_allVariationsRedundant'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_compileTupleVariationStore_roundTrip_cvar'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_compileTupleVariationStore_roundTrip_gvar'], ['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/TupleVariation_test.py', 'Tests.ttLib.tables.TupleVariation_test', 'TupleVariationTest', 'test_compileTupleVariationStore_noVariations']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/ttLib/tables/_a_v_a_r.py,AxisVariationTableTest,test_compile,"for (key, value) in mappings:
    fixedKey = fl2fi(key, 14)
    fixedValue = fl2fi(value, 14)
    result.append(struct.pack('>hh', fixedKey, fixedValue))","for e_target in mappings:
    value = e_target[1]
    key = e_target[0]
    fixedKey = fl2fi(key, 14)
    fixedValue = fl2fi(value, 14)
    result.append(struct.pack('>hh', fixedKey, fixedValue))

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/ttLib/tables/_a_v_a_r_test.py', 'Tests.ttLib.tables._a_v_a_r_test', 'AxisVariationTableTest', 'test_compile']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/mutator.py,BuildTest,test_kerning_merging,"for (i, delta) in deltas.items():
    cvt[i] += otRound(delta)","for e_target in deltas.items():
    delta = e_target[1]
    i = e_target[0]
    cvt[i] += otRound(delta)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/mutator_test.py', 'Tests.varLib.mutator_test', 'MutatorTest', 'test_varlib_mutator_CFF2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/varLib_test.py', 'Tests.varLib.varLib_test', 'BuildTest', 'test_kerning_merging']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/mutator.py,BuildTest,test_kerning_merging,"for (percent, widthClass) in sorted(OS2_WIDTH_CLASS_VALUES.items()):
    if wdth < percent:
        varfont['OS/2'].usWidthClass = widthClass
        break
else:
    varfont['OS/2'].usWidthClass = 9","for e_target in sorted(OS2_WIDTH_CLASS_VALUES.items()):
    widthClass = e_target[1]
    percent = e_target[0]
    if wdth < percent:
        varfont['OS/2'].usWidthClass = widthClass
        break
else:
    varfont['OS/2'].usWidthClass = 9

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/mutator_test.py', 'Tests.varLib.mutator_test', 'MutatorTest', 'test_varlib_mutator_CFF2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/varLib_test.py', 'Tests.varLib.varLib_test', 'BuildTest', 'test_kerning_merging']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/mutator.py,BuildTest,test_kerning_merging,"for (i, c) in enumerate(var.coordinates):
    if c is not None:
        deltas[i] = deltas.get(i, 0) + scalar * c","for e_target in enumerate(var.coordinates):
    c = e_target[1]
    i = e_target[0]
    if c is not None:
        deltas[i] = deltas.get(i, 0) + scalar * c

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/mutator_test.py', 'Tests.varLib.mutator_test', 'MutatorTest', 'test_varlib_mutator_CFF2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/varLib_test.py', 'Tests.varLib.varLib_test', 'BuildTest', 'test_kerning_merging']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/interpolatable.py,BuildTest,test_varlib_main_ttf,"for (glyph, glyph_problems) in problems.items():
    print(f'Glyph {glyph} was not compatible: ')
    for p in glyph_problems:
        if p['type'] == 'missing':
            print('    Glyph was missing in master %s' % p['master'])
        if p['type'] == 'open_path':
            print('    Glyph has an open path in master %s' % p['master'])
        if p['type'] == 'path_count':
            print('    Path count differs: %i in %s, %i in %s' % (p['value_1'], p['master_1'], p['value_2'], p['master_2']))
        if p['type'] == 'node_count':
            print('    Node count differs in path %i: %i in %s, %i in %s' % (p['path'], p['value_1'], p['master_1'], p['value_2'], p['master_2']))
        if p['type'] == 'node_incompatibility':
            print('    Node %o incompatible in path %i: %s in %s, %s in %s' % (p['node'], p['path'], p['value_1'], p['master_1'], p['value_2'], p['master_2']))
        if p['type'] == 'contour_order':
            print('    Contour order differs: %s in %s, %s in %s' % (p['value_1'], p['master_1'], p['value_2'], p['master_2']))
        if p['type'] == 'high_cost':
            print('    Interpolation has high cost: cost of %s to %s = %i, threshold %i' % (p['master_1'], p['master_2'], p['value_1'], p['value_2']))","for e_target in problems.items():
    glyph_problems = e_target[1]
    glyph = e_target[0]
    print(f'Glyph {glyph} was not compatible: ')
    for p in glyph_problems:
        if p['type'] == 'missing':
            print('    Glyph was missing in master %s' % p['master'])
        if p['type'] == 'open_path':
            print('    Glyph has an open path in master %s' % p['master'])
        if p['type'] == 'path_count':
            print('    Path count differs: %i in %s, %i in %s' % (p['value_1'], p['master_1'], p['value_2'], p['master_2']))
        if p['type'] == 'node_count':
            print('    Node count differs in path %i: %i in %s, %i in %s' % (p['path'], p['value_1'], p['master_1'], p['value_2'], p['master_2']))
        if p['type'] == 'node_incompatibility':
            print('    Node %o incompatible in path %i: %s in %s, %s in %s' % (p['node'], p['path'], p['value_1'], p['master_1'], p['value_2'], p['master_2']))
        if p['type'] == 'contour_order':
            print('    Contour order differs: %s in %s, %s in %s' % (p['value_1'], p['master_1'], p['value_2'], p['master_2']))
        if p['type'] == 'high_cost':
            print('    Interpolation has high cost: cost of %s to %s = %i, threshold %i' % (p['master_1'], p['master_2'], p['value_1'], p['value_2']))

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/interpolatable_test.py', 'Tests.varLib.interpolatable_test', 'InterpolatableTest', 'test_interpolatable_ttf'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/interpolatable_test.py', 'Tests.varLib.interpolatable_test', 'InterpolatableTest', 'test_interpolatable_otf'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/varLib_test.py', 'Tests.varLib.varLib_test', 'BuildTest', 'test_varlib_main_ttf']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/featureVars.py,,test_overlaps_1,"for (value, key) in conditionalSubstitutions:
    key = hashdict(key)
    if key in merged:
        merged[key].extend(value)
    else:
        merged[key] = value","for e_target in conditionalSubstitutions:
    key = e_target[1]
    value = e_target[0]
    key = hashdict(key)
    if key in merged:
        merged[key].extend(value)
    else:
        merged[key] = value

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_linear'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_quadratic'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_1']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/featureVars.py,,test_overlaps_1,"for (key, value) in reversed(conditionalSubstitutions):
    key = tuple(sorted((hashdict(cleanupBox(k)) for k in key), key=lambda d: tuple(sorted(d.items()))))
    if key in merged:
        merged[key].update(value)
    else:
        merged[key] = dict(value)","for e_target in reversed(conditionalSubstitutions):
    value = e_target[1]
    key = e_target[0]
    key = tuple(sorted((hashdict(cleanupBox(k)) for k in key), key=lambda d: tuple(sorted(d.items()))))
    if key in merged:
        merged[key].update(value)
    else:
        merged[key] = dict(value)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_linear'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_quadratic'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_1']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/featureVars.py,,test_overlaps_1,"for (i, (currRegion, _)) in enumerate(conditionalSubstitutions):
    newMap = OrderedDict(initMapInit)
    currRank = 1 << i
    for (box, rank) in boxMap.items():
        for currBox in currRegion:
            (intersection, remainder) = overlayBox(currBox, box)
            if intersection is not None:
                intersection = hashdict(intersection)
                newMap[intersection] = newMap.get(intersection, 0) | rank | currRank
            if remainder is not None:
                remainder = hashdict(remainder)
                newMap[remainder] = newMap.get(remainder, 0) | rank
    boxMap = newMap","for e_target in enumerate(conditionalSubstitutions):
    _ = e_target[1][1]
    currRegion = e_target[1][0]
    i = e_target[0]
    newMap = OrderedDict(initMapInit)
    currRank = 1 << i
    for (box, rank) in boxMap.items():
        for currBox in currRegion:
            (intersection, remainder) = overlayBox(currBox, box)
            if intersection is not None:
                intersection = hashdict(intersection)
                newMap[intersection] = newMap.get(intersection, 0) | rank | currRank
            if remainder is not None:
                remainder = hashdict(remainder)
                newMap[remainder] = newMap.get(remainder, 0) | rank
    boxMap = newMap

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_linear'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_quadratic'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_1']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/featureVars.py,,test_overlaps_1,"for (box, rank) in sorted(boxMap.items(), key=lambda BoxAndRank: -popCount(BoxAndRank[1])):
    if rank == 0:
        continue
    substsList = []
    i = 0
    while rank:
        if rank & 1:
            substsList.append(conditionalSubstitutions[i][1])
        rank >>= 1
        i += 1
    items.append((dict(box), substsList))","for e_target in sorted(boxMap.items(), key=lambda BoxAndRank: -popCount(BoxAndRank[1])):
    rank = e_target[1]
    box = e_target[0]
    if rank == 0:
        continue
    substsList = []
    i = 0
    while rank:
        if rank & 1:
            substsList.append(conditionalSubstitutions[i][1])
        rank >>= 1
        i += 1
    items.append((dict(box), substsList))

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_linear'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_quadratic'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_1']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/featureVars.py,,test_overlaps_1,"for (box, rank) in boxMap.items():
    for currBox in currRegion:
        (intersection, remainder) = overlayBox(currBox, box)
        if intersection is not None:
            intersection = hashdict(intersection)
            newMap[intersection] = newMap.get(intersection, 0) | rank | currRank
        if remainder is not None:
            remainder = hashdict(remainder)
            newMap[remainder] = newMap.get(remainder, 0) | rank","for e_target in boxMap.items():
    rank = e_target[1]
    box = e_target[0]
    for currBox in currRegion:
        (intersection, remainder) = overlayBox(currBox, box)
        if intersection is not None:
            intersection = hashdict(intersection)
            newMap[intersection] = newMap.get(intersection, 0) | rank | currRank
        if remainder is not None:
            remainder = hashdict(remainder)
            newMap[remainder] = newMap.get(remainder, 0) | rank

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_linear'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_2'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_quadratic'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/featureVars_test.py', 'Tests.varLib.featureVars_test', '', 'test_overlaps_1']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/models.py,,test_normalizeLocation,"for (tag, triple) in axes.items():
    v = location.get(tag, triple[1])
    out[tag] = normalizeValue(v, triple)","for e_target in axes.items():
    triple = e_target[1]
    tag = e_target[0]
    v = location.get(tag, triple[1])
    out[tag] = normalizeValue(v, triple)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/models_test.py', 'Tests.varLib.models_test', '', 'test_normalizeLocation']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/models.py,,test_supportScalar,"for (axis, (lower, peak, upper)) in support.items():
    if ot:
        if peak == 0.0:
            continue
        if lower > peak or peak > upper:
            continue
        if lower < 0.0 and upper > 0.0:
            continue
        v = location.get(axis, 0.0)
    else:
        assert axis in location
        v = location[axis]
    if v == peak:
        continue
    if v <= lower or upper <= v:
        scalar = 0.0
        break
    if v < peak:
        scalar *= (v - lower) / (peak - lower)
    else:
        scalar *= (v - upper) / (peak - upper)","for e_target in support.items():
    upper = e_target[1][2]
    peak = e_target[1][1]
    lower = e_target[1][0]
    axis = e_target[0]
    if ot:
        if peak == 0.0:
            continue
        if lower > peak or peak > upper:
            continue
        if lower < 0.0 and upper > 0.0:
            continue
        v = location.get(axis, 0.0)
    else:
        assert axis in location
        v = location[axis]
    if v == peak:
        continue
    if v <= lower or upper <= v:
        scalar = 0.0
        break
    if v < peak:
        scalar *= (v - lower) / (peak - lower)
    else:
        scalar *= (v - upper) / (peak - upper)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/models_test.py', 'Tests.varLib.models_test', '', 'test_supportScalar']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/varLib/instancer/names.py,,test_updateNameTable_existing_subfamily_name_is_not_regular,"for (axisTag, val) in fvarDefaults.items():
    if axisTag not in defaultAxisCoords or isinstance(defaultAxisCoords[axisTag], AxisRange):
        defaultAxisCoords[axisTag] = val","for e_target in fvarDefaults.items():
    val = e_target[1]
    axisTag = e_target[0]
    if axisTag not in defaultAxisCoords or isinstance(defaultAxisCoords[axisTag], AxisRange):
        defaultAxisCoords[axisTag] = val

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/instancer/names_test.py', 'Tests.varLib.instancer.names_test', '', 'test_updatetNameTable_axis_order'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/instancer/names_test.py', 'Tests.varLib.instancer.names_test', '', 'test_updateNameTable_format4_axisValues'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/instancer/names_test.py', 'Tests.varLib.instancer.names_test', '', 'test_updateNameTable_elided_axisValues'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/instancer/names_test.py', 'Tests.varLib.instancer.names_test', '', 'test_updateNameTable_missing_stat'], ['https://github.com/fonttools/fonttools/tree/master/Tests/varLib/instancer/names_test.py', 'Tests.varLib.instancer.names_test', '', 'test_updateNameTable_existing_subfamily_name_is_not_regular']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/colorLib/builder.py,,test_unbuildColrV1,"for (baseGlyph, paint) in colorGlyphItems:
    try:
        baseGlyphs.append(buildBaseGlyphPaintRecord(baseGlyph, layerBuilder, paint))
    except (ColorLibError, OverflowError, ValueError, TypeError) as e:
        errors[baseGlyph] = e","for e_target in colorGlyphItems:
    paint = e_target[1]
    baseGlyph = e_target[0]
    try:
        baseGlyphs.append(buildBaseGlyphPaintRecord(baseGlyph, layerBuilder, paint))
    except (ColorLibError, OverflowError, ValueError, TypeError) as e:
        errors[baseGlyph] = e

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/colorLib/unbuilder_test.py', 'Tests.colorLib.unbuilder_test', '', 'test_unbuildColrV1_noLayers'], ['https://github.com/fonttools/fonttools/tree/master/Tests/colorLib/unbuilder_test.py', 'Tests.colorLib.unbuilder_test', '', 'test_unbuildColrV1']]"
fonttools,https://github.com/fonttools/fonttools/tree/master/Lib/fontTools/cffLib/specializer.py,CFF2VFTestSpecialize,test_blend_round_trip,"for (op, args) in commands:
    if any((isinstance(arg, list) for arg in args)):
        args = _flattenBlendArgs(args)
    program.extend(args)
    if op:
        program.append(op)","for e_target in commands:
    args = e_target[1]
    op = e_target[0]
    if any((isinstance(arg, list) for arg in args)):
        args = _flattenBlendArgs(args)
    program.extend(args)
    if op:
        program.append(op)

",1,"[['https://github.com/fonttools/fonttools/tree/master/Tests/cffLib/specializer_test.py', 'Tests.cffLib.specializer_test', 'CFF2VFTestSpecialize', 'test_blend_programToCommands'], ['https://github.com/fonttools/fonttools/tree/master/Tests/cffLib/specializer_test.py', 'Tests.cffLib.specializer_test', 'CFF2VFTestSpecialize', 'test_blend_round_trip']]"
traitlets,https://github.com/ipython/traitlets/tree/master/traitlets/config/loader.py,TestConfig,test_merge_multi_lazy_update_II,"for (k, v) in other.items():
    if k not in self:
        to_update[k] = v
    elif isinstance(v, Config) and isinstance(self[k], Config):
        self[k].merge(v)
    elif isinstance(v, LazyConfigValue):
        self[k] = v.merge_into(self[k])
    else:
        to_update[k] = v","for e_target in other.items():
    v = e_target[1]
    k = e_target[0]
    if k not in self:
        to_update[k] = v
    elif isinstance(v, Config) and isinstance(self[k], Config):
        self[k].merge(v)
    elif isinstance(v, LazyConfigValue):
        self[k] = v.merge_into(self[k])
    else:
        to_update[k] = v

",1,"[['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_multi_lazy_III'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_doesnt_exist'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_no_copies'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_fromdictmerge'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_exists'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_multi_lazy_update_III'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_multi_lazy_IV'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_multi_lazy_update_I'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_multi_lazyII'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_multi_lazy'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_fromdictmerge2'], ['https://github.com/ipython/traitlets/tree/master/traitlets/config/tests/test_loader.py', 'traitlets.config.tests.test_loader', 'TestConfig', 'test_merge_multi_lazy_update_II']]"
CTags,https://github.com/SublimeText/CTags/tree/master//ctags.py,CTagsTest,test_parse_tag_lines__python,"for (key, val) in list(filt.items()):
    if re.match(val, tag[key]):
        skip = True","for e_target in list(filt.items()):
    val = e_target[1]
    key = e_target[0]
    if re.match(val, tag[key]):
        skip = True

",1,"[['https://github.com/SublimeText/CTags/tree/master//test_ctags.py', 'test_ctags', 'CTagsTest', 'test_parse_tag_lines__c'], ['https://github.com/SublimeText/CTags/tree/master//test_ctags.py', 'test_ctags', 'CTagsTest', 'test_parse_tag_lines__python']]"
trash-cli,https://github.com/andreafrancia/trash-cli/tree/master/trashcli/empty.py,TestPrepareOutputMessage,test_no_dirs,"for (event, args) in trash_dirs:
    if event == trash_dir_found:
        (trash_dir, volume) = args
        result.append('    - %s' % trash_dir)","for e_target in trash_dirs:
    args = e_target[1]
    event = e_target[0]
    if event == trash_dir_found:
        (trash_dir, volume) = args
        result.append('    - %s' % trash_dir)

",1,"[['https://github.com/andreafrancia/trash-cli/tree/master/tests/empty/test_prepare_output_message.py', 'tests.empty.test_prepare_output_message', 'TestPrepareOutputMessage', 'test_one_dir'], ['https://github.com/andreafrancia/trash-cli/tree/master/tests/empty/test_prepare_output_message.py', 'tests.empty.test_prepare_output_message', 'TestPrepareOutputMessage', 'test_multiple_dirs'], ['https://github.com/andreafrancia/trash-cli/tree/master/tests/empty/test_prepare_output_message.py', 'tests.empty.test_prepare_output_message', 'TestPrepareOutputMessage', 'test_no_dirs']]"
trash-cli,https://github.com/andreafrancia/trash-cli/tree/master/trashcli/rm.py,TestTrashRmCmdRun,test_without_pattern_argument,"for (event, args) in scanner.scan_trash_dirs(self.environ):
    if event == trash_dir_found:
        (path, volume) = args
        for (type, arg) in listing.list_from_volume_trashdir(path, volume):
            if type == 'unable_to_parse_path':
                self.unable_to_parse_path(arg)
            elif type == 'trashed_file':
                (original_location, info_file) = arg
                if cmd.matches(original_location):
                    trashcan.delete_trashinfo_and_backup_copy(info_file)","for e_target in scanner.scan_trash_dirs(self.environ):
    args = e_target[1]
    event = e_target[0]
    if event == trash_dir_found:
        (path, volume) = args
        for (type, arg) in listing.list_from_volume_trashdir(path, volume):
            if type == 'unable_to_parse_path':
                self.unable_to_parse_path(arg)
            elif type == 'trashed_file':
                (original_location, info_file) = arg
                if cmd.matches(original_location):
                    trashcan.delete_trashinfo_and_backup_copy(info_file)

",1,"[['https://github.com/andreafrancia/trash-cli/tree/master/tests/test_trash_rm.py', 'tests.test_trash_rm', 'TestTrashRmCmdRun', 'test_without_arguments'], ['https://github.com/andreafrancia/trash-cli/tree/master/tests/test_trash_rm.py', 'tests.test_trash_rm', 'TestTrashRmCmdRun', 'test_without_pattern_argument']]"
trash-cli,https://github.com/andreafrancia/trash-cli/tree/master/trashcli/rm.py,TestTrashRmCmdRun,test_without_pattern_argument,"for (type, arg) in listing.list_from_volume_trashdir(path, volume):
    if type == 'unable_to_parse_path':
        self.unable_to_parse_path(arg)
    elif type == 'trashed_file':
        (original_location, info_file) = arg
        if cmd.matches(original_location):
            trashcan.delete_trashinfo_and_backup_copy(info_file)","for e_target in listing.list_from_volume_trashdir(path, volume):
    arg = e_target[1]
    type = e_target[0]
    if type == 'unable_to_parse_path':
        self.unable_to_parse_path(arg)
    elif type == 'trashed_file':
        (original_location, info_file) = arg
        if cmd.matches(original_location):
            trashcan.delete_trashinfo_and_backup_copy(info_file)

",1,"[['https://github.com/andreafrancia/trash-cli/tree/master/tests/test_trash_rm.py', 'tests.test_trash_rm', 'TestTrashRmCmdRun', 'test_without_arguments'], ['https://github.com/andreafrancia/trash-cli/tree/master/tests/test_trash_rm.py', 'tests.test_trash_rm', 'TestTrashRmCmdRun', 'test_without_pattern_argument']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/distributed.py,,test_host_is_local,"for (ignored_family, ignored_socktype, ignored_proto, ignored_canonname, sockaddr) in localaddrs:
    for (ignored_rfamily, ignored_rsocktype, ignored_rproto, ignored_rcanonname, rsockaddr) in targetaddrs:
        if rsockaddr[0] == sockaddr[0]:
            return True","for e_target in localaddrs:
    sockaddr = e_target[4]
    ignored_canonname = e_target[3]
    ignored_proto = e_target[2]
    ignored_socktype = e_target[1]
    ignored_family = e_target[0]
    for (ignored_rfamily, ignored_rsocktype, ignored_rproto, ignored_rcanonname, rsockaddr) in targetaddrs:
        if rsockaddr[0] == sockaddr[0]:
            return True

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_distributed.py', 'tests.test_distributed', '', 'test_host_is_local']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/distributed.py,,test_host_is_local,"for (ignored_rfamily, ignored_rsocktype, ignored_rproto, ignored_rcanonname, rsockaddr) in targetaddrs:
    if rsockaddr[0] == sockaddr[0]:
        return True","for e_target in targetaddrs:
    rsockaddr = e_target[4]
    ignored_rcanonname = e_target[3]
    ignored_rproto = e_target[2]
    ignored_rsocktype = e_target[1]
    ignored_rfamily = e_target[0]
    if rsockaddr[0] == sockaddr[0]:
        return True

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_distributed.py', 'tests.test_distributed', '', 'test_host_is_local']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/distributed.py,,test_DistributedEvaluator_primary_restrictions,"for (genome_id, fitness) in results:
    genome = id2genome[genome_id]
    genome.fitness = fitness","for e_target in results:
    fitness = e_target[1]
    genome_id = e_target[0]
    genome = id2genome[genome_id]
    genome.fitness = fitness

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_distributed.py', 'tests.test_distributed', '', 'test_DistributedEvaluator_primary_restrictions']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/reproduction.py,TestSpawnComputation,test_spawn_adjust1,"for (af, ps) in zip(adjusted_fitness, previous_sizes):
    if af_sum > 0:
        s = max(min_species_size, af / af_sum * pop_size)
    else:
        s = min_species_size
    d = (s - ps) * 0.5
    c = int(round(d))
    spawn = ps
    if abs(c) > 0:
        spawn += c
    elif d > 0:
        spawn += 1
    elif d < 0:
        spawn -= 1
    spawn_amounts.append(spawn)","for e_target in zip(adjusted_fitness, previous_sizes):
    ps = e_target[1]
    af = e_target[0]
    if af_sum > 0:
        s = max(min_species_size, af / af_sum * pop_size)
    else:
        s = min_species_size
    d = (s - ps) * 0.5
    c = int(round(d))
    spawn = ps
    if abs(c) > 0:
        spawn += c
    elif d > 0:
        spawn += 1
    elif d < 0:
        spawn -= 1
    spawn_amounts.append(spawn)

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_reproduction.py', 'tests.test_reproduction', 'TestSpawnComputation', 'test_spawn_adjust3'], ['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_reproduction.py', 'tests.test_reproduction', 'TestSpawnComputation', 'test_spawn_adjust2'], ['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_reproduction.py', 'tests.test_reproduction', 'TestSpawnComputation', 'test_spawn_adjust1']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/graphs.py,,test_creates_cycle,"for (a, b) in connections:
    if a in visited and b not in visited:
        if b == i:
            return True
        visited.add(b)
        num_added += 1","for e_target in connections:
    b = e_target[1]
    a = e_target[0]
    if a in visited and b not in visited:
        if b == i:
            return True
        visited.add(b)
        num_added += 1

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_graphs.py', 'tests.test_graphs', '', 'test_creates_cycle']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/nn/feed_forward.py,,test_basic,"for (k, v) in zip(self.input_nodes, inputs):
    self.values[k] = v","for e_target in zip(self.input_nodes, inputs):
    v = e_target[1]
    k = e_target[0]
    self.values[k] = v

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_feedforward_network.py', 'tests.test_feedforward_network', '', 'test_unconnected'], ['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_feedforward_network.py', 'tests.test_feedforward_network', '', 'test_basic']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/nn/feed_forward.py,,test_basic,"for (node, act_func, agg_func, bias, response, links) in self.node_evals:
    node_inputs = []
    for (i, w) in links:
        node_inputs.append(self.values[i] * w)
    s = agg_func(node_inputs)
    self.values[node] = act_func(bias + response * s)","for e_target in self.node_evals:
    links = e_target[5]
    response = e_target[4]
    bias = e_target[3]
    agg_func = e_target[2]
    act_func = e_target[1]
    node = e_target[0]
    node_inputs = []
    for (i, w) in links:
        node_inputs.append(self.values[i] * w)
    s = agg_func(node_inputs)
    self.values[node] = act_func(bias + response * s)

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_feedforward_network.py', 'tests.test_feedforward_network', '', 'test_unconnected'], ['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_feedforward_network.py', 'tests.test_feedforward_network', '', 'test_basic']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/nn/feed_forward.py,,test_basic,"for (i, w) in links:
    node_inputs.append(self.values[i] * w)","for e_target in links:
    w = e_target[1]
    i = e_target[0]
    node_inputs.append(self.values[i] * w)

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_feedforward_network.py', 'tests.test_feedforward_network', '', 'test_unconnected'], ['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_feedforward_network.py', 'tests.test_feedforward_network', '', 'test_basic']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/nn/recurrent.py,,test_basic,"for (i, v) in zip(self.input_nodes, inputs):
    ivalues[i] = v
    ovalues[i] = v","for e_target in zip(self.input_nodes, inputs):
    v = e_target[1]
    i = e_target[0]
    ivalues[i] = v
    ovalues[i] = v

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_recurrent_network.py', 'tests.test_recurrent_network', '', 'test_unconnected'], ['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_recurrent_network.py', 'tests.test_recurrent_network', '', 'test_basic']]"
neat-python,https://github.com/CodeReclaimers/neat-python/tree/master/neat/nn/recurrent.py,,test_basic,"for (node, activation, aggregation, bias, response, links) in self.node_evals:
    node_inputs = [ivalues[i] * w for (i, w) in links]
    s = aggregation(node_inputs)
    ovalues[node] = activation(bias + response * s)","for e_target in self.node_evals:
    links = e_target[5]
    response = e_target[4]
    bias = e_target[3]
    aggregation = e_target[2]
    activation = e_target[1]
    node = e_target[0]
    node_inputs = [ivalues[i] * w for (i, w) in links]
    s = aggregation(node_inputs)
    ovalues[node] = activation(bias + response * s)

",1,"[['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_recurrent_network.py', 'tests.test_recurrent_network', '', 'test_unconnected'], ['https://github.com/CodeReclaimers/neat-python/tree/master/tests/test_recurrent_network.py', 'tests.test_recurrent_network', '', 'test_basic']]"
flow-forecast,https://github.com/AIStream-Peelout/flow-forecast/tree/master/flood_forecast/preprocessing/temporal_feats.py,TestInterpolationCode,test_make_temp_feats,"for (key, value) in preprocess_params['datetime_params'].items():
    df = create_feature(key, value, df, dt_column)
    if value == 'cyclical':
        column_names.append('cos_' + key)
        column_names.append('sin_' + key)
    else:
        column_names.append(key)","for e_target in preprocess_params['datetime_params'].items():
    value = e_target[1]
    key = e_target[0]
    df = create_feature(key, value, df, dt_column)
    if value == 'cyclical':
        column_names.append('cos_' + key)
        column_names.append('sin_' + key)
    else:
        column_names.append(key)

",1,"[['https://github.com/AIStream-Peelout/flow-forecast/tree/master/tests/test_preprocessing.py', 'tests.test_preprocessing', 'TestInterpolationCode', 'test_make_temp_feats2'], ['https://github.com/AIStream-Peelout/flow-forecast/tree/master/tests/test_preprocessing.py', 'tests.test_preprocessing', 'TestInterpolationCode', 'test_make_temp_feats']]"
youtube-dl,https://github.com/lrvick/youtube-dl/tree/master/test/helper.py,TestInfoExtractor,test_parse_xspf,"for (index, (item_got, item_expected)) in enumerate(zip(got, expected)):
    type_got = type(item_got)
    type_expected = type(item_expected)
    self.assertEqual(type_expected, type_got, 'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (index, field, type_expected, type_got))
    expect_value(self, item_got, item_expected, field)","for e_target in enumerate(zip(got, expected)):
    item_expected = e_target[1][1]
    item_got = e_target[1][0]
    index = e_target[0]
    type_got = type(item_got)
    type_expected = type(item_expected)
    self.assertEqual(type_expected, type_got, 'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (index, field, type_expected, type_got))
    expect_value(self, item_got, item_expected, field)

",1,"[['https://github.com/lrvick/youtube-dl/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_mpd_formats'], ['https://github.com/lrvick/youtube-dl/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_m3u8_formats'], ['https://github.com/lrvick/youtube-dl/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_f4m_formats'], ['https://github.com/lrvick/youtube-dl/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_xspf']]"
youtube-dl,https://github.com/lrvick/youtube-dl/tree/master/youtube_dl/utils.py,TestUtil,test_sanitize_url,"for (mistake, fixup) in COMMON_TYPOS:
    if re.match(mistake, url):
        return re.sub(mistake, fixup, url)","for e_target in COMMON_TYPOS:
    fixup = e_target[1]
    mistake = e_target[0]
    if re.match(mistake, url):
        return re.sub(mistake, fixup, url)

",1,"[['https://github.com/lrvick/youtube-dl/tree/master/test/test_utils.py', 'test.test_utils', 'TestUtil', 'test_sanitize_url']]"
youtube-dl,https://github.com/lrvick/youtube-dl/tree/master/youtube_dl/options.py,TestOptions,test_hide_login_info,"for (idx, opt) in enumerate(opts):
    if opt in PRIVATE_OPTS and idx + 1 < len(opts):
        opts[idx + 1] = 'PRIVATE'","for e_target in enumerate(opts):
    opt = e_target[1]
    idx = e_target[0]
    if opt in PRIVATE_OPTS and idx + 1 < len(opts):
        opts[idx + 1] = 'PRIVATE'

",1,"[['https://github.com/lrvick/youtube-dl/tree/master/test/test_options.py', 'test.test_options', 'TestOptions', 'test_hide_login_info']]"
youtube-dl,https://github.com/lrvick/youtube-dl/tree/master/youtube_dl/compat.py,TestUtil,test_update_url_query,"for (name, value) in pairs:
    if name in parsed_result:
        parsed_result[name].append(value)
    else:
        parsed_result[name] = [value]","for e_target in pairs:
    value = e_target[1]
    name = e_target[0]
    if name in parsed_result:
        parsed_result[name].append(value)
    else:
        parsed_result[name] = [value]

",1,"[['https://github.com/lrvick/youtube-dl/tree/master/test/test_utils.py', 'test.test_utils', 'TestUtil', 'test_update_url_query']]"
cantools,https://github.com/cantools/cantools/tree/master/cantools/subparsers/plot.py,CanToolsPlotUnittests,test_parse_user_input_absolute_time,"for (attrs, patterns) in [(['year', 'month', 'day', 'hour', 'minute'], patterns_second), (['year', 'month', 'day', 'hour'], patterns_minute), (['year', 'month', 'day'], patterns_hour), (['year', 'month'], patterns_day), (['year'], patterns_month), ([], patterns_year)]:
    for p in patterns:
        try:
            out = datetime.datetime.strptime(user_input, p)
        except ValueError:
            pass
        else:
            kw = {a: getattr(first_timestamp, a) for a in attrs}
            out = out.replace(**kw)
            return out","for e_target in [(['year', 'month', 'day', 'hour', 'minute'], patterns_second), (['year', 'month', 'day', 'hour'], patterns_minute), (['year', 'month', 'day'], patterns_hour), (['year', 'month'], patterns_day), (['year'], patterns_month), ([], patterns_year)]:
    patterns = e_target[1]
    attrs = e_target[0]
    for p in patterns:
        try:
            out = datetime.datetime.strptime(user_input, p)
        except ValueError:
            pass
        else:
            kw = {a: getattr(first_timestamp, a) for a in attrs}
            out = out.replace(**kw)
            return out

",1,"[['https://github.com/cantools/cantools/tree/master/tests/test_plot_unittests.py', 'tests.test_plot_unittests', 'CanToolsPlotUnittests', 'test_parse_user_input_absolute_time_invalid_input'], ['https://github.com/cantools/cantools/tree/master/tests/test_plot_unittests.py', 'tests.test_plot_unittests', 'CanToolsPlotUnittests', 'test_parse_user_input_absolute_time_output_formats'], ['https://github.com/cantools/cantools/tree/master/tests/test_plot_unittests.py', 'tests.test_plot_unittests', 'CanToolsPlotUnittests', 'test_parse_user_input_absolute_time']]"
cantools,https://github.com/cantools/cantools/tree/master/cantools/subparsers/dump/formatting.py,CanToolsDumpTest,test_multiplex_choices,"for (index, multiplexed_signal) in enumerate(multiplexed_signals):
    (multiplexer_id, signal_names) = multiplexed_signal
    lines.append('+-- {}'.format(multiplexer_id))
    lines += add_prefix(get_prefix(index, len(multiplexed_signals)), format_level_lines(signal_names))","for e_target in enumerate(multiplexed_signals):
    multiplexed_signal = e_target[1]
    index = e_target[0]
    (multiplexer_id, signal_names) = multiplexed_signal
    lines.append('+-- {}'.format(multiplexer_id))
    lines += add_prefix(get_prefix(index, len(multiplexed_signals)), format_level_lines(signal_names))

",1,"[['https://github.com/cantools/cantools/tree/master/tests/test_dump.py', 'tests.test_dump', 'CanToolsDumpTest', 'test_multiplex'], ['https://github.com/cantools/cantools/tree/master/tests/test_dump.py', 'tests.test_dump', 'CanToolsDumpTest', 'test_the_homer'], ['https://github.com/cantools/cantools/tree/master/tests/test_dump.py', 'tests.test_dump', 'CanToolsDumpTest', 'test_multiplex_extended'], ['https://github.com/cantools/cantools/tree/master/tests/test_dump.py', 'tests.test_dump', 'CanToolsDumpTest', 'test_multiplex_choices']]"
cantools,https://github.com/cantools/cantools/tree/master/cantools/subparsers/dump/formatting.py,CanToolsDumpTest,test_multiplex_choices,"for (index, signal_name) in enumerate(signal_names):
    if isinstance(signal_name, dict):
        (signal_name_line, signal_lines) = format_mux(signal_name)
        signal_lines = add_prefix(get_prefix(index, len(signal_names)), signal_lines)
    else:
        signal_name_line = format_signal_line(signal_name)
        signal_lines = []
    lines.append(signal_name_line)
    lines += signal_lines","for e_target in enumerate(signal_names):
    signal_name = e_target[1]
    index = e_target[0]
    if isinstance(signal_name, dict):
        (signal_name_line, signal_lines) = format_mux(signal_name)
        signal_lines = add_prefix(get_prefix(index, len(signal_names)), signal_lines)
    else:
        signal_name_line = format_signal_line(signal_name)
        signal_lines = []
    lines.append(signal_name_line)
    lines += signal_lines

",1,"[['https://github.com/cantools/cantools/tree/master/tests/test_dump.py', 'tests.test_dump', 'CanToolsDumpTest', 'test_multiplex'], ['https://github.com/cantools/cantools/tree/master/tests/test_dump.py', 'tests.test_dump', 'CanToolsDumpTest', 'test_the_homer'], ['https://github.com/cantools/cantools/tree/master/tests/test_dump.py', 'tests.test_dump', 'CanToolsDumpTest', 'test_multiplex_extended'], ['https://github.com/cantools/cantools/tree/master/tests/test_dump.py', 'tests.test_dump', 'CanToolsDumpTest', 'test_multiplex_choices']]"
scikit-plot,https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/metrics.py,TestPlotConfusionMatrix,test_string_classes,"for (i, j) in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    if not (hide_zeros and cm[i, j] == 0):
        ax.text(j, i, cm[i, j], horizontalalignment='center', verticalalignment='center', fontsize=text_fontsize, color='white' if cm[i, j] > thresh else 'black')","for e_target in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    j = e_target[1]
    i = e_target[0]
    if not (hide_zeros and cm[i, j] == 0):
        ax.text(j, i, cm[i, j], horizontalalignment='center', verticalalignment='center', fontsize=text_fontsize, color='white' if cm[i, j] > thresh else 'black')

",1,"[['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_metrics.py', 'scikitplot.tests.test_metrics', 'TestPlotConfusionMatrix', 'test_true_pred_labels'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_metrics.py', 'scikitplot.tests.test_metrics', 'TestPlotConfusionMatrix', 'test_labels'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_metrics.py', 'scikitplot.tests.test_metrics', 'TestPlotConfusionMatrix', 'test_normalize'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_metrics.py', 'scikitplot.tests.test_metrics', 'TestPlotConfusionMatrix', 'test_array_like'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_metrics.py', 'scikitplot.tests.test_metrics', 'TestPlotConfusionMatrix', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_metrics.py', 'scikitplot.tests.test_metrics', 'TestPlotConfusionMatrix', 'test_hide_counts'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_metrics.py', 'scikitplot.tests.test_metrics', 'TestPlotConfusionMatrix', 'test_cmap'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_metrics.py', 'scikitplot.tests.test_metrics', 'TestPlotConfusionMatrix', 'test_string_classes']]"
scikit-plot,https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/classifiers.py,TestFeatureImportances,test_string_classes,"for (key, fn) in six.iteritems(additional_methods):
    if hasattr(clf, key):
        warnings.warn('""{}"" method already in clf. Overriding anyway. This may result in unintended behavior.'.format(key))
    setattr(clf, key, types.MethodType(fn, clf))","for e_target in six.iteritems(additional_methods):
    fn = e_target[1]
    key = e_target[0]
    if hasattr(clf, key):
        warnings.warn('""{}"" method already in clf. Overriding anyway. This may result in unintended behavior.'.format(key))
    setattr(clf, key, types.MethodType(fn, clf))

",1,"[['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotROCCurve', 'test_do_cv'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotPrecisionRecall', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotROCCurve', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotKSStatistic', 'test_do_cv'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_shuffle'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotPrecisionRecall', 'test_do_cv'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotKSStatistic', 'test_predict_proba'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_cv'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestFeatureImportances', 'test_feature_importances_in_clf'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestFeatureImportances', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotPrecisionRecall', 'test_cmap'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotKSStatistic', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_do_cv'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_normalize'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotROCCurve', 'test_curve_diffs'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotLearningCurve', 'test_n_jobs'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotPrecisionRecall', 'test_string_classes'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_labels'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_string_classes'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_cmap'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_true_pred_labels'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotLearningCurve', 'test_cv'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotROCCurve', 'test_cmap'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestFeatureImportances', 'test_feature_names'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestFeatureImportances', 'test_order'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotROCCurve', 'test_invalid_curve_arg'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestClassifierFactory', 'test_method_insertion'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotKSStatistic', 'test_two_classes'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotLearningCurve', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestClassifierFactory', 'test_instance_validation'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotLearningCurve', 'test_string_classes'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotPrecisionRecall', 'test_curve_diffs'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotPrecisionRecall', 'test_invalid_curve_arg'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotLearningCurve', 'test_train_sizes'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotROCCurve', 'test_predict_proba'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotROCCurve', 'test_string_classes'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestFeatureImportances', 'test_max_num_features'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotKSStatistic', 'test_string_classes'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotPrecisionRecall', 'test_predict_proba'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestFeatureImportances', 'test_string_classes']]"
scikit-plot,https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/decomposition.py,TestPlotPCA2DProjection,test_cmap,"for (label, color) in zip(classes, colors):
    ax.scatter(transformed_X[y == label, 0], transformed_X[y == label, 1], alpha=0.8, lw=2, label=label, color=color)","for e_target in zip(classes, colors):
    color = e_target[1]
    label = e_target[0]
    ax.scatter(transformed_X[y == label, 0], transformed_X[y == label, 1], alpha=0.8, lw=2, label=label, color=color)

",1,"[['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_decomposition.py', 'scikitplot.tests.test_decomposition', 'TestPlotPCA2DProjection', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_decomposition.py', 'scikitplot.tests.test_decomposition', 'TestPlotPCA2DProjection', 'test_biplot'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_decomposition.py', 'scikitplot.tests.test_decomposition', 'TestPlotPCA2DProjection', 'test_cmap']]"
scikit-plot,https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/clustering.py,TestClassifierFactory,test_instance_validation,"for (key, fn) in six.iteritems(additional_methods):
    if hasattr(clf, key):
        warnings.warn('""{}"" method already in clf. Overriding anyway. This may result in unintended behavior.'.format(key))
    setattr(clf, key, types.MethodType(fn, clf))","for e_target in six.iteritems(additional_methods):
    fn = e_target[1]
    key = e_target[0]
    if hasattr(clf, key):
        warnings.warn('""{}"" method already in clf. Overriding anyway. This may result in unintended behavior.'.format(key))
    setattr(clf, key, types.MethodType(fn, clf))

",1,"[['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_clustering.py', 'scikitplot.tests.test_clustering', 'TestPlotSilhouette', 'test_copy'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_clustering.py', 'scikitplot.tests.test_clustering', 'TestPlotElbow', 'test_cluster_ranges'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_clustering.py', 'scikitplot.tests.test_clustering', 'TestPlotElbow', 'test_n_clusters_in_clf'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_clustering.py', 'scikitplot.tests.test_clustering', 'TestPlotElbow', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_clustering.py', 'scikitplot.tests.test_clustering', 'TestPlotSilhouette', 'test_ax'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_clustering.py', 'scikitplot.tests.test_clustering', 'TestPlotSilhouette', 'test_cmap'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_clustering.py', 'scikitplot.tests.test_clustering', 'TestClassifierFactory', 'test_method_insertion'], ['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_clustering.py', 'scikitplot.tests.test_clustering', 'TestClassifierFactory', 'test_instance_validation']]"
scikit-plot,https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/plotters.py,TestPlotConfusionMatrix,test_array_like,"for (i, j) in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    if not (hide_zeros and cm[i, j] == 0):
        ax.text(j, i, cm[i, j], horizontalalignment='center', verticalalignment='center', fontsize=text_fontsize, color='white' if cm[i, j] > thresh else 'black')","for e_target in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    j = e_target[1]
    i = e_target[0]
    if not (hide_zeros and cm[i, j] == 0):
        ax.text(j, i, cm[i, j], horizontalalignment='center', verticalalignment='center', fontsize=text_fontsize, color='white' if cm[i, j] > thresh else 'black')

",1,"[['https://github.com/reiinakano/scikit-plot/tree/master/scikitplot/tests/test_classifiers.py', 'scikitplot.tests.test_classifiers', 'TestPlotConfusionMatrix', 'test_array_like']]"
python-bitcoinlib,https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/fakebitcoinproxy.py,FakeBitcoinProxyTestCase,test_getblockhash_many,"for (height, blockhash) in enumerate(blockhashes):
    block = {'hash': blockhash, 'height': height, 'tx': []}
    if height != 0:
        block['previousblockhash'] = previousblockhash
    blocks.append(block)
    previousblockhash = blockhash","for e_target in enumerate(blockhashes):
    blockhash = e_target[1]
    height = e_target[0]
    block = {'hash': blockhash, 'height': height, 'tx': []}
    if height != 0:
        block['previousblockhash'] = previousblockhash
    blocks.append(block)
    previousblockhash = blockhash

",1,"[['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test_make_blocks_from_blockhashes_empty'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test_make_blocks_from_blockhashes'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test_getblockhash_many']]"
python-bitcoinlib,https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/fakebitcoinproxy.py,FakeBitcoinProxyTestCase,test__batch_raises_when_no_params,"for (idx, request) in enumerate(batch_request_entries):
    error = None
    result = None
    for necessary_key in necessary_keys:
        if not necessary_key in request.keys():
            raise FakeBitcoinProxyException('Missing necessary key {} for _batch request number {}'.format(necessary_key, idx))
    if isinstance(request['params'], list):
        method = getattr(self, request['method'])
        result = method(*request['params'])
    else:
        error = {'message': 'Params must be an array', 'code': -32600}
    results.append({'error': error, 'id': request['id'], 'result': result})","for e_target in enumerate(batch_request_entries):
    request = e_target[1]
    idx = e_target[0]
    error = None
    result = None
    for necessary_key in necessary_keys:
        if not necessary_key in request.keys():
            raise FakeBitcoinProxyException('Missing necessary key {} for _batch request number {}'.format(necessary_key, idx))
    if isinstance(request['params'], list):
        method = getattr(self, request['method'])
        result = method(*request['params'])
    else:
        error = {'message': 'Params must be an array', 'code': -32600}
    results.append({'error': error, 'id': request['id'], 'result': result})

",1,"[['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test__batch_result_error_is_none'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test__batch_getblockhash_many'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test__batch_empty_list_input'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test__batch_result_keys'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test__batch_gives_reasonable_getblockcount_result'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test__batch_same_count_results_as_requests'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test__batch_returns_error_when_given_invalid_params'], ['https://github.com/petertodd/python-bitcoinlib/tree/master/bitcoin/tests/test_fakebitcoinproxy.py', 'bitcoin.tests.test_fakebitcoinproxy', 'FakeBitcoinProxyTestCase', 'test__batch_raises_when_no_params']]"
pint,https://github.com/hgrecco/pint/tree/master/pint/util.py,TestPiTheorem,test_simple,"for (name, value) in quantities.items():
    if isinstance(value, str):
        value = ParserHelper.from_string(value, non_int_type=non_int_type)
    if isinstance(value, dict):
        dims = getdim(registry.UnitsContainer(value))
    elif not hasattr(value, 'dimensionality'):
        dims = getdim(value)
    else:
        dims = value.dimensionality
    if not registry and any((not key.startswith('[') for key in dims)):
        logger.warning('A non dimension was found and a registry was not provided. Assuming that it is a dimension name: {}.'.format(dims))
    quant.append((name, dims))
    dimensions = dimensions.union(dims.keys())","for e_target in quantities.items():
    value = e_target[1]
    name = e_target[0]
    if isinstance(value, str):
        value = ParserHelper.from_string(value, non_int_type=non_int_type)
    if isinstance(value, dict):
        dims = getdim(registry.UnitsContainer(value))
    elif not hasattr(value, 'dimensionality'):
        dims = getdim(value)
    else:
        dims = value.dimensionality
    if not registry and any((not key.startswith('[') for key in dims)):
        logger.warning('A non dimension was found and a registry was not provided. Assuming that it is a dimension name: {}.'.format(dims))
    quant.append((name, dims))
    dimensions = dimensions.union(dims.keys())

",1,"[['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_pitheorem.py', 'pint.testsuite.test_pitheorem', 'TestPiTheorem', 'test_simple']]"
pint,https://github.com/hgrecco/pint/tree/master/pint/util.py,TestPiTheorem,test_simple,"for (rowm, rowi) in zip(M, identity):
    if any((el != 0 for el in rowm)):
        continue
    max_den = max((f.denominator for f in rowi))
    neg = -1 if sum((f < 0 for f in rowi)) > sum((f > 0 for f in rowi)) else 1
    results.append(dict(((q[0], neg * f.numerator * max_den / f.denominator) for (q, f) in zip(quant, rowi) if f.numerator != 0)))","for e_target in zip(M, identity):
    rowi = e_target[1]
    rowm = e_target[0]
    if any((el != 0 for el in rowm)):
        continue
    max_den = max((f.denominator for f in rowi))
    neg = -1 if sum((f < 0 for f in rowi)) > sum((f > 0 for f in rowi)) else 1
    results.append(dict(((q[0], neg * f.numerator * max_den / f.denominator) for (q, f) in zip(quant, rowi) if f.numerator != 0)))

",1,"[['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_pitheorem.py', 'pint.testsuite.test_pitheorem', 'TestPiTheorem', 'test_simple']]"
pint,https://github.com/hgrecco/pint/tree/master/pint/formatting.py,TestFormatter,test_formatter,"for (key, value) in items:
    if locale and babel_length and babel_plural_form and (key in _babel_units):
        _key = _babel_units[key]
        locale = babel_parse(locale)
        unit_patterns = locale._data['unit_patterns']
        compound_unit_patterns = locale._data['compound_unit_patterns']
        plural = 'one' if abs(value) <= 0 else babel_plural_form
        if babel_length not in _babel_lengths:
            other_lengths = [_babel_length for _babel_length in reversed(_babel_lengths) if babel_length != _babel_length]
        else:
            other_lengths = []
        for _babel_length in [babel_length] + other_lengths:
            pat = unit_patterns.get(_key, {}).get(_babel_length, {}).get(plural)
            if pat is not None:
                key = pat.replace('{0}', '').strip()
                break
        division_fmt = compound_unit_patterns.get('per', {}).get(babel_length, division_fmt)
        power_fmt = '{}{}'
        exp_call = _pretty_fmt_exponent
    if value == 1:
        pos_terms.append(key)
    elif value > 0:
        pos_terms.append(power_fmt.format(key, fun(value)))
    elif value == -1 and as_ratio:
        neg_terms.append(key)
    else:
        neg_terms.append(power_fmt.format(key, fun(value)))","for e_target in items:
    value = e_target[1]
    key = e_target[0]
    if locale and babel_length and babel_plural_form and (key in _babel_units):
        _key = _babel_units[key]
        locale = babel_parse(locale)
        unit_patterns = locale._data['unit_patterns']
        compound_unit_patterns = locale._data['compound_unit_patterns']
        plural = 'one' if abs(value) <= 0 else babel_plural_form
        if babel_length not in _babel_lengths:
            other_lengths = [_babel_length for _babel_length in reversed(_babel_lengths) if babel_length != _babel_length]
        else:
            other_lengths = []
        for _babel_length in [babel_length] + other_lengths:
            pat = unit_patterns.get(_key, {}).get(_babel_length, {}).get(plural)
            if pat is not None:
                key = pat.replace('{0}', '').strip()
                break
        division_fmt = compound_unit_patterns.get('per', {}).get(babel_length, division_fmt)
        power_fmt = '{}{}'
        exp_call = _pretty_fmt_exponent
    if value == 1:
        pos_terms.append(key)
    elif value > 0:
        pos_terms.append(power_fmt.format(key, fun(value)))
    elif value == -1 and as_ratio:
        neg_terms.append(key)
    else:
        neg_terms.append(power_fmt.format(key, fun(value)))

",1,"[['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_formatter.py', 'pint.testsuite.test_formatter', 'TestFormatter', 'test_formatter']]"
pint,https://github.com/hgrecco/pint/tree/master/pint/context.py,,test_err_dimension_redefinition,"for (lineno, line) in lines:
    if '=' in line:
        ctx.redefine(line)
        continue
    try:
        (rel, eq) = line.split(':')
        names.update(_varname_re.findall(eq))
        func = _expression_to_function(eq)
        if '<->' in rel:
            (src, dst) = (ParserHelper.from_string(s, non_int_type) for s in rel.split('<->'))
            if to_base_func:
                src = to_base_func(src)
                dst = to_base_func(dst)
            ctx.add_transformation(src, dst, func)
            ctx.add_transformation(dst, src, func)
        elif '->' in rel:
            (src, dst) = (ParserHelper.from_string(s, non_int_type) for s in rel.split('->'))
            if to_base_func:
                src = to_base_func(src)
                dst = to_base_func(dst)
            ctx.add_transformation(src, dst, func)
        else:
            raise Exception
    except Exception as exc:
        raise DefinitionSyntaxError(""Could not parse Context %s relation '%s'"" % (name, line), lineno=lineno) from exc","for e_target in lines:
    line = e_target[1]
    lineno = e_target[0]
    if '=' in line:
        ctx.redefine(line)
        continue
    try:
        (rel, eq) = line.split(':')
        names.update(_varname_re.findall(eq))
        func = _expression_to_function(eq)
        if '<->' in rel:
            (src, dst) = (ParserHelper.from_string(s, non_int_type) for s in rel.split('<->'))
            if to_base_func:
                src = to_base_func(src)
                dst = to_base_func(dst)
            ctx.add_transformation(src, dst, func)
            ctx.add_transformation(dst, src, func)
        elif '->' in rel:
            (src, dst) = (ParserHelper.from_string(s, non_int_type) for s in rel.split('->'))
            if to_base_func:
                src = to_base_func(src)
                dst = to_base_func(dst)
            ctx.add_transformation(src, dst, func)
        else:
            raise Exception
    except Exception as exc:
        raise DefinitionSyntaxError(""Could not parse Context %s relation '%s'"" % (name, line), lineno=lineno) from exc

",1,"[['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_contexts.py', 'pint.testsuite.test_contexts', 'TestContexts', 'test_parse_parameterized'], ['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_issues.py', 'pint.testsuite.test_issues', 'TestIssues', 'test_issue1062_issue1097'], ['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_contexts.py', 'pint.testsuite.test_contexts', 'TestContexts', 'test_parse_simple'], ['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_contexts.py', 'pint.testsuite.test_contexts', '', 'test_err_to_base_unit'], ['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_contexts.py', 'pint.testsuite.test_contexts', 'TestContexts', 'test_parse_auto_inverse'], ['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_contexts.py', 'pint.testsuite.test_contexts', 'TestContexts', 'test_parse_define'], ['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_contexts.py', 'pint.testsuite.test_contexts', '', 'test_err_prefix_redefinition'], ['https://github.com/hgrecco/pint/tree/master/pint/testsuite/test_contexts.py', 'pint.testsuite.test_contexts', '', 'test_err_dimension_redefinition']]"
qark,https://github.com/linkedin/qark/tree/master/qark/plugins/manifest/task_reparenting.py,,test_vulnerable_allow_backup,"for (line_number, line) in enumerate(manifest_file):
    if 'android:allowTaskReparenting=""true""' in line:
        self.issues.append(Issue(category=self.category, severity=self.severity, name=self.name, description=self.description, file_object=self.manifest_path, line_number=line_number))","for e_target in enumerate(manifest_file):
    line = e_target[1]
    line_number = e_target[0]
    if 'android:allowTaskReparenting=""true""' in line:
        self.issues.append(Issue(category=self.category, severity=self.severity, name=self.name, description=self.description, file_object=self.manifest_path, line_number=line_number))

",1,"[['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_custom_permission_vulnerable'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_custom_permission_nonvulnerable'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_android_path'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_single_task_launch_mode'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_vulnerable_exported_tags'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_task_reparenting'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_debuggable_vulnerable'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_debuggable_nonvulnerable'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_nonvulnerable_allow_backup'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_api_keys'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_manifest_plugins/test_manifest_plugins.py', 'tests.test_plugins.test_manifest_plugins.test_manifest_plugins', '', 'test_vulnerable_allow_backup']]"
qark,https://github.com/linkedin/qark/tree/master/qark/plugins/file/api_keys.py,,test_insecure_functions,"for (line_number, line) in enumerate(self.file_contents.split('\n')):
    for word in line.split():
        if re.search(API_KEY_REGEX, word) and (not re.search(SPECIAL_CHARACTER_REGEX, word)):
            self.issues.append(Issue(category=self.category, severity=self.severity, name=self.name, description=self.description, file_object=self.file_path, line_number=(line_number, 0)))","for e_target in enumerate(self.file_contents.split('\n')):
    line = e_target[1]
    line_number = e_target[0]
    for word in line.split():
        if re.search(API_KEY_REGEX, word) and (not re.search(SPECIAL_CHARACTER_REGEX, word)):
            self.issues.append(Issue(category=self.category, severity=self.severity, name=self.name, description=self.description, file_object=self.file_path, line_number=(line_number, 0)))

",1,"[['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_file_plugins/test_file_plugins.py', 'tests.test_plugins.test_file_plugins.test_file_plugins', '', 'test_http_url_hardcoded'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_file_plugins/test_file_plugins.py', 'tests.test_plugins.test_file_plugins.test_file_plugins', '', 'test_android_logging'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_file_plugins/test_file_plugins.py', 'tests.test_plugins.test_file_plugins.test_file_plugins', '', 'test_phone_identifier'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_file_plugins/test_file_plugins.py', 'tests.test_plugins.test_file_plugins.test_file_plugins', '', 'test_api_keys'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_file_plugins/test_file_plugins.py', 'tests.test_plugins.test_file_plugins.test_file_plugins', '', 'test_external_storage'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_file_plugins/test_file_plugins.py', 'tests.test_plugins.test_file_plugins.test_file_plugins', '', 'test_file_permissions'], ['https://github.com/linkedin/qark/tree/master/tests/test_plugins/test_file_plugins/test_file_plugins.py', 'tests.test_plugins.test_file_plugins.test_file_plugins', '', 'test_insecure_functions']]"
pyowm,https://github.com/csparpa/pyowm/tree/master/pyowm/weatherapi25/weather.py,TestWeather,test_from_dict,"for (label, temp) in feels_like.items():
    temperature[f'feels_like_{label}'] = temp","for e_target in feels_like.items():
    temp = e_target[1]
    label = e_target[0]
    temperature[f'feels_like_{label}'] = temp

",1,"[['https://github.com/csparpa/pyowm/tree/master/tests/unit/weatherapi25/test_weather.py', 'tests.unit.weatherapi25.test_weather', 'TestWeather', 'test_one_call_hourly_from_dic'], ['https://github.com/csparpa/pyowm/tree/master/tests/unit/weatherapi25/test_weather.py', 'tests.unit.weatherapi25.test_weather', 'TestWeather', 'test_one_call_daily_from_dic'], ['https://github.com/csparpa/pyowm/tree/master/tests/unit/weatherapi25/test_weather.py', 'tests.unit.weatherapi25.test_weather', 'TestWeather', 'test_from_dict_when_data_fields_are_none'], ['https://github.com/csparpa/pyowm/tree/master/tests/unit/weatherapi25/test_weather.py', 'tests.unit.weatherapi25.test_weather', 'TestWeather', 'test_one_call_current_from_dic'], ['https://github.com/csparpa/pyowm/tree/master/tests/unit/weatherapi25/test_weather.py', 'tests.unit.weatherapi25.test_weather', 'TestWeather', 'test_from_dict']]"
pyowm,https://github.com/csparpa/pyowm/tree/master/pyowm/utils/measurables.py,TestMeasurablesUtils,test_metric_wind_dict_to_imperial,"for (key, value) in d.items():
    if key != 'deg':
        result[key] = value * MILES_PER_HOUR_FOR_ONE_METER_PER_SEC
    else:
        result[key] = value","for e_target in d.items():
    value = e_target[1]
    key = e_target[0]
    if key != 'deg':
        result[key] = value * MILES_PER_HOUR_FOR_ONE_METER_PER_SEC
    else:
        result[key] = value

",1,"[['https://github.com/csparpa/pyowm/tree/master/tests/unit/utils/test_measurables.py', 'tests.unit.utils.test_measurables', 'TestMeasurablesUtils', 'test_metric_wind_dict_to_imperial']]"
subfinder,https://github.com/ausaki/subfinder/tree/master/subfinder/utils.py,,test_search_subs_by_subhd,"for (root, dirs, files) in os.walk(path):
    for f in files:
        (_, ext) = os.path.splitext(f)
        ext = ext[1:]
        if ext in sub_exts:
            p = os.path.join(root, f)
            count += 1
            print('Delete {}'.format(p))
            os.remove(p)","for e_target in os.walk(path):
    files = e_target[2]
    dirs = e_target[1]
    root = e_target[0]
    for f in files:
        (_, ext) = os.path.splitext(f)
        ext = ext[1:]
        if ext in sub_exts:
            p = os.path.join(root, f)
            count += 1
            print('Delete {}'.format(p))
            os.remove(p)

",1,"[['https://github.com/ausaki/subfinder/tree/master/tests/test_subfinder.py', 'tests.test_subfinder', '', 'test_search_subs_by_zimuku'], ['https://github.com/ausaki/subfinder/tree/master/tests/test_subfinder.py', 'tests.test_subfinder', '', 'test_search_subs_by_subhd']]"
subfinder,https://github.com/ausaki/subfinder/tree/master/subfinder/subfinder.py,,test_search_subs_by_subhd,"for (v, subs) in self._history.items():
    basename = os.path.basename(v)
    self.logger.info('{}: 下载 {} 个字幕'.format(basename, len(subs)))","for e_target in self._history.items():
    subs = e_target[1]
    v = e_target[0]
    basename = os.path.basename(v)
    self.logger.info('{}: 下载 {} 个字幕'.format(basename, len(subs)))

",1,"[['https://github.com/ausaki/subfinder/tree/master/tests/test_subfinder.py', 'tests.test_subfinder', '', 'test_search_subs_by_zimuku'], ['https://github.com/ausaki/subfinder/tree/master/tests/test_subfinder.py', 'tests.test_subfinder', '', 'test_search_subs_by_subhd']]"
Detectron,https://github.com/facebookresearch/Detectron/tree/master/detectron/core/config.py,TestCfg,test_merge_cfg_from_list,"for (full_key, v) in zip(cfg_list[0::2], cfg_list[1::2]):
    if _key_is_deprecated(full_key):
        continue
    if _key_is_renamed(full_key):
        _raise_key_rename_error(full_key)
    key_list = full_key.split('.')
    d = __C
    for subkey in key_list[:-1]:
        assert subkey in d, 'Non-existent key: {}'.format(full_key)
        d = d[subkey]
    subkey = key_list[-1]
    assert subkey in d, 'Non-existent key: {}'.format(full_key)
    value = _decode_cfg_value(v)
    value = _check_and_coerce_cfg_value_type(value, d[subkey], subkey, full_key)
    d[subkey] = value","for e_target in zip(cfg_list[0::2], cfg_list[1::2]):
    v = e_target[1]
    full_key = e_target[0]
    if _key_is_deprecated(full_key):
        continue
    if _key_is_renamed(full_key):
        _raise_key_rename_error(full_key)
    key_list = full_key.split('.')
    d = __C
    for subkey in key_list[:-1]:
        assert subkey in d, 'Non-existent key: {}'.format(full_key)
        d = d[subkey]
    subkey = key_list[-1]
    assert subkey in d, 'Non-existent key: {}'.format(full_key)
    value = _decode_cfg_value(v)
    value = _check_and_coerce_cfg_value_type(value, d[subkey], subkey, full_key)
    d[subkey] = value

",1,"[['https://github.com/facebookresearch/Detectron/tree/master/detectron/tests/test_cfg.py', 'detectron.tests.test_cfg', 'TestCfg', 'test_renamed_key_from_list'], ['https://github.com/facebookresearch/Detectron/tree/master/detectron/tests/test_cfg.py', 'detectron.tests.test_cfg', 'TestCfg', 'test_deprecated_key_from_list'], ['https://github.com/facebookresearch/Detectron/tree/master/detectron/tests/test_cfg.py', 'detectron.tests.test_cfg', 'TestCfg', 'test_merge_cfg_from_list']]"
Minecraft-Overviewer,https://github.com/overviewer/Minecraft-Overviewer/tree/master/contrib/contributors.py,TestContributors,test_merge_short_term_contributors,"for (i, line) in enumerate(contrib_file_lines):
    if not short_term_found:
        if 'Short-term' in line:
            short_term_found = True
    elif CONTRIB_FILE_CONTRIBUTOR_RE.search(line):
        break","for e_target in enumerate(contrib_file_lines):
    line = e_target[1]
    i = e_target[0]
    if not short_term_found:
        if 'Short-term' in line:
            short_term_found = True
    elif CONTRIB_FILE_CONTRIBUTOR_RE.search(line):
        break

",1,"[['https://github.com/overviewer/Minecraft-Overviewer/tree/master/test/test_contributors.py', 'test.test_contributors', 'TestContributors', 'test_merge_short_term_contributors']]"
flasgger,https://github.com/flasgger/flasgger/tree/master/flasgger/base.py,,test_custom_specs,"for (name, def_model) in self.get_def_models(spec.get('definition_filter')).items():
    (description, swag) = parse_definition_docstring(def_model, self.sanitizer)
    if name and swag:
        if description:
            swag.update({'description': description})
        definitions[name].update(swag)","for e_target in self.get_def_models(spec.get('definition_filter')).items():
    def_model = e_target[1]
    name = e_target[0]
    (description, swag) = parse_definition_docstring(def_model, self.sanitizer)
    if name and swag:
        if description:
            swag.update({'description': description})
        definitions[name].update(swag)

",1,"[['https://github.com/flasgger/flasgger/tree/master/tests/test_commands.py', 'tests.test_commands', '', 'test_default_specs'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_get_apispecs_with_valid_endpoint'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_get_apispecs_with_invalid_endpoint'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_commands.py', 'tests.test_commands', '', 'test_custom_specs']]"
flasgger,https://github.com/flasgger/flasgger/tree/master/flasgger/base.py,,test_custom_specs,"for (rule, verbs) in specs:
    operations = dict()
    for (verb, swag) in verbs:
        if is_openapi3(openapi_version):
            update_dict = swag.get('components', {}).get('schemas', {})
        else:
            update_dict = swag.get('definitions', {})
        if type(update_dict) == list and type(update_dict[0]) == dict:
            (update_dict,) = update_dict
        definitions.update(update_dict)
        defs = []
        defs += extract_definitions(defs, endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        params = swag.get('parameters', [])
        if verb in swag.keys():
            verb_swag = swag.get(verb)
            if len(params) == 0 and verb.lower() in http_methods:
                params = verb_swag.get('parameters', [])
        defs += extract_definitions(params, endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        request_body = swag.get('requestBody')
        if request_body:
            content = request_body.get('content', {})
            extract_definitions(list(content.values()), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        callbacks = swag.get('callbacks', {})
        if callbacks:
            callbacks = {str(key): value for (key, value) in callbacks.items()}
            extract_definitions(list(callbacks.values()), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        responses = None
        if 'responses' in swag:
            responses = swag.get('responses', {})
            responses = {str(key): value for (key, value) in responses.items()}
            if responses is not None:
                defs = defs + extract_definitions(responses.values(), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
            for definition in defs:
                if 'id' not in definition:
                    definitions.update(definition)
                    continue
                def_id = definition.pop('id')
                if def_id is not None:
                    definitions[def_id].update(definition)
        operation = {}
        if swag.get('summary'):
            operation['summary'] = swag.get('summary')
        if swag.get('description'):
            operation['description'] = swag.get('description')
        if request_body:
            operation['requestBody'] = request_body
        if callbacks:
            operation['callbacks'] = callbacks
        if responses:
            operation['responses'] = responses
        if len(params) > 0:
            operation['parameters'] = params
        for key in optional_fields:
            if key in swag:
                value = swag.get(key)
                if key in ('produces', 'consumes'):
                    if not isinstance(value, (list, tuple)):
                        value = [value]
                operation[key] = value
        operations[verb] = operation
    if len(operations):
        try:
            prefix = self.template['swaggerUiPrefix']
        except (KeyError, TypeError):
            prefix = ''
        srule = '{0}{1}'.format(prefix, rule)
        try:
            base_path = self.template['basePath']
            if base_path:
                if base_path.endswith('/'):
                    base_path = base_path[:-1]
                if base_path:
                    if srule.startswith(base_path):
                        srule = srule[len(base_path):]
        except (KeyError, TypeError):
            pass
        for arg in re.findall('(<([^<>]*:)?([^<>]*)>)', srule):
            srule = srule.replace(arg[0], '{%s}' % arg[2])
        for (key, val) in operations.items():
            if srule not in paths:
                paths[srule] = {}
            if key in paths[srule]:
                paths[srule][key].update(val)
            else:
                paths[srule][key] = val","for e_target in specs:
    verbs = e_target[1]
    rule = e_target[0]
    operations = dict()
    for (verb, swag) in verbs:
        if is_openapi3(openapi_version):
            update_dict = swag.get('components', {}).get('schemas', {})
        else:
            update_dict = swag.get('definitions', {})
        if type(update_dict) == list and type(update_dict[0]) == dict:
            (update_dict,) = update_dict
        definitions.update(update_dict)
        defs = []
        defs += extract_definitions(defs, endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        params = swag.get('parameters', [])
        if verb in swag.keys():
            verb_swag = swag.get(verb)
            if len(params) == 0 and verb.lower() in http_methods:
                params = verb_swag.get('parameters', [])
        defs += extract_definitions(params, endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        request_body = swag.get('requestBody')
        if request_body:
            content = request_body.get('content', {})
            extract_definitions(list(content.values()), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        callbacks = swag.get('callbacks', {})
        if callbacks:
            callbacks = {str(key): value for (key, value) in callbacks.items()}
            extract_definitions(list(callbacks.values()), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        responses = None
        if 'responses' in swag:
            responses = swag.get('responses', {})
            responses = {str(key): value for (key, value) in responses.items()}
            if responses is not None:
                defs = defs + extract_definitions(responses.values(), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
            for definition in defs:
                if 'id' not in definition:
                    definitions.update(definition)
                    continue
                def_id = definition.pop('id')
                if def_id is not None:
                    definitions[def_id].update(definition)
        operation = {}
        if swag.get('summary'):
            operation['summary'] = swag.get('summary')
        if swag.get('description'):
            operation['description'] = swag.get('description')
        if request_body:
            operation['requestBody'] = request_body
        if callbacks:
            operation['callbacks'] = callbacks
        if responses:
            operation['responses'] = responses
        if len(params) > 0:
            operation['parameters'] = params
        for key in optional_fields:
            if key in swag:
                value = swag.get(key)
                if key in ('produces', 'consumes'):
                    if not isinstance(value, (list, tuple)):
                        value = [value]
                operation[key] = value
        operations[verb] = operation
    if len(operations):
        try:
            prefix = self.template['swaggerUiPrefix']
        except (KeyError, TypeError):
            prefix = ''
        srule = '{0}{1}'.format(prefix, rule)
        try:
            base_path = self.template['basePath']
            if base_path:
                if base_path.endswith('/'):
                    base_path = base_path[:-1]
                if base_path:
                    if srule.startswith(base_path):
                        srule = srule[len(base_path):]
        except (KeyError, TypeError):
            pass
        for arg in re.findall('(<([^<>]*:)?([^<>]*)>)', srule):
            srule = srule.replace(arg[0], '{%s}' % arg[2])
        for (key, val) in operations.items():
            if srule not in paths:
                paths[srule] = {}
            if key in paths[srule]:
                paths[srule][key].update(val)
            else:
                paths[srule][key] = val

",1,"[['https://github.com/flasgger/flasgger/tree/master/tests/test_commands.py', 'tests.test_commands', '', 'test_default_specs'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_get_apispecs_with_valid_endpoint'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_get_apispecs_with_invalid_endpoint'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_commands.py', 'tests.test_commands', '', 'test_custom_specs']]"
flasgger,https://github.com/flasgger/flasgger/tree/master/flasgger/base.py,,test_custom_specs,"for (verb, swag) in verbs:
    if is_openapi3(openapi_version):
        update_dict = swag.get('components', {}).get('schemas', {})
    else:
        update_dict = swag.get('definitions', {})
    if type(update_dict) == list and type(update_dict[0]) == dict:
        (update_dict,) = update_dict
    definitions.update(update_dict)
    defs = []
    defs += extract_definitions(defs, endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
    params = swag.get('parameters', [])
    if verb in swag.keys():
        verb_swag = swag.get(verb)
        if len(params) == 0 and verb.lower() in http_methods:
            params = verb_swag.get('parameters', [])
    defs += extract_definitions(params, endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
    request_body = swag.get('requestBody')
    if request_body:
        content = request_body.get('content', {})
        extract_definitions(list(content.values()), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
    callbacks = swag.get('callbacks', {})
    if callbacks:
        callbacks = {str(key): value for (key, value) in callbacks.items()}
        extract_definitions(list(callbacks.values()), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
    responses = None
    if 'responses' in swag:
        responses = swag.get('responses', {})
        responses = {str(key): value for (key, value) in responses.items()}
        if responses is not None:
            defs = defs + extract_definitions(responses.values(), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        for definition in defs:
            if 'id' not in definition:
                definitions.update(definition)
                continue
            def_id = definition.pop('id')
            if def_id is not None:
                definitions[def_id].update(definition)
    operation = {}
    if swag.get('summary'):
        operation['summary'] = swag.get('summary')
    if swag.get('description'):
        operation['description'] = swag.get('description')
    if request_body:
        operation['requestBody'] = request_body
    if callbacks:
        operation['callbacks'] = callbacks
    if responses:
        operation['responses'] = responses
    if len(params) > 0:
        operation['parameters'] = params
    for key in optional_fields:
        if key in swag:
            value = swag.get(key)
            if key in ('produces', 'consumes'):
                if not isinstance(value, (list, tuple)):
                    value = [value]
            operation[key] = value
    operations[verb] = operation","for e_target in verbs:
    swag = e_target[1]
    verb = e_target[0]
    if is_openapi3(openapi_version):
        update_dict = swag.get('components', {}).get('schemas', {})
    else:
        update_dict = swag.get('definitions', {})
    if type(update_dict) == list and type(update_dict[0]) == dict:
        (update_dict,) = update_dict
    definitions.update(update_dict)
    defs = []
    defs += extract_definitions(defs, endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
    params = swag.get('parameters', [])
    if verb in swag.keys():
        verb_swag = swag.get(verb)
        if len(params) == 0 and verb.lower() in http_methods:
            params = verb_swag.get('parameters', [])
    defs += extract_definitions(params, endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
    request_body = swag.get('requestBody')
    if request_body:
        content = request_body.get('content', {})
        extract_definitions(list(content.values()), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
    callbacks = swag.get('callbacks', {})
    if callbacks:
        callbacks = {str(key): value for (key, value) in callbacks.items()}
        extract_definitions(list(callbacks.values()), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
    responses = None
    if 'responses' in swag:
        responses = swag.get('responses', {})
        responses = {str(key): value for (key, value) in responses.items()}
        if responses is not None:
            defs = defs + extract_definitions(responses.values(), endpoint=rule.endpoint, verb=verb, prefix_ids=prefix_ids, openapi_version=openapi_version)
        for definition in defs:
            if 'id' not in definition:
                definitions.update(definition)
                continue
            def_id = definition.pop('id')
            if def_id is not None:
                definitions[def_id].update(definition)
    operation = {}
    if swag.get('summary'):
        operation['summary'] = swag.get('summary')
    if swag.get('description'):
        operation['description'] = swag.get('description')
    if request_body:
        operation['requestBody'] = request_body
    if callbacks:
        operation['callbacks'] = callbacks
    if responses:
        operation['responses'] = responses
    if len(params) > 0:
        operation['parameters'] = params
    for key in optional_fields:
        if key in swag:
            value = swag.get(key)
            if key in ('produces', 'consumes'):
                if not isinstance(value, (list, tuple)):
                    value = [value]
            operation[key] = value
    operations[verb] = operation

",1,"[['https://github.com/flasgger/flasgger/tree/master/tests/test_commands.py', 'tests.test_commands', '', 'test_default_specs'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_get_apispecs_with_valid_endpoint'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_get_apispecs_with_invalid_endpoint'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_commands.py', 'tests.test_commands', '', 'test_custom_specs']]"
flasgger,https://github.com/flasgger/flasgger/tree/master/flasgger/base.py,,test_custom_specs,"for (key, val) in operations.items():
    if srule not in paths:
        paths[srule] = {}
    if key in paths[srule]:
        paths[srule][key].update(val)
    else:
        paths[srule][key] = val","for e_target in operations.items():
    val = e_target[1]
    key = e_target[0]
    if srule not in paths:
        paths[srule] = {}
    if key in paths[srule]:
        paths[srule][key].update(val)
    else:
        paths[srule][key] = val

",1,"[['https://github.com/flasgger/flasgger/tree/master/tests/test_commands.py', 'tests.test_commands', '', 'test_default_specs'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_get_apispecs_with_valid_endpoint'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_base.py', 'tests.test_base', '', 'test_get_apispecs_with_invalid_endpoint'], ['https://github.com/flasgger/flasgger/tree/master/tests/test_commands.py', 'tests.test_commands', '', 'test_custom_specs']]"
mobile-vision,https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/misc/iter_utils.py,TestIterUtils,test_recursive_iter_dict,"for (idx, x) in enumerate(obj):
    cur = (yield from recursive_iterate(x, iter_types, map_check_func, seq_check_func, wait_on_send, yield_name=yield_name, _name_prefix=_get_name_with_prefix(idx)))
    ret.append(cur)","for e_target in enumerate(obj):
    x = e_target[1]
    idx = e_target[0]
    cur = (yield from recursive_iterate(x, iter_types, map_check_func, seq_check_func, wait_on_send, yield_name=yield_name, _name_prefix=_get_name_with_prefix(idx)))
    ret.append(cur)

",1,"[['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_send_with_name'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_simple_no_wait_on_send'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_map_check_func'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_paired'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_send_None'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_dict_with_name'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_send'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_simple'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_seq_check_func'], ['https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/common/tests/test_iter_utils.py', 'mobile_cv.common.tests.test_iter_utils', 'TestIterUtils', 'test_recursive_iter_dict']]"
PyCNC,https://github.com/Nikolay-Kha/PyCNC/tree/master/cnc/hal_virtual.py,TestPulses,test_with_hal_virtual,"for (direction, tx, ty, tz, te) in generator:
    if direction:
        direction_found = True
        (direction_x, direction_y, direction_z, direction_e) = (tx, ty, tz, te)
        if STEPPER_INVERTED_X:
            direction_x = -direction_x
        if STEPPER_INVERTED_Y:
            direction_y = -direction_y
        if STEPPER_INVERTED_Z:
            direction_z = -direction_z
        if STEPPER_INVERTED_E:
            direction_e = -direction_e
        if isinstance(generator, PulseGeneratorLinear):
            assert direction_x < 0 and delta.x < 0 or (direction_x > 0 and delta.x > 0) or delta.x == 0
            assert direction_y < 0 and delta.y < 0 or (direction_y > 0 and delta.y > 0) or delta.y == 0
            assert direction_z < 0 and delta.z < 0 or (direction_z > 0 and delta.z > 0) or delta.z == 0
            assert direction_e < 0 and delta.e < 0 or (direction_e > 0 and delta.e > 0) or delta.e == 0
        continue
    if tx is not None:
        if tx > mx:
            mx = tx
        tx = int(round(tx * 1000000))
        ix += direction_x
        cx += 1
        if lx is not None:
            dx = tx - lx
            assert dx > 0, 'negative or zero time delta detected for x'
        lx = tx
    else:
        dx = None
    if ty is not None:
        if ty > my:
            my = ty
        ty = int(round(ty * 1000000))
        iy += direction_y
        cy += 1
        if ly is not None:
            dy = ty - ly
            assert dy > 0, 'negative or zero time delta detected for y'
        ly = ty
    else:
        dy = None
    if tz is not None:
        if tz > mz:
            mz = tz
        tz = int(round(tz * 1000000))
        iz += direction_z
        cz += 1
        if lz is not None:
            dz = tz - lz
            assert dz > 0, 'negative or zero time delta detected for z'
        lz = tz
    else:
        dz = None
    if te is not None:
        if te > me:
            me = te
        te = int(round(te * 1000000))
        ie += direction_e
        ce += 1
        if le is not None:
            de = te - le
            assert de > 0, 'negative or zero time delta detected for e'
        le = te
    else:
        de = None
    f = list((x for x in (tx, ty, tz, te) if x is not None))
    assert f.count(f[0]) == len(f), 'fast forwarded pulse detected'","for e_target in generator:
    te = e_target[4]
    tz = e_target[3]
    ty = e_target[2]
    tx = e_target[1]
    direction = e_target[0]
    if direction:
        direction_found = True
        (direction_x, direction_y, direction_z, direction_e) = (tx, ty, tz, te)
        if STEPPER_INVERTED_X:
            direction_x = -direction_x
        if STEPPER_INVERTED_Y:
            direction_y = -direction_y
        if STEPPER_INVERTED_Z:
            direction_z = -direction_z
        if STEPPER_INVERTED_E:
            direction_e = -direction_e
        if isinstance(generator, PulseGeneratorLinear):
            assert direction_x < 0 and delta.x < 0 or (direction_x > 0 and delta.x > 0) or delta.x == 0
            assert direction_y < 0 and delta.y < 0 or (direction_y > 0 and delta.y > 0) or delta.y == 0
            assert direction_z < 0 and delta.z < 0 or (direction_z > 0 and delta.z > 0) or delta.z == 0
            assert direction_e < 0 and delta.e < 0 or (direction_e > 0 and delta.e > 0) or delta.e == 0
        continue
    if tx is not None:
        if tx > mx:
            mx = tx
        tx = int(round(tx * 1000000))
        ix += direction_x
        cx += 1
        if lx is not None:
            dx = tx - lx
            assert dx > 0, 'negative or zero time delta detected for x'
        lx = tx
    else:
        dx = None
    if ty is not None:
        if ty > my:
            my = ty
        ty = int(round(ty * 1000000))
        iy += direction_y
        cy += 1
        if ly is not None:
            dy = ty - ly
            assert dy > 0, 'negative or zero time delta detected for y'
        ly = ty
    else:
        dy = None
    if tz is not None:
        if tz > mz:
            mz = tz
        tz = int(round(tz * 1000000))
        iz += direction_z
        cz += 1
        if lz is not None:
            dz = tz - lz
            assert dz > 0, 'negative or zero time delta detected for z'
        lz = tz
    else:
        dz = None
    if te is not None:
        if te > me:
            me = te
        te = int(round(te * 1000000))
        ie += direction_e
        ce += 1
        if le is not None:
            de = te - le
            assert de > 0, 'negative or zero time delta detected for e'
        le = te
    else:
        de = None
    f = list((x for x in (tx, ty, tz, te) if x is not None))
    assert f.count(f[0]) == len(f), 'fast forwarded pulse detected'

",1,"[['https://github.com/Nikolay-Kha/PyCNC/tree/master/tests/test_pulses.py', 'tests.test_pulses', 'TestPulses', 'test_with_hal_virtual']]"
bubbles,https://github.com/Stiivi/bubbles/tree/master/bubbles/operation.py,OperationTestCase,test_match,"for (mine, their) in zip(self.operands, operands):
    if mine.islist != their.islist:
        return False
    if not mine.isany and mine.rep != their.rep:
        return False","for e_target in zip(self.operands, operands):
    their = e_target[1]
    mine = e_target[0]
    if mine.islist != their.islist:
        return False
    if not mine.isany and mine.rep != their.rep:
        return False

",1,"[['https://github.com/Stiivi/bubbles/tree/master/tests/test_core.py', 'tests.test_core', 'OperationTestCase', 'test_match']]"
inception,https://github.com/carmaa/inception/tree/master/inception/memory.py,TestMemory,test_find,"for (caddr, cand) in self.interface.readv(r):
    if self.match(cand, p[m].chunks):
        result = (caddr, p[m], o)
        z.append(result)
        if findtag and p[m].tag:
            print()
            return z
        elif not (findall or findtag):
            print()
            return result
    m += 1","for e_target in self.interface.readv(r):
    cand = e_target[1]
    caddr = e_target[0]
    if self.match(cand, p[m].chunks):
        result = (caddr, p[m], o)
        z.append(result)
        if findtag and p[m].tag:
            print()
            return z
        elif not (findall or findtag):
            print()
            return result
    m += 1

",1,"[['https://github.com/carmaa/inception/tree/master/inception/test/test_memory.py', 'inception.test.test_memory', 'TestMemory', 'test_findtag'], ['https://github.com/carmaa/inception/tree/master/inception/test/test_memory.py', 'inception.test.test_memory', 'TestMemory', 'test_findall'], ['https://github.com/carmaa/inception/tree/master/inception/test/test_memory.py', 'inception.test.test_memory', 'TestMemory', 'test_find']]"
python-tabulate,https://github.com/astanin/python-tabulate/tree/master//tabulate.py,,test_wrap_text_to_colwidths_colors_wide_char,"for (cell, width, numparse) in zip(row, colwidths, numparses):
    if _isnumber(cell) and numparse:
        new_row.append(cell)
        continue
    if width is not None:
        wrapper = _CustomTextWrap(width=width)
        wrapped = wrapper.wrap(cell)
        new_row.append('\n'.join(wrapped))
    else:
        new_row.append(cell)","for e_target in zip(row, colwidths, numparses):
    numparse = e_target[2]
    width = e_target[1]
    cell = e_target[0]
    if _isnumber(cell) and numparse:
        new_row.append(cell)
        continue
    if width is not None:
        wrapper = _CustomTextWrap(width=width)
        wrapped = wrapper.wrap(cell)
        new_row.append('\n'.join(wrapped))
    else:
        new_row.append(cell)

",1,"[['https://github.com/astanin/python-tabulate/tree/master/test/test_internal.py', 'test.test_internal', '', 'test_wrap_text_to_colwidths_multi_ansi_colors_full_cell'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_internal.py', 'test.test_internal', '', 'test_wrap_text_wide_chars'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_internal.py', 'test.test_internal', '', 'test_wrap_text_to_numbers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_internal.py', 'test.test_internal', '', 'test_wrap_text_to_colwidths_single_ansi_colors_full_cell'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_internal.py', 'test.test_internal', '', 'test_wrap_text_to_colwidths'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_internal.py', 'test.test_internal', '', 'test_wrap_text_to_colwidths_multi_ansi_colors_in_subset'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_internal.py', 'test.test_internal', '', 'test_wrap_text_to_colwidths_colors_wide_char']]"
python-tabulate,https://github.com/astanin/python-tabulate/tree/master//tabulate.py,,test_plain_multiline_with_empty_cells_headerless,"for (idx, align) in enumerate(colalign):
    aligns[idx] = align","for e_target in enumerate(colalign):
    align = e_target[1]
    idx = e_target[0]
    aligns[idx] = align

",1,"[['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_iterable_of_iterables'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_latex_booktabs'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_presto_multiline_with_empty_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_alignment_of_decimal_numbers_with_ansi_color'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pretty'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_rst_multiline_with_empty_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_empty_data_without_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pretty_multiline_with_links'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_html'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_lists_firstrow'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_pandas'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_escape_empty_cell_in_first_column_in_rst'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_simple'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_psql_multiline'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pretty_multiline'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_isconvertible_on_set_values'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_string_with_comma_between_digits_without_floatfmt_grouping_option'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_numeric_column_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_column_with_mixed_value_types'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_custom_tablefmt'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pipe_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_no_data'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pandas_without_index'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_sqlite3_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_empty_table_with_keys_as_header'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_mediawiki'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_list_of_lists_with_supplied_index'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_py27orlater_list_of_ordereddicts'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_missingval_multi'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_multiline_with_wide_characters'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_empty_data'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain_maxcolwidth_autowraps'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_fancy_grid_multiline_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_datetime_values'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_latex_raw'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_pandas_firstrow'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_grid_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_namedtuples'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_grid_multiline_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pandas_rst_with_named_index'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_psql_multiline_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_simple_multiline_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_dict_like'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_presto_multiline_with_empty_cells_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain_multiline_with_empty_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_simple_multiline_with_links'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_disable_numparse_list'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_unsafehtml_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_namedtuples_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_rst_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_numpy_record_array_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_iterable_of_iterables_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_list_of_lists_with_index'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_numpy_array_as_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_psql_multiline_with_empty_cells_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_grid_wide_characters'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_jira'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_preserve_whitespace'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_html_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_ragged_rows'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_numpy_record_array_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_simple_multiline_2'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_88_256_ANSI_color_codes'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_ansi_color_in_table_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_maxcolwidth_honor_disable_parsenum'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pretty_multiline_with_empty_cells_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_ansi_color_bold_and_fgcolor'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_iter_of_iters_with_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts_with_list_of_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_fancy_grid_multiline_with_empty_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_align_long_integers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_empty_pipe_table_with_columns'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts_with_missing_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_no_data_without_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pandas_with_index'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_presto_multiline_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_colorclass_colors'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_github'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_float_conversions'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_list_of_lists_with_index_firstrow'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_missingval'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_pandas_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_rst_with_empty_values_in_first_column'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_long_integers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_moinmoin_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_rst'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_simple_multiline_with_empty_cells_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_psql'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pipe'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_fancy_grid'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_rst_multiline_with_links'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_fancy_grid_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_dict_like_with_index'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_ansi_color_for_decimal_numbers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_userdicts_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_alignment_of_link_text_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pretty_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_moinmoin'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_simple_multiline'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_floatfmt_multi'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_numpy_2d'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_latex_booktabs_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain_multiline_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_colalign_multi'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_textile_with_header'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_orgtbl_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_simple_separated_format_with_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain_maxcolwidth_autowraps_wide_chars'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_lists_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_presto_multiline'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_unaligned_separated'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_alignment_of_link_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_alignment_of_colored_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_numpy_2d_firstrow'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_mix_normal_and_wide_characters'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_maxcolwidth_single_value'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_disable_numparse_default'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain_multiline_with_links'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_psql_multiline_with_empty_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_column_alignment'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_simple_separated_format'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pandas_rst_with_index'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_boolean_columns'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_textile_with_center_align'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_presto'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pretty_multiline_with_empty_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_textile'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_latex_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_disable_numparse_true'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_pretty_multiline_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_grid_multiline'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_floatfmt'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_simple_multiline_with_empty_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_orgtbl'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts_firstrow'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_latex'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_rst_multiline_with_empty_cells_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_fancy_grid_multiline_with_empty_cells_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_sqlite3'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_numpy_record_array'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_fancy_grid_multiline'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_jira_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_latex_escape_special_chars'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_mediawiki_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_youtrack'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_unsafehtml'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_grid'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_grid_multiline_with_empty_cells'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_psql_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_rst_multiline'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_iterable_of_iterables_firstrow'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_lists'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_userdicts'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts_with_dict_of_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_simple_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain_multiline'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_maxcolwidth_pad_tailing_widths'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_presto_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_grid_multiline_with_empty_cells_headerless'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_numpy_2d_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_output.py', 'test.test_output', '', 'test_plain_multiline_with_empty_cells_headerless']]"
python-tabulate,https://github.com/astanin/python-tabulate/tree/master/test/common.py,,test_list_of_dicts_keys,"for (i, expected) in zip(nums, expected_set):
    print('Expected %d:\n%s\n' % (i, expected))","for e_target in zip(nums, expected_set):
    expected = e_target[1]
    i = e_target[0]
    print('Expected %d:\n%s\n' % (i, expected))

",1,"[['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_dict_like'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_userdicts'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts_with_dict_of_headers'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_regression.py', 'test.test_regression', '', 'test_isconvertible_on_set_values'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_userdicts_keys'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts_firstrow'], ['https://github.com/astanin/python-tabulate/tree/master/test/test_input.py', 'test.test_input', '', 'test_list_of_dicts_keys']]"
parallel-ssh,https://github.com/ParallelSSH/parallel-ssh/tree/master/pssh/clients/native/tunnel.py,TunnelTest,test_forwarder,"for (client, server) in self._servers.items():
    server.stop()","for e_target in self._servers.items():
    server = e_target[1]
    client = e_target[0]
    server.stop()

",1,"[['https://github.com/ParallelSSH/parallel-ssh/tree/master/tests/native/test_tunnel.py', 'tests.native.test_tunnel', 'TunnelTest', 'test_forwarder']]"
tasktiger,https://github.com/closeio/tasktiger/tree/master/tasktiger/task.py,TestTasks,test_tasks_from_queue,"for (serialized_data, serialized_executions, ts) in zip(results[0], results[1:], tss):
    data = json.loads(serialized_data)
    executions = [json.loads(e) for e in serialized_executions if e]
    task = Task(tiger, queue=queue, _data=data, _state=state, _ts=ts, _executions=executions)
    tasks.append(task)","for e_target in zip(results[0], results[1:], tss):
    ts = e_target[2]
    serialized_executions = e_target[1]
    serialized_data = e_target[0]
    data = json.loads(serialized_data)
    executions = [json.loads(e) for e in serialized_executions if e]
    task = Task(tiger, queue=queue, _data=data, _state=state, _ts=ts, _executions=executions)
    tasks.append(task)

",1,"[['https://github.com/closeio/tasktiger/tree/master/tests/test_periodic.py', 'tests.test_periodic', 'TestPeriodicTasks', 'test_successful_execution_doesnt_clear_previous_errors'], ['https://github.com/closeio/tasktiger/tree/master/tests/test_base.py', 'tests.test_base', 'TestCase', 'test_purge_errored_tasks_older_than'], ['https://github.com/closeio/tasktiger/tree/master/tests/test_base.py', 'tests.test_base', 'TestTasks', 'test_tasks_from_queue_with_executions'], ['https://github.com/closeio/tasktiger/tree/master/tests/test_periodic.py', 'tests.test_periodic', 'TestPeriodicTasks', 'test_successful_execution_clears_executions_from_retries'], ['https://github.com/closeio/tasktiger/tree/master/tests/test_base.py', 'tests.test_base', 'TestTasks', 'test_tasks_from_queue']]"
tasktiger,https://github.com/closeio/tasktiger/tree/master/tasktiger/task.py,TestTasks,test_tasks_from_queue,"for (serialized_data, ts) in zip(data, tss):
    data = json.loads(serialized_data)
    task = Task(tiger, queue=queue, _data=data, _state=state, _ts=ts)
    tasks.append(task)","for e_target in zip(data, tss):
    ts = e_target[1]
    serialized_data = e_target[0]
    data = json.loads(serialized_data)
    task = Task(tiger, queue=queue, _data=data, _state=state, _ts=ts)
    tasks.append(task)

",1,"[['https://github.com/closeio/tasktiger/tree/master/tests/test_periodic.py', 'tests.test_periodic', 'TestPeriodicTasks', 'test_successful_execution_doesnt_clear_previous_errors'], ['https://github.com/closeio/tasktiger/tree/master/tests/test_base.py', 'tests.test_base', 'TestCase', 'test_purge_errored_tasks_older_than'], ['https://github.com/closeio/tasktiger/tree/master/tests/test_base.py', 'tests.test_base', 'TestTasks', 'test_tasks_from_queue_with_executions'], ['https://github.com/closeio/tasktiger/tree/master/tests/test_periodic.py', 'tests.test_periodic', 'TestPeriodicTasks', 'test_successful_execution_clears_executions_from_retries'], ['https://github.com/closeio/tasktiger/tree/master/tests/test_base.py', 'tests.test_base', 'TestTasks', 'test_tasks_from_queue']]"
influxdb-python,https://github.com/influxdata/influxdb-python/tree/master/influxdb/resultset.py,TestResultSet,test_point_from_cols_vals,"for (col_index, col_name) in enumerate(cols):
    point[col_name] = vals[col_index]","for e_target in enumerate(cols):
    col_name = e_target[1]
    col_index = e_target[0]
    point[col_name] = vals[col_index]

",1,"[['https://github.com/influxdata/influxdb-python/tree/master/influxdb/tests/resultset_test.py', 'influxdb.tests.resultset_test', 'TestResultSet', 'test_point_from_cols_vals']]"
morphsnakes,https://github.com/pmneila/morphsnakes/tree/master//morphsnakes.py,,test_morphsnakes_black,"for (el1, el2) in zip(dimage, du):
    aux += el1 * el2","for e_target in zip(dimage, du):
    el2 = e_target[1]
    el1 = e_target[0]
    aux += el1 * el2

",1,"[['https://github.com/pmneila/morphsnakes/tree/master//test_morphsnakes.py', 'test_morphsnakes', '', 'test_init_level_sets'], ['https://github.com/pmneila/morphsnakes/tree/master//test_morphsnakes.py', 'test_morphsnakes', '', 'test_morphsnakes_incorrect_image_shape'], ['https://github.com/pmneila/morphsnakes/tree/master//test_morphsnakes.py', 'test_morphsnakes', '', 'test_morphsnakes_incorrect_ndim'], ['https://github.com/pmneila/morphsnakes/tree/master//test_morphsnakes.py', 'test_morphsnakes', '', 'test_morphsnakes_simple_shape_geodesic_active_contour'], ['https://github.com/pmneila/morphsnakes/tree/master//test_morphsnakes.py', 'test_morphsnakes', '', 'test_morphsnakes_black']]"
dacite,https://github.com/konradhalas/dacite/tree/master/dacite/types.py,,test_is_instance_with_numeric_tower_and_optional,"for (key, val) in value.items():
    if not is_instance(key, key_type) or not is_instance(val, val_type):
        return False","for e_target in value.items():
    val = e_target[1]
    key = e_target[0]
    if not is_instance(key, key_type) or not is_instance(val, val_type):
        return False

",1,"[['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_empty_tuple_and_not_matching_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_built_in_type_and_not_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_mapping_and_not_matching_mapping_key_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_tuple_and_not_matching_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_empty_tuple_and_matching_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_optional_and_not_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_abstract_collection_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_collection_without_specified_inner_types_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_variable_length_tuple_and_matching_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_any_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_new_type_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_tuple_and_matching_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_union_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_not_supported_generic_types'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_union_and_not_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_collection_and_not_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_nested_generic_collection_and_not_matching_item_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_tuple_and_wrong_length'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_union_and_not_matching_generic_collection'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_collection_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_new_type_and_not_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_optional_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_collection_without_specified_inner_types_and_not_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_with_type_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_union_and_matching_generic_collection'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_built_in_type_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_numeric_tower'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_nested_generic_collection_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_mapping_and_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_with_type_and_not_matching_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_collection_and_not_matching_item_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_generic_mapping_and_not_matching_mapping_value_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_numeric_tower_and_new_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_variable_length_tuple_and_not_matching_type'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_types.py', 'tests.test_types', '', 'test_is_instance_with_numeric_tower_and_optional']]"
dacite,https://github.com/konradhalas/dacite/tree/master/dacite/dataclasses.py,,test_create_instance_with_simple_data_class,"for (key, value) in post_init_values.items():
    setattr(instance, key, value)","for e_target in post_init_values.items():
    value = e_target[1]
    key = e_target[0]
    setattr(instance, key, value)

",1,"[['https://github.com/konradhalas/dacite/tree/master/tests/test_dataclasses.py', 'tests.test_dataclasses', '', 'test_create_instance_with_post_init_values'], ['https://github.com/konradhalas/dacite/tree/master/tests/test_dataclasses.py', 'tests.test_dataclasses', '', 'test_create_instance_with_simple_data_class']]"
pytm,https://github.com/izar/pytm/tree/master/pytm/pytm.py,TestTM,test_resolve,"for (e, findings) in elements.items():
    e.findings = findings","for e_target in elements.items():
    findings = e_target[1]
    e = e_target[0]
    e.findings = findings

",1,"[['https://github.com/izar/pytm/tree/master/tests/test_pytmfunc.py', 'tests.test_pytmfunc', 'TestTM', 'test_overrides'], ['https://github.com/izar/pytm/tree/master/tests/test_pytmfunc.py', 'tests.test_pytmfunc', 'TestTM', 'test_exclude_threats_ignore'], ['https://github.com/izar/pytm/tree/master/tests/test_pytmfunc.py', 'tests.test_pytmfunc', 'TestTM', 'test_resolve']]"
skll,https://github.com/EducationalTestingService/skll/tree/master/skll/utils/commandline/generate_predictions.py,,test_generate_predictions_threshold_not_trained_with_probability,"for (i, input_file) in enumerate(args.input_files):
    input_extension = os.path.splitext(input_file)[1].lower()
    if input_extension not in EXT_TO_READER:
        logger.error(f'Input file must be in either .arff, .csv, .jsonlines, .libsvm, .ndj, or .tsv format.  Skipping file {input_file}')
        continue
    else:
        reader = EXT_TO_READER[input_extension](input_file, quiet=args.quiet, label_col=args.label_col, id_col=args.id_col)
        feature_set = reader.read()
        original_predictions = learner.predict(feature_set, class_labels=not learner.probability or args.predict_labels)
        if estimator_type == 'regressor' or not learner.probability or args.predict_labels or (args.threshold is not None):
            header = ['id', 'prediction']
        else:
            header = ['id'] + [str(x) for x in learner.label_list]
        if args.threshold is not None:
            predictions = []
            for (neg_label_prob, pos_label_prob) in original_predictions:
                chosen_label = pos_label_str if pos_label_prob >= args.threshold else neg_label_str
                predictions.append(chosen_label)
        else:
            predictions = original_predictions
        outputfh = None
        try:
            outputfh = open(args.output_file, 'a') if args.output_file else sys.stdout
            if i == 0:
                print('\t'.join(header), file=outputfh)
            for (j, prediction) in enumerate(predictions):
                id_ = feature_set.ids[j]
                if isinstance(prediction, (np.ndarray, list)):
                    prediction_str = '\t'.join([str(p) for p in prediction])
                else:
                    prediction_str = prediction
                print(f'{id_}\t{prediction_str}', file=outputfh)
        finally:
            if args.output_file:
                outputfh.close()","for e_target in enumerate(args.input_files):
    input_file = e_target[1]
    i = e_target[0]
    input_extension = os.path.splitext(input_file)[1].lower()
    if input_extension not in EXT_TO_READER:
        logger.error(f'Input file must be in either .arff, .csv, .jsonlines, .libsvm, .ndj, or .tsv format.  Skipping file {input_file}')
        continue
    else:
        reader = EXT_TO_READER[input_extension](input_file, quiet=args.quiet, label_col=args.label_col, id_col=args.id_col)
        feature_set = reader.read()
        original_predictions = learner.predict(feature_set, class_labels=not learner.probability or args.predict_labels)
        if estimator_type == 'regressor' or not learner.probability or args.predict_labels or (args.threshold is not None):
            header = ['id', 'prediction']
        else:
            header = ['id'] + [str(x) for x in learner.label_list]
        if args.threshold is not None:
            predictions = []
            for (neg_label_prob, pos_label_prob) in original_predictions:
                chosen_label = pos_label_str if pos_label_prob >= args.threshold else neg_label_str
                predictions.append(chosen_label)
        else:
            predictions = original_predictions
        outputfh = None
        try:
            outputfh = open(args.output_file, 'a') if args.output_file else sys.stdout
            if i == 0:
                print('\t'.join(header), file=outputfh)
            for (j, prediction) in enumerate(predictions):
                id_ = feature_set.ids[j]
                if isinstance(prediction, (np.ndarray, list)):
                    prediction_str = '\t'.join([str(p) for p in prediction])
                else:
                    prediction_str = prediction
                print(f'{id_}\t{prediction_str}', file=outputfh)
        finally:
            if args.output_file:
                outputfh.close()

",1,"[['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_predict_labels_non_probabilistic'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_mutually_exclusive_generate_predictions_args'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_predict_labels_not_trained_with_probability'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_multi_class'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_non_probabilistic'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_not_trained_with_probability']]"
skll,https://github.com/EducationalTestingService/skll/tree/master/skll/utils/commandline/generate_predictions.py,,test_generate_predictions_threshold_not_trained_with_probability,"for (neg_label_prob, pos_label_prob) in original_predictions:
    chosen_label = pos_label_str if pos_label_prob >= args.threshold else neg_label_str
    predictions.append(chosen_label)","for e_target in original_predictions:
    pos_label_prob = e_target[1]
    neg_label_prob = e_target[0]
    chosen_label = pos_label_str if pos_label_prob >= args.threshold else neg_label_str
    predictions.append(chosen_label)

",1,"[['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_predict_labels_non_probabilistic'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_mutually_exclusive_generate_predictions_args'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_predict_labels_not_trained_with_probability'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_multi_class'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_non_probabilistic'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_not_trained_with_probability']]"
skll,https://github.com/EducationalTestingService/skll/tree/master/skll/utils/commandline/generate_predictions.py,,test_generate_predictions_threshold_not_trained_with_probability,"for (j, prediction) in enumerate(predictions):
    id_ = feature_set.ids[j]
    if isinstance(prediction, (np.ndarray, list)):
        prediction_str = '\t'.join([str(p) for p in prediction])
    else:
        prediction_str = prediction
    print(f'{id_}\t{prediction_str}', file=outputfh)","for e_target in enumerate(predictions):
    prediction = e_target[1]
    j = e_target[0]
    id_ = feature_set.ids[j]
    if isinstance(prediction, (np.ndarray, list)):
        prediction_str = '\t'.join([str(p) for p in prediction])
    else:
        prediction_str = prediction
    print(f'{id_}\t{prediction_str}', file=outputfh)

",1,"[['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_predict_labels_non_probabilistic'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_mutually_exclusive_generate_predictions_args'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_predict_labels_not_trained_with_probability'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_multi_class'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_non_probabilistic'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_commandline_utils.py', 'tests.test_commandline_utils', '', 'test_generate_predictions_threshold_not_trained_with_probability']]"
skll,https://github.com/EducationalTestingService/skll/tree/master/skll/learner/voting.py,,test_train_with_custom_path,"for (learner, param_grid) in zip_longest(self.learners, self._param_grids):
    _ = learner.train(examples, grid_search=grid_search, grid_objective=grid_objective, param_grid=param_grid, grid_search_folds=grid_search_folds, grid_jobs=grid_jobs, shuffle=shuffle)","for e_target in zip_longest(self.learners, self._param_grids):
    param_grid = e_target[1]
    learner = e_target[0]
    _ = learner.train(examples, grid_search=grid_search, grid_objective=grid_objective, param_grid=param_grid, grid_search_folds=grid_search_folds, grid_jobs=grid_jobs, shuffle=shuffle)

",1,"[['https://github.com/EducationalTestingService/skll/tree/master/tests/test_voting_learners_api_2.py', 'tests.test_voting_learners_api_2', '', 'test_evaluate_bad_output_metric'], ['https://github.com/EducationalTestingService/skll/tree/master/tests/test_voting_learners_api_1.py', 'tests.test_voting_learners_api_1', '', 'test_train_with_custom_path']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/mbjson.py,ArtistTranslationTest,test_artist_match_root_locale_fallback,"for (script_id, script_weighting) in config.setting['script_exceptions']:
    if script_id in detected_scripts and detected_scripts[script_id] >= script_weighting / 100:
        log.debug('Match' + log_text)
        return (node['name'], node['sort-name'])","for e_target in config.setting['script_exceptions']:
    script_weighting = e_target[1]
    script_id = e_target[0]
    if script_id in detected_scripts and detected_scripts[script_id] >= script_weighting / 100:
        log.debug('Match' + log_text)
        return (node['name'], node['sort-name'])

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_mbjson.py', 'test.test_mbjson', 'ArtistTranslationTest', 'test_locale_specific_match_second'], ['https://github.com/metabrainz/picard/tree/master/test/test_mbjson.py', 'test.test_mbjson', 'ArtistTranslationTest', 'test_locale_specific_match_first'], ['https://github.com/metabrainz/picard/tree/master/test/test_mbjson.py', 'test.test_mbjson', 'ArtistTranslationTest', 'test_artist_no_match'], ['https://github.com/metabrainz/picard/tree/master/test/test_mbjson.py', 'test.test_mbjson', 'ArtistTranslationTest', 'test_artist_match_root_locale_fallback']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/track.py,TagGenreFilterTest,test_filter_method,"for (name, count) in counter:
    if not self.skip(name):
        yield (name, count)","for e_target in counter:
    count = e_target[1]
    name = e_target[0]
    if not self.skip(name):
        yield (name, count)

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_taggenrefilter.py', 'test.test_taggenrefilter', 'TagGenreFilterTest', 'test_filter_method']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/track.py,TrackGenres2MetadataTest,test_join_with,"for (name, count) in genres_filter.filter(most_common_genres):
    percent = 100 * count // topcount
    if percent < minusage:
        break
    name = _TRANSLATE_TAGS.get(name, name.title())
    genres_list.append(name)","for e_target in genres_filter.filter(most_common_genres):
    count = e_target[1]
    name = e_target[0]
    percent = 100 * count // topcount
    if percent < minusage:
        break
    name = _TRANSLATE_TAGS.get(name, name.title())
    genres_list.append(name)

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_track.py', 'test.test_track', 'TrackGenres2MetadataTest', 'test_limit'], ['https://github.com/metabrainz/picard/tree/master/test/test_track.py', 'test.test_track', 'TrackGenres2MetadataTest', 'test_empty'], ['https://github.com/metabrainz/picard/tree/master/test/test_track.py', 'test.test_track', 'TrackGenres2MetadataTest', 'test_basic'], ['https://github.com/metabrainz/picard/tree/master/test/test_track.py', 'test.test_track', 'TrackGenres2MetadataTest', 'test_negative_zero'], ['https://github.com/metabrainz/picard/tree/master/test/test_track.py', 'test.test_track', 'TrackGenres2MetadataTest', 'test_filters'], ['https://github.com/metabrainz/picard/tree/master/test/test_track.py', 'test.test_track', 'TrackGenres2MetadataTest', 'test_minusage'], ['https://github.com/metabrainz/picard/tree/master/test/test_track.py', 'test.test_track', 'TrackGenres2MetadataTest', 'test_limit_0'], ['https://github.com/metabrainz/picard/tree/master/test/test_track.py', 'test.test_track', 'TrackGenres2MetadataTest', 'test_join_with']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/releasegroup.py,ReleaseTest,test_1,"for (name, releases) in versions.items():
    for (a, b) in combinations(releases, 2):
        for key in extrakeys:
            (value1, value2) = (a[key], b[key])
            if value1 != value2:
                a['_disambiguate_name'].append(value1)
                b['_disambiguate_name'].append(value2)","for e_target in versions.items():
    releases = e_target[1]
    name = e_target[0]
    for (a, b) in combinations(releases, 2):
        for key in extrakeys:
            (value1, value2) = (a[key], b[key])
            if value1 != value2:
                a['_disambiguate_name'].append(value1)
                b['_disambiguate_name'].append(value2)

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_3'], ['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_2'], ['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_1']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/releasegroup.py,ReleaseTest,test_1,"for (name, releases) in versions.items():
    for release in releases:
        dis = ' / '.join(filter(None, uniqify(release['_disambiguate_name']))).replace('&', '&&')
        disname = name if not dis else name + ' / ' + dis
        version = {'id': release['id'], 'name': disname, 'totaltracks': release['totaltracks'], 'countries': release['countries'], 'formats': release['formats']}
        self.versions.append(version)","for e_target in versions.items():
    releases = e_target[1]
    name = e_target[0]
    for release in releases:
        dis = ' / '.join(filter(None, uniqify(release['_disambiguate_name']))).replace('&', '&&')
        disname = name if not dis else name + ' / ' + dis
        version = {'id': release['id'], 'name': disname, 'totaltracks': release['totaltracks'], 'countries': release['countries'], 'formats': release['formats']}
        self.versions.append(version)

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_3'], ['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_2'], ['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_1']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/releasegroup.py,ReleaseTest,test_1,"for (a, b) in combinations(releases, 2):
    for key in extrakeys:
        (value1, value2) = (a[key], b[key])
        if value1 != value2:
            a['_disambiguate_name'].append(value1)
            b['_disambiguate_name'].append(value2)","for e_target in combinations(releases, 2):
    b = e_target[1]
    a = e_target[0]
    for key in extrakeys:
        (value1, value2) = (a[key], b[key])
        if value1 != value2:
            a['_disambiguate_name'].append(value1)
            b['_disambiguate_name'].append(value2)

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_3'], ['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_2'], ['https://github.com/metabrainz/picard/tree/master/test/test_releaseversions.py', 'test.test_releaseversions', 'ReleaseTest', 'test_1']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/config_upgrade.py,TestPicardConfigUpgrades,test_upgrade_to_v1_3_0_dev_3,"for (opt, sep) in option_separators.items():
    if opt in _s:
        try:
            _s[opt] = _s.raw_value(opt, qtype='QString').split(sep)
        except AttributeError:
            pass","for e_target in option_separators.items():
    sep = e_target[1]
    opt = e_target[0]
    if opt in _s:
        try:
            _s[opt] = _s.raw_value(opt, qtype='QString').split(sep)
        except AttributeError:
            pass

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_config_upgrade.py', 'test.test_config_upgrade', 'TestPicardConfigUpgrades', 'test_upgrade_to_v1_3_0_dev_3']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/similarity.py,Similarity2Test,test_6,"for (position, bv) in enumerate(blist):
    s = astrcmp(av, bv)
    if s > ms:
        ms = s
        mp = position","for e_target in enumerate(blist):
    bv = e_target[1]
    position = e_target[0]
    s = astrcmp(av, bv)
    if s > ms:
        ms = s
        mp = position

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_similarity.py', 'test.test_similarity', 'Similarity2Test', 'test_4'], ['https://github.com/metabrainz/picard/tree/master/test/test_similarity.py', 'test.test_similarity', 'Similarity2Test', 'test_7'], ['https://github.com/metabrainz/picard/tree/master/test/test_similarity.py', 'test.test_similarity', 'Similarity2Test', 'test_3'], ['https://github.com/metabrainz/picard/tree/master/test/test_similarity.py', 'test.test_similarity', 'Similarity2Test', 'test_2'], ['https://github.com/metabrainz/picard/tree/master/test/test_similarity.py', 'test.test_similarity', 'Similarity2Test', 'test_1'], ['https://github.com/metabrainz/picard/tree/master/test/test_similarity.py', 'test.test_similarity', 'Similarity2Test', 'test_5'], ['https://github.com/metabrainz/picard/tree/master/test/test_similarity.py', 'test.test_similarity', 'Similarity2Test', 'test_6']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/coverart/providers/caa.py,CoverArtImageProviderCaaTest,test_caa_url_fallback_list,"for (item_id, item) in reversed_map.items():
    if item_id == -1 or item_id > desired_size:
        continue
    url = thumbnails.get(item.thumbnail, None)
    if url is None:
        size_alias = _CAA_THUMBNAIL_SIZE_ALIASES.get(item.thumbnail, None)
        if size_alias is not None:
            url = thumbnails.get(size_alias, None)
    if url is not None:
        urls.append(url)","for e_target in reversed_map.items():
    item = e_target[1]
    item_id = e_target[0]
    if item_id == -1 or item_id > desired_size:
        continue
    url = thumbnails.get(item.thumbnail, None)
    if url is None:
        size_alias = _CAA_THUMBNAIL_SIZE_ALIASES.get(item.thumbnail, None)
        if size_alias is not None:
            url = thumbnails.get(size_alias, None)
    if url is not None:
        urls.append(url)

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_coverartprovider_caa.py', 'test.test_coverartprovider_caa', 'CoverArtImageProviderCaaTest', 'test_caa_url_fallback_list']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/ui/colors.py,InterfaceColorsTest,test_interface_colors,"for (key, color) in self._colors.items():
    if key not in conf:
        conf[key] = color
    elif color != conf[key]:
        conf[key] = color
        changed = True","for e_target in self._colors.items():
    color = e_target[1]
    key = e_target[0]
    if key not in conf:
        conf[key] = color
    elif color != conf[key]:
        conf[key] = color
        changed = True

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_interface_colors.py', 'test.test_interface_colors', 'InterfaceColorsTest', 'test_interface_colors']]"
picard,https://github.com/metabrainz/picard/tree/master/picard/ui/tagsfromfilenames.py,TagMatchExpressionTest,test_parse_tags_hidden,"for (group, tag) in self._group_map.items():
    value = match.group(group).strip()
    if tag in self._numeric_tags:
        value = value.lstrip('0')
    if self.replace_underscores:
        value = value.replace('_', ' ')
    all_values = result.get(tag, [])
    all_values.append(value)
    result[tag] = all_values","for e_target in self._group_map.items():
    tag = e_target[1]
    group = e_target[0]
    value = match.group(group).strip()
    if tag in self._numeric_tags:
        value = value.lstrip('0')
    if self.replace_underscores:
        value = value.replace('_', ' ')
    all_values = result.get(tag, [])
    all_values.append(value)
    result[tag] = all_values

",1,"[['https://github.com/metabrainz/picard/tree/master/test/test_tagsfromfilenames.py', 'test.test_tagsfromfilenames', 'TagMatchExpressionTest', 'test_parse_tags'], ['https://github.com/metabrainz/picard/tree/master/test/test_tagsfromfilenames.py', 'test.test_tagsfromfilenames', 'TagMatchExpressionTest', 'test_parse_replace_underscores'], ['https://github.com/metabrainz/picard/tree/master/test/test_tagsfromfilenames.py', 'test.test_tagsfromfilenames', 'TagMatchExpressionTest', 'test_parse_tags_with_path'], ['https://github.com/metabrainz/picard/tree/master/test/test_tagsfromfilenames.py', 'test.test_tagsfromfilenames', 'TagMatchExpressionTest', 'test_parse_tags_duplicates'], ['https://github.com/metabrainz/picard/tree/master/test/test_tagsfromfilenames.py', 'test.test_tagsfromfilenames', 'TagMatchExpressionTest', 'test_parse_tags_hidden']]"
jackit,https://github.com/insecurityofthings/jackit/tree/master/jackit/duckyparser.py,,test_parse_arrowkeys,"for (pos, line) in enumerate(self.script):
    if line.startswith('REPEAT'):
        self.script.remove(line)
        for i in range(1, int(line.split()[1])):
            self.script.insert(pos, self.script[pos - 1])","for e_target in enumerate(self.script):
    line = e_target[1]
    pos = e_target[0]
    if line.startswith('REPEAT'):
        self.script.remove(line)
        for i in range(1, int(line.split()[1])):
            self.script.insert(pos, self.script[pos - 1])

",1,"[['https://github.com/insecurityofthings/jackit/tree/master/jackit/test/test_duckyparser.py', 'jackit.test.test_duckyparser', '', 'test_parse_repeat'], ['https://github.com/insecurityofthings/jackit/tree/master/jackit/test/test_duckyparser.py', 'jackit.test.test_duckyparser', '', 'test_parse'], ['https://github.com/insecurityofthings/jackit/tree/master/jackit/test/test_duckyparser.py', 'jackit.test.test_duckyparser', '', 'test_parse_advance'], ['https://github.com/insecurityofthings/jackit/tree/master/jackit/test/test_duckyparser.py', 'jackit.test.test_duckyparser', '', 'test_parse_arrowkeys']]"
requests,https://github.com/psf/requests/tree/master/requests/sessions.py,TestRequests,test_session_get_adapter_prefix_matching,"for (prefix, adapter) in self.adapters.items():
    if url.lower().startswith(prefix.lower()):
        return adapter","for e_target in self.adapters.items():
    adapter = e_target[1]
    prefix = e_target[0]
    if url.lower().startswith(prefix.lower()):
        return adapter

",1,"[['https://github.com/psf/requests/tree/master/tests/test_requests.py', 'tests.test_requests', 'TestRequests', 'test_session_get_adapter_prefix_matching_mixed_case'], ['https://github.com/psf/requests/tree/master/tests/test_requests.py', 'tests.test_requests', 'TestRequests', 'test_session_get_adapter_prefix_matching_is_case_insensitive'], ['https://github.com/psf/requests/tree/master/tests/test_requests.py', 'tests.test_requests', 'TestRequests', 'test_session_get_adapter_prefix_matching']]"
netaddr,https://github.com/netaddr/netaddr/tree/master/netaddr/ip/rfc1924.py,,test_RFC_1924,"for (i, num) in enumerate(reversed(tokens)):
    num = BASE_85_DICT[num]
    result += num * 85 ** i","for e_target in enumerate(reversed(tokens)):
    num = e_target[1]
    i = e_target[0]
    num = BASE_85_DICT[num]
    result += num * 85 ** i

",1,"[['https://github.com/netaddr/netaddr/tree/master/netaddr/tests/ip/test_ip_rfc1924.py', 'netaddr.tests.ip.test_ip_rfc1924', '', 'test_RFC_1924']]"
netaddr,https://github.com/netaddr/netaddr/tree/master/netaddr/strategy/eui48.py,,test_strategy_eui48_py3,"for (i, num) in enumerate(reversed(words)):
    word = num
    word = word << 8 * i
    int_val = int_val | word","for e_target in enumerate(reversed(words)):
    num = e_target[1]
    i = e_target[0]
    word = num
    word = word << 8 * i
    int_val = int_val | word

",1,"[['https://github.com/netaddr/netaddr/tree/master/netaddr/tests/strategy/test_eui48_strategy.py', 'netaddr.tests.strategy.test_eui48_strategy', '', 'test_strategy_eui48_py3']]"
netaddr,https://github.com/netaddr/netaddr/tree/master/netaddr/strategy/ipv6.py,,test_strategy_ipv6_py3,"for (i, num) in enumerate(reversed(words)):
    word = num
    word = word << 32 * i
    int_val = int_val | word","for e_target in enumerate(reversed(words)):
    num = e_target[1]
    i = e_target[0]
    word = num
    word = word << 32 * i
    int_val = int_val | word

",1,"[['https://github.com/netaddr/netaddr/tree/master/netaddr/tests/strategy/test_ipv6_strategy.py', 'netaddr.tests.strategy.test_ipv6_strategy', '', 'test_strategy_ipv6_py3']]"
python-twitter,https://github.com/bear/python-twitter/tree/master/twitter/models.py,ModelsChangesTest,test_extended_in_compat_mode,"for (k, v) in data['extended_tweet'].items():
    data[k] = v","for e_target in data['extended_tweet'].items():
    v = e_target[1]
    k = e_target[0]
    data[k] = v

",1,"[['https://github.com/bear/python-twitter/tree/master/tests/test_models.py', 'tests.test_models', 'ModelsTest', 'test_status_no_user'], ['https://github.com/bear/python-twitter/tree/master/tests/test_streaming.py', 'tests.test_streaming', '', 'test_streaming_extended_tweet'], ['https://github.com/bear/python-twitter/tree/master/tests/test_models.py', 'tests.test_models', 'ModelsTest', 'test_status'], ['https://github.com/bear/python-twitter/tree/master/tests/test_media.py', 'tests.test_media', 'MediaTest', 'test_media_info'], ['https://github.com/bear/python-twitter/tree/master/tests/test_streaming.py', 'tests.test_streaming', '', 'test_streaming_extended_tweet_media'], ['https://github.com/bear/python-twitter/tree/master/tests/test_models.py', 'tests.test_models', 'ModelsTest', 'test_status_quoted_tweet_with_media'], ['https://github.com/bear/python-twitter/tree/master/tests/test_tweet_changes.py', 'tests.test_tweet_changes', 'ModelsChangesTest', 'test_extended_in_extended_mode'], ['https://github.com/bear/python-twitter/tree/master/tests/test_models.py', 'tests.test_models', 'ModelsTest', 'test_status_quoted_tweet'], ['https://github.com/bear/python-twitter/tree/master/tests/test_tweet_changes.py', 'tests.test_tweet_changes', 'ModelsChangesTest', 'test_extended_in_compat_mode']]"
sqlalchemy-mixins,https://github.com/absent1706/sqlalchemy-mixins/tree/master/sqlalchemy_mixins/smartquery.py,TestSmartQueryAutoEagerLoad,test_lazy_dynamic,"for (path, al) in aliases.items():
    relationship_path = path.replace(RELATION_SPLITTER, '.')
    if not (relationship_path in flat_schema and flat_schema[relationship_path] == SUBQUERY):
        query = query.outerjoin(al[0], al[1]).options(contains_eager(relationship_path, alias=al[0]))
        loaded_paths.append(relationship_path)","for e_target in aliases.items():
    al = e_target[1]
    path = e_target[0]
    relationship_path = path.replace(RELATION_SPLITTER, '.')
    if not (relationship_path in flat_schema and flat_schema[relationship_path] == SUBQUERY):
        query = query.outerjoin(al[0], al[1]).options(contains_eager(relationship_path, alias=al[0]))
        loaded_paths.append(relationship_path)

",1,"[['https://github.com/absent1706/sqlalchemy-mixins/tree/master/sqlalchemy_mixins/tests/test_smartquery.py', 'sqlalchemy_mixins.tests.test_smartquery', 'TestFullSmartQuery', 'test_schema_with_strings'], ['https://github.com/absent1706/sqlalchemy-mixins/tree/master/sqlalchemy_mixins/tests/test_smartquery.py', 'sqlalchemy_mixins.tests.test_smartquery', 'TestFullSmartQuery', 'test_schema_with_class_properties'], ['https://github.com/absent1706/sqlalchemy-mixins/tree/master/sqlalchemy_mixins/tests/test_smartquery.py', 'sqlalchemy_mixins.tests.test_smartquery', 'TestSmartQueryAutoEagerLoad', 'test_lazy_dynamic']]"
sqlalchemy-mixins,https://github.com/absent1706/sqlalchemy-mixins/tree/master/sqlalchemy_mixins/smartquery.py,TestSmartQueryAutoEagerLoad,test_lazy_dynamic,"for (attr, value) in _filters.items():
    if callable(attr):
        yield attr(*recurse_filters(value))
        continue
    if RELATION_SPLITTER in attr:
        parts = attr.rsplit(RELATION_SPLITTER, 1)
        (entity, attr_name) = (aliases[parts[0]][0], parts[1])
    else:
        (entity, attr_name) = (root_cls, attr)
    try:
        yield from entity.filter_expr(**{attr_name: value})
    except KeyError as e:
        raise KeyError('Incorrect filter path `{}`: {}'.format(attr, e))","for e_target in _filters.items():
    value = e_target[1]
    attr = e_target[0]
    if callable(attr):
        yield attr(*recurse_filters(value))
        continue
    if RELATION_SPLITTER in attr:
        parts = attr.rsplit(RELATION_SPLITTER, 1)
        (entity, attr_name) = (aliases[parts[0]][0], parts[1])
    else:
        (entity, attr_name) = (root_cls, attr)
    try:
        yield from entity.filter_expr(**{attr_name: value})
    except KeyError as e:
        raise KeyError('Incorrect filter path `{}`: {}'.format(attr, e))

",1,"[['https://github.com/absent1706/sqlalchemy-mixins/tree/master/sqlalchemy_mixins/tests/test_smartquery.py', 'sqlalchemy_mixins.tests.test_smartquery', 'TestFullSmartQuery', 'test_schema_with_strings'], ['https://github.com/absent1706/sqlalchemy-mixins/tree/master/sqlalchemy_mixins/tests/test_smartquery.py', 'sqlalchemy_mixins.tests.test_smartquery', 'TestFullSmartQuery', 'test_schema_with_class_properties'], ['https://github.com/absent1706/sqlalchemy-mixins/tree/master/sqlalchemy_mixins/tests/test_smartquery.py', 'sqlalchemy_mixins.tests.test_smartquery', 'TestSmartQueryAutoEagerLoad', 'test_lazy_dynamic']]"
spiderfoot,https://github.com/smicallef/spiderfoot/tree/master//sflib.py,TestSpiderFoot,test_fetchUrl_argument_url_invalid_type_should_return_none,"for (header, value) in res.headers.items():
    result['headers'][str(header).lower()] = str(value)","for e_target in res.headers.items():
    value = e_target[1]
    header = e_target[0]
    result['headers'][str(header).lower()] = str(value)

",1,"[['https://github.com/smicallef/spiderfoot/tree/master/test/unit/test_spiderfoot.py', 'test.unit.test_spiderfoot', 'TestSpiderFoot', 'test_fetchUrl_argument_headOnly_should_return_http_response_as_dict'], ['https://github.com/smicallef/spiderfoot/tree/master/test/unit/test_spiderfoot.py', 'test.unit.test_spiderfoot', 'TestSpiderFoot', 'test_fetchUrl_argument_url_should_return_http_response_as_dict'], ['https://github.com/smicallef/spiderfoot/tree/master/test/unit/test_spiderfoot.py', 'test.unit.test_spiderfoot', 'TestSpiderFoot', 'test_fetchUrl_argument_url_invalid_url_should_return_None'], ['https://github.com/smicallef/spiderfoot/tree/master/test/unit/test_spiderfoot.py', 'test.unit.test_spiderfoot', 'TestSpiderFoot', 'test_fetchUrl_argument_url_invalid_type_should_return_none']]"
spiderfoot,https://github.com/smicallef/spiderfoot/tree/master/modules/sfp_hostio.py,TestModulehostio,test_handleEvent_no_api_key_should_set_errorState,"for (address, ip_data) in data['ipinfo'].items():
    if not self.sf.validIP(address):
        continue
    evt = SpiderFootEvent('IP_ADDRESS', address, self.__name__, event)
    self.notifyListeners(evt)
    found = True
    loc = ip_data.get('loc')
    if loc and isinstance(loc, str):
        loc_evt = SpiderFootEvent('PHYSICAL_COORDINATES', loc, self.__name__, evt)
        self.notifyListeners(loc_evt)
        found = True
    geo_info = ', '.join(filter(None, (ip_data.get(k) for k in ('city', 'region', 'country'))))
    if geo_info:
        geo_info_evt = SpiderFootEvent('GEOINFO', geo_info, self.__name__, evt)
        self.notifyListeners(geo_info_evt)
        found = True","for e_target in data['ipinfo'].items():
    ip_data = e_target[1]
    address = e_target[0]
    if not self.sf.validIP(address):
        continue
    evt = SpiderFootEvent('IP_ADDRESS', address, self.__name__, event)
    self.notifyListeners(evt)
    found = True
    loc = ip_data.get('loc')
    if loc and isinstance(loc, str):
        loc_evt = SpiderFootEvent('PHYSICAL_COORDINATES', loc, self.__name__, evt)
        self.notifyListeners(loc_evt)
        found = True
    geo_info = ', '.join(filter(None, (ip_data.get(k) for k in ('city', 'region', 'country'))))
    if geo_info:
        geo_info_evt = SpiderFootEvent('GEOINFO', geo_info, self.__name__, evt)
        self.notifyListeners(geo_info_evt)
        found = True

",1,"[['https://github.com/smicallef/spiderfoot/tree/master/test/unit/modules/test_sfp_hostio.py', 'test.unit.modules.test_sfp_hostio', 'TestModulehostio', 'test_handleEvent_no_api_key_should_set_errorState']]"
glom,https://github.com/mahmoud/glom/tree/master/glom/core.py,,test_types_bare,"for (cur_type, sub_tree) in type_tree.items():
    if isinstance(obj, cur_type):
        sub_type = self._get_closest_type(obj, type_tree=sub_tree)
        ret = cur_type if sub_type is None else sub_type
        return ret","for e_target in type_tree.items():
    sub_tree = e_target[1]
    cur_type = e_target[0]
    if isinstance(obj, cur_type):
        sub_type = self._get_closest_type(obj, type_tree=sub_tree)
        ret = cur_type if sub_type is None else sub_type
        return ret

",1,"[['https://github.com/mahmoud/glom/tree/master/glom/test/test_target_types.py', 'glom.test.test_target_types', '', 'test_types_leave_one_out'], ['https://github.com/mahmoud/glom/tree/master/glom/test/test_target_types.py', 'glom.test.test_target_types', '', 'test_types_bare']]"
markovify,https://github.com/jsvine/markovify/tree/master/markovify/utils.py,MarkovifyTest,test_mismatched_state_sizes,"for (m, w) in zip(model_dicts, weights):
    for (state, options) in m.items():
        current = c.get(state, {})
        for (subseq_k, subseq_v) in options.items():
            subseq_prev = current.get(subseq_k, 0)
            current[subseq_k] = subseq_prev + subseq_v * w
        c[state] = current","for e_target in zip(model_dicts, weights):
    w = e_target[1]
    m = e_target[0]
    for (state, options) in m.items():
        current = c.get(state, {})
        for (subseq_k, subseq_v) in options.items():
            subseq_prev = current.get(subseq_k, 0)
            current[subseq_k] = subseq_prev + subseq_v * w
        c[state] = current

",1,"[['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_chains'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_no_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_no_retain_on_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_lists'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_bad_types'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_dicts'], ['https://github.com/jsvine/markovify/tree/master/test/test_itertext.py', 'test.test_itertext', 'MarkovifyTest', 'test_from_mult_files_without_retaining'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_mismatched_model_types'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_bad_weights'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_compiled_chain_fail'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_simple'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_double_weighted'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_compiled_model_fail'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_retain_on_no_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_mismatched_state_sizes']]"
markovify,https://github.com/jsvine/markovify/tree/master/markovify/utils.py,MarkovifyTest,test_mismatched_state_sizes,"for (state, options) in m.items():
    current = c.get(state, {})
    for (subseq_k, subseq_v) in options.items():
        subseq_prev = current.get(subseq_k, 0)
        current[subseq_k] = subseq_prev + subseq_v * w
    c[state] = current","for e_target in m.items():
    options = e_target[1]
    state = e_target[0]
    current = c.get(state, {})
    for (subseq_k, subseq_v) in options.items():
        subseq_prev = current.get(subseq_k, 0)
        current[subseq_k] = subseq_prev + subseq_v * w
    c[state] = current

",1,"[['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_chains'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_no_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_no_retain_on_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_lists'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_bad_types'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_dicts'], ['https://github.com/jsvine/markovify/tree/master/test/test_itertext.py', 'test.test_itertext', 'MarkovifyTest', 'test_from_mult_files_without_retaining'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_mismatched_model_types'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_bad_weights'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_compiled_chain_fail'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_simple'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_double_weighted'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_compiled_model_fail'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_retain_on_no_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_mismatched_state_sizes']]"
markovify,https://github.com/jsvine/markovify/tree/master/markovify/utils.py,MarkovifyTest,test_mismatched_state_sizes,"for (subseq_k, subseq_v) in options.items():
    subseq_prev = current.get(subseq_k, 0)
    current[subseq_k] = subseq_prev + subseq_v * w","for e_target in options.items():
    subseq_v = e_target[1]
    subseq_k = e_target[0]
    subseq_prev = current.get(subseq_k, 0)
    current[subseq_k] = subseq_prev + subseq_v * w

",1,"[['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_chains'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_no_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_no_retain_on_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_lists'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_bad_types'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_dicts'], ['https://github.com/jsvine/markovify/tree/master/test/test_itertext.py', 'test.test_itertext', 'MarkovifyTest', 'test_from_mult_files_without_retaining'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_mismatched_model_types'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_bad_weights'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_compiled_chain_fail'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_simple'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_double_weighted'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_compiled_model_fail'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_combine_retain_on_no_retain'], ['https://github.com/jsvine/markovify/tree/master/test/test_combine.py', 'test.test_combine', 'MarkovifyTest', 'test_mismatched_state_sizes']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/dtw.py,,test_distance_matrix1_b,"for (k, v) in dist_opts.items():
    if v is None:
        dist_opts[k] = 0","for e_target in dist_opts.items():
    v = e_target[1]
    k = e_target[0]
    if v is None:
        dist_opts[k] = 0

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_benchmark.py', 'tests.test_benchmark', '', 'test_distance_matrix1_serial_python'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_bugsvis.py', 'tests.test_bugsvis', '', 'test_bug3'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_benchmark.py', 'tests.test_benchmark', '', 'test_distance_matrix1_parallel_python'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_dtw.py', 'tests.test_dtw', '', 'test_distance_matrix1_a'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_dtw.py', 'tests.test_dtw', '', 'test_distance_matrix1_b']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/dtw.py,,test_normalize,"for (r_c, c_c) in path:
    from_s2[c_c] += from_s[r_c]
    from_s2_cnt[c_c] += 1","for e_target in path:
    c_c = e_target[1]
    r_c = e_target[0]
    from_s2[c_c] += from_s[r_c]
    from_s2_cnt[c_c] += 1

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_warping.py', 'tests.test_warping', '', 'test_normalize']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/util.py,,test_sequences_custom,"for (j, value) in enumerate(line[1:]):
    matrix[idx[j], symbol] = float(value)","for e_target in enumerate(line[1:]):
    value = e_target[1]
    j = e_target[0]
    matrix[idx[j], symbol] = float(value)

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_sequences_blosum'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_substitution_function'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_sequences_custom']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/dtw_ndim_visualisation.py,,test_visualisation_a,"for (r_c, c_c) in path:
    if r_c < 0 or c_c < 0:
        continue
    coord1 = transFigure.transform(ax[0].transData.transform([r_c + 0.5, 0]))
    coord2 = transFigure.transform(ax[1].transData.transform([c_c + 0.5, 0]))
    lines.append(mpl.lines.Line2D((coord1[0], coord2[0]), (coord1[1], coord2[1]), transform=fig.transFigure, **line_options))","for e_target in path:
    c_c = e_target[1]
    r_c = e_target[0]
    if r_c < 0 or c_c < 0:
        continue
    coord1 = transFigure.transform(ax[0].transData.transform([r_c + 0.5, 0]))
    coord2 = transFigure.transform(ax[1].transData.transform([c_c + 0.5, 0]))
    lines.append(mpl.lines.Line2D((coord1[0], coord2[0]), (coord1[1], coord2[1]), transform=fig.transFigure, **line_options))

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_dtw2d.py', 'tests.test_dtw2d', '', 'test_visualisation_a']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/alignment.py,,test_sequences3,"for (s1i, s2i) in p[1:]:
    if s1i != s1ip and s2i != s2ip:
        if s1a is not None:
            s1a.append(s1[s1ip])
        if s2a is not None:
            s2a.append(s2[s2ip])
    elif s1i == s1ip:
        if s1a is not None:
            s1a.append(gap)
        if s2a is not None:
            s2a.append(s2[s2ip])
    elif s2i == s2ip:
        if s1a is not None:
            s1a.append(s1[s1ip])
        if s2a is not None:
            s2a.append(gap)
    (s1ip, s2ip) = (s1i, s2i)","for e_target in p[1:]:
    s2i = e_target[1]
    s1i = e_target[0]
    if s1i != s1ip and s2i != s2ip:
        if s1a is not None:
            s1a.append(s1[s1ip])
        if s2a is not None:
            s2a.append(s2[s2ip])
    elif s1i == s1ip:
        if s1a is not None:
            s1a.append(gap)
        if s2a is not None:
            s2a.append(s2[s2ip])
    elif s2i == s2ip:
        if s1a is not None:
            s1a.append(s1[s1ip])
        if s2a is not None:
            s2a.append(gap)
    (s1ip, s2ip) = (s1i, s2i)

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_sequences1'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_sequences_custom'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_sequences4'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_sequences2'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_sequences_blosum'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_alignment.py', 'tests.test_alignment', '', 'test_sequences3']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/dtw_ndim.py,,test_distances1_python,"for (k, v) in dist_opts.items():
    if v is None:
        dist_opts[k] = 0","for e_target in dist_opts.items():
    v = e_target[1]
    k = e_target[0]
    if v is None:
        dist_opts[k] = 0

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_dtw2d.py', 'tests.test_dtw2d', '', 'test_distances1_python']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/dtw_visualisation.py,,test_normalize,"for (r_c, c_c) in path:
    if r_c < 0 or c_c < 0:
        continue
    con = ConnectionPatch(xyA=[r_c, from_s[r_c]], coordsA=ax[0].transData, xyB=[c_c, to_s[c_c]], coordsB=ax[1].transData, **line_options)
    lines.append(con)","for e_target in path:
    c_c = e_target[1]
    r_c = e_target[0]
    if r_c < 0 or c_c < 0:
        continue
    con = ConnectionPatch(xyA=[r_c, from_s[r_c]], coordsA=ax[0].transData, xyB=[c_c, to_s[c_c]], coordsB=ax[1].transData, **line_options)
    lines.append(con)

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_warping.py', 'tests.test_warping', '', 'test_normalize']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/dtw_visualisation.py,,test_twoleadecg_1,"for (r_c, c_c) in path:
    if r_c < 0 or c_c < 0:
        continue
    con = ConnectionPatch(xyA=[r_c, s1[r_c]], coordsA=ax[0].transData, xyB=[c_c, s2[c_c]], coordsB=ax[1].transData, **line_options)
    lines.append(con)","for e_target in path:
    c_c = e_target[1]
    r_c = e_target[0]
    if r_c < 0 or c_c < 0:
        continue
    con = ConnectionPatch(xyA=[r_c, s1[r_c]], coordsA=ax[0].transData, xyB=[c_c, s2[c_c]], coordsB=ax[1].transData, **line_options)
    lines.append(con)

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_bugsvis.py', 'tests.test_bugsvis', '', 'test_bug4'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_warping.py', 'tests.test_warping', '', 'test_normalize'], ['https://github.com/wannesm/dtaidistance/tree/master/tests/test_warping.py', 'tests.test_warping', '', 'test_twoleadecg_1']]"
dtaidistance,https://github.com/wannesm/dtaidistance/tree/master/dtaidistance/dtw_weighted.py,,test_decisiontree,"for (fi, ig, thr, kd) in all_gains:
    gain = ig * (1 + (kd / max_kd) ** 1)
    if best_gain < gain:
        best_gain = gain
        best_fi = fi
        best_thr = thr
        best_kd = kd","for e_target in all_gains:
    kd = e_target[3]
    thr = e_target[2]
    ig = e_target[1]
    fi = e_target[0]
    gain = ig * (1 + (kd / max_kd) ** 1)
    if best_gain < gain:
        best_gain = gain
        best_fi = fi
        best_thr = thr
        best_kd = kd

",1,"[['https://github.com/wannesm/dtaidistance/tree/master/tests/test_dtw_weighted_dt.py', 'tests.test_dtw_weighted_dt', '', 'test_decisiontree']]"
extruct,https://github.com/scrapinghub/extruct/tree/master/extruct/_extruct.py,TestUniform,test_uopengraph_with_og_array,"for (syntax, extract, document) in processors:
    try:
        output[syntax] = list(extract(document, base_url=base_url))
    except Exception as e:
        if errors == 'log':
            logger.exception('Failed to extract {}, raises {}'.format(syntax, e))
        if errors == 'ignore':
            pass
        if errors == 'strict':
            raise","for e_target in processors:
    document = e_target[2]
    extract = e_target[1]
    syntax = e_target[0]
    try:
        output[syntax] = list(extract(document, base_url=base_url))
    except Exception as e:
        if errors == 'log':
            logger.exception('Failed to extract {}, raises {}'.format(syntax, e))
        if errors == 'ignore':
            pass
        if errors == 'strict':
            raise

",1,"[['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_deprecated_url'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct_uniform.py', 'tests.test_extruct_uniform', 'TestFlatten', 'test_microdata'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_rdfa_is_preserving_order'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_umicroformat'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct_uniform.py', 'tests.test_extruct_uniform', 'TestFlatten', 'test_microformat'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_udublincore'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_errors'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_extra_kwargs'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_microdata_custom_url'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_uopengraph'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_all'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_umicrodata'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_microdata_with_returning_node'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct_uniform.py', 'tests.test_extruct_uniform', 'TestFlatten', 'test_microdata_with_returning_node'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct_uniform.py', 'tests.test_extruct_uniform', 'TestFlatten', 'test_opengraph'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_uopengraph_with_og_array']]"
extruct,https://github.com/scrapinghub/extruct/tree/master/extruct/_extruct.py,TestUniform,test_uopengraph_with_og_array,"for (syntax, uniform, raw, schema_context) in uniform_processors:
    try:
        if syntax == 'opengraph':
            output[syntax] = uniform(raw, with_og_array=with_og_array)
        elif syntax == 'dublincore':
            output[syntax] = uniform(raw)
        else:
            output[syntax] = uniform(raw, schema_context)
    except Exception as e:
        if errors == 'ignore':
            output[syntax] = []
        if errors == 'log':
            output[syntax] = []
            logger.exception('Failed to uniform extracted for {}, raises {}'.format(syntax, e))
        if errors == 'strict':
            raise","for e_target in uniform_processors:
    schema_context = e_target[3]
    raw = e_target[2]
    uniform = e_target[1]
    syntax = e_target[0]
    try:
        if syntax == 'opengraph':
            output[syntax] = uniform(raw, with_og_array=with_og_array)
        elif syntax == 'dublincore':
            output[syntax] = uniform(raw)
        else:
            output[syntax] = uniform(raw, schema_context)
    except Exception as e:
        if errors == 'ignore':
            output[syntax] = []
        if errors == 'log':
            output[syntax] = []
            logger.exception('Failed to uniform extracted for {}, raises {}'.format(syntax, e))
        if errors == 'strict':
            raise

",1,"[['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_deprecated_url'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct_uniform.py', 'tests.test_extruct_uniform', 'TestFlatten', 'test_microdata'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_rdfa_is_preserving_order'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_umicroformat'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct_uniform.py', 'tests.test_extruct_uniform', 'TestFlatten', 'test_microformat'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_udublincore'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_errors'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_extra_kwargs'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_microdata_custom_url'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_uopengraph'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_all'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_umicrodata'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct.py', 'tests.test_extruct', 'TestGeneric', 'test_microdata_with_returning_node'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct_uniform.py', 'tests.test_extruct_uniform', 'TestFlatten', 'test_microdata_with_returning_node'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_extruct_uniform.py', 'tests.test_extruct_uniform', 'TestFlatten', 'test_opengraph'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_uopengraph_with_og_array']]"
extruct,https://github.com/scrapinghub/extruct/tree/master/extruct/uniform.py,TestUniform,test_uopengraph_duplicated_with_og_array,"for (k, v) in properties:
    if k not in flattened.keys():
        flattened[k] = v
    elif v and v.strip():
        if not with_og_array:
            if not flattened[k] or not flattened[k].strip():
                flattened[k] = v
        elif isinstance(flattened[k], list):
            flattened[k].append(v)
        elif flattened[k] and flattened[k].strip():
            flattened[k] = [flattened[k], v]
        else:
            flattened[k] = v","for e_target in properties:
    v = e_target[1]
    k = e_target[0]
    if k not in flattened.keys():
        flattened[k] = v
    elif v and v.strip():
        if not with_og_array:
            if not flattened[k] or not flattened[k].strip():
                flattened[k] = v
        elif isinstance(flattened[k], list):
            flattened[k].append(v)
        elif flattened[k] and flattened[k].strip():
            flattened[k] = [flattened[k], v]
        else:
            flattened[k] = v

",1,"[['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_uopengraph_duplicated_priorities'], ['https://github.com/scrapinghub/extruct/tree/master/tests/test_uniform.py', 'tests.test_uniform', 'TestUniform', 'test_uopengraph_duplicated_with_og_array']]"
pymemcache,https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/utils.py,,test_get_many_set_many_non_ascii_values,"for (key, value) in values.items():
    ret = self.set(key, value, expire, noreply, flags=flags)
    if not ret:
        result.append(key)","for e_target in values.items():
    value = e_target[1]
    key = e_target[0]
    ret = self.set(key, value, expire, noreply, flags=flags)
    if not ret:
        result.append(key)

",1,"[['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_utils.py', 'pymemcache.test.test_utils', '', 'test_get_many_set_many'], ['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_utils.py', 'pymemcache.test.test_utils', '', 'test_get_many_set_many_non_ascii_values']]"
pymemcache,https://github.com/pinterest/pymemcache/tree/master/pymemcache/client/hash.py,TestHashClient,test_set_many_unix,"for (key, value) in values.items():
    client = self._get_client(key)
    if client is None:
        failed.append(key)
        continue
    client_batches[client.server][key] = value","for e_target in values.items():
    value = e_target[1]
    key = e_target[0]
    client = self._get_client(key)
    if client is None:
        failed.append(key)
        continue
    client_batches[client.server][key] = value

",1,"[['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_client_hash.py', 'pymemcache.test.test_client_hash', 'TestHashClient', 'test_noreply_set_many'], ['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_client_hash.py', 'pymemcache.test.test_client_hash', 'TestHashClient', 'test_no_servers_left_with_set_many'], ['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_client_hash.py', 'pymemcache.test.test_client_hash', 'TestHashClient', 'test_ignore_exec_set_many'], ['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_client_hash.py', 'pymemcache.test.test_client_hash', 'TestHashClient', 'test_set_many_unix']]"
pymemcache,https://github.com/pinterest/pymemcache/tree/master/pymemcache/client/hash.py,TestHashClient,test_set_many_unix,"for (server, values) in client_batches.items():
    client = self.clients[self._make_client_key(server)]
    failed += self._safely_run_set_many(client, values, *args, **kwargs)","for e_target in client_batches.items():
    values = e_target[1]
    server = e_target[0]
    client = self.clients[self._make_client_key(server)]
    failed += self._safely_run_set_many(client, values, *args, **kwargs)

",1,"[['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_client_hash.py', 'pymemcache.test.test_client_hash', 'TestHashClient', 'test_noreply_set_many'], ['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_client_hash.py', 'pymemcache.test.test_client_hash', 'TestHashClient', 'test_no_servers_left_with_set_many'], ['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_client_hash.py', 'pymemcache.test.test_client_hash', 'TestHashClient', 'test_ignore_exec_set_many'], ['https://github.com/pinterest/pymemcache/tree/master/pymemcache/test/test_client_hash.py', 'pymemcache.test.test_client_hash', 'TestHashClient', 'test_set_many_unix']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/convert.py,TestConvert,test_graph,"for (n, dd) in data.nodes.items():
    result._node[n].update(dd)","for e_target in data.nodes.items():
    dd = e_target[1]
    n = e_target[0]
    result._node[n].update(dd)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert.py', 'networkx.tests.test_convert', 'TestConvert', 'test_digraphs'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert.py', 'networkx.tests.test_convert', 'TestConvert', 'test_attribute_dict_integrity'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert.py', 'networkx.tests.test_convert', '', 'test_to_networkx_graph_non_edgelist'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert.py', 'networkx.tests.test_convert', 'TestConvert', 'test_simple_graphs'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert.py', 'networkx.tests.test_convert', 'TestConvert', 'test_with_multiedges_self_loops'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert.py', 'networkx.tests.test_convert', 'TestConvert', 'test_graph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/convert_matrix.py,TestConvertPandas,test_from_edgelist_no_attr,"for (s, t, attrs) in zip(df[source], df[target], attribute_data):
    if edge_key is not None:
        (attrs, multigraph_edge_key) = attrs
        key = g.add_edge(s, t, key=multigraph_edge_key)
    else:
        key = g.add_edge(s, t)
    g[s][t][key].update(zip(attr_col_headings, attrs))","for e_target in zip(df[source], df[target], attribute_data):
    attrs = e_target[2]
    t = e_target[1]
    s = e_target[0]
    if edge_key is not None:
        (attrs, multigraph_edge_key) = attrs
        key = g.add_edge(s, t, key=multigraph_edge_key)
    else:
        key = g.add_edge(s, t)
    g[s][t][key].update(zip(attr_col_headings, attrs))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_multi_attr'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_edgekey_with_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_all_attr'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_edgekey_with_normal_graph_no_action'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_multidigraph_and_edge_attr'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_int_attr_name'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_one_attr'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_nonexisting_edgekey_raises'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_multi_attr_incl_target'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_no_attr']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/convert_matrix.py,TestConvertPandas,test_from_edgelist_no_attr,"for (s, t, attrs) in zip(df[source], df[target], attribute_data):
    g.add_edge(s, t)
    g[s][t].update(zip(attr_col_headings, attrs))","for e_target in zip(df[source], df[target], attribute_data):
    attrs = e_target[2]
    t = e_target[1]
    s = e_target[0]
    g.add_edge(s, t)
    g[s][t].update(zip(attr_col_headings, attrs))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_multi_attr'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_edgekey_with_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_all_attr'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_edgekey_with_normal_graph_no_action'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_multidigraph_and_edge_attr'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_int_attr_name'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_one_attr'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_nonexisting_edgekey_raises'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_multi_attr_incl_target'], ['https://github.com/networkx/networkx/tree/master/networkx/tests/test_convert_pandas.py', 'networkx.tests.test_convert_pandas', 'TestConvertPandas', 'test_from_edgelist_no_attr']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/generators/social.py,,test_spectral_graph_forge,"for (row, line) in enumerate(zacharydat.split('\n')):
    thisrow = [int(b) for b in line.split()]
    for (col, entry) in enumerate(thisrow):
        if entry == 1:
            G.add_edge(row, col)","for e_target in enumerate(zacharydat.split('\n')):
    line = e_target[1]
    row = e_target[0]
    thisrow = [int(b) for b in line.split()]
    for (col, entry) in enumerate(thisrow):
        if entry == 1:
            G.add_edge(row, col)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/generators/tests/test_spectral_graph_forge.py', 'networkx.generators.tests.test_spectral_graph_forge', '', 'test_spectral_graph_forge']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/generators/social.py,,test_spectral_graph_forge,"for (col, entry) in enumerate(thisrow):
    if entry == 1:
        G.add_edge(row, col)","for e_target in enumerate(thisrow):
    entry = e_target[1]
    col = e_target[0]
    if entry == 1:
        G.add_edge(row, col)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/generators/tests/test_spectral_graph_forge.py', 'networkx.generators.tests.test_spectral_graph_forge', '', 'test_spectral_graph_forge']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/generators/expanders.py,,test_directed_combinatorial_laplacian,"for (x, y) in itertools.product(range(n), repeat=2):
    for (u, v) in (((x + 2 * y) % n, y), ((x + (2 * y + 1)) % n, y), (x, (y + 2 * x) % n), (x, (y + (2 * x + 1)) % n)):
        G.add_edge((x, y), (u, v))","for e_target in itertools.product(range(n), repeat=2):
    y = e_target[1]
    x = e_target[0]
    for (u, v) in (((x + 2 * y) % n, y), ((x + (2 * y + 1)) % n, y), (x, (y + 2 * x) % n), (x, (y + (2 * x + 1)) % n)):
        G.add_edge((x, y), (u, v))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/linalg/tests/test_laplacian.py', 'networkx.linalg.tests.test_laplacian', '', 'test_directed_combinatorial_laplacian']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/generators/expanders.py,,test_directed_combinatorial_laplacian,"for (u, v) in (((x + 2 * y) % n, y), ((x + (2 * y + 1)) % n, y), (x, (y + 2 * x) % n), (x, (y + (2 * x + 1)) % n)):
    G.add_edge((x, y), (u, v))","for e_target in (((x + 2 * y) % n, y), ((x + (2 * y + 1)) % n, y), (x, (y + 2 * x) % n), (x, (y + (2 * x + 1)) % n)):
    v = e_target[1]
    u = e_target[0]
    G.add_edge((x, y), (u, v))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/linalg/tests/test_laplacian.py', 'networkx.linalg.tests.test_laplacian', '', 'test_directed_combinatorial_laplacian']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/generators/joint_degree_seq.py,,test_joint_degree_graph,"for (degree, num_nodes) in degree_count.items():
    h_degree_nodelist[degree] = range(nodeid, nodeid + num_nodes)
    for v in h_degree_nodelist[degree]:
        h_node_residual[v] = degree
    nodeid += int(num_nodes)","for e_target in degree_count.items():
    num_nodes = e_target[1]
    degree = e_target[0]
    h_degree_nodelist[degree] = range(nodeid, nodeid + num_nodes)
    for v in h_degree_nodelist[degree]:
        h_node_residual[v] = degree
    nodeid += int(num_nodes)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/generators/tests/test_joint_degree_seq.py', 'networkx.generators.tests.test_joint_degree_seq', '', 'test_joint_degree_graph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/generators/joint_degree_seq.py,,test_directed_joint_degree_graph,"for (idx, i) in enumerate(in_degrees):
    idx = int(idx)
    if i > 0:
        h_degree_nodelist_in.setdefault(i, [])
        h_degree_nodelist_in_unsat.setdefault(i, set())
        h_degree_nodelist_in[i].append(idx)
        h_degree_nodelist_in_unsat[i].add(idx)
        h_node_residual_in[idx] = i
        h_partition_in[idx] = i","for e_target in enumerate(in_degrees):
    i = e_target[1]
    idx = e_target[0]
    idx = int(idx)
    if i > 0:
        h_degree_nodelist_in.setdefault(i, [])
        h_degree_nodelist_in_unsat.setdefault(i, set())
        h_degree_nodelist_in[i].append(idx)
        h_degree_nodelist_in_unsat[i].add(idx)
        h_node_residual_in[idx] = i
        h_partition_in[idx] = i

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/generators/tests/test_joint_degree_seq.py', 'networkx.generators.tests.test_joint_degree_seq', '', 'test_directed_joint_degree_graph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/generators/joint_degree_seq.py,,test_directed_joint_degree_graph,"for (idx, o) in enumerate(out_degrees):
    o = out_degrees[idx]
    non_chords[o, in_degrees[idx]] = non_chords.get((o, in_degrees[idx]), 0) + 1
    idx = int(idx)
    if o > 0:
        h_degree_nodelist_out.setdefault(o, [])
        h_degree_nodelist_out_unsat.setdefault(o, set())
        h_degree_nodelist_out[o].append(idx)
        h_degree_nodelist_out_unsat[o].add(idx)
        h_node_residual_out[idx] = o
        h_partition_out[idx] = o
    G.add_node(idx)","for e_target in enumerate(out_degrees):
    o = e_target[1]
    idx = e_target[0]
    o = out_degrees[idx]
    non_chords[o, in_degrees[idx]] = non_chords.get((o, in_degrees[idx]), 0) + 1
    idx = int(idx)
    if o > 0:
        h_degree_nodelist_out.setdefault(o, [])
        h_degree_nodelist_out_unsat.setdefault(o, set())
        h_degree_nodelist_out[o].append(idx)
        h_degree_nodelist_out_unsat[o].add(idx)
        h_node_residual_out[idx] = o
        h_partition_out[idx] = o
    G.add_node(idx)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/generators/tests/test_joint_degree_seq.py', 'networkx.generators.tests.test_joint_degree_seq', '', 'test_directed_joint_degree_graph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/utils/misc.py,,test_make_list_of_ints,"for (indx, i) in enumerate(sequence):
    errmsg = f'sequence is not all integers: {i}'
    if isinstance(i, int):
        continue
    try:
        ii = int(i)
    except ValueError:
        raise nx.NetworkXError(errmsg) from None
    if ii != i:
        raise nx.NetworkXError(errmsg)
    sequence[indx] = ii","for e_target in enumerate(sequence):
    i = e_target[1]
    indx = e_target[0]
    errmsg = f'sequence is not all integers: {i}'
    if isinstance(i, int):
        continue
    try:
        ii = int(i)
    except ValueError:
        raise nx.NetworkXError(errmsg) from None
    if ii != i:
        raise nx.NetworkXError(errmsg)
    sequence[indx] = ii

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_misc.py', 'networkx.utils.tests.test_misc', 'TestNumpyArray', 'test_numpy_to_list_of_ints'], ['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_misc.py', 'networkx.utils.tests.test_misc', '', 'test_make_list_of_ints']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/utils/misc.py,TestNumpyArray,test_dict_to_numpy_array_a,"for (k1, i) in mapping.items():
    for (k2, j) in mapping.items():
        try:
            a[i, j] = d[k1][k2]
        except KeyError:
            pass","for e_target in mapping.items():
    i = e_target[1]
    k1 = e_target[0]
    for (k2, j) in mapping.items():
        try:
            a[i, j] = d[k1][k2]
        except KeyError:
            pass

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_misc.py', 'networkx.utils.tests.test_misc', 'TestNumpyArray', 'test_dict_to_numpy_array2'], ['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_misc.py', 'networkx.utils.tests.test_misc', 'TestNumpyArray', 'test_dict_to_numpy_array_a']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/utils/misc.py,TestNumpyArray,test_dict_to_numpy_array_a,"for (k, v) in d.items():
    s.update(v.keys())","for e_target in d.items():
    v = e_target[1]
    k = e_target[0]
    s.update(v.keys())

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_misc.py', 'networkx.utils.tests.test_misc', 'TestNumpyArray', 'test_dict_to_numpy_array2'], ['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_misc.py', 'networkx.utils.tests.test_misc', 'TestNumpyArray', 'test_dict_to_numpy_array_a']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/utils/misc.py,TestNumpyArray,test_dict_to_numpy_array_a,"for (k2, j) in mapping.items():
    try:
        a[i, j] = d[k1][k2]
    except KeyError:
        pass","for e_target in mapping.items():
    j = e_target[1]
    k2 = e_target[0]
    try:
        a[i, j] = d[k1][k2]
    except KeyError:
        pass

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_misc.py', 'networkx.utils.tests.test_misc', 'TestNumpyArray', 'test_dict_to_numpy_array2'], ['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_misc.py', 'networkx.utils.tests.test_misc', 'TestNumpyArray', 'test_dict_to_numpy_array_a']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/utils/random_sequence.py,,test_random_weighted_choice,"for (k, w) in mapping.items():
    rnd -= w
    if rnd < 0:
        return k","for e_target in mapping.items():
    w = e_target[1]
    k = e_target[0]
    rnd -= w
    if rnd < 0:
        return k

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/utils/tests/test_random_sequence.py', 'networkx.utils.tests.test_random_sequence', '', 'test_random_weighted_choice']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/tournament.py,,test_empty_iterable,"for (i, x) in enumerate(iterable):
    if condition(x):
        return i","for e_target in enumerate(iterable):
    x = e_target[1]
    i = e_target[0]
    if condition(x):
        return i

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_tournament.py', 'networkx.algorithms.tests.test_tournament', '', 'test_condition_not_satisfied'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_tournament.py', 'networkx.algorithms.tests.test_tournament', '', 'test_empty_iterable']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/threshold.py,TestGeneratorThreshold,test_creation_sequence_to_weights,"for (j, s) in enumerate(wseq):
    if s == 'i':
        wseq[j] = w
        prev = s
    elif prev == 'i':
        prev = s
        w += 1","for e_target in enumerate(wseq):
    s = e_target[1]
    j = e_target[0]
    if s == 'i':
        wseq[j] = w
        prev = s
    elif prev == 'i':
        prev = s
        w += 1

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_threshold.py', 'networkx.algorithms.tests.test_threshold', 'TestGeneratorThreshold', 'test_weights_thresholds'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_threshold.py', 'networkx.algorithms.tests.test_threshold', 'TestGeneratorThreshold', 'test_creation_sequence_to_weights']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/threshold.py,TestGeneratorThreshold,test_creation_sequence_to_weights,"for (j, s) in enumerate(wseq):
    if s == 'd':
        wseq[j] = w
        prev = s
    elif prev == 'd':
        prev = s
        w += 1","for e_target in enumerate(wseq):
    s = e_target[1]
    j = e_target[0]
    if s == 'd':
        wseq[j] = w
        prev = s
    elif prev == 'd':
        prev = s
        w += 1

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_threshold.py', 'networkx.algorithms.tests.test_threshold', 'TestGeneratorThreshold', 'test_weights_thresholds'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_threshold.py', 'networkx.algorithms.tests.test_threshold', 'TestGeneratorThreshold', 'test_creation_sequence_to_weights']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/regular.py,TestKFactor,test_k_factor5,"for (node, degree) in list(g.degree):
    if k < degree / 2.0:
        gadget = SmallKGadget(k, degree, node, g)
    else:
        gadget = LargeKGadget(k, degree, node, g)
    gadget.replace_node()
    gadgets.append(gadget)","for e_target in list(g.degree):
    degree = e_target[1]
    node = e_target[0]
    if k < degree / 2.0:
        gadget = SmallKGadget(k, degree, node, g)
    else:
        gadget = LargeKGadget(k, degree, node, g)
    gadget.replace_node()
    gadgets.append(gadget)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor2'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor3'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor_trivial'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor4'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor5']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/regular.py,TestKFactor,test_k_factor5,"for (outer, neighbor, edge_attrs) in zip(self.outer_vertices, neighbors, edge_attrs):
    self.g.add_edge(outer, neighbor, **edge_attrs)","for e_target in zip(self.outer_vertices, neighbors, edge_attrs):
    edge_attrs = e_target[2]
    neighbor = e_target[1]
    outer = e_target[0]
    self.g.add_edge(outer, neighbor, **edge_attrs)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor2'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor3'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor_trivial'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor4'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor5']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/regular.py,TestKFactor,test_k_factor5,"for (outer, inner, (neighbor, edge_attrs)) in zip(self.outer_vertices, self.inner_vertices, list(adj_view.items())):
    self.g.add_edge(outer, inner)
    self.g.add_edge(outer, neighbor, **edge_attrs)","for e_target in zip(self.outer_vertices, self.inner_vertices, list(adj_view.items())):
    edge_attrs = e_target[2][1]
    neighbor = e_target[2][0]
    inner = e_target[1]
    outer = e_target[0]
    self.g.add_edge(outer, inner)
    self.g.add_edge(outer, neighbor, **edge_attrs)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor2'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor3'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor_trivial'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor4'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor5']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/regular.py,TestKFactor,test_k_factor5,"for (neighbor, edge_attrs) in list(adj_view.items()):
    if neighbor not in self.core_vertices:
        self.g.add_edge(self.original, neighbor, **edge_attrs)
        break","for e_target in list(adj_view.items()):
    edge_attrs = e_target[1]
    neighbor = e_target[0]
    if neighbor not in self.core_vertices:
        self.g.add_edge(self.original, neighbor, **edge_attrs)
        break

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor2'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor3'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor_trivial'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor4'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor5']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/regular.py,TestKFactor,test_k_factor5,"for (neighbor, edge_attrs) in adj_view.items():
    if neighbor not in self.core_vertices:
        self.g.add_edge(self.original, neighbor, **edge_attrs)
        break","for e_target in adj_view.items():
    edge_attrs = e_target[1]
    neighbor = e_target[0]
    if neighbor not in self.core_vertices:
        self.g.add_edge(self.original, neighbor, **edge_attrs)
        break

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor2'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor3'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor_trivial'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor4'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_regular.py', 'networkx.algorithms.tests.test_regular', 'TestKFactor', 'test_k_factor5']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/similarity.py,TestSimilarity,test_digraph,"for (vertex_path, edge_path, cost) in optimize_edit_paths(G1, G2, node_match, edge_match, node_subst_cost, node_del_cost, node_ins_cost, edge_subst_cost, edge_del_cost, edge_ins_cost, upper_bound, True, roots, timeout):
    bestcost = cost","for e_target in optimize_edit_paths(G1, G2, node_match, edge_match, node_subst_cost, node_del_cost, node_ins_cost, edge_subst_cost, edge_del_cost, edge_ins_cost, upper_bound, True, roots, timeout):
    cost = e_target[2]
    edge_path = e_target[1]
    vertex_path = e_target[0]
    bestcost = cost

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_graph_edit_distance_edge_match'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_graph_edit_distance_node_match'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_graph_edit_distance_roots_and_timeout'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_graph_edit_distance_edge_cost'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_selfloops'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_graph_edit_distance_node_cost'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_graph_edit_distance'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_graph_edit_distance_upper_bound'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_multidigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_similarity.py', 'networkx.algorithms.tests.test_similarity', 'TestSimilarity', 'test_digraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/cycles.py,TestFindCycle,test_multidigraph,"for (i, edge) in enumerate(cycle):
    (tail, head) = tailhead(edge)
    if tail == final_node:
        break","for e_target in enumerate(cycle):
    edge = e_target[1]
    i = e_target[0]
    (tail, head) = tailhead(edge)
    if tail == final_node:
        break

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_multidigraph_ignore2'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_dag'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_digraph_orientation_original'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_digraph_orientation_none'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_digraph_reverse'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_graph_orientation_original'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_digraph_ignore'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_graph_orientation_none'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_digraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_multidigraph_ignore'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_graph_cycle'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tests/test_cycles.py', 'networkx.algorithms.tests.test_cycles', 'TestFindCycle', 'test_multidigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/utils.py,TestMaxflowLargeGraph,test_complete_graph,"for (u, v, attr) in edge_list:
    r = min(attr.get(capacity, inf), inf)
    if not R.has_edge(u, v):
        R.add_edge(u, v, capacity=r)
        R.add_edge(v, u, capacity=0)
    else:
        R[u][v]['capacity'] = r","for e_target in edge_list:
    attr = e_target[2]
    v = e_target[1]
    u = e_target[0]
    r = min(attr.get(capacity, inf), inf)
    if not R.has_edge(u, v):
        R.add_edge(u, v, capacity=r)
        R.add_edge(v, u, capacity=0)
    else:
        R[u][v]['capacity'] = r

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow_large_graph.py', 'networkx.algorithms.flow.tests.test_maxflow_large_graph', 'TestMaxflowLargeGraph', 'test_gl1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow_large_graph.py', 'networkx.algorithms.flow.tests.test_maxflow_large_graph', 'TestMaxflowLargeGraph', 'test_pyramid'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow.py', 'networkx.algorithms.flow.tests.test_maxflow', 'TestMaxFlowMinCutInterface', 'test_reusing_residual'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow_large_graph.py', 'networkx.algorithms.flow.tests.test_maxflow_large_graph', 'TestMaxflowLargeGraph', 'test_wlm3'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow_large_graph.py', 'networkx.algorithms.flow.tests.test_maxflow_large_graph', 'TestMaxflowLargeGraph', 'test_complete_graph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/utils.py,TestMaxflowLargeGraph,test_complete_graph,"for (u, v, attr) in edge_list:
    r = min(attr.get(capacity, inf), inf)
    R.add_edge(u, v, capacity=r)
    R.add_edge(v, u, capacity=r)","for e_target in edge_list:
    attr = e_target[2]
    v = e_target[1]
    u = e_target[0]
    r = min(attr.get(capacity, inf), inf)
    R.add_edge(u, v, capacity=r)
    R.add_edge(v, u, capacity=r)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow_large_graph.py', 'networkx.algorithms.flow.tests.test_maxflow_large_graph', 'TestMaxflowLargeGraph', 'test_gl1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow_large_graph.py', 'networkx.algorithms.flow.tests.test_maxflow_large_graph', 'TestMaxflowLargeGraph', 'test_pyramid'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow.py', 'networkx.algorithms.flow.tests.test_maxflow', 'TestMaxFlowMinCutInterface', 'test_reusing_residual'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow_large_graph.py', 'networkx.algorithms.flow.tests.test_maxflow_large_graph', 'TestMaxflowLargeGraph', 'test_wlm3'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/tests/test_maxflow_large_graph.py', 'networkx.algorithms.flow.tests.test_maxflow_large_graph', 'TestMaxflowLargeGraph', 'test_complete_graph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/quality.py,TestPerformance,test_bad_partition,"for (i, community) in enumerate(partition):
    for node in community:
        node_community[node] = i","for e_target in enumerate(partition):
    community = e_target[1]
    i = e_target[0]
    for node in community:
        node_community[node] = i

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_quality.py', 'networkx.algorithms.community.tests.test_quality', 'TestCoverage', 'test_good_partition'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_louvain.py', 'networkx.algorithms.community.tests.test_louvain', '', 'test_quality'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_quality.py', 'networkx.algorithms.community.tests.test_quality', 'TestPerformance', 'test_good_partition'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_quality.py', 'networkx.algorithms.community.tests.test_quality', 'TestCoverage', 'test_bad_partition'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_quality.py', 'networkx.algorithms.community.tests.test_quality', 'TestPerformance', 'test_bad_partition']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/label_propagation.py,,test_one_node,"for (node, label) in labeling.items():
    clusters[label].add(node)","for e_target in labeling.items():
    label = e_target[1]
    node = e_target[0]
    clusters[label].add(node)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_connected_communities'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_unconnected_communities'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_iterator_vs_iterable'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_directed_not_supported'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_one_node']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/label_propagation.py,,test_one_node,"for (color, nodes) in coloring.items():
    for n in nodes:
        _update_label(n, labeling, G)","for e_target in coloring.items():
    nodes = e_target[1]
    color = e_target[0]
    for n in nodes:
        _update_label(n, labeling, G)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_connected_communities'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_unconnected_communities'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_iterator_vs_iterable'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_directed_not_supported'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_label_propagation.py', 'networkx.algorithms.community.tests.test_label_propagation', '', 'test_one_node']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/kernighan_lin.py,,test_too_many_blocks,"for (_, _, (u, v)) in costs[:min_i]:
    side[u] = 1
    side[v] = 0","for e_target in costs[:min_i]:
    v = e_target[2][1]
    u = e_target[2][0]
    _ = e_target[1]
    side[u] = 1
    side[v] = 0

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_kernighan_lin.py', 'networkx.algorithms.community.tests.test_kernighan_lin', '', 'test_max_iter_argument'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_kernighan_lin.py', 'networkx.algorithms.community.tests.test_kernighan_lin', '', 'test_partition'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_kernighan_lin.py', 'networkx.algorithms.community.tests.test_kernighan_lin', '', 'test_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_kernighan_lin.py', 'networkx.algorithms.community.tests.test_kernighan_lin', '', 'test_seed_argument'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_kernighan_lin.py', 'networkx.algorithms.community.tests.test_kernighan_lin', '', 'test_partition_argument_non_integer_nodes'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_kernighan_lin.py', 'networkx.algorithms.community.tests.test_kernighan_lin', '', 'test_non_disjoint_partition'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_kernighan_lin.py', 'networkx.algorithms.community.tests.test_kernighan_lin', '', 'test_partition_argument'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_kernighan_lin.py', 'networkx.algorithms.community.tests.test_kernighan_lin', '', 'test_too_many_blocks']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/modularity_max.py,,test_greed_modularity_communities_multidigraph,"for (u, v, wt) in G.edges(data=weight, default=1):
    if u == v:
        continue
    dq_dict[u][v] += wt
    dq_dict[v][u] += wt","for e_target in G.edges(data=weight, default=1):
    wt = e_target[2]
    v = e_target[1]
    u = e_target[0]
    if u == v:
        continue
    dq_dict[u][v] += wt
    dq_dict[v][u] += wt

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_resolution_parameter_impact'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_n_communities_parameter'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_floating_point'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_relabeled'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_directed_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_directed'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/modularity_max.py,,test_greed_modularity_communities_multidigraph,"for (u, nbrdict) in dq_dict.items():
    for (v, wt) in nbrdict.items():
        dq_dict[u][v] = q0 * wt - resolution * (a[u] * b[v] + b[u] * a[v])","for e_target in dq_dict.items():
    nbrdict = e_target[1]
    u = e_target[0]
    for (v, wt) in nbrdict.items():
        dq_dict[u][v] = q0 * wt - resolution * (a[u] * b[v] + b[u] * a[v])

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_resolution_parameter_impact'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_n_communities_parameter'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_floating_point'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_relabeled'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_directed_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_directed'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/modularity_max.py,,test_greed_modularity_communities_multidigraph,"for (v, wt) in nbrdict.items():
    dq_dict[u][v] = q0 * wt - resolution * (a[u] * b[v] + b[u] * a[v])","for e_target in nbrdict.items():
    wt = e_target[1]
    v = e_target[0]
    dq_dict[u][v] = q0 * wt - resolution * (a[u] * b[v] + b[u] * a[v])

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_resolution_parameter_impact'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_n_communities_parameter'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_floating_point'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_relabeled'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_directed_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_directed'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/modularity_max.py,,test_greed_modularity_communities_multidigraph,"for (row, col) in [(v, w), (w, v)]:
    dq_heap_row = dq_heap[row]
    dq_dict[row][col] = dq_vw
    if len(dq_heap_row) > 0:
        d_oldmax = dq_heap_row.heap[0]
    else:
        d_oldmax = None
    d = (row, col)
    d_negdq = -dq_vw
    if w in v_nbrs:
        dq_heap_row.update(d, d, priority=d_negdq)
    else:
        dq_heap_row.push(d, priority=d_negdq)
    if d_oldmax is None:
        H.push(d, priority=d_negdq)
    else:
        row_max = dq_heap_row.heap[0]
        if d_oldmax != row_max or d_oldmax.priority != row_max.priority:
            H.update(d_oldmax, row_max)","for e_target in [(v, w), (w, v)]:
    col = e_target[1]
    row = e_target[0]
    dq_heap_row = dq_heap[row]
    dq_dict[row][col] = dq_vw
    if len(dq_heap_row) > 0:
        d_oldmax = dq_heap_row.heap[0]
    else:
        d_oldmax = None
    d = (row, col)
    d_negdq = -dq_vw
    if w in v_nbrs:
        dq_heap_row.update(d, d, priority=d_negdq)
    else:
        dq_heap_row.push(d, priority=d_negdq)
    if d_oldmax is None:
        H.push(d, priority=d_negdq)
    else:
        row_max = dq_heap_row.heap[0]
        if d_oldmax != row_max or d_oldmax.priority != row_max.priority:
            H.update(d_oldmax, row_max)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_resolution_parameter_impact'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_n_communities_parameter'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_floating_point'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_relabeled'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_directed_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_directed'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/modularity_max.py,,test_greed_modularity_communities_multidigraph,"for (row, col) in [(w, u), (u, w)]:
    dq_heap_row = dq_heap[row]
    d_old = (row, col)
    if dq_heap_row.heap[0] == d_old:
        dq_heap_row.remove(d_old)
        H.remove(d_old)
        if len(dq_heap_row) > 0:
            H.push(dq_heap_row.heap[0])
    else:
        dq_heap_row.remove(d_old)","for e_target in [(w, u), (u, w)]:
    col = e_target[1]
    row = e_target[0]
    dq_heap_row = dq_heap[row]
    d_old = (row, col)
    if dq_heap_row.heap[0] == d_old:
        dq_heap_row.remove(d_old)
        H.remove(d_old)
        if len(dq_heap_row) > 0:
            H.push(dq_heap_row.heap[0])
    else:
        dq_heap_row.remove(d_old)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_resolution_parameter_impact'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_n_communities_parameter'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_floating_point'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_multigraph_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_relabeled'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_modularity_communities_directed_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greedy_modularity_communities_directed'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_greed_modularity_communities_multidigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/modularity_max.py,,test_resolution_parameter_impact,"for (i, u) in enumerate(communities):
    for (j, v) in enumerate(communities):
        if j <= i or len(u) == 0 or len(v) == 0:
            continue
        trial_communities[j] = u | v
        trial_communities[i] = frozenset([])
        trial_modularity = modularity(G, trial_communities, resolution=resolution)
        if trial_modularity >= new_modularity:
            if trial_modularity > new_modularity:
                new_modularity = trial_modularity
                to_merge = (i, j, new_modularity - old_modularity)
            elif to_merge and min(i, j) < min(to_merge[0], to_merge[1]):
                new_modularity = trial_modularity
                to_merge = (i, j, new_modularity - old_modularity)
        trial_communities[i] = u
        trial_communities[j] = v","for e_target in enumerate(communities):
    u = e_target[1]
    i = e_target[0]
    for (j, v) in enumerate(communities):
        if j <= i or len(u) == 0 or len(v) == 0:
            continue
        trial_communities[j] = u | v
        trial_communities[i] = frozenset([])
        trial_modularity = modularity(G, trial_communities, resolution=resolution)
        if trial_modularity >= new_modularity:
            if trial_modularity > new_modularity:
                new_modularity = trial_modularity
                to_merge = (i, j, new_modularity - old_modularity)
            elif to_merge and min(i, j) < min(to_merge[0], to_merge[1]):
                new_modularity = trial_modularity
                to_merge = (i, j, new_modularity - old_modularity)
        trial_communities[i] = u
        trial_communities[j] = v

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_resolution_parameter_impact']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/modularity_max.py,,test_resolution_parameter_impact,"for (j, v) in enumerate(communities):
    if j <= i or len(u) == 0 or len(v) == 0:
        continue
    trial_communities[j] = u | v
    trial_communities[i] = frozenset([])
    trial_modularity = modularity(G, trial_communities, resolution=resolution)
    if trial_modularity >= new_modularity:
        if trial_modularity > new_modularity:
            new_modularity = trial_modularity
            to_merge = (i, j, new_modularity - old_modularity)
        elif to_merge and min(i, j) < min(to_merge[0], to_merge[1]):
            new_modularity = trial_modularity
            to_merge = (i, j, new_modularity - old_modularity)
    trial_communities[i] = u
    trial_communities[j] = v","for e_target in enumerate(communities):
    v = e_target[1]
    j = e_target[0]
    if j <= i or len(u) == 0 or len(v) == 0:
        continue
    trial_communities[j] = u | v
    trial_communities[i] = frozenset([])
    trial_modularity = modularity(G, trial_communities, resolution=resolution)
    if trial_modularity >= new_modularity:
        if trial_modularity > new_modularity:
            new_modularity = trial_modularity
            to_merge = (i, j, new_modularity - old_modularity)
        elif to_merge and min(i, j) < min(to_merge[0], to_merge[1]):
            new_modularity = trial_modularity
            to_merge = (i, j, new_modularity - old_modularity)
    trial_communities[i] = u
    trial_communities[j] = v

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_modularity_max.py', 'networkx.algorithms.community.tests.test_modularity_max', '', 'test_resolution_parameter_impact']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/lukes.py,,test_mandatory_tree,"for (w, (best_part_for_vl, vl)) in bp_buffer.items():
    t_G.nodes[x_node][PKEY][w] = best_part_for_vl","for e_target in bp_buffer.items():
    vl = e_target[1][1]
    best_part_for_vl = e_target[1][0]
    w = e_target[0]
    t_G.nodes[x_node][PKEY][w] = best_part_for_vl

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_lukes.py', 'networkx.algorithms.community.tests.test_lukes', '', 'test_mandatory_integrality'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_lukes.py', 'networkx.algorithms.community.tests.test_lukes', '', 'test_mandatory_tree']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/lukes.py,,test_mandatory_tree,"for (a, b) in _split_n_from(j, weight_of_x):
    if a not in t_G.nodes[x_node][PKEY].keys() or b not in t_G.nodes[i_node][PKEY].keys():
        continue
    part1 = t_G.nodes[x_node][PKEY][a]
    part2 = t_G.nodes[i_node][PKEY][b]
    (part, value) = _concatenate_or_merge(part1, part2, x_node, i_node, j)
    if j not in bp_buffer.keys() or bp_buffer[j][1] < value:
        bp_buffer[j] = (part, value)
    if best_value <= value:
        best_value = value
        best_partition = part","for e_target in _split_n_from(j, weight_of_x):
    b = e_target[1]
    a = e_target[0]
    if a not in t_G.nodes[x_node][PKEY].keys() or b not in t_G.nodes[i_node][PKEY].keys():
        continue
    part1 = t_G.nodes[x_node][PKEY][a]
    part2 = t_G.nodes[i_node][PKEY][b]
    (part, value) = _concatenate_or_merge(part1, part2, x_node, i_node, j)
    if j not in bp_buffer.keys() or bp_buffer[j][1] < value:
        bp_buffer[j] = (part, value)
    if best_value <= value:
        best_value = value
        best_partition = part

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_lukes.py', 'networkx.algorithms.community.tests.test_lukes', '', 'test_mandatory_integrality'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/community/tests/test_lukes.py', 'networkx.algorithms.community.tests.test_lukes', '', 'test_mandatory_tree']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/isomorphism/matchhelpers.py,TestGenericMultiEdgeMatch,test_generic_multiedge_match,"for (xi, yi) in zip(values1, vals2):
    if not all(map(lambda x, y, z: z(x, y), xi, yi, op)):
        break
else:
    return True","for e_target in zip(values1, vals2):
    yi = e_target[1]
    xi = e_target[0]
    if not all(map(lambda x, y, z: z(x, y), xi, yi, op)):
        break
else:
    return True

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/isomorphism/tests/test_match_helpers.py', 'networkx.algorithms.isomorphism.tests.test_match_helpers', 'TestGenericMultiEdgeMatch', 'test_generic_multiedge_match']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/isomorphism/tree_isomorphism.py,,test_hardcoded,"for (i, (ol, v)) in enumerate(forlabel):
    if i != 0 and ol != forlabel[i - 1][0]:
        current += 1
    label[v] = current","for e_target in enumerate(forlabel):
    v = e_target[1][1]
    ol = e_target[1][0]
    i = e_target[0]
    if i != 0 and ol != forlabel[i - 1][0]:
        current += 1
    label[v] = current

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/isomorphism/tests/test_tree_isomorphism.py', 'networkx.algorithms.isomorphism.tests.test_tree_isomorphism', '', 'test_trivial'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/isomorphism/tests/test_tree_isomorphism.py', 'networkx.algorithms.isomorphism.tests.test_tree_isomorphism', '', 'test_hardcoded']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/branchings.py,,test_greedy_max3,"for (i, (u, v, w)) in enumerate(edges):
    if uf[u] == uf[v]:
        continue
    elif B.in_degree(v) == 1:
        continue
    else:
        data = {}
        if attr is not None:
            data[attr] = w
        B.add_edge(u, v, **data)
        uf.union(u, v)","for e_target in enumerate(edges):
    w = e_target[1][2]
    v = e_target[1][1]
    u = e_target[1][0]
    i = e_target[0]
    if uf[u] == uf[v]:
        continue
    elif B.in_degree(v) == 1:
        continue
    else:
        data = {}
        if attr is not None:
            data[attr] = w
        B.add_edge(u, v, **data)
        uf.union(u, v)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_greedy_min'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_greedy_max2'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_greedy_max1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_greedy_max3']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/branchings.py,,test_edge_attribute_preservation_multigraph,"for (u, _, key, data) in G.in_edges(v, data=True, keys=True):
    if data.get(partition) == nx.EdgePartition.EXCLUDED:
        continue
    new_weight = data[attr]
    if data.get(partition) == nx.EdgePartition.INCLUDED:
        weight = new_weight
        edge = (u, v, key, new_weight, data)
        return (edge, weight)
    if new_weight > weight:
        weight = new_weight
        edge = (u, v, key, new_weight, data)","for e_target in G.in_edges(v, data=True, keys=True):
    data = e_target[3]
    key = e_target[2]
    _ = e_target[1]
    u = e_target[0]
    if data.get(partition) == nx.EdgePartition.EXCLUDED:
        continue
    new_weight = data[attr]
    if data.get(partition) == nx.EdgePartition.INCLUDED:
        weight = new_weight
        edge = (u, v, key, new_weight, data)
        return (edge, weight)
    if new_weight > weight:
        weight = new_weight
        edge = (u, v, key, new_weight, data)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_preservation_normal_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_discard'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_preservation_multigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/branchings.py,,test_edge_attribute_preservation_multigraph,"for (key, value) in d.items():
    if key not in [self.attr, self.candidate_attr]:
        dd[key] = value","for e_target in d.items():
    value = e_target[1]
    key = e_target[0]
    if key not in [self.attr, self.candidate_attr]:
        dd[key] = value

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_preservation_normal_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_discard'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_preservation_multigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/branchings.py,,test_edge_attribute_preservation_multigraph,"for (u, v, key, data) in G.edges(data=True, keys=True):
    if u in Q_incoming_weight:
        if v in Q_incoming_weight:
            continue
        else:
            dd = data.copy()
            new_edges.append((new_node, v, key, dd))
    elif v in Q_incoming_weight:
        w = data[attr]
        w += minweight - Q_incoming_weight[v]
        dd = data.copy()
        dd[attr] = w
        new_edges.append((u, new_node, key, dd))
    else:
        continue","for e_target in G.edges(data=True, keys=True):
    data = e_target[3]
    key = e_target[2]
    v = e_target[1]
    u = e_target[0]
    if u in Q_incoming_weight:
        if v in Q_incoming_weight:
            continue
        else:
            dd = data.copy()
            new_edges.append((new_node, v, key, dd))
    elif v in Q_incoming_weight:
        w = data[attr]
        w += minweight - Q_incoming_weight[v]
        dd = data.copy()
        dd[attr] = w
        new_edges.append((u, new_node, key, dd))
    else:
        continue

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_preservation_normal_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_discard'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_preservation_multigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/branchings.py,,test_edge_attribute_preservation_multigraph,"for (u, v, key, data) in new_edges:
    G.add_edge(u, v, key, **data)
    if self.candidate_attr in data:
        del data[self.candidate_attr]
        B.add_edge(u, v, key, **data)
        uf.union(u, v)","for e_target in new_edges:
    data = e_target[3]
    key = e_target[2]
    v = e_target[1]
    u = e_target[0]
    G.add_edge(u, v, key, **data)
    if self.candidate_attr in data:
        del data[self.candidate_attr]
        B.add_edge(u, v, key, **data)
        uf.union(u, v)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_preservation_normal_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_discard'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/tree/tests/test_branchings.py', 'networkx.algorithms.tree.tests.test_branchings', '', 'test_edge_attribute_preservation_multigraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/connectivity.py,,test_petersen,"for (x, y) in iter_func(neighbors(v), 2):
    if y not in G[x] and x != y:
        K = min(K, local_node_connectivity(G, x, y, cutoff=K))","for e_target in iter_func(neighbors(v), 2):
    y = e_target[1]
    x = e_target[0]
    if y not in G[x] and x != y:
        K = min(K, local_node_connectivity(G, x, y, cutoff=K))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', '', 'test_global_node_connectivity'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', '', 'test_octahedral'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', '', 'test_dodecahedral'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', '', 'test_white_harary1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', '', 'test_directed_node_connectivity'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', '', 'test_complete_graphs'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', '', 'test_empty_graphs'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', '', 'test_petersen']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/connectivity.py,TestAllPairsNodeConnectivityApprox,test_all_pairs_connectivity_nbunch,"for (u, v) in iter_func(nbunch, 2):
    k = local_node_connectivity(G, u, v, cutoff=cutoff)
    all_pairs[u][v] = k
    if not directed:
        all_pairs[v][u] = k","for e_target in iter_func(nbunch, 2):
    v = e_target[1]
    u = e_target[0]
    k = local_node_connectivity(G, u, v, cutoff=cutoff)
    all_pairs[u][v] = k
    if not directed:
        all_pairs[v][u] = k

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', 'TestAllPairsNodeConnectivityApprox', 'test_cutoff'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', 'TestAllPairsNodeConnectivityApprox', 'test_complete'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', 'TestAllPairsNodeConnectivityApprox', 'test_paths'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', 'TestAllPairsNodeConnectivityApprox', 'test_cycles'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_connectivity.py', 'networkx.algorithms.approximation.tests.test_connectivity', 'TestAllPairsNodeConnectivityApprox', 'test_all_pairs_connectivity_nbunch']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/treewidth.py,TestTreewidthMinFillIn,test_heuristic_abort,"for (_, node) in degree_list:
    num_fill_in = 0
    nbrs = graph[node]
    for nbr in nbrs:
        num_fill_in += len(nbrs - graph[nbr]) - 1
        if num_fill_in >= 2 * min_fill_in:
            break
    num_fill_in /= 2
    if num_fill_in < min_fill_in:
        if num_fill_in == 0:
            return node
        min_fill_in = num_fill_in
        min_fill_in_node = node","for e_target in degree_list:
    node = e_target[1]
    _ = e_target[0]
    num_fill_in = 0
    nbrs = graph[node]
    for nbr in nbrs:
        num_fill_in += len(nbrs - graph[nbr]) - 1
        if num_fill_in >= 2 * min_fill_in:
            break
    num_fill_in /= 2
    if num_fill_in < min_fill_in:
        if num_fill_in == 0:
            return node
        min_fill_in = num_fill_in
        min_fill_in_node = node

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_treewidth.py', 'networkx.algorithms.approximation.tests.test_treewidth', 'TestTreewidthMinFillIn', 'test_heuristic_first_steps'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_treewidth.py', 'networkx.algorithms.approximation.tests.test_treewidth', 'TestTreewidthMinFillIn', 'test_heuristic_abort']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/vertex_cover.py,TestMWVC,test_unweighted_directed,"for (u, v) in G.edges():
    if u in cover or v in cover:
        continue
    if cost[u] <= cost[v]:
        cover.add(u)
        cost[v] -= cost[u]
    else:
        cover.add(v)
        cost[u] -= cost[v]","for e_target in G.edges():
    v = e_target[1]
    u = e_target[0]
    if u in cover or v in cover:
        continue
    if cost[u] <= cost[v]:
        cover.add(u)
        cost[v] -= cost[u]
    else:
        cover.add(v)
        cost[u] -= cost[v]

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_vertex_cover.py', 'networkx.algorithms.approximation.tests.test_vertex_cover', 'TestMWVC', 'test_unweighted_undirected'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_vertex_cover.py', 'networkx.algorithms.approximation.tests.test_vertex_cover', 'TestMWVC', 'test_weighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_vertex_cover.py', 'networkx.algorithms.approximation.tests.test_vertex_cover', 'TestMWVC', 'test_unweighted_self_loop'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_vertex_cover.py', 'networkx.algorithms.approximation.tests.test_vertex_cover', 'TestMWVC', 'test_unweighted_directed']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/kcomponents.py,,test_example_1_detail_3_and_4,"for (u, v) in combinations(SG, 2):
    K = node_connectivity(SG, u, v, cutoff=k)
    if k > K:
        H.add_edge(u, v)","for e_target in combinations(SG, 2):
    v = e_target[1]
    u = e_target[0]
    K = node_connectivity(SG, u, v, cutoff=k)
    if k > K:
        H.add_edge(u, v)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_kcomponents.py', 'networkx.algorithms.approximation.tests.test_kcomponents', '', 'test_karate_1'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_kcomponents.py', 'networkx.algorithms.approximation.tests.test_kcomponents', '', 'test_directed'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_kcomponents.py', 'networkx.algorithms.approximation.tests.test_kcomponents', '', 'test_example_1_detail_3_and_4']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/steinertree.py,TestSteinerTree,test_metric_closure,"for (u, (distance, path)) in all_paths_iter:
    Gnodes.remove(u)
    for v in Gnodes:
        M.add_edge(u, v, distance=distance[v], path=path[v])","for e_target in all_paths_iter:
    path = e_target[1][1]
    distance = e_target[1][0]
    u = e_target[0]
    Gnodes.remove(u)
    for v in Gnodes:
        M.add_edge(u, v, distance=distance[v], path=path[v])

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_steinertree.py', 'networkx.algorithms.approximation.tests.test_steinertree', 'TestSteinerTree', 'test_metric_closure']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/traveling_salesman.py,,test_asadpour_tsp,"for (n, (d, p)) in nx.all_pairs_dijkstra(G, weight=weight):
    dist[n] = d
    path[n] = p","for e_target in nx.all_pairs_dijkstra(G, weight=weight):
    p = e_target[1][1]
    d = e_target[1][0]
    n = e_target[0]
    dist[n] = d
    path[n] = p

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world_path'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_TSP_incomplete_graph_short_path'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_TSP_unweighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_TSP_method'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_tsp']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/traveling_salesman.py,,test_asadpour_tsp,"for (u, v) in pairwise(best_GG):
    best_path.extend(path[u][v][:-1])","for e_target in pairwise(best_GG):
    v = e_target[1]
    u = e_target[0]
    best_path.extend(path[u][v][:-1])

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world_path'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_TSP_incomplete_graph_short_path'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_TSP_unweighted'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_TSP_method'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_tsp']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/traveling_salesman.py,,test_asadpour_real_world_path,"for (u, v) in z_star:
    if (u, v) not in z_support.edges:
        edge_weight = min(G[u][v][weight], G[v][u][weight])
        z_support.add_edge(u, v, **{weight: edge_weight})","for e_target in z_star:
    v = e_target[1]
    u = e_target[0]
    if (u, v) not in z_support.edges:
        edge_weight = min(G[u][v][weight], G[v][u][weight])
        z_support.add_edge(u, v, **{weight: edge_weight})

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_tsp'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world_path']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/traveling_salesman.py,,test_asadpour_real_world_path,"for (u, v, d) in minimum_sampled_tree.edges(data=weight):
    if d == G[u][v][weight]:
        t_star.add_edge(u, v, **{weight: d})
    else:
        t_star.add_edge(v, u, **{weight: d})","for e_target in minimum_sampled_tree.edges(data=weight):
    d = e_target[2]
    v = e_target[1]
    u = e_target[0]
    if d == G[u][v][weight]:
        t_star.add_edge(u, v, **{weight: d})
    else:
        t_star.add_edge(v, u, **{weight: d})

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_tsp'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world_path']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/traveling_salesman.py,,test_asadpour_real_world_path,"for (source, values) in flow_dict.items():
    for target in values:
        if (source, target) not in t_star.edges and values[target] > 0:
            for _ in range(values[target]):
                t_star.add_edge(source, target)","for e_target in flow_dict.items():
    values = e_target[1]
    source = e_target[0]
    for target in values:
        if (source, target) not in t_star.edges and values[target] > 0:
            for _ in range(values[target]):
                t_star.add_edge(source, target)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_tsp'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_traveling_salesman.py', 'networkx.algorithms.approximation.tests.test_traveling_salesman', '', 'test_asadpour_real_world_path']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/link_analysis/pagerank_alg.py,TestPageRank,test_empty,"for (_, nbr, wt) in W.edges(n, data=weight):
    x[nbr] += alpha * xlast[n] * wt","for e_target in W.edges(n, data=weight):
    wt = e_target[2]
    nbr = e_target[1]
    _ = e_target[0]
    x[nbr] += alpha * xlast[n] * wt

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/link_analysis/tests/test_pagerank.py', 'networkx.algorithms.link_analysis.tests.test_pagerank', 'TestPageRank', 'test_empty']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/coloring/equitable_coloring.py,TestColoring,test_is_coloring,"for (s, d) in G.edges:
    if coloring[s] == coloring[d]:
        return False","for e_target in G.edges:
    d = e_target[1]
    s = e_target[0]
    if coloring[s] == coloring[d]:
        return False

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/coloring/tests/test_coloring.py', 'networkx.algorithms.coloring.tests.test_coloring', 'TestColoring', 'test_is_equitable'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/coloring/tests/test_coloring.py', 'networkx.algorithms.coloring.tests.test_coloring', 'TestColoring', 'test_is_coloring']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/edge_augmentation.py,,test_gnp_augmentation,"for (u, v) in it.combinations(G.nodes(), 2):
    if v not in G_adj[u]:
        yield (u, v)
    if u not in G_adj[v]:
        yield (v, u)","for e_target in it.combinations(G.nodes(), 2):
    v = e_target[1]
    u = e_target[0]
    if v not in G_adj[u]:
        yield (u, v)
    if u not in G_adj[v]:
        yield (v, u)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/tests/test_edge_augmentation.py', 'networkx.algorithms.connectivity.tests.test_edge_augmentation', '', 'test_weight_key'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/tests/test_edge_augmentation.py', 'networkx.algorithms.connectivity.tests.test_edge_augmentation', '', 'test_gnp_augmentation']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/edge_augmentation.py,,test_gnp_augmentation,"for (u, v) in it.combinations(G.nodes(), 2):
    if v not in G_adj[u]:
        yield (u, v)","for e_target in it.combinations(G.nodes(), 2):
    v = e_target[1]
    u = e_target[0]
    if v not in G_adj[u]:
        yield (u, v)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/tests/test_edge_augmentation.py', 'networkx.algorithms.connectivity.tests.test_edge_augmentation', '', 'test_weight_key'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/tests/test_edge_augmentation.py', 'networkx.algorithms.connectivity.tests.test_edge_augmentation', '', 'test_gnp_augmentation']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/kcomponents.py,,test_karate_1,"for (k, comps) in sorted(kcomps.items(), key=itemgetter(0)):
    for comp in comps:
        for node in comp:
            result[node] = k","for e_target in sorted(kcomps.items(), key=itemgetter(0)):
    comps = e_target[1]
    k = e_target[0]
    for comp in comps:
        for node in comp:
            result[node] = k

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/tests/test_kcomponents.py', 'networkx.algorithms.connectivity.tests.test_kcomponents', '', 'test_karate_component_number'], ['https://github.com/networkx/networkx/tree/master/networkx/algorithms/approximation/tests/test_kcomponents.py', 'networkx.algorithms.approximation.tests.test_kcomponents', '', 'test_karate_1']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/cuts.py,,test_unbounded,"for (u, nbrs) in ((n, G[n]) for n in reachable):
    cutset.update(((u, v) for v in nbrs if v in non_reachable))","for e_target in ((n, G[n]) for n in reachable):
    nbrs = e_target[1]
    u = e_target[0]
    cutset.update(((u, v) for v in nbrs if v in non_reachable))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/algorithms/connectivity/tests/test_cuts.py', 'networkx.algorithms.connectivity.tests.test_cuts', '', 'test_unbounded']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/cytoscape.py,,test_digraph,"for (i, j) in G.nodes.items():
    n = {'data': j.copy()}
    n['data']['id'] = j.get(ident) or str(i)
    n['data']['value'] = i
    n['data']['name'] = j.get(name) or str(i)
    nodes.append(n)","for e_target in G.nodes.items():
    j = e_target[1]
    i = e_target[0]
    n = {'data': j.copy()}
    n['data']['id'] = j.get(ident) or str(i)
    n['data']['value'] = i
    n['data']['name'] = j.get(name) or str(i)
    nodes.append(n)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_cytoscape.py', 'networkx.readwrite.json_graph.tests.test_cytoscape', '', 'test_multidigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_cytoscape.py', 'networkx.readwrite.json_graph.tests.test_cytoscape', '', 'test_graph_attributes'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_cytoscape.py', 'networkx.readwrite.json_graph.tests.test_cytoscape', '', 'test_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_cytoscape.py', 'networkx.readwrite.json_graph.tests.test_cytoscape', '', 'test_attrs_deprecation'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_cytoscape.py', 'networkx.readwrite.json_graph.tests.test_cytoscape', '', 'test_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_cytoscape.py', 'networkx.readwrite.json_graph.tests.test_cytoscape', '', 'test_input_data_is_not_modified_when_building_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_cytoscape.py', 'networkx.readwrite.json_graph.tests.test_cytoscape', '', 'test_exception'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_cytoscape.py', 'networkx.readwrite.json_graph.tests.test_cytoscape', '', 'test_digraph']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/adjacency.py,TestAdjacency,test_graph_attributes,"for (n, nbrdict) in G.adjacency():
    data['nodes'].append(dict(chain(G.nodes[n].items(), [(id_, n)])))
    adj = []
    if multigraph:
        for (nbr, keys) in nbrdict.items():
            for (k, d) in keys.items():
                adj.append(dict(chain(d.items(), [(id_, nbr), (key, k)])))
    else:
        for (nbr, d) in nbrdict.items():
            adj.append(dict(chain(d.items(), [(id_, nbr)])))
    data['adjacency'].append(adj)","for e_target in G.adjacency():
    nbrdict = e_target[1]
    n = e_target[0]
    data['nodes'].append(dict(chain(G.nodes[n].items(), [(id_, n)])))
    adj = []
    if multigraph:
        for (nbr, keys) in nbrdict.items():
            for (k, d) in keys.items():
                adj.append(dict(chain(d.items(), [(id_, nbr), (key, k)])))
    else:
        for (nbr, d) in nbrdict.items():
            adj.append(dict(chain(d.items(), [(id_, nbr)])))
    data['adjacency'].append(adj)

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_multidigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_exception'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_digraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_graph_attributes']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/adjacency.py,TestAdjacency,test_graph_attributes,"for (nbr, keys) in nbrdict.items():
    for (k, d) in keys.items():
        adj.append(dict(chain(d.items(), [(id_, nbr), (key, k)])))","for e_target in nbrdict.items():
    keys = e_target[1]
    nbr = e_target[0]
    for (k, d) in keys.items():
        adj.append(dict(chain(d.items(), [(id_, nbr), (key, k)])))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_multidigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_exception'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_digraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_graph_attributes']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/adjacency.py,TestAdjacency,test_graph_attributes,"for (nbr, d) in nbrdict.items():
    adj.append(dict(chain(d.items(), [(id_, nbr)])))","for e_target in nbrdict.items():
    d = e_target[1]
    nbr = e_target[0]
    adj.append(dict(chain(d.items(), [(id_, nbr)])))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_multidigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_exception'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_digraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_graph_attributes']]"
networkx,https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/adjacency.py,TestAdjacency,test_graph_attributes,"for (k, d) in keys.items():
    adj.append(dict(chain(d.items(), [(id_, nbr), (key, k)])))","for e_target in keys.items():
    d = e_target[1]
    k = e_target[0]
    adj.append(dict(chain(d.items(), [(id_, nbr), (key, k)])))

",1,"[['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_multidigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_exception'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_multigraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_digraph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_graph'], ['https://github.com/networkx/networkx/tree/master/networkx/readwrite/json_graph/tests/test_adjacency.py', 'networkx.readwrite.json_graph.tests.test_adjacency', 'TestAdjacency', 'test_graph_attributes']]"
gmplot,https://github.com/gmplot/gmplot/tree/master/gmplot/google_map_plotter.py,GoogleMapPlotterTest,test_invalid_symbol,"for (option, info) in OPTION_MAP.items():
    (name, value) = _get(kwargs, *info, get_key=True)
    if value is None:
        continue
    if isinstance(value, (list, tuple)):
        _validate_num_points(name, value, len(lats))
        options[option] = value
    else:
        options[option] = [value] * len(lats)","for e_target in OPTION_MAP.items():
    info = e_target[1]
    option = e_target[0]
    (name, value) = _get(kwargs, *info, get_key=True)
    if value is None:
        continue
    if isinstance(value, (list, tuple)):
        _validate_num_points(name, value, len(lats))
        options[option] = value
    else:
        options[option] = [value] * len(lats)

",1,"[['https://github.com/gmplot/gmplot/tree/master/tests/test_gmplot.py', 'tests.test_gmplot', 'GoogleMapPlotterTest', 'test_get'], ['https://github.com/gmplot/gmplot/tree/master/tests/test_gmplot.py', 'tests.test_gmplot', 'GoogleMapPlotterTest', 'test_scatter_length_mismatch'], ['https://github.com/gmplot/gmplot/tree/master/tests/test_gmplot.py', 'tests.test_gmplot', 'GoogleMapPlotterTest', 'test_invalid_symbol']]"
gmplot,https://github.com/gmplot/gmplot/tree/master/gmplot/google_map_plotter.py,GoogleMapPlotterTest,test_invalid_symbol,"for (i, location) in enumerate(zip(lats, lngs)):
    point_options = {option: value[i] for (option, value) in options.items()}
    if point_options.get('marker'):
        self._markers.append(_Marker(location[0], location[1], point_options.get('face_color'), point_options.get('precision'), title=point_options.get('title'), label=point_options.get('label'), info_window=point_options.get('info_window'), draggable=point_options.get('draggable')))
    else:
        self._drawables.append(_Symbol(location[0], location[1], point_options.get('symbol'), point_options.get('size'), point_options.get('precision'), edge_color=point_options.get('edge_color'), edge_alpha=point_options.get('edge_alpha'), edge_width=point_options.get('edge_width'), face_color=point_options.get('face_color'), face_alpha=point_options.get('face_alpha')))","for e_target in enumerate(zip(lats, lngs)):
    location = e_target[1]
    i = e_target[0]
    point_options = {option: value[i] for (option, value) in options.items()}
    if point_options.get('marker'):
        self._markers.append(_Marker(location[0], location[1], point_options.get('face_color'), point_options.get('precision'), title=point_options.get('title'), label=point_options.get('label'), info_window=point_options.get('info_window'), draggable=point_options.get('draggable')))
    else:
        self._drawables.append(_Symbol(location[0], location[1], point_options.get('symbol'), point_options.get('size'), point_options.get('precision'), edge_color=point_options.get('edge_color'), edge_alpha=point_options.get('edge_alpha'), edge_width=point_options.get('edge_width'), face_color=point_options.get('face_color'), face_alpha=point_options.get('face_alpha')))

",1,"[['https://github.com/gmplot/gmplot/tree/master/tests/test_gmplot.py', 'tests.test_gmplot', 'GoogleMapPlotterTest', 'test_get'], ['https://github.com/gmplot/gmplot/tree/master/tests/test_gmplot.py', 'tests.test_gmplot', 'GoogleMapPlotterTest', 'test_scatter_length_mismatch'], ['https://github.com/gmplot/gmplot/tree/master/tests/test_gmplot.py', 'tests.test_gmplot', 'GoogleMapPlotterTest', 'test_invalid_symbol']]"
toolz,https://github.com/pytoolz/toolz/tree/master/toolz/dicttoolz.py,,test_merge_with_non_dict_mappings,"for (k, v) in d.items():
    if k not in result:
        result[k] = [v]
    else:
        result[k].append(v)","for e_target in d.items():
    v = e_target[1]
    k = e_target[0]
    if k not in result:
        result[k] = [v]
    else:
        result[k].append(v)

",1,"[['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_curried.py', 'toolz.tests.test_curried', '', 'test_curried_namespace'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_dicttoolz.py', 'toolz.tests.test_dicttoolz', 'TestDict', 'test_merge_with_iterable_arg'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_dicttoolz.py', 'toolz.tests.test_dicttoolz', 'TestDict', 'test_merge_with'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_dicttoolz.py', 'toolz.tests.test_dicttoolz', '', 'test_merge_with_non_dict_mappings']]"
toolz,https://github.com/pytoolz/toolz/tree/master/toolz/dicttoolz.py,,test_curried_namespace,"for (k, v) in d.items():
    if predicate(v):
        rv[k] = v","for e_target in d.items():
    v = e_target[1]
    k = e_target[0]
    if predicate(v):
        rv[k] = v

",1,"[['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_dicttoolz.py', 'toolz.tests.test_dicttoolz', 'TestDict', 'test_valfilter'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_curried.py', 'toolz.tests.test_curried', '', 'test_curried_namespace']]"
toolz,https://github.com/pytoolz/toolz/tree/master/toolz/dicttoolz.py,TestDict,test_keyfilter,"for (k, v) in d.items():
    if predicate(k):
        rv[k] = v","for e_target in d.items():
    v = e_target[1]
    k = e_target[0]
    if predicate(k):
        rv[k] = v

",1,"[['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_dicttoolz.py', 'toolz.tests.test_dicttoolz', 'TestDict', 'test_keyfilter']]"
toolz,https://github.com/pytoolz/toolz/tree/master/toolz/itertoolz.py,,test_groupby,"for (k, v) in d.items():
    rv[k] = v.__self__","for e_target in d.items():
    v = e_target[1]
    k = e_target[0]
    rv[k] = v.__self__

",1,"[['https://github.com/pytoolz/toolz/tree/master/bench/test_groupby.py', 'bench.test_groupby', '', 'test_groupby'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_groupby_non_callable'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_groupby']]"
toolz,https://github.com/pytoolz/toolz/tree/master/toolz/itertoolz.py,,test_partitionby,"for (key, matches) in d.items():
    if key not in seen_keys:
        for match in matches:
            yield (match, right_default)","for e_target in d.items():
    matches = e_target[1]
    key = e_target[0]
    if key not in seen_keys:
        for match in matches:
            yield (match, right_default)

",1,"[['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_interleave'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_key_as_getter'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_left_outer_join'], ['https://github.com/pytoolz/toolz/tree/master/bench/test_join.py', 'bench.test_join', '', 'test_one_to_many'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_join'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_join_missing_element'], ['https://github.com/pytoolz/toolz/tree/master/bench/test_join.py', 'bench.test_join', '', 'test_many_to_many_large'], ['https://github.com/pytoolz/toolz/tree/master/bench/test_join.py', 'bench.test_join', '', 'test_one_to_one_tiny'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_merge_sorted'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_curried.py', 'toolz.tests.test_curried', '', 'test_curried_namespace'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_right_outer_join'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_interpose'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_inspect_args.py', 'toolz.tests.test_inspect_args', '', 'test_introspect_builtin_modules'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_outer_join'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_itertoolz.py', 'toolz.tests.test_itertoolz', '', 'test_join_double_repeats'], ['https://github.com/pytoolz/toolz/tree/master/toolz/tests/test_recipes.py', 'toolz.tests.test_recipes', '', 'test_partitionby']]"
gkeepapi,https://github.com/kiwiz/gkeepapi/tree/master/gkeepapi/node.py,CollaboratorTests,test_save_load,"for (email, action) in self._collaborators.items():
    if isinstance(action, ShareRequestValue):
        requests.append({'email': email, 'type': action.value})
    else:
        collaborators.append({'email': email, 'role': action.value, 'auxiliary_type': 'None'})","for e_target in self._collaborators.items():
    action = e_target[1]
    email = e_target[0]
    if isinstance(action, ShareRequestValue):
        requests.append({'email': email, 'type': action.value})
    else:
        collaborators.append({'email': email, 'role': action.value, 'auxiliary_type': 'None'})

",1,"[['https://github.com/kiwiz/gkeepapi/tree/master/test/test_nodes.py', 'test.test_nodes', 'CollaboratorTests', 'test_save_load']]"
pipreqs,https://github.com/bndr/pipreqs/tree/master/pipreqs/pipreqs.py,TestPipreqs,test_get_imports_info,"for (root, dirs, files) in walk:
    dirs[:] = [d for d in dirs if d not in ignore_dirs]
    candidates.append(os.path.basename(root))
    files = [fn for fn in files if os.path.splitext(fn)[1] == '.py']
    candidates += [os.path.splitext(fn)[0] for fn in files]
    for file_name in files:
        file_name = os.path.join(root, file_name)
        with open(file_name, 'r', encoding=encoding) as f:
            contents = f.read()
        try:
            tree = ast.parse(contents)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for subnode in node.names:
                        raw_imports.add(subnode.name)
                elif isinstance(node, ast.ImportFrom):
                    raw_imports.add(node.module)
        except Exception as exc:
            if ignore_errors:
                traceback.print_exc(exc)
                logging.warn('Failed on file: %s' % file_name)
                continue
            else:
                logging.error('Failed on file: %s' % file_name)
                raise exc","for e_target in walk:
    files = e_target[2]
    dirs = e_target[1]
    root = e_target[0]
    dirs[:] = [d for d in dirs if d not in ignore_dirs]
    candidates.append(os.path.basename(root))
    files = [fn for fn in files if os.path.splitext(fn)[1] == '.py']
    candidates += [os.path.splitext(fn)[0] for fn in files]
    for file_name in files:
        file_name = os.path.join(root, file_name)
        with open(file_name, 'r', encoding=encoding) as f:
            contents = f.read()
        try:
            tree = ast.parse(contents)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for subnode in node.names:
                        raw_imports.add(subnode.name)
                elif isinstance(node, ast.ImportFrom):
                    raw_imports.add(node.module)
        except Exception as exc:
            if ignore_errors:
                traceback.print_exc(exc)
                logging.warn('Failed on file: %s' % file_name)
                continue
            else:
                logging.error('Failed on file: %s' % file_name)
                raise exc

",1,"[['https://github.com/bndr/pipreqs/tree/master/tests/test_pipreqs.py', 'tests.test_pipreqs', 'TestPipreqs', 'test_get_all_imports'], ['https://github.com/bndr/pipreqs/tree/master/tests/test_pipreqs.py', 'tests.test_pipreqs', 'TestPipreqs', 'test_deduplicate_dependencies'], ['https://github.com/bndr/pipreqs/tree/master/tests/test_pipreqs.py', 'tests.test_pipreqs', 'TestPipreqs', 'test_get_imports_info']]"
lbry-sdk,https://github.com/lbryio/lbry-sdk/tree/master/lbry/dht/serialization/datagram.py,TestDatagram,test_mixed_str_or_int_keys,"for (i, _) in enumerate(OPTIONAL_FIELDS):
    if str(i + OPTIONAL_ARG_OFFSET).encode() in converted:
        decoded[i + OPTIONAL_ARG_OFFSET] = converted[str(i + OPTIONAL_ARG_OFFSET).encode()]","for e_target in enumerate(OPTIONAL_FIELDS):
    _ = e_target[1]
    i = e_target[0]
    if str(i + OPTIONAL_ARG_OFFSET).encode() in converted:
        decoded[i + OPTIONAL_ARG_OFFSET] = converted[str(i + OPTIONAL_ARG_OFFSET).encode()]

",1,"[['https://github.com/lbryio/lbry-sdk/tree/master/tests/unit/dht/serialization/test_datagram.py', 'tests.unit.dht.serialization.test_datagram', 'TestDatagram', 'test_mixed_str_or_int_keys']]"
pinject,https://github.com/google/pinject/tree/master/pinject/support.py,VerifySubclassesTest,test_verifies_empty_sequence_ok,"for (idx, elt) in enumerate(seq):
    if not isinstance(elt, required_superclass):
        raise errors.WrongArgElementTypeError(arg_name, idx, 'subclass of {0}'.format(required_superclass.__name__), type(elt).__name__)","for e_target in enumerate(seq):
    elt = e_target[1]
    idx = e_target[0]
    if not isinstance(elt, required_superclass):
        raise errors.WrongArgElementTypeError(arg_name, idx, 'subclass of {0}'.format(required_superclass.__name__), type(elt).__name__)

",1,"[['https://github.com/google/pinject/tree/master/tests/support_test.py', 'tests.support_test', 'VerifySubclassesTest', 'test_verifies_empty_sequence_ok'], ['https://github.com/google/pinject/tree/master/pinject/support_test.py', 'pinject.support_test', 'VerifySubclassesTest', 'test_verifies_correct_type_ok'], ['https://github.com/google/pinject/tree/master/tests/support_test.py', 'tests.support_test', 'VerifySubclassesTest', 'test_verifies_correct_type_ok'], ['https://github.com/google/pinject/tree/master/pinject/support_test.py', 'pinject.support_test', 'VerifySubclassesTest', 'test_verifies_empty_sequence_ok']]"
pinject,https://github.com/google/pinject/tree/master/pinject/decorators.py,InjectTest,test_all_except_arg_names_must_reference_existing_args,"for (arg, arg_value) in [('arg_names', arg_names), ('all_except', all_except)]:
    if arg_value is not None:
        if not arg_value:
            raise errors.EmptySequenceArgError(back_frame_loc, arg)
        if not support.is_sequence(arg_value) or support.is_string(arg_value):
            raise errors.WrongArgTypeError(arg, 'sequence (of arg names)', type(arg_value).__name__)","for e_target in [('arg_names', arg_names), ('all_except', all_except)]:
    arg_value = e_target[1]
    arg = e_target[0]
    if arg_value is not None:
        if not arg_value:
            raise errors.EmptySequenceArgError(back_frame_loc, arg)
        if not support.is_sequence(arg_value) or support.is_string(arg_value):
            raise errors.WrongArgTypeError(arg, 'sequence (of arg names)', type(arg_value).__name__)

",1,"[['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_can_set_non_injectable_arg_names'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_can_set_injectable_arg_names'], ['https://github.com/google/pinject/tree/master/tests/object_graph_test.py', 'tests.object_graph_test', 'ObjectGraphProvideTest', 'test_can_pass_direct_args_to_provider_fn'], ['https://github.com/google/pinject/tree/master/tests/object_graph_test.py', 'tests.object_graph_test', 'ObjectGraphProvideTest', 'test_inject_decorator_works_on_initializer'], ['https://github.com/google/pinject/tree/master/tests/object_graph_test.py', 'tests.object_graph_test', 'ObjectGraphProvideTest', 'test_cannot_directly_inject_something_expecting_direct_args'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_cannot_be_applied_twice_to_same_fn'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_cannot_set_all_args_non_injectable'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_arg_names_must_be_sequence'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_no_args_means_all_args_are_injectable'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_arg_names_must_reference_existing_args'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_arg_names_must_be_non_empty_if_specified'], ['https://github.com/google/pinject/tree/master/tests/object_graph_test.py', 'tests.object_graph_test', 'ObjectGraphProvideTest', 'test_inject_decorated_class_is_explicitly_bound'], ['https://github.com/google/pinject/tree/master/tests/object_providers_test.py', 'tests.object_providers_test', 'ObjectProviderTest', 'test_provides_class_with_direct_pargs_and_kwargs'], ['https://github.com/google/pinject/tree/master/tests/object_graph_test.py', 'tests.object_graph_test', 'ObjectGraphProvideTest', 'test_cannot_pass_non_existent_args_to_provider_fn'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_all_except_arg_names_must_be_non_empty_if_specified'], ['https://github.com/google/pinject/tree/master/tests/object_graph_test.py', 'tests.object_graph_test', 'ObjectGraphProvideTest', 'test_inject_decorated_class_can_be_directly_provided'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_all_except_arg_names_must_be_sequence'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_cannot_set_injectable_and_non_injectable_arg_names'], ['https://github.com/google/pinject/tree/master/tests/decorators_test.py', 'tests.decorators_test', 'InjectTest', 'test_all_except_arg_names_must_reference_existing_args']]"
pinject,https://github.com/google/pinject/tree/master/pinject/bindings.py,GetProviderBindingsTest,test_uses_provided_fn_to_map_provider_fn_names_to_arg_names,"for (_, fn) in fns:
    default_arg_names = get_arg_names_from_provider_fn_name(fn.__name__)
    fn_bindings = get_provider_fn_bindings(fn, default_arg_names)
    for binding in fn_bindings:
        if binding.scope_id not in known_scope_ids:
            raise errors.UnknownScopeError(binding.scope_id, locations.get_name_and_loc(fn))
    provider_bindings.extend(fn_bindings)","for e_target in fns:
    fn = e_target[1]
    _ = e_target[0]
    default_arg_names = get_arg_names_from_provider_fn_name(fn.__name__)
    fn_bindings = get_provider_fn_bindings(fn, default_arg_names)
    for binding in fn_bindings:
        if binding.scope_id not in known_scope_ids:
            raise errors.UnknownScopeError(binding.scope_id, locations.get_name_and_loc(fn))
    provider_bindings.extend(fn_bindings)

",1,"[['https://github.com/google/pinject/tree/master/tests/bindings_test.py', 'tests.bindings_test', 'GetProviderBindingsTest', 'test_returns_binding_for_provider_fn'], ['https://github.com/google/pinject/tree/master/tests/bindings_test.py', 'tests.bindings_test', 'GetProviderBindingsTest', 'test_returns_no_bindings_for_non_binding_spec'], ['https://github.com/google/pinject/tree/master/tests/bindings_test.py', 'tests.bindings_test', 'GetProviderBindingsTest', 'test_uses_provided_fn_to_map_provider_fn_names_to_arg_names']]"
powerline,https://github.com/powerline/powerline/tree/master/powerline/lib/config.py,TestLoaderCondition,test_update_missing,"for (path, functions) in self.watched.items():
    for function in functions:
        try:
            modified = self.watcher(path)
        except OSError as e:
            modified = True
            self.exception('Error while running watcher for path {0}: {1}', path, str(e))
        else:
            if modified:
                toload.append(path)
        if modified:
            function(path)","for e_target in self.watched.items():
    functions = e_target[1]
    path = e_target[0]
    for function in functions:
        try:
            modified = self.watcher(path)
        except OSError as e:
            modified = True
            self.exception('Error while running watcher for path {0}: {1}', path, str(e))
        else:
            if modified:
                toload.append(path)
        if modified:
            function(path)

",1,"[['https://github.com/powerline/powerline/tree/master/tests/test_python/test_lib_config.py', 'tests.test_python.test_lib_config', 'TestLoaderCondition', 'test_update_missing']]"
powerline,https://github.com/powerline/powerline/tree/master/powerline/lib/config.py,TestLoaderCondition,test_update_missing,"for (key, functions) in list(self.missing.items()):
    for (condition_function, function) in list(functions):
        try:
            path = condition_function(key)
        except IOError:
            pass
        except Exception as e:
            self.exception('Error while running condition function for key {0}: {1}', key, str(e))
        else:
            if path:
                toload.append(path)
                function(path)
                functions.remove((condition_function, function))
    if not functions:
        self.missing.pop(key)","for e_target in list(self.missing.items()):
    functions = e_target[1]
    key = e_target[0]
    for (condition_function, function) in list(functions):
        try:
            path = condition_function(key)
        except IOError:
            pass
        except Exception as e:
            self.exception('Error while running condition function for key {0}: {1}', key, str(e))
        else:
            if path:
                toload.append(path)
                function(path)
                functions.remove((condition_function, function))
    if not functions:
        self.missing.pop(key)

",1,"[['https://github.com/powerline/powerline/tree/master/tests/test_python/test_lib_config.py', 'tests.test_python.test_lib_config', 'TestLoaderCondition', 'test_update_missing']]"
powerline,https://github.com/powerline/powerline/tree/master/powerline/lib/config.py,TestLoaderCondition,test_update_missing,"for (condition_function, function) in list(functions):
    try:
        path = condition_function(key)
    except IOError:
        pass
    except Exception as e:
        self.exception('Error while running condition function for key {0}: {1}', key, str(e))
    else:
        if path:
            toload.append(path)
            function(path)
            functions.remove((condition_function, function))","for e_target in list(functions):
    function = e_target[1]
    condition_function = e_target[0]
    try:
        path = condition_function(key)
    except IOError:
        pass
    except Exception as e:
        self.exception('Error while running condition function for key {0}: {1}', key, str(e))
    else:
        if path:
            toload.append(path)
            function(path)
            functions.remove((condition_function, function))

",1,"[['https://github.com/powerline/powerline/tree/master/tests/test_python/test_lib_config.py', 'tests.test_python.test_lib_config', 'TestLoaderCondition', 'test_update_missing']]"
bayespy,https://github.com/bayespy/bayespy/tree/master/bayespy/inference/vmp/nodes/dot.py,TestSumMultiply,test_message_to_parent,"for (k, u) in enumerate(u_parents):
    if k != index:
        num_dims = (ind + 1) * len(self.in_keys[k]) if not self.is_constant[k] else len(self.in_keys[k])
        ui = u[ind] if not self.is_constant[k] else u[0]
        num_plates = np.ndim(ui) - num_dims
        plates = np.shape(ui)[:num_plates]
        plate_keys = list(range(N + num_plates, N, -1))
        if ind == 0:
            args.append(ui)
            args.append(plate_keys + self.in_keys[k])
        else:
            in_keys2 = [key + self.N_keys for key in self.in_keys[k]]
            if not self.is_constant[k]:
                args.append(ui)
                args.append(plate_keys + in_keys2 + self.in_keys[k])
            else:
                args.append(ui)
                args.append(plate_keys + self.in_keys[k])
                args.append(ui)
                args.append(plate_keys + in_keys2)
        result_num_plates = max(result_num_plates, num_plates)
        result_plates = misc.broadcasted_shape(result_plates, plates)","for e_target in enumerate(u_parents):
    u = e_target[1]
    k = e_target[0]
    if k != index:
        num_dims = (ind + 1) * len(self.in_keys[k]) if not self.is_constant[k] else len(self.in_keys[k])
        ui = u[ind] if not self.is_constant[k] else u[0]
        num_plates = np.ndim(ui) - num_dims
        plates = np.shape(ui)[:num_plates]
        plate_keys = list(range(N + num_plates, N, -1))
        if ind == 0:
            args.append(ui)
            args.append(plate_keys + self.in_keys[k])
        else:
            in_keys2 = [key + self.N_keys for key in self.in_keys[k]]
            if not self.is_constant[k]:
                args.append(ui)
                args.append(plate_keys + in_keys2 + self.in_keys[k])
            else:
                args.append(ui)
                args.append(plate_keys + self.in_keys[k])
                args.append(ui)
                args.append(plate_keys + in_keys2)
        result_num_plates = max(result_num_plates, num_plates)
        result_plates = misc.broadcasted_shape(result_plates, plates)

",1,"[['https://github.com/bayespy/bayespy/tree/master/bayespy/inference/vmp/nodes/tests/test_dot.py', 'bayespy.inference.vmp.nodes.tests.test_dot', 'TestSumMultiply', 'test_message_to_parent']]"
gallery-dl,https://github.com/mikf/gallery-dl/tree/master/gallery_dl/util.py,TestOther,test_combine_dict,"for (key, value) in b.items():
    if key in a and isinstance(value, dict) and isinstance(a[key], dict):
        combine_dict(a[key], value)
    else:
        a[key] = value","for e_target in b.items():
    value = e_target[1]
    key = e_target[0]
    if key in a and isinstance(value, dict) and isinstance(a[key], dict):
        combine_dict(a[key], value)
    else:
        a[key] = value

",1,"[['https://github.com/mikf/gallery-dl/tree/master/test/test_util.py', 'test.test_util', 'TestOther', 'test_combine_dict']]"
XlsxWriter,https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/helperfunctions.py,TestAssembleChartsheet,test_assemble_xml_file,"for (index, element) in enumerate(elements):
    if not element[0] == '<':
        elements[index] = '<' + elements[index]
    if not element[-1] == '>':
        elements[index] = elements[index] + '>'","for e_target in enumerate(elements):
    element = e_target[1]
    index = e_target[0]
    if not element[0] == '<':
        elements[index] = '<' + elements[index]
    if not element[-1] == '>':
        elements[index] = elements[index] + '>'

",1,"[['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_5'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar01.py', 'xlsxwriter.test.worksheet.test_data_bar01', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_1'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/drawing/test_drawing_image01.py', 'xlsxwriter.test.drawing.test_drawing_image01', 'TestAssembleDrawing', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_43'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format18.py', 'xlsxwriter.test.worksheet.test_cond_format18', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar06.py', 'xlsxwriter.test.worksheet.test_data_bar06', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format23.py', 'xlsxwriter.test.worksheet.test_cond_format23', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format06.py', 'xlsxwriter.test.worksheet.test_cond_format06', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format16.py', 'xlsxwriter.test.worksheet.test_cond_format16', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_22'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline04.py', 'xlsxwriter.test.worksheet.test_sparkline04', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_35'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles09.py', 'xlsxwriter.test.styles.test_styles09', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline05.py', 'xlsxwriter.test.worksheet.test_sparkline05', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_31'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format13.py', 'xlsxwriter.test.worksheet.test_cond_format13', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_45'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_21'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/workbook/test_workbook02.py', 'xlsxwriter.test.workbook.test_workbook02', 'TestAssembleWorkbook', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_2'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_merge_range02.py', 'xlsxwriter.test.worksheet.test_merge_range02', 'TestAssembleWorksheet', 'test_assemble_xml_file_write'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations01.py', 'xlsxwriter.test.worksheet.test_write_data_validations01', 'TestWriteDataValidations', 'test_write_data_validations_3'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/contenttypes/test_contenttypes01.py', 'xlsxwriter.test.contenttypes.test_contenttypes01', 'TestAssembleContentTypes', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table03.py', 'xlsxwriter.test.table.test_table03', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar11.py', 'xlsxwriter.test.worksheet.test_data_bar11', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/app/test_app02.py', 'xlsxwriter.test.app.test_app02', 'TestAssembleApp', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format05.py', 'xlsxwriter.test.worksheet.test_cond_format05', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table08.py', 'xlsxwriter.test.table.test_table08', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet08.py', 'xlsxwriter.test.worksheet.test_worksheet08', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/relationships/test_relationships01.py', 'xlsxwriter.test.relationships.test_relationships01', 'TestAssembleRelationships', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline09.py', 'xlsxwriter.test.worksheet.test_sparkline09', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet07.py', 'xlsxwriter.test.worksheet.test_worksheet07', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations01.py', 'xlsxwriter.test.worksheet.test_write_data_validations01', 'TestWriteDataValidations', 'test_write_data_validations_4'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_merge_range01.py', 'xlsxwriter.test.worksheet.test_merge_range01', 'TestAssembleWorksheet', 'test_assemble_xml_file_write'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/workbook/test_workbook03.py', 'xlsxwriter.test.workbook.test_workbook03', 'TestAssembleWorkbook', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_44'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles02.py', 'xlsxwriter.test.styles.test_styles02', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table10.py', 'xlsxwriter.test.table.test_table10', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_15'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/sharedstrings/test_sharedstrings02.py', 'xlsxwriter.test.sharedstrings.test_sharedstrings02', 'TestAssembleSharedStrings', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet02.py', 'xlsxwriter.test.worksheet.test_worksheet02', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table06.py', 'xlsxwriter.test.table.test_table06', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table12.py', 'xlsxwriter.test.table.test_table12', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline11.py', 'xlsxwriter.test.worksheet.test_sparkline11', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_merge_range01.py', 'xlsxwriter.test.worksheet.test_merge_range01', 'TestAssembleWorksheet', 'test_assemble_xml_file_A1'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations01.py', 'xlsxwriter.test.worksheet.test_write_data_validations01', 'TestWriteDataValidations', 'test_write_data_validations_1'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations01.py', 'xlsxwriter.test.worksheet.test_write_data_validations01', 'TestWriteDataValidations', 'test_write_data_validations_1b'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_41'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table09.py', 'xlsxwriter.test.table.test_table09', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/core/test_core02.py', 'xlsxwriter.test.core.test_core02', 'TestAssembleCore', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format20.py', 'xlsxwriter.test.worksheet.test_cond_format20', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/sharedstrings/test_sharedstrings01.py', 'xlsxwriter.test.sharedstrings.test_sharedstrings01', 'TestAssembleSharedStrings', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format02.py', 'xlsxwriter.test.worksheet.test_cond_format02', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format09.py', 'xlsxwriter.test.worksheet.test_cond_format09', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations01.py', 'xlsxwriter.test.worksheet.test_write_data_validations01', 'TestWriteDataValidations', 'test_write_data_validations_7'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/drawing/test_drawing_chart01.py', 'xlsxwriter.test.drawing.test_drawing_chart01', 'TestAssembleDrawing', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_24'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table11.py', 'xlsxwriter.test.table.test_table11', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles01.py', 'xlsxwriter.test.styles.test_styles01', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet01.py', 'xlsxwriter.test.worksheet.test_worksheet01', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_34'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet09.py', 'xlsxwriter.test.worksheet.test_worksheet09', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles04.py', 'xlsxwriter.test.styles.test_styles04', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table07.py', 'xlsxwriter.test.table.test_table07', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_6'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_39'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar02.py', 'xlsxwriter.test.worksheet.test_data_bar02', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_28'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_18'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format22.py', 'xlsxwriter.test.worksheet.test_cond_format22', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_27'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table01.py', 'xlsxwriter.test.table.test_table01', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline06.py', 'xlsxwriter.test.worksheet.test_sparkline06', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/comments/test_comments01.py', 'xlsxwriter.test.comments.test_comments01', 'TestAssembleComments', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format15.py', 'xlsxwriter.test.worksheet.test_cond_format15', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format24.py', 'xlsxwriter.test.worksheet.test_cond_format24', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_7'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline08.py', 'xlsxwriter.test.worksheet.test_sparkline08', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format12.py', 'xlsxwriter.test.worksheet.test_cond_format12', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar12.py', 'xlsxwriter.test.worksheet.test_data_bar12', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations01.py', 'xlsxwriter.test.worksheet.test_write_data_validations01', 'TestWriteDataValidations', 'test_write_data_validations_5'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_19'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_37'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format07.py', 'xlsxwriter.test.worksheet.test_cond_format07', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_23'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles07.py', 'xlsxwriter.test.styles.test_styles07', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_11'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline07.py', 'xlsxwriter.test.worksheet.test_sparkline07', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/app/test_app01.py', 'xlsxwriter.test.app.test_app01', 'TestAssembleApp', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table02.py', 'xlsxwriter.test.table.test_table02', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/workbook/test_workbook01.py', 'xlsxwriter.test.workbook.test_workbook01', 'TestAssembleWorkbook', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline03.py', 'xlsxwriter.test.worksheet.test_sparkline03', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles06.py', 'xlsxwriter.test.styles.test_styles06', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_merge_range02.py', 'xlsxwriter.test.worksheet.test_merge_range02', 'TestAssembleWorksheet', 'test_assemble_xml_file_A1'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet06.py', 'xlsxwriter.test.worksheet.test_worksheet06', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline02.py', 'xlsxwriter.test.worksheet.test_sparkline02', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles03.py', 'xlsxwriter.test.styles.test_styles03', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/vml/test_vml01.py', 'xlsxwriter.test.vml.test_vml01', 'TestAssembleVml', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles08.py', 'xlsxwriter.test.styles.test_styles08', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_4'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table05.py', 'xlsxwriter.test.table.test_table05', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format14.py', 'xlsxwriter.test.worksheet.test_cond_format14', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar07.py', 'xlsxwriter.test.worksheet.test_data_bar07', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format10.py', 'xlsxwriter.test.worksheet.test_cond_format10', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_merge_range02.py', 'xlsxwriter.test.worksheet.test_merge_range02', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_8'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_20'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar04.py', 'xlsxwriter.test.worksheet.test_data_bar04', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format03.py', 'xlsxwriter.test.worksheet.test_cond_format03', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/vml/test_vml02.py', 'xlsxwriter.test.vml.test_vml02', 'TestAssembleVml', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/table/test_table04.py', 'xlsxwriter.test.table.test_table04', 'TestAssembleTable', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations01.py', 'xlsxwriter.test.worksheet.test_write_data_validations01', 'TestWriteDataValidations', 'test_write_data_validations_6'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_9'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_10'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar09.py', 'xlsxwriter.test.worksheet.test_data_bar09', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations01.py', 'xlsxwriter.test.worksheet.test_write_data_validations01', 'TestWriteDataValidations', 'test_write_data_validations_2'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_13'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_25'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_46'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format01.py', 'xlsxwriter.test.worksheet.test_cond_format01', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format08.py', 'xlsxwriter.test.worksheet.test_cond_format08', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar03.py', 'xlsxwriter.test.worksheet.test_data_bar03', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar08.py', 'xlsxwriter.test.worksheet.test_data_bar08', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_merge_range01.py', 'xlsxwriter.test.worksheet.test_merge_range01', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar10.py', 'xlsxwriter.test.worksheet.test_data_bar10', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar05.py', 'xlsxwriter.test.worksheet.test_data_bar05', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_36'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format21.py', 'xlsxwriter.test.worksheet.test_cond_format21', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_33'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet09.py', 'xlsxwriter.test.worksheet.test_worksheet09', 'TestAssembleWorksheet', 'test_assemble_xml_file_write'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/core/test_core01.py', 'xlsxwriter.test.core.test_core01', 'TestAssembleCore', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet05.py', 'xlsxwriter.test.worksheet.test_worksheet05', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline10.py', 'xlsxwriter.test.worksheet.test_sparkline10', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_42'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline12.py', 'xlsxwriter.test.worksheet.test_sparkline12', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_29'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_40'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/vml/test_vml03.py', 'xlsxwriter.test.vml.test_vml03', 'TestAssembleVml', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet03.py', 'xlsxwriter.test.worksheet.test_worksheet03', 'TestAssembleWorksheet', 'test_assemble_xml_file_A1'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet04.py', 'xlsxwriter.test.worksheet.test_worksheet04', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet03.py', 'xlsxwriter.test.worksheet.test_worksheet03', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_12'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/styles/test_styles05.py', 'xlsxwriter.test.styles.test_styles05', 'TestAssembleStyles', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format04.py', 'xlsxwriter.test.worksheet.test_cond_format04', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_worksheet09.py', 'xlsxwriter.test.worksheet.test_worksheet09', 'TestAssembleWorksheet', 'test_assemble_xml_file_A1'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_17'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format17.py', 'xlsxwriter.test.worksheet.test_cond_format17', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_32'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_30'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_38'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format11.py', 'xlsxwriter.test.worksheet.test_cond_format11', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/app/test_app03.py', 'xlsxwriter.test.app.test_app03', 'TestAssembleApp', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/drawing/test_drawing_image01.py', 'xlsxwriter.test.drawing.test_drawing_image01', 'TestAssembleDrawing', 'test_assemble_xml_file_with_url'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_sparkline01.py', 'xlsxwriter.test.worksheet.test_sparkline01', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_data_bar13.py', 'xlsxwriter.test.worksheet.test_data_bar13', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_14'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_cond_format19.py', 'xlsxwriter.test.worksheet.test_cond_format19', 'TestAssembleWorksheet', 'test_assemble_xml_file'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_16'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/worksheet/test_write_data_validations02.py', 'xlsxwriter.test.worksheet.test_write_data_validations02', 'TestWriteDataValidations', 'test_write_data_validations_3'], ['https://github.com/jmcnamara/XlsxWriter/tree/master/xlsxwriter/test/chartsheet/test_chartsheet01.py', 'xlsxwriter.test.chartsheet.test_chartsheet01', 'TestAssembleChartsheet', 'test_assemble_xml_file']]"
caldera,https://github.com/mitre/caldera/tree/master/app/api/v2/managers/config_api_manager.py,,test_filter_keys,"for (key, val) in mapping.items():
    if key not in keys_to_remove:
        filtered[key] = val","for e_target in mapping.items():
    val = e_target[1]
    key = e_target[0]
    if key not in keys_to_remove:
        filtered[key] = val

",1,"[['https://github.com/mitre/caldera/tree/master/tests/api/v2/managers/test_config_api_manager.py', 'tests.api.v2.managers.test_config_api_manager', '', 'test_filter_keys']]"
caldera,https://github.com/mitre/caldera/tree/master/app/utility/base_object.py,,test_replace_app_props,"for (k, v) in self.get_config().items():
    if k.startswith('app.'):
        var = '#{%s}' % k
        decoded_test = decoded_test.replace(var, str(v).strip())","for e_target in self.get_config().items():
    v = e_target[1]
    k = e_target[0]
    if k.startswith('app.'):
        var = '#{%s}' % k
        decoded_test = decoded_test.replace(var, str(v).strip())

",1,"[['https://github.com/mitre/caldera/tree/master/tests/utility/test_base_object.py', 'tests.utility.test_base_object', '', 'test_replace_app_props']]"
gspread,https://github.com/burnash/gspread/tree/master/gspread/utils.py,UtilsTest,test_a1_to_rowcol,"for (i, c) in enumerate(reversed(column_label)):
    col += (ord(c) - MAGIC_NUMBER) * 26 ** i","for e_target in enumerate(reversed(column_label)):
    c = e_target[1]
    i = e_target[0]
    col += (ord(c) - MAGIC_NUMBER) * 26 ** i

",1,"[['https://github.com/burnash/gspread/tree/master/tests/utils_test.py', 'tests.utils_test', 'UtilsTest', 'test_addr_converters'], ['https://github.com/burnash/gspread/tree/master/tests/utils_test.py', 'tests.utils_test', 'UtilsTest', 'test_a1_to_rowcol']]"
icalendar,https://github.com/collective/icalendar/tree/master/src/icalendar/parser.py,TestPropertyParams,test_parameters_class,"for (key, value) in items:
    value = param_value(value)
    if isinstance(value, compat.unicode_type):
        value = value.encode(DEFAULT_ENCODING)
    key = key.upper().encode(DEFAULT_ENCODING)
    result.append(key + b'=' + value)","for e_target in items:
    value = e_target[1]
    key = e_target[0]
    value = param_value(value)
    if isinstance(value, compat.unicode_type):
        value = value.encode(DEFAULT_ENCODING)
    key = key.upper().encode(DEFAULT_ENCODING)
    result.append(key + b'=' + value)

",1,"[['https://github.com/collective/icalendar/tree/master/src/icalendar/tests/test_property_params.py', 'src.icalendar.tests.test_property_params', 'TestPropertyParams', 'test_parameters_class']]"
icalendar,https://github.com/collective/icalendar/tree/master/src/icalendar/parser.py,IcalendarTestCase,test_contentline_class,"for (i, ch) in enumerate(st):
    if not in_quotes:
        if ch in ':;' and (not name_split):
            name_split = i
        if ch == ':' and (not value_split):
            value_split = i
    if ch == '""':
        in_quotes = not in_quotes","for e_target in enumerate(st):
    ch = e_target[1]
    i = e_target[0]
    if not in_quotes:
        if ch in ':;' and (not name_split):
            name_split = i
        if ch == ':' and (not value_split):
            value_split = i
    if ch == '""':
        in_quotes = not in_quotes

",1,"[['https://github.com/collective/icalendar/tree/master/src/icalendar/tests/test_icalendar.py', 'src.icalendar.tests.test_icalendar', 'IcalendarTestCase', 'test_contentline_class']]"
icalendar,https://github.com/collective/icalendar/tree/master/src/icalendar/caselessdict.py,TestCaselessdict,test_CaselessDict,"for (key, value) in mapping:
    self[key] = value","for e_target in mapping:
    value = e_target[1]
    key = e_target[0]
    self[key] = value

",1,"[['https://github.com/collective/icalendar/tree/master/src/icalendar/tests/test_unit_caselessdict.py', 'src.icalendar.tests.test_unit_caselessdict', 'TestCaselessdict', 'test_CaselessDict']]"
altair,https://github.com/altair-viz/altair/tree/master/altair/utils/core.py,,test_sanitize_dataframe_infs,"for (col_name, dtype) in df.dtypes.iteritems():
    if str(dtype) == 'category':
        col = df[col_name].astype(object)
        df[col_name] = col.where(col.notnull(), None)
    elif str(dtype) == 'string':
        col = df[col_name].astype(object)
        df[col_name] = col.where(col.notnull(), None)
    elif str(dtype) == 'bool':
        df[col_name] = df[col_name].astype(object)
    elif str(dtype) == 'boolean':
        col = df[col_name].astype(object)
        df[col_name] = col.where(col.notnull(), None)
    elif str(dtype).startswith('datetime'):
        df[col_name] = df[col_name].apply(lambda x: x.isoformat()).replace('NaT', '')
    elif str(dtype).startswith('timedelta'):
        raise ValueError('Field ""{col_name}"" has type ""{dtype}"" which is not supported by Altair. Please convert to either a timestamp or a numerical value.'.format(col_name=col_name, dtype=dtype))
    elif str(dtype).startswith('geometry'):
        continue
    elif str(dtype) in {'Int8', 'Int16', 'Int32', 'Int64', 'UInt8', 'UInt16', 'UInt32', 'UInt64', 'Float32', 'Float64'}:
        col = df[col_name].astype(object)
        df[col_name] = col.where(col.notnull(), None)
    elif np.issubdtype(dtype, np.integer):
        df[col_name] = df[col_name].astype(object)
    elif np.issubdtype(dtype, np.floating):
        col = df[col_name]
        bad_values = col.isnull() | np.isinf(col)
        df[col_name] = col.astype(object).where(~bad_values, None)
    elif dtype == object:
        col = df[col_name].apply(to_list_if_array, convert_dtype=False)
        df[col_name] = col.where(col.notnull(), None)","for e_target in df.dtypes.iteritems():
    dtype = e_target[1]
    col_name = e_target[0]
    if str(dtype) == 'category':
        col = df[col_name].astype(object)
        df[col_name] = col.where(col.notnull(), None)
    elif str(dtype) == 'string':
        col = df[col_name].astype(object)
        df[col_name] = col.where(col.notnull(), None)
    elif str(dtype) == 'bool':
        df[col_name] = df[col_name].astype(object)
    elif str(dtype) == 'boolean':
        col = df[col_name].astype(object)
        df[col_name] = col.where(col.notnull(), None)
    elif str(dtype).startswith('datetime'):
        df[col_name] = df[col_name].apply(lambda x: x.isoformat()).replace('NaT', '')
    elif str(dtype).startswith('timedelta'):
        raise ValueError('Field ""{col_name}"" has type ""{dtype}"" which is not supported by Altair. Please convert to either a timestamp or a numerical value.'.format(col_name=col_name, dtype=dtype))
    elif str(dtype).startswith('geometry'):
        continue
    elif str(dtype) in {'Int8', 'Int16', 'Int32', 'Int64', 'UInt8', 'UInt16', 'UInt32', 'UInt64', 'Float32', 'Float64'}:
        col = df[col_name].astype(object)
        df[col_name] = col.where(col.notnull(), None)
    elif np.issubdtype(dtype, np.integer):
        df[col_name] = df[col_name].astype(object)
    elif np.issubdtype(dtype, np.floating):
        col = df[col_name]
        bad_values = col.isnull() | np.isinf(col)
        df[col_name] = col.astype(object).where(~bad_values, None)
    elif dtype == object:
        col = df[col_name].apply(to_list_if_array, convert_dtype=False)
        df[col_name] = col.where(col.notnull(), None)

",1,"[['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_utils.py', 'altair.utils.tests.test_utils', '', 'test_sanitize_dataframe_timedelta'], ['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_utils.py', 'altair.utils.tests.test_utils', '', 'test_sanitize_dataframe'], ['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_utils.py', 'altair.utils.tests.test_utils', '', 'test_sanitize_dataframe_colnames'], ['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_utils.py', 'altair.utils.tests.test_utils', '', 'test_sanitize_boolean_dtype'], ['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_utils.py', 'altair.utils.tests.test_utils', '', 'test_sanitize_nullable_integers'], ['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_utils.py', 'altair.utils.tests.test_utils', '', 'test_sanitize_string_dtype'], ['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_utils.py', 'altair.utils.tests.test_utils', '', 'test_sanitize_dataframe_infs']]"
altair,https://github.com/altair-viz/altair/tree/master/altair/utils/core.py,,test_update_nested,"for (key, val) in update.items():
    if isinstance(val, Mapping):
        orig_val = original.get(key, {})
        if isinstance(orig_val, Mapping):
            original[key] = update_nested(orig_val, val)
        else:
            original[key] = val
    else:
        original[key] = val","for e_target in update.items():
    val = e_target[1]
    key = e_target[0]
    if isinstance(val, Mapping):
        orig_val = original.get(key, {})
        if isinstance(orig_val, Mapping):
            original[key] = update_nested(orig_val, val)
        else:
            original[key] = val
    else:
        original[key] = val

",1,"[['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_core.py', 'altair.utils.tests.test_core', '', 'test_update_nested']]"
altair,https://github.com/altair-viz/altair/tree/master/altair/utils/core.py,,test_infer_encoding_types_with_condition,"for (chan, name) in channel_to_name.items():
    chans = name_to_channel.setdefault(name, {})
    if chan.__name__.endswith('Datum'):
        key = 'datum'
    elif chan.__name__.endswith('Value'):
        key = 'value'
    else:
        key = 'field'
    chans[key] = chan","for e_target in channel_to_name.items():
    name = e_target[1]
    chan = e_target[0]
    chans = name_to_channel.setdefault(name, {})
    if chan.__name__.endswith('Datum'):
        key = 'datum'
    elif chan.__name__.endswith('Value'):
        key = 'value'
    else:
        key = 'field'
    chans[key] = chan

",1,"[['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_core.py', 'altair.utils.tests.test_core', '', 'test_infer_encoding_types'], ['https://github.com/altair-viz/altair/tree/master/altair/utils/tests/test_core.py', 'altair.utils.tests.test_core', '', 'test_infer_encoding_types_with_condition']]"
gns3-server,https://github.com/GNS3/gns3-server/tree/master/gns3server/controller/symbols.py,,test_list,"for (root, _, files) in os.walk(get_resource('symbols')):
    for filename in files:
        if filename.startswith('.'):
            continue
        symbol_file = posixpath.normpath(os.path.relpath(os.path.join(root, filename), get_resource('symbols'))).replace('\\', '/')
        theme = posixpath.dirname(symbol_file).replace('/', '-').capitalize()
        if not theme:
            continue
        symbol_id = ':/symbols/' + symbol_file
        symbols.append({'symbol_id': symbol_id, 'filename': filename, 'theme': theme, 'builtin': True})
        self._symbols_path[symbol_id] = os.path.join(root, filename)","for e_target in os.walk(get_resource('symbols')):
    files = e_target[2]
    _ = e_target[1]
    root = e_target[0]
    for filename in files:
        if filename.startswith('.'):
            continue
        symbol_file = posixpath.normpath(os.path.relpath(os.path.join(root, filename), get_resource('symbols'))).replace('\\', '/')
        theme = posixpath.dirname(symbol_file).replace('/', '-').capitalize()
        if not theme:
            continue
        symbol_id = ':/symbols/' + symbol_file
        symbols.append({'symbol_id': symbol_id, 'filename': filename, 'theme': theme, 'builtin': True})
        self._symbols_path[symbol_id] = os.path.join(root, filename)

",1,"[['https://github.com/GNS3/gns3-server/tree/master/tests/controller/test_symbols.py', 'tests.controller.test_symbols', '', 'test_list']]"
gns3-server,https://github.com/GNS3/gns3-server/tree/master/gns3server/controller/symbols.py,,test_list,"for (root, _, files) in os.walk(directory):
    for filename in files:
        if filename.startswith('.'):
            continue
        symbol_file = posixpath.normpath(os.path.relpath(os.path.join(root, filename), directory)).replace('\\', '/')
        symbols.append({'symbol_id': symbol_file, 'filename': filename, 'builtin': False, 'theme': 'Custom symbols'})
        self._symbols_path[symbol_file] = os.path.join(root, filename)","for e_target in os.walk(directory):
    files = e_target[2]
    _ = e_target[1]
    root = e_target[0]
    for filename in files:
        if filename.startswith('.'):
            continue
        symbol_file = posixpath.normpath(os.path.relpath(os.path.join(root, filename), directory)).replace('\\', '/')
        symbols.append({'symbol_id': symbol_file, 'filename': filename, 'builtin': False, 'theme': 'Custom symbols'})
        self._symbols_path[symbol_file] = os.path.join(root, filename)

",1,"[['https://github.com/GNS3/gns3-server/tree/master/tests/controller/test_symbols.py', 'tests.controller.test_symbols', '', 'test_list']]"
gns3-server,https://github.com/GNS3/gns3-server/tree/master/gns3server/utils/images.py,,test_list_images,"for (root, _, filenames) in _os_walk(directory, recurse=recurse):
    for filename in filenames:
        path = os.path.join(root, filename)
        if filename not in files:
            if filename.endswith('.md5sum') or filename.startswith('.'):
                continue
            elif (filename.endswith('.image') or filename.endswith('.bin')) and type == 'dynamips' or ((filename.endswith('.bin') or filename.startswith('i86bi')) and type == 'iou') or (not filename.endswith('.bin') and (not filename.endswith('.image')) and (type == 'qemu')):
                files.add(filename)
                if os.path.commonprefix([root, default_directory]) != default_directory:
                    path = os.path.join(root, filename)
                else:
                    path = os.path.relpath(os.path.join(root, filename), default_directory)
                try:
                    if type in ['dynamips', 'iou']:
                        with open(os.path.join(root, filename), 'rb') as f:
                            elf_header_start = f.read(7)
                        if not elf_header_start == b'\x7fELF\x01\x02\x01' and (not elf_header_start == b'\x7fELF\x01\x01\x01'):
                            continue
                    images.append({'filename': filename, 'path': force_unix_path(path), 'md5sum': md5sum(os.path.join(root, filename)), 'filesize': os.stat(os.path.join(root, filename)).st_size})
                except OSError as e:
                    log.warning(""Can't add image {}: {}"".format(path, str(e)))","for e_target in _os_walk(directory, recurse=recurse):
    filenames = e_target[2]
    _ = e_target[1]
    root = e_target[0]
    for filename in filenames:
        path = os.path.join(root, filename)
        if filename not in files:
            if filename.endswith('.md5sum') or filename.startswith('.'):
                continue
            elif (filename.endswith('.image') or filename.endswith('.bin')) and type == 'dynamips' or ((filename.endswith('.bin') or filename.startswith('i86bi')) and type == 'iou') or (not filename.endswith('.bin') and (not filename.endswith('.image')) and (type == 'qemu')):
                files.add(filename)
                if os.path.commonprefix([root, default_directory]) != default_directory:
                    path = os.path.join(root, filename)
                else:
                    path = os.path.relpath(os.path.join(root, filename), default_directory)
                try:
                    if type in ['dynamips', 'iou']:
                        with open(os.path.join(root, filename), 'rb') as f:
                            elf_header_start = f.read(7)
                        if not elf_header_start == b'\x7fELF\x01\x02\x01' and (not elf_header_start == b'\x7fELF\x01\x01\x01'):
                            continue
                    images.append({'filename': filename, 'path': force_unix_path(path), 'md5sum': md5sum(os.path.join(root, filename)), 'filesize': os.stat(os.path.join(root, filename)).st_size})
                except OSError as e:
                    log.warning(""Can't add image {}: {}"".format(path, str(e)))

",1,"[['https://github.com/GNS3/gns3-server/tree/master/tests/utils/test_images.py', 'tests.utils.test_images', '', 'test_list_images']]"
pycco,https://github.com/pycco-docs/pycco/tree/master/pycco/main.py,,test_skip_coding_directive,"for (linenum, line) in enumerate(lines[:2]):
    if re.search('coding[:=]\\s*([-\\w.]+)', lines[linenum]):
        lines.pop(linenum)
        break","for e_target in enumerate(lines[:2]):
    line = e_target[1]
    linenum = e_target[0]
    if re.search('coding[:=]\\s*([-\\w.]+)', lines[linenum]):
        lines.pop(linenum)
        break

",1,"[['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_multi_line_leading_spaces'], ['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_parse'], ['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_ensure_multiline_string_support'], ['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_indented_block'], ['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_comment_with_only_cross_ref'], ['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_skip_coding_directive']]"
pycco,https://github.com/pycco-docs/pycco/tree/master/pycco/main.py,,test_indented_block,"for (i, section) in enumerate(sections):
    section['code_html'] = highlight_start + shift(fragments, '') + highlight_end
    try:
        docs_text = unicode(section['docs_text'])
    except UnicodeError:
        docs_text = unicode(section['docs_text'].decode('utf-8'))
    except NameError:
        docs_text = section['docs_text']
    section['docs_html'] = markdown(preprocess(docs_text, preserve_paths=preserve_paths, outdir=outdir), extensions=['markdown.extensions.smarty', 'markdown.extensions.fenced_code', 'markdown.extensions.footnotes'])
    section['num'] = i","for e_target in enumerate(sections):
    section = e_target[1]
    i = e_target[0]
    section['code_html'] = highlight_start + shift(fragments, '') + highlight_end
    try:
        docs_text = unicode(section['docs_text'])
    except UnicodeError:
        docs_text = unicode(section['docs_text'].decode('utf-8'))
    except NameError:
        docs_text = section['docs_text']
    section['docs_html'] = markdown(preprocess(docs_text, preserve_paths=preserve_paths, outdir=outdir), extensions=['markdown.extensions.smarty', 'markdown.extensions.fenced_code', 'markdown.extensions.footnotes'])
    section['num'] = i

",1,"[['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_comment_with_only_cross_ref'], ['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_indented_block']]"
pycco,https://github.com/pycco-docs/pycco/tree/master/pycco/main.py,,test_flatten_sources,"for (dirpath, _, filenames) in os.walk(source):
    _sources.extend([os.path.join(dirpath, f) for f in filenames])","for e_target in os.walk(source):
    filenames = e_target[2]
    _ = e_target[1]
    dirpath = e_target[0]
    _sources.extend([os.path.join(dirpath, f) for f in filenames])

",1,"[['https://github.com/pycco-docs/pycco/tree/master/tests/test_pycco.py', 'tests.test_pycco', '', 'test_flatten_sources']]"
tmuxomatic,https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram.py,Test_Windowgram_Convert,test_Windowgram_Convert_StringToMosaic,"for (m1, m2) in zip(windowgram_mosaic_1[1], windowgram_mosaic_2[1]):
    if m1 != m2:
        return False","for e_target in zip(windowgram_mosaic_1[1], windowgram_mosaic_2[1]):
    m2 = e_target[1]
    m1 = e_target[0]
    if m1 != m2:
        return False

",1,"[['https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram_test.py', 'windowgram.windowgram_test', 'Test_Windowgram_Convert', 'test_Windowgram_Convert_StringToMosaic']]"
tmuxomatic,https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram.py,Test_Windowgram_Convert,test_Windowgram_Convert_StringToParsed,"for (ix, line) in enumerate(windowgram_lines):
    if not line:
        continue
    panes_y += 1
    panes_x = 0
    for ch in line:
        if not ValidPane(ch, extend):
            raise Exception('Windowgram must contain valid identifiers: [0-9a-zA-Z]')
    if panes_y > 1 and len(line) != width:
        raise Exception('Windowgram width does not match previous lines')
    else:
        if width == 0:
            width = len(line)
        for ch in line:
            panes_x += 1
            if not ValidPane(ch, extend):
                raise Exception('Windowgram must contain valid identifiers: [0-9a-zA-Z]')
            if not ch in windowgram_parsed:
                windowgram_parsed[ch] = {'n': ch, 'x': panes_x, 'y': panes_y, 'w': 1, 'h': 1}
            else:
                x2 = panes_x - windowgram_parsed[ch]['x'] + 1
                if x2 > windowgram_parsed[ch]['w']:
                    windowgram_parsed[ch]['w'] = x2
                y2 = panes_y - windowgram_parsed[ch]['y'] + 1
                if y2 > windowgram_parsed[ch]['h']:
                    windowgram_parsed[ch]['h'] = y2
                if windowgram_parsed[ch]['x'] > panes_x:
                    windowgram_parsed[ch]['x'] = panes_x","for e_target in enumerate(windowgram_lines):
    line = e_target[1]
    ix = e_target[0]
    if not line:
        continue
    panes_y += 1
    panes_x = 0
    for ch in line:
        if not ValidPane(ch, extend):
            raise Exception('Windowgram must contain valid identifiers: [0-9a-zA-Z]')
    if panes_y > 1 and len(line) != width:
        raise Exception('Windowgram width does not match previous lines')
    else:
        if width == 0:
            width = len(line)
        for ch in line:
            panes_x += 1
            if not ValidPane(ch, extend):
                raise Exception('Windowgram must contain valid identifiers: [0-9a-zA-Z]')
            if not ch in windowgram_parsed:
                windowgram_parsed[ch] = {'n': ch, 'x': panes_x, 'y': panes_y, 'w': 1, 'h': 1}
            else:
                x2 = panes_x - windowgram_parsed[ch]['x'] + 1
                if x2 > windowgram_parsed[ch]['w']:
                    windowgram_parsed[ch]['w'] = x2
                y2 = panes_y - windowgram_parsed[ch]['y'] + 1
                if y2 > windowgram_parsed[ch]['h']:
                    windowgram_parsed[ch]['h'] = y2
                if windowgram_parsed[ch]['x'] > panes_x:
                    windowgram_parsed[ch]['x'] = panes_x

",1,"[['https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram_test.py', 'windowgram.windowgram_test', 'Test_Windowgram_Convert', 'test_Windowgram_Convert_StringToParsed']]"
tmuxomatic,https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram.py,Test_WindowgramGroup_Convert,test_WindowgramGroup_Convert_PatternToList,"for (col, ch) in enumerate(list(line)):
    if ch == ' ' or ch == '\t' or (not linewithcol):
        if not linewithcol or linewithcol[-1][0]:
            linewithcol.append(['', None])
    if ch != ' ' and ch != '\t':
        if linewithcol[-1][1] is None:
            linewithcol[-1][1] = col
        linewithcol[-1][0] += ch","for e_target in enumerate(list(line)):
    ch = e_target[1]
    col = e_target[0]
    if ch == ' ' or ch == '\t' or (not linewithcol):
        if not linewithcol or linewithcol[-1][0]:
            linewithcol.append(['', None])
    if ch != ' ' and ch != '\t':
        if linewithcol[-1][1] is None:
            linewithcol[-1][1] = col
        linewithcol[-1][0] += ch

",1,"[['https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram_test.py', 'windowgram.windowgram_test', 'Test_FlexCores', 'test_SmudgeCore_Basic'], ['https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram_test.py', 'windowgram.windowgram_test', 'Test_WindowgramGroup_Convert', 'test_WindowgramGroup_Convert_PatternToList']]"
tmuxomatic,https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram.py,Test_WindowgramGroup_Convert,test_WindowgramGroup_Convert_PatternToList,"for (ix1, (_, col1)) in enumerate(linewithcol):
    ix2 = [ix2 for (ix2, (_, col2)) in enumerate(first_linewithcol) if col2 == col1]
    if not ix2:
        drop.append(ix1)","for e_target in enumerate(linewithcol):
    col1 = e_target[1][1]
    _ = e_target[1][0]
    ix1 = e_target[0]
    ix2 = [ix2 for (ix2, (_, col2)) in enumerate(first_linewithcol) if col2 == col1]
    if not ix2:
        drop.append(ix1)

",1,"[['https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram_test.py', 'windowgram.windowgram_test', 'Test_FlexCores', 'test_SmudgeCore_Basic'], ['https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram_test.py', 'windowgram.windowgram_test', 'Test_WindowgramGroup_Convert', 'test_WindowgramGroup_Convert_PatternToList']]"
tmuxomatic,https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram.py,Test_WindowgramGroup_Convert,test_WindowgramGroup_Convert_PatternToList,"for (ix1, (_, col1)) in enumerate(first_linewithcol):
    if not [(ix2, col2) for (ix2, (_, col2)) in enumerate(linewithcol) if col2 == col1]:
        linewithcol.insert(ix1, ['', col1])","for e_target in enumerate(first_linewithcol):
    col1 = e_target[1][1]
    _ = e_target[1][0]
    ix1 = e_target[0]
    if not [(ix2, col2) for (ix2, (_, col2)) in enumerate(linewithcol) if col2 == col1]:
        linewithcol.insert(ix1, ['', col1])

",1,"[['https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram_test.py', 'windowgram.windowgram_test', 'Test_FlexCores', 'test_SmudgeCore_Basic'], ['https://github.com/oxidane/tmuxomatic/tree/master/windowgram/windowgram_test.py', 'windowgram.windowgram_test', 'Test_WindowgramGroup_Convert', 'test_WindowgramGroup_Convert_PatternToList']]"
chalice,https://github.com/aws/chalice/tree/master/chalice/utils.py,,test_can_zip_recursive_contents,"for (root, _, filenames) in os.walk(source_dir):
    for filename in filenames:
        full_name = os.path.join(root, filename)
        archive_name = os.path.relpath(full_name, source_dir)
        z.write(full_name, archive_name)","for e_target in os.walk(source_dir):
    filenames = e_target[2]
    _ = e_target[1]
    root = e_target[0]
    for filename in filenames:
        full_name = os.path.join(root, filename)
        archive_name = os.path.relpath(full_name, source_dir)
        z.write(full_name, archive_name)

",1,"[['https://github.com/aws/chalice/tree/master/tests/functional/test_utils.py', 'tests.functional.test_utils', '', 'test_can_zip_single_file'], ['https://github.com/aws/chalice/tree/master/tests/functional/test_utils.py', 'tests.functional.test_utils', '', 'test_can_zip_recursive_contents']]"
chalice,https://github.com/aws/chalice/tree/master/chalice/cli/newproj.py,,test_newproj_copies_and_templates_files,"for (full_src_path, full_dst_path) in self._iter_files(source_dir, destination_dir):
    dest_dir = self._osutils.dirname(full_dst_path)
    if not self._osutils.directory_exists(dest_dir):
        self._osutils.makedirs(dest_dir)
    contents = self._osutils.get_file_contents(full_src_path, binary=False)
    templated_contents = get_templated_content(contents, template_kwargs)
    self._osutils.set_file_contents(full_dst_path, templated_contents, binary=False)","for e_target in self._iter_files(source_dir, destination_dir):
    full_dst_path = e_target[1]
    full_src_path = e_target[0]
    dest_dir = self._osutils.dirname(full_dst_path)
    if not self._osutils.directory_exists(dest_dir):
        self._osutils.makedirs(dest_dir)
    contents = self._osutils.get_file_contents(full_src_path, binary=False)
    templated_contents = get_templated_content(contents, template_kwargs)
    self._osutils.set_file_contents(full_dst_path, templated_contents, binary=False)

",1,"[['https://github.com/aws/chalice/tree/master/tests/unit/cli/test_newproj.py', 'tests.unit.cli.test_newproj', '', 'test_newproj_copies_and_templates_files']]"
chalice,https://github.com/aws/chalice/tree/master/chalice/deploy/validate.py,TestValidateCORS,test_can_have_one_cors_configured_and_others_not,"for (route_name, methods) in routes.items():
    if not route_name:
        raise ValueError('Route cannot be the empty string')
    if route_name != '/' and route_name.endswith('/'):
        raise ValueError('Route cannot end with a trailing slash: %s' % route_name)
    _validate_cors_for_route(route_name, methods)","for e_target in routes.items():
    methods = e_target[1]
    route_name = e_target[0]
    if not route_name:
        raise ValueError('Route cannot be the empty string')
    if route_name != '/' and route_name.endswith('/'):
        raise ValueError('Route cannot end with a trailing slash: %s' % route_name)
    _validate_cors_for_route(route_name, methods)

",1,"[['https://github.com/aws/chalice/tree/master/tests/unit/deploy/test_validate.py', 'tests.unit.deploy.test_validate', 'TestValidateCORS', 'test_cant_have_differing_cors_configurations'], ['https://github.com/aws/chalice/tree/master/tests/unit/deploy/test_validate.py', 'tests.unit.deploy.test_validate', 'TestValidateCORS', 'test_can_have_same_custom_cors_configurations'], ['https://github.com/aws/chalice/tree/master/tests/unit/deploy/test_validate.py', 'tests.unit.deploy.test_validate', 'TestValidateCORS', 'test_can_have_same_cors_configurations'], ['https://github.com/aws/chalice/tree/master/tests/unit/deploy/test_validate.py', 'tests.unit.deploy.test_validate', 'TestValidateCORS', 'test_cant_have_options_with_cors'], ['https://github.com/aws/chalice/tree/master/tests/unit/deploy/test_validate.py', 'tests.unit.deploy.test_validate', 'TestValidateCORS', 'test_can_have_one_cors_configured_and_others_not']]"
falcon,https://github.com/falconry/falcon/tree/master/falcon/inspect.py,TestRouter,test_compiled_partial,"for (method, func) in root.method_map.items():
    if isinstance(func, partial):
        real_func = func.func
    else:
        real_func = func
    source_info = _get_source_info(real_func)
    internal = _is_internal(real_func)
    method_info = RouteMethodInfo(method, source_info, real_func.__name__, internal)
    methods.append(method_info)","for e_target in root.method_map.items():
    func = e_target[1]
    method = e_target[0]
    if isinstance(func, partial):
        real_func = func.func
    else:
        real_func = func
    source_info = _get_source_info(real_func)
    internal = _is_internal(real_func)
    method_info = RouteMethodInfo(method, source_info, real_func.__name__, internal)
    methods.append(method_info)

",1,"[['https://github.com/falconry/falcon/tree/master/tests/test_inspect.py', 'tests.test_inspect', 'TestRouter', 'test_compiled_no_method_map'], ['https://github.com/falconry/falcon/tree/master/tests/test_inspect.py', 'tests.test_inspect', 'TestRouter', 'test_compiled_partial']]"
optopsy,https://github.com/michaelchu/optopsy/tree/master/optopsy/checks.py,,test_check_data_types,"for (k, et) in expected_types.items():
    if k not in df_type_dict:
        raise ValueError('Expected column: {k} not found in DataFrame')
    if all((df_type_dict[k] != t for t in et)):
        raise ValueError(f'{df_type_dict[k]} of {k} does not match expected types: {expected_types[k]}')","for e_target in expected_types.items():
    et = e_target[1]
    k = e_target[0]
    if k not in df_type_dict:
        raise ValueError('Expected column: {k} not found in DataFrame')
    if all((df_type_dict[k] != t for t in et)):
        raise ValueError(f'{df_type_dict[k]} of {k} does not match expected types: {expected_types[k]}')

",1,"[['https://github.com/michaelchu/optopsy/tree/master/tests/test_checks.py', 'tests.test_checks', '', 'test_check_data_types']]"
st2,https://github.com/StackStorm/st2/tree/master/st2client/st2client/config_parser.py,CLIConfigPermissionsTestCase,test_warn_on_bad_config_permissions,"for (section, keys) in six.iteritems(CONFIG_FILE_OPTIONS):
    for (key, options) in six.iteritems(keys):
        key_type = options['type']
        key_default_value = options['default']
        if config.has_option(section, key):
            if key_type in ['str', 'string']:
                get_func = config.get
            elif key_type in ['int', 'integer']:
                get_func = config.getint
            elif key_type in ['float']:
                get_func = config.getfloat
            elif key_type in ['bool', 'boolean']:
                get_func = config.getboolean
            else:
                msg = 'Invalid type ""%s"" for option ""%s""' % (key_type, key)
                raise ValueError(msg)
            value = get_func(section, key, raw=True)
            result[section][key] = value
        else:
            result[section][key] = key_default_value","for e_target in six.iteritems(CONFIG_FILE_OPTIONS):
    keys = e_target[1]
    section = e_target[0]
    for (key, options) in six.iteritems(keys):
        key_type = options['type']
        key_default_value = options['default']
        if config.has_option(section, key):
            if key_type in ['str', 'string']:
                get_func = config.get
            elif key_type in ['int', 'integer']:
                get_func = config.getint
            elif key_type in ['float']:
                get_func = config.getfloat
            elif key_type in ['bool', 'boolean']:
                get_func = config.getboolean
            else:
                msg = 'Invalid type ""%s"" for option ""%s""' % (key_type, key)
                raise ValueError(msg)
            value = get_func(section, key, raw=True)
            result[section][key] = value
        else:
            result[section][key] = key_default_value

",1,"[['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigParserTestCase', 'test_parse'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigPermissionsTestCase', 'test_weird_but_correct_permissions_emit_no_warnings'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigPermissionsTestCase', 'test_correct_permissions_emit_no_warnings'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigPermissionsTestCase', 'test_disable_permissions_warnings'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigParserTestCase', 'test_get_config_for_unicode_char'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigPermissionsTestCase', 'test_warn_on_bad_config_permissions']]"
st2,https://github.com/StackStorm/st2/tree/master/st2client/st2client/config_parser.py,CLIConfigPermissionsTestCase,test_warn_on_bad_config_permissions,"for (key, options) in six.iteritems(keys):
    key_type = options['type']
    key_default_value = options['default']
    if config.has_option(section, key):
        if key_type in ['str', 'string']:
            get_func = config.get
        elif key_type in ['int', 'integer']:
            get_func = config.getint
        elif key_type in ['float']:
            get_func = config.getfloat
        elif key_type in ['bool', 'boolean']:
            get_func = config.getboolean
        else:
            msg = 'Invalid type ""%s"" for option ""%s""' % (key_type, key)
            raise ValueError(msg)
        value = get_func(section, key, raw=True)
        result[section][key] = value
    else:
        result[section][key] = key_default_value","for e_target in six.iteritems(keys):
    options = e_target[1]
    key = e_target[0]
    key_type = options['type']
    key_default_value = options['default']
    if config.has_option(section, key):
        if key_type in ['str', 'string']:
            get_func = config.get
        elif key_type in ['int', 'integer']:
            get_func = config.getint
        elif key_type in ['float']:
            get_func = config.getfloat
        elif key_type in ['bool', 'boolean']:
            get_func = config.getboolean
        else:
            msg = 'Invalid type ""%s"" for option ""%s""' % (key_type, key)
            raise ValueError(msg)
        value = get_func(section, key, raw=True)
        result[section][key] = value
    else:
        result[section][key] = key_default_value

",1,"[['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigParserTestCase', 'test_parse'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigPermissionsTestCase', 'test_weird_but_correct_permissions_emit_no_warnings'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigPermissionsTestCase', 'test_correct_permissions_emit_no_warnings'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigPermissionsTestCase', 'test_disable_permissions_warnings'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigParserTestCase', 'test_get_config_for_unicode_char'], ['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_config_parser.py', 'st2client.tests.unit.test_config_parser', 'CLIConfigPermissionsTestCase', 'test_warn_on_bad_config_permissions']]"
st2,https://github.com/StackStorm/st2/tree/master/st2client/st2client/utils/misc.py,MiscUtilTestCase,test_merge_dicts,"for (key, value) in six.iteritems(d2):
    if isinstance(value, dict):
        result[key] = merge_dicts(result[key], value)
    elif key not in result or value is not None:
        result[key] = value","for e_target in six.iteritems(d2):
    value = e_target[1]
    key = e_target[0]
    if isinstance(value, dict):
        result[key] = merge_dicts(result[key], value)
    elif key not in result or value is not None:
        result[key] = value

",1,"[['https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_util_misc.py', 'st2client.tests.unit.test_util_misc', 'MiscUtilTestCase', 'test_merge_dicts']]"
st2,https://github.com/StackStorm/st2/tree/master/st2common/st2common/util/file_system.py,FileSystemUtilsTestCase,test_get_file_list,"for (dirpath, dirnames, filenames) in os.walk(directory):
    base_path = dirpath.replace(directory, '')
    for filename in filenames:
        if base_path:
            file_path = os.path.join(base_path, filename)
        else:
            file_path = filename
        if include_file(file_path=file_path):
            result.append(file_path)","for e_target in os.walk(directory):
    filenames = e_target[2]
    dirnames = e_target[1]
    dirpath = e_target[0]
    base_path = dirpath.replace(directory, '')
    for filename in filenames:
        if base_path:
            file_path = os.path.join(base_path, filename)
        else:
            file_path = filename
        if include_file(file_path=file_path):
            result.append(file_path)

",1,"[['https://github.com/StackStorm/st2/tree/master/st2common/tests/unit/test_util_file_system.py', 'st2common.tests.unit.test_util_file_system', 'FileSystemUtilsTestCase', 'test_get_file_list']]"
Hypernets,https://github.com/DataCanvasIO/Hypernets/tree/master/hypernets/core/search_space.py,Test_HyperSpace,test_basic_ops,"for (f, t) in self.edges:
    if f == from_module and t == to_module:
        found = True
        break","for e_target in self.edges:
    t = e_target[1]
    f = e_target[0]
    if f == from_module and t == to_module:
        found = True
        break

",1,"[['https://github.com/DataCanvasIO/Hypernets/tree/master/hypernets/tests/core/hyper_space_test.py', 'hypernets.tests.core.hyper_space_test', 'Test_HyperSpace', 'test_basic_ops']]"
Hypernets,https://github.com/DataCanvasIO/Hypernets/tree/master/hypernets/searchers/evolution_searcher.py,Test_Evolution,test_mutate,"for (i, hp) in enumerate(offspring_space.params_iterator):
    if i > len(parent_params) - 1 or not parent_params[i].same_config(hp):
        hp.random_sample()
    elif i == pos:
        new_value = hp.random_sample(assign=False)
        while new_value == parent_params[i].value:
            new_value = hp.random_sample(assign=False)
        hp.assign(new_value)
    else:
        hp.assign(parent_params[i].value)","for e_target in enumerate(offspring_space.params_iterator):
    hp = e_target[1]
    i = e_target[0]
    if i > len(parent_params) - 1 or not parent_params[i].same_config(hp):
        hp.random_sample()
    elif i == pos:
        new_value = hp.random_sample(assign=False)
        while new_value == parent_params[i].value:
            new_value = hp.random_sample(assign=False)
        hp.assign(new_value)
    else:
        hp.assign(parent_params[i].value)

",1,"[['https://github.com/DataCanvasIO/Hypernets/tree/master/hypernets/tests/searchers/evolution_test.py', 'hypernets.tests.searchers.evolution_test', 'Test_Evolution', 'test_mutate']]"
openstack-ansible,https://github.com/openstack/openstack-ansible/tree/master/osa_toolkit/ip.py,TestIPManager,test_release_used_ip,"for (name, network) in self._networks.items():
    if addr in network:
        self._queues[name].append(ip)","for e_target in self._networks.items():
    network = e_target[1]
    name = e_target[0]
    if addr in network:
        self._queues[name].append(ip)

",1,"[['https://github.com/openstack/openstack-ansible/tree/master/tests/test_ip.py', 'tests.test_ip', 'TestIPManager', 'test_release_used_ip']]"
openstack-ansible,https://github.com/openstack/openstack-ansible/tree/master/osa_toolkit/generate.py,TestOverridingEnvIntegration,test_empty_contains,"for (key, value) in container_skel.items():
    contains_in = value.get('contains', False)
    belongs_to_in = value.get('belongs_to', False)
    if contains_in or belongs_to_in:
        for assignment in value['contains']:
            for container_type in value['belongs_to']:
                _add_container_hosts(assignment, config, key, container_type, inventory, value.get('properties', {}))
else:
    cidr_networks = config.get('cidr_networks')
    provider_queues = {}
    for net_name in cidr_networks:
        ip_q = ip.load_optional_q(cidr_networks, cidr_name=net_name)
        provider_queues[net_name] = ip_q
        if ip_q is not None:
            net = netaddr.IPNetwork(cidr_networks.get(net_name))
            q_netmask = '{}_netmask'.format(net_name)
            provider_queues[q_netmask] = str(net.netmask)
    overrides = config.get('global_overrides', dict())
    pns = overrides.get('provider_networks', list())
    for pn in pns:
        p_net = pn.get('network')
        if not p_net:
            continue
        q_name = p_net.get('ip_from_q')
        ip_from_q = provider_queues.get(q_name)
        if ip_from_q:
            netmask = provider_queues['{}_netmask'.format(q_name)]
        else:
            netmask = None
        for group in p_net.get('group_binds', list()):
            _add_additional_networks(key=group, inventory=inventory, ip_q=ip_from_q, q_name=q_name, netmask=netmask, interface=p_net.get('container_interface'), bridge=p_net.get('container_bridge'), net_type=p_net.get('container_type'), net_mtu=p_net.get('container_mtu'), user_config=config, is_container_address=p_net.get('is_container_address'), static_routes=p_net.get('static_routes'), gateway=p_net.get('gateway'), reference_group=p_net.get('reference_group'), address_prefix=p_net.get('address_prefix'))","for e_target in container_skel.items():
    value = e_target[1]
    key = e_target[0]
    contains_in = value.get('contains', False)
    belongs_to_in = value.get('belongs_to', False)
    if contains_in or belongs_to_in:
        for assignment in value['contains']:
            for container_type in value['belongs_to']:
                _add_container_hosts(assignment, config, key, container_type, inventory, value.get('properties', {}))
else:
    cidr_networks = config.get('cidr_networks')
    provider_queues = {}
    for net_name in cidr_networks:
        ip_q = ip.load_optional_q(cidr_networks, cidr_name=net_name)
        provider_queues[net_name] = ip_q
        if ip_q is not None:
            net = netaddr.IPNetwork(cidr_networks.get(net_name))
            q_netmask = '{}_netmask'.format(net_name)
            provider_queues[q_netmask] = str(net.netmask)
    overrides = config.get('global_overrides', dict())
    pns = overrides.get('provider_networks', list())
    for pn in pns:
        p_net = pn.get('network')
        if not p_net:
            continue
        q_name = p_net.get('ip_from_q')
        ip_from_q = provider_queues.get(q_name)
        if ip_from_q:
            netmask = provider_queues['{}_netmask'.format(q_name)]
        else:
            netmask = None
        for group in p_net.get('group_binds', list()):
            _add_additional_networks(key=group, inventory=inventory, ip_q=ip_from_q, q_name=q_name, netmask=netmask, interface=p_net.get('container_interface'), bridge=p_net.get('container_bridge'), net_type=p_net.get('container_type'), net_mtu=p_net.get('container_mtu'), user_config=config, is_container_address=p_net.get('is_container_address'), static_routes=p_net.get('static_routes'), gateway=p_net.get('gateway'), reference_group=p_net.get('reference_group'), address_prefix=p_net.get('address_prefix'))

",1,"[['https://github.com/openstack/openstack-ansible/tree/master/tests/test_inventory.py', 'tests.test_inventory', 'TestOverridingEnvIntegration', 'test_emptying_container_integration'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_inventory.py', 'tests.test_inventory', 'TestOverridingEnvIntegration', 'test_empty_belongs_to'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_inventory.py', 'tests.test_inventory', 'TestOverridingEnvIntegration', 'test_empty_contains']]"
openstack-ansible,https://github.com/openstack/openstack-ansible/tree/master/osa_toolkit/dictutils.py,TestMergeDictUnit,test_merging_nested_dicts_with_same_key,"for (key, value) in new_items.items():
    if isinstance(value, dict) and value:
        base_merge = merge_dict(base_items.get(key, {}), value)
        base_items[key] = base_merge
    else:
        base_items[key] = new_items[key]","for e_target in new_items.items():
    value = e_target[1]
    key = e_target[0]
    if isinstance(value, dict) and value:
        base_merge = merge_dict(base_items.get(key, {}), value)
        base_items[key] = base_merge
    else:
        base_items[key] = new_items[key]

",1,"[['https://github.com/openstack/openstack-ansible/tree/master/tests/test_dictutils.py', 'tests.test_dictutils', 'TestMergeDictUnit', 'test_merging_dict'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_dictutils.py', 'tests.test_dictutils', 'TestMergeDictUnit', 'test_merging_nested_dicts'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_dictutils.py', 'tests.test_dictutils', 'TestMergeDictUnit', 'test_base_dict_is_modified'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_dictutils.py', 'tests.test_dictutils', 'TestMergeDictUnit', 'test_merging_nested_dicts_with_same_key']]"
openstack-ansible,https://github.com/openstack/openstack-ansible/tree/master/osa_toolkit/manage.py,TestExportFunction,test_host_is_present,"for (host, hostvars) in inventory['_meta']['hostvars'].items():
    host_info[host] = {}
    host_info[host]['hostvars'] = hostvars","for e_target in inventory['_meta']['hostvars'].items():
    hostvars = e_target[1]
    host = e_target[0]
    host_info[host] = {}
    host_info[host]['hostvars'] = hostvars

",1,"[['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_all_information_added'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_variables_added'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_all_lb_information'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_groups_added'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_number_of_hosts'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_host_is_present']]"
openstack-ansible,https://github.com/openstack/openstack-ansible/tree/master/osa_toolkit/manage.py,TestExportFunction,test_host_is_present,"for (group_name, group_info) in inventory.items():
    if group_name in ('_meta', 'all'):
        continue
    for host in group_info['hosts']:
        if 'groups' not in host_info[host]:
            host_info[host]['groups'] = []
        host_info[host]['groups'].append(group_name)","for e_target in inventory.items():
    group_info = e_target[1]
    group_name = e_target[0]
    if group_name in ('_meta', 'all'):
        continue
    for host in group_info['hosts']:
        if 'groups' not in host_info[host]:
            host_info[host]['groups'] = []
        host_info[host]['groups'].append(group_name)

",1,"[['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_all_information_added'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_variables_added'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_all_lb_information'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_groups_added'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_number_of_hosts'], ['https://github.com/openstack/openstack-ansible/tree/master/tests/test_manage.py', 'tests.test_manage', 'TestExportFunction', 'test_host_is_present']]"
FACT_core,https://github.com/fkie-cad/FACT_core/tree/master/src/helperFunctions/merge_generators.py,TestHelperFunctionsMergeGenerators,test_sum_up_lists,"for (key, value) in itertools.chain(list_a, list_b):
    tmp.setdefault(key, 0)
    tmp[key] += value","for e_target in itertools.chain(list_a, list_b):
    value = e_target[1]
    key = e_target[0]
    tmp.setdefault(key, 0)
    tmp[key] += value

",1,"[['https://github.com/fkie-cad/FACT_core/tree/master/src/test/unit/helperFunctions/test_merge_generators.py', 'src.test.unit.helperFunctions.test_merge_generators', 'TestHelperFunctionsMergeGenerators', 'test_sum_up_lists']]"
FACT_core,https://github.com/fkie-cad/FACT_core/tree/master/src/helperFunctions/logging.py,,test_coloring_formatter,"for (log_level, color) in self.LOG_LEVEL_COLORS:
    log_level_prefix = '[{}]'.format(log_level)
    if log_level_prefix in formatted_text:
        formatted_prefix = '[{}{}{}]'.format(color, log_level, TerminalColors.ENDC)
        formatted_text = formatted_text.replace(log_level_prefix, formatted_prefix)","for e_target in self.LOG_LEVEL_COLORS:
    color = e_target[1]
    log_level = e_target[0]
    log_level_prefix = '[{}]'.format(log_level)
    if log_level_prefix in formatted_text:
        formatted_prefix = '[{}{}{}]'.format(color, log_level, TerminalColors.ENDC)
        formatted_text = formatted_text.replace(log_level_prefix, formatted_prefix)

",1,"[['https://github.com/fkie-cad/FACT_core/tree/master/src/test/unit/helperFunctions/test_logging.py', 'src.test.unit.helperFunctions.test_logging', '', 'test_coloring_formatter']]"
netmiko,https://github.com/ktbyers/netmiko/tree/master/netmiko/utilities.py,,test_obtain_all_devices,"for (device_name, device_or_group) in my_devices.items():
    if not isinstance(device_or_group, list):
        new_devices[device_name] = device_or_group","for e_target in my_devices.items():
    device_or_group = e_target[1]
    device_name = e_target[0]
    if not isinstance(device_or_group, list):
        new_devices[device_name] = device_or_group

",1,"[['https://github.com/ktbyers/netmiko/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', '', 'test_obtain_all_devices']]"
netmiko,https://github.com/ktbyers/netmiko/tree/master/netmiko/utilities.py,,test_clitable_to_dict,"for (index, element) in enumerate(row):
    temp_dict[cli_table.header[index].lower()] = element","for e_target in enumerate(row):
    element = e_target[1]
    index = e_target[0]
    temp_dict[cli_table.header[index].lower()] = element

",1,"[['https://github.com/ktbyers/netmiko/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', '', 'test_clitable_to_dict']]"
PMapper,https://github.com/nccgroup/PMapper/tree/master/principalmapper/querying/local_policy_simulation.py,TestLocalPolicyVariableExpansions,test_qmark_expansion,"for (k, v) in condition_keys.items():
    if isinstance(v, list):
        v = str(v)
    full_key = '${' + k + '}'
    copy_string = copy_string.replace(full_key, v)","for e_target in condition_keys.items():
    v = e_target[1]
    k = e_target[0]
    if isinstance(v, list):
        v = str(v)
    full_key = '${' + k + '}'
    copy_string = copy_string.replace(full_key, v)

",1,"[['https://github.com/nccgroup/PMapper/tree/master/tests/test_local_policy_sim.py', 'tests.test_local_policy_sim', 'TestLocalPolicyVariableExpansions', 'test_var_expansion'], ['https://github.com/nccgroup/PMapper/tree/master/tests/test_local_policy_sim.py', 'tests.test_local_policy_sim', 'TestLocalPolicyVariableExpansions', 'test_asterisk_expansion'], ['https://github.com/nccgroup/PMapper/tree/master/tests/test_local_policy_sim.py', 'tests.test_local_policy_sim', 'TestLocalPolicyVariableExpansions', 'test_qmark_expansion']]"
PMapper,https://github.com/nccgroup/PMapper/tree/master/principalmapper/querying/query_interface.py,LocalQueryingTests,test_inferred_keys,"for (tag_key, tag_value) in principal.tags.items():
    if 'aws:PrincipalTag/{}'.format(tag_key) not in current_keys:
        result['aws:PrincipalTag/{}'.format(tag_key)] = tag_value","for e_target in principal.tags.items():
    tag_value = e_target[1]
    tag_key = e_target[0]
    if 'aws:PrincipalTag/{}'.format(tag_key) not in current_keys:
        result['aws:PrincipalTag/{}'.format(tag_key)] = tag_value

",1,"[['https://github.com/nccgroup/PMapper/tree/master/tests/test_local_querying.py', 'tests.test_local_querying', 'LocalQueryingTests', 'test_inferred_keys']]"
maigret,https://github.com/soxoj/maigret/tree/master/maigret/utils.py,,test_get_dict_ascii_tree,"for (num, item) in enumerate(items):
    box_symbol = new_result + new_line if num != len(items) - 1 else last_result + new_line
    if type(item) == tuple:
        (field_name, field_value) = item
        if field_value.startswith(""['""):
            is_last_item = num == len(items) - 1
            prepend_symbols = ' ' * 3 if is_last_item else f' {skip_result} '
            data = ascii_data_display(field_value)
            field_value = get_dict_ascii_tree(data, prepend_symbols)
        text += f'\n{prepend}{box_symbol}{field_name}: {field_value}'
    else:
        text += f'\n{prepend}{box_symbol} {item}'","for e_target in enumerate(items):
    item = e_target[1]
    num = e_target[0]
    box_symbol = new_result + new_line if num != len(items) - 1 else last_result + new_line
    if type(item) == tuple:
        (field_name, field_value) = item
        if field_value.startswith(""['""):
            is_last_item = num == len(items) - 1
            prepend_symbols = ' ' * 3 if is_last_item else f' {skip_result} '
            data = ascii_data_display(field_value)
            field_value = get_dict_ascii_tree(data, prepend_symbols)
        text += f'\n{prepend}{box_symbol}{field_name}: {field_value}'
    else:
        text += f'\n{prepend}{box_symbol} {item}'

",1,"[['https://github.com/soxoj/maigret/tree/master/tests/test_utils.py', 'tests.test_utils', '', 'test_get_dict_ascii_tree']]"
maigret,https://github.com/soxoj/maigret/tree/master/maigret/maigret.py,,test_extract_ids_from_results,"for (u, utype) in new_usernames.items():
    ids_results[u] = utype","for e_target in new_usernames.items():
    utype = e_target[1]
    u = e_target[0]
    ids_results[u] = utype

",1,"[['https://github.com/soxoj/maigret/tree/master/tests/test_maigret.py', 'tests.test_maigret', '', 'test_extract_ids_from_results']]"
capirca,https://github.com/google/capirca/tree/master/tools/cgrep.py,CgrepTest,test_one_ip_fail,"for (index, group) in enumerate(results):
    results[index] = (group[0], group[1][1])","for e_target in enumerate(results):
    group = e_target[1]
    index = e_target[0]
    results[index] = (group[0], group[1][1])

",1,"[['https://github.com/google/capirca/tree/master/tests/lib/cgrep_test.py', 'tests.lib.cgrep_test', 'CgrepTest', 'test_one_ipv6'], ['https://github.com/google/capirca/tree/master/tests/lib/cgrep_test.py', 'tests.lib.cgrep_test', 'CgrepTest', 'test_one_ipv6_fail'], ['https://github.com/google/capirca/tree/master/tests/lib/cgrep_test.py', 'tests.lib.cgrep_test', 'CgrepTest', 'test_one_ip_nested'], ['https://github.com/google/capirca/tree/master/tests/lib/cgrep_test.py', 'tests.lib.cgrep_test', 'CgrepTest', 'test_one_ipv6_nested'], ['https://github.com/google/capirca/tree/master/tests/lib/cgrep_test.py', 'tests.lib.cgrep_test', 'CgrepTest', 'test_one_ip_multi_nested'], ['https://github.com/google/capirca/tree/master/tests/lib/cgrep_test.py', 'tests.lib.cgrep_test', 'CgrepTest', 'test_one_ip'], ['https://github.com/google/capirca/tree/master/tests/lib/cgrep_test.py', 'tests.lib.cgrep_test', 'CgrepTest', 'test_one_ip_fail']]"
gitfs,https://github.com/presslabs/gitfs/tree/master/gitfs/router.py,TestRouter,test_call_with_invalid_operation,"for (regex, view) in routes:
    log.debug('Registering %s for %s', view, regex)
    self.routes.append({'regex': regex, 'view': view})","for e_target in routes:
    view = e_target[1]
    regex = e_target[0]
    log.debug('Registering %s for %s', view, regex)
    self.routes.append({'regex': regex, 'view': view})

",1,"[['https://github.com/presslabs/gitfs/tree/master/tests/test_router.py', 'tests.test_router', 'TestRouter', 'test_call_with_valid_operation'], ['https://github.com/presslabs/gitfs/tree/master/tests/test_router.py', 'tests.test_router', 'TestRouter', 'test_get_view_from_cache'], ['https://github.com/presslabs/gitfs/tree/master/tests/test_router.py', 'tests.test_router', 'TestRouter', 'test_get_view'], ['https://github.com/presslabs/gitfs/tree/master/tests/test_router.py', 'tests.test_router', 'TestRouter', 'test_call_with_invalid_operation']]"
gitfs,https://github.com/presslabs/gitfs/tree/master/gitfs/merges/accept_mine.py,TestAcceptMine,test_solve_conflicts_we_deleted_the_file,"for (_, theirs, ours) in conflicts:
    if not ours and theirs:
        log.debug(""AcceptMine: if we deleted the file and they didn't, remove the file"")
        self.repository.index.remove(theirs.path, 2)
        self.repository.index.remove(theirs.path, 1)
    elif ours and (not theirs):
        log.debug(""AcceptMine: if they deleted the file and we didn't, add the file"")
        self.repository.index.add(ours.path)
    else:
        log.debug('AcceptMine: overwrite all file with our content')
        with open(self.repository._full_path(ours.path), 'w') as f:
            data = self.repository.get(ours.id).data
            f.write(six.text_type(data))
        self.repository.index.add(ours.path)","for e_target in conflicts:
    ours = e_target[2]
    theirs = e_target[1]
    _ = e_target[0]
    if not ours and theirs:
        log.debug(""AcceptMine: if we deleted the file and they didn't, remove the file"")
        self.repository.index.remove(theirs.path, 2)
        self.repository.index.remove(theirs.path, 1)
    elif ours and (not theirs):
        log.debug(""AcceptMine: if they deleted the file and we didn't, add the file"")
        self.repository.index.add(ours.path)
    else:
        log.debug('AcceptMine: overwrite all file with our content')
        with open(self.repository._full_path(ours.path), 'w') as f:
            data = self.repository.get(ours.id).data
            f.write(six.text_type(data))
        self.repository.index.add(ours.path)

",1,"[['https://github.com/presslabs/gitfs/tree/master/tests/mergers/test_accept_mine.py', 'tests.mergers.test_accept_mine', 'TestAcceptMine', 'test_solve_conflicts_they_deleted_the_file'], ['https://github.com/presslabs/gitfs/tree/master/tests/mergers/test_accept_mine.py', 'tests.mergers.test_accept_mine', 'TestAcceptMine', 'test_solve_conflicts_both_update_a_file'], ['https://github.com/presslabs/gitfs/tree/master/tests/mergers/test_accept_mine.py', 'tests.mergers.test_accept_mine', 'TestAcceptMine', 'test_solve_conflicts_we_deleted_the_file']]"
dfply,https://github.com/kieferk/dfply/tree/master/dfply/vector.py,,test_case_when,"for (logical, outcome) in conditions:
    if isinstance(logical, collections.Iterable):
        lengths.append(len(logical))
    if isinstance(outcome, collections.Iterable) and (not isinstance(outcome, str)):
        lengths.append(len(outcome))","for e_target in conditions:
    outcome = e_target[1]
    logical = e_target[0]
    if isinstance(logical, collections.Iterable):
        lengths.append(len(logical))
    if isinstance(outcome, collections.Iterable) and (not isinstance(outcome, str)):
        lengths.append(len(outcome))

",1,"[['https://github.com/kieferk/dfply/tree/master/test/test_vector.py', 'test.test_vector', '', 'test_case_when']]"
dfply,https://github.com/kieferk/dfply/tree/master/dfply/vector.py,,test_case_when,"for (logical, outcome) in conditions:
    if isinstance(logical, bool):
        logical = np.repeat(logical, output_len)
    if isinstance(logical, pd.Series):
        logical = logical.values
    if not isinstance(outcome, collections.Iterable) or isinstance(outcome, str):
        outcome = pd.Series(np.repeat(outcome, output_len))
    outcome[~logical] = np.nan
    output.append(outcome)","for e_target in conditions:
    outcome = e_target[1]
    logical = e_target[0]
    if isinstance(logical, bool):
        logical = np.repeat(logical, output_len)
    if isinstance(logical, pd.Series):
        logical = logical.values
    if not isinstance(outcome, collections.Iterable) or isinstance(outcome, str):
        outcome = pd.Series(np.repeat(outcome, output_len))
    outcome[~logical] = np.nan
    output.append(outcome)

",1,"[['https://github.com/kieferk/dfply/tree/master/test/test_vector.py', 'test.test_vector', '', 'test_case_when']]"
dfply,https://github.com/kieferk/dfply/tree/master/dfply/reshape.py,,test_separate,"for (i, split_col) in enumerate(into):
    df[split_col] = [x[i] if not x[i] == '' else np.nan for x in splits]","for e_target in enumerate(into):
    split_col = e_target[1]
    i = e_target[0]
    df[split_col] = [x[i] if not x[i] == '' else np.nan for x in splits]

",1,"[['https://github.com/kieferk/dfply/tree/master/test/test_reshape.py', 'test.test_reshape', '', 'test_separate']]"
rdflib,https://github.com/RDFLib/rdflib/tree/master/rdflib/graph.py,MemoryStoreTestCase,test_memory_store,"for (_s, _o) in p.eval(self, s, o):
    yield (_s, p, _o)","for e_target in p.eval(self, s, o):
    _o = e_target[1]
    _s = e_target[0]
    yield (_s, p, _o)

",1,"[['https://github.com/RDFLib/rdflib/tree/master/test/test_canonicalization.py', 'test.test_canonicalization', '', 'test_issue494_collapsing_bnodes'], ['https://github.com/RDFLib/rdflib/tree/master/test/test_memory_store.py', 'test.test_memory_store', 'SimpleStoreTestCase', 'test_memory_store'], ['https://github.com/RDFLib/rdflib/tree/master/test/test_sparql.py', 'test.test_sparql', '', 'test_sparql_update_with_bnode'], ['https://github.com/RDFLib/rdflib/tree/master/test/test_issue223.py', 'test.test_issue223', '', 'test_collection_with_duplicates'], ['https://github.com/RDFLib/rdflib/tree/master/test/test_memory_store.py', 'test.test_memory_store', 'MemoryStoreTestCase', 'test_memory_store']]"
rdflib,https://github.com/RDFLib/rdflib/tree/master/rdflib/graph.py,MemoryStoreTestCase,test_memory_store,"for ((s, p, o), cg) in self.__store.triples((s, p, o), context=self):
    yield (s, p, o)","for e_target in self.__store.triples((s, p, o), context=self):
    cg = e_target[1]
    o = e_target[0][2]
    p = e_target[0][1]
    s = e_target[0][0]
    yield (s, p, o)

",1,"[['https://github.com/RDFLib/rdflib/tree/master/test/test_canonicalization.py', 'test.test_canonicalization', '', 'test_issue494_collapsing_bnodes'], ['https://github.com/RDFLib/rdflib/tree/master/test/test_memory_store.py', 'test.test_memory_store', 'SimpleStoreTestCase', 'test_memory_store'], ['https://github.com/RDFLib/rdflib/tree/master/test/test_sparql.py', 'test.test_sparql', '', 'test_sparql_update_with_bnode'], ['https://github.com/RDFLib/rdflib/tree/master/test/test_issue223.py', 'test.test_issue223', '', 'test_collection_with_duplicates'], ['https://github.com/RDFLib/rdflib/tree/master/test/test_memory_store.py', 'test.test_memory_store', 'MemoryStoreTestCase', 'test_memory_store']]"
rdflib,https://github.com/RDFLib/rdflib/tree/master/rdflib/graph.py,TestUtilTermConvert,test_util_from_n3_expectsameasn3parser,"for (s, o) in p.eval(context, s, o):
    yield (s, p, o)","for e_target in p.eval(context, s, o):
    o = e_target[1]
    s = e_target[0]
    yield (s, p, o)

",1,"[['https://github.com/RDFLib/rdflib/tree/master/test/test_util.py', 'test.test_util', 'TestUtilTermConvert', 'test_util_from_n3_expectsameasn3parser']]"
rdflib,https://github.com/RDFLib/rdflib/tree/master/rdflib/graph.py,TestUtilTermConvert,test_util_from_n3_expectsameasn3parser,"for ((s, p, o), cg) in self.store.triples((s, p, o), context=context):
    yield (s, p, o)","for e_target in self.store.triples((s, p, o), context=context):
    cg = e_target[1]
    o = e_target[0][2]
    p = e_target[0][1]
    s = e_target[0][0]
    yield (s, p, o)

",1,"[['https://github.com/RDFLib/rdflib/tree/master/test/test_util.py', 'test.test_util', 'TestUtilTermConvert', 'test_util_from_n3_expectsameasn3parser']]"
tavern,https://github.com/taverntesting/tavern/tree/master/tavern/core.py,TestFormatMQTTVarsJson,test_format_request_var_dict,"for (name, session) in sessions.items():
    logger.debug('Entering context for %s', name)
    stack.enter_context(session)","for e_target in sessions.items():
    session = e_target[1]
    name = e_target[0]
    logger.debug('Entering context for %s', name)
    stack.enter_context(session)

",1,"[['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestIncludeStages', 'test_neither'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRunStages', 'test_invalid_body'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestDelay', 'test_sleep_before'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRetry', 'test_repeats_twice_and_fails'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRunStages', 'test_invalid_headers'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestTavernMetaFormat', 'test_format_env_keys'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRunStages', 'test_invalid_code'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestIncludeStages', 'test_global_stage'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestTavernMetaFormat', 'test_format_env_keys_missing_failure'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestIncludeStages', 'test_included_stage'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestIncludeStages', 'test_both_stages'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRetry', 'test_repeats_twice_and_succeeds'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRetry', 'test_run_once'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestFormatMQTTVarsPlain', 'test_format_request_var_value'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRunStages', 'test_success'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestDelay', 'test_sleep_after'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestFormatMQTTVarsJson', 'test_format_request_var_dict']]"
tavern,https://github.com/taverntesting/tavern/tree/master/tavern/core.py,TestFormatMQTTVarsJson,test_format_request_var_dict,"for (idx, stage) in enumerate(test_spec['stages']):
    if stage.get('skip'):
        continue
    if has_only and (not getonly(stage)):
        continue
    test_block_config['strict'] = default_global_stricness
    _calculate_stage_strictness(stage, test_block_config, test_spec)
    run_stage_with_retries = retry(stage, test_block_config)(run_stage)
    partial = functools.partial(run_stage_with_retries, sessions, stage, test_block_config)
    allure_name = 'Stage {}: {}'.format(idx, stage['name'])
    step = wrap_step(allure_name, partial)
    try:
        step()
    except exceptions.TavernException as e:
        e.stage = stage
        e.test_block_config = test_block_config
        raise
    if getonly(stage):
        break","for e_target in enumerate(test_spec['stages']):
    stage = e_target[1]
    idx = e_target[0]
    if stage.get('skip'):
        continue
    if has_only and (not getonly(stage)):
        continue
    test_block_config['strict'] = default_global_stricness
    _calculate_stage_strictness(stage, test_block_config, test_spec)
    run_stage_with_retries = retry(stage, test_block_config)(run_stage)
    partial = functools.partial(run_stage_with_retries, sessions, stage, test_block_config)
    allure_name = 'Stage {}: {}'.format(idx, stage['name'])
    step = wrap_step(allure_name, partial)
    try:
        step()
    except exceptions.TavernException as e:
        e.stage = stage
        e.test_block_config = test_block_config
        raise
    if getonly(stage):
        break

",1,"[['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestIncludeStages', 'test_neither'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRunStages', 'test_invalid_body'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestDelay', 'test_sleep_before'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRetry', 'test_repeats_twice_and_fails'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRunStages', 'test_invalid_headers'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestTavernMetaFormat', 'test_format_env_keys'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRunStages', 'test_invalid_code'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestIncludeStages', 'test_global_stage'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestTavernMetaFormat', 'test_format_env_keys_missing_failure'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestIncludeStages', 'test_included_stage'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestIncludeStages', 'test_both_stages'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRetry', 'test_repeats_twice_and_succeeds'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRetry', 'test_run_once'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestFormatMQTTVarsPlain', 'test_format_request_var_value'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestRunStages', 'test_success'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestDelay', 'test_sleep_after'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_core.py', 'tests.unit.test_core', 'TestFormatMQTTVarsJson', 'test_format_request_var_dict']]"
tavern,https://github.com/taverntesting/tavern/tree/master/tavern/util/dict_util.py,TestMatchRecursive,test_match_ordered,"for (i, e_val) in enumerate(expected_val):
    while 1:
        try:
            current_response_val = next(actual_iter)
        except StopIteration:
            logger.debug('Ran out of list response items to check')
            missing.append(e_val)
            break
        else:
            logger.debug(""Got '%s' from response to check against '%s' from expected"", current_response_val, e_val)
        try:
            check_keys_match_recursive(e_val, current_response_val, keys + [i], strict)
        except exceptions.KeyMismatchError:
            logger.debug('%s did not match next response value %s', e_val, current_response_val)
        else:
            logger.debug(""'%s' present in response"", e_val)
            if strict_setting == StrictSetting.LIST_ANY_ORDER:
                actual_iter = iter(actual_val)
            break","for e_target in enumerate(expected_val):
    e_val = e_target[1]
    i = e_target[0]
    while 1:
        try:
            current_response_val = next(actual_iter)
        except StopIteration:
            logger.debug('Ran out of list response items to check')
            missing.append(e_val)
            break
        else:
            logger.debug(""Got '%s' from response to check against '%s' from expected"", current_response_val, e_val)
        try:
            check_keys_match_recursive(e_val, current_response_val, keys + [i], strict)
        except exceptions.KeyMismatchError:
            logger.debug('%s did not match next response value %s', e_val, current_response_val)
        else:
            logger.debug(""'%s' present in response"", e_val)
            if strict_setting == StrictSetting.LIST_ANY_ORDER:
                actual_iter = iter(actual_val)
            break

",1,"[['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_nested_list'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_list_items'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_key_case_matters'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_multiple'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_dict_mismatch'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_list_items_more_as'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_multiple_wrong_order'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_nested_list_length'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_value_case_matters'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_nested_anything_list'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_wrong_type'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_nested_anything_dict'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_dict'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_ordered']]"
tavern,https://github.com/taverntesting/tavern/tree/master/tavern/util/dict_util.py,TestMatchRecursive,test_match_ordered,"for (i, (e_val, a_val)) in enumerate(zip(expected_val, actual_val)):
    try:
        check_keys_match_recursive(e_val, a_val, keys + [i], strict)
    except exceptions.KeyMismatchError as sub_e:
        raise sub_e from e","for e_target in enumerate(zip(expected_val, actual_val)):
    a_val = e_target[1][1]
    e_val = e_target[1][0]
    i = e_target[0]
    try:
        check_keys_match_recursive(e_val, a_val, keys + [i], strict)
    except exceptions.KeyMismatchError as sub_e:
        raise sub_e from e

",1,"[['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_nested_list'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_list_items'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_key_case_matters'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_multiple'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_dict_mismatch'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_list_items_more_as'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_multiple_wrong_order'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_nested_list_length'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_value_case_matters'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_nested_anything_list'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestNonStrictListMatching', 'test_match_wrong_type'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_nested_anything_dict'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_dict'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_utilities.py', 'tests.unit.test_utilities', 'TestMatchRecursive', 'test_match_ordered']]"
tavern,https://github.com/taverntesting/tavern/tree/master/tavern/_plugins/rest/request.py,TestRequestArgs,test_no_override_content_type,"for (key, value) in request_args.get('params', {}).items():
    if not isinstance(value, str):
        if key == '$ext':
            logger.debug('Skipping converting of ext function (%s)', value)
            continue
    if isinstance(value, dict):
        request_args['params'][key] = quote_plus(json.dumps(value))","for e_target in request_args.get('params', {}).items():
    value = e_target[1]
    key = e_target[0]
    if not isinstance(value, str):
        if key == '$ext':
            logger.debug('Skipping converting of ext function (%s)', value)
            continue
    if isinstance(value, dict):
        request_args['params'][key] = quote_plus(json.dumps(value))

",1,"[['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_no_override_method'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestFileBody', 'test_file_body'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_nested_params_encoded'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_file_and_data_succeeds'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_no_set_content_type'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_no_override_content_type_case_insensitive'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_array_substitution'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_default_method'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_file_and_json_fails'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_cannot_send_data_and_json'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_no_override_content_type']]"
tavern,https://github.com/taverntesting/tavern/tree/master/tavern/_plugins/rest/request.py,TestRequestArgs,test_no_override_content_type,"for (key, val) in optional_with_default.items():
    request_args[key] = fspec.get(key, val)","for e_target in optional_with_default.items():
    val = e_target[1]
    key = e_target[0]
    request_args[key] = fspec.get(key, val)

",1,"[['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_no_override_method'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestFileBody', 'test_file_body'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_nested_params_encoded'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_file_and_data_succeeds'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_no_set_content_type'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_no_override_content_type_case_insensitive'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_array_substitution'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_default_method'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_file_and_json_fails'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_cannot_send_data_and_json'], ['https://github.com/taverntesting/tavern/tree/master/tests/unit/test_request.py', 'tests.unit.test_request', 'TestRequestArgs', 'test_no_override_content_type']]"
Growler,https://github.com/pyGrowler/Growler/tree/master/growler/http/response.py,,test_set_method,"for (k, v) in header.items():
    self.headers[k] = v","for e_target in header.items():
    v = e_target[1]
    k = e_target[0]
    self.headers[k] = v

",1,"[['https://github.com/pyGrowler/Growler/tree/master/tests/test_http_response.py', 'tests.test_http_response', '', 'test_set_headers_via_dict'], ['https://github.com/pyGrowler/Growler/tree/master/tests/test_http_response.py', 'tests.test_http_response', '', 'test_set_method']]"
Growler,https://github.com/pyGrowler/Growler/tree/master/growler/http/response.py,,test_header_update_with_keyword,"for (k, v) in next_dict.items():
    self[k] = v","for e_target in next_dict.items():
    v = e_target[1]
    k = e_target[0]
    self[k] = v

",1,"[['https://github.com/pyGrowler/Growler/tree/master/tests/test_http_response.py', 'tests.test_http_response', '', 'test_header_update_with_multiple_dicts'], ['https://github.com/pyGrowler/Growler/tree/master/tests/test_http_response.py', 'tests.test_http_response', '', 'test_header_update_with_mixed'], ['https://github.com/pyGrowler/Growler/tree/master/tests/test_http_response.py', 'tests.test_http_response', '', 'test_header_update_with_dict'], ['https://github.com/pyGrowler/Growler/tree/master/tests/test_http_response.py', 'tests.test_http_response', '', 'test_header_update_with_keyword']]"
Box,https://github.com/cdgriffith/Box/tree/master/box/box.py,TestBox,test_dots,"for (idx, char) in enumerate(item):
    if char == '[':
        return (item[:idx], item[idx:])
    elif char == '.':
        if item[:idx] in bx:
            return (item[:idx], item[idx + 1:])","for e_target in enumerate(item):
    char = e_target[1]
    idx = e_target[0]
    if char == '[':
        return (item[:idx], item[idx:])
    elif char == '.':
        if item[:idx] in bx:
            return (item[:idx], item[idx + 1:])

",1,"[['https://github.com/cdgriffith/Box/tree/master/test/test_box.py', 'test.test_box', 'TestBox', 'test_dots']]"
Box,https://github.com/cdgriffith/Box/tree/master/box/box.py,TestBoxList,test_box_list_dots,"for (key, value) in self.items():
    added = False
    if isinstance(key, str):
        if isinstance(value, Box):
            for sub_key in value.keys(dotted=True):
                keys.add(f'{key}.{sub_key}')
                added = True
        elif isinstance(value, box.BoxList):
            for pos in value._dotted_helper():
                keys.add(f'{key}{pos}')
                added = True
        if not added:
            keys.add(key)","for e_target in self.items():
    value = e_target[1]
    key = e_target[0]
    added = False
    if isinstance(key, str):
        if isinstance(value, Box):
            for sub_key in value.keys(dotted=True):
                keys.add(f'{key}.{sub_key}')
                added = True
        elif isinstance(value, box.BoxList):
            for pos in value._dotted_helper():
                keys.add(f'{key}{pos}')
                added = True
        if not added:
            keys.add(key)

",1,"[['https://github.com/cdgriffith/Box/tree/master/test/test_box.py', 'test.test_box', 'TestBox', 'test_camel_killer'], ['https://github.com/cdgriffith/Box/tree/master/test/test_box.py', 'test.test_box', 'TestBox', 'test_default_box_restricted_calls'], ['https://github.com/cdgriffith/Box/tree/master/test/test_box.py', 'test.test_box', 'TestBox', 'test_box_dots'], ['https://github.com/cdgriffith/Box/tree/master/test/test_box.py', 'test.test_box', 'TestBox', 'test_key_view'], ['https://github.com/cdgriffith/Box/tree/master/test/test_box_list.py', 'test.test_box_list', 'TestBoxList', 'test_box_list_dots']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/math/general.py,,test_weighted_wheel_selection,"for (i, c_sum) in enumerate(cumulative_sum):
    if c_sum > prob:
        return i","for e_target in enumerate(cumulative_sum):
    c_sum = e_target[1]
    i = e_target[0]
    if c_sum > prob:
        return i

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/math/test_general.py', 'tests.opytimizer.math.test_general', '', 'test_weighted_wheel_selection']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/core/optimizer.py,,test_optimizer_build,"for (k, v) in params.items():
    setattr(self, k, v)","for e_target in params.items():
    v = e_target[1]
    k = e_target[0]
    setattr(self, k, v)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/core/test_optimizer.py', 'tests.opytimizer.core.test_optimizer', '', 'test_optimizer_build']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/core/agent.py,,test_agent_clip_by_bound,"for (j, (lb, ub)) in enumerate(zip(self.lb, self.ub)):
    self.position[j] = np.clip(self.position[j], lb, ub)","for e_target in enumerate(zip(self.lb, self.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    self.position[j] = np.clip(self.position[j], lb, ub)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/core/test_agent.py', 'tests.opytimizer.core.test_agent', '', 'test_agent_clip_by_bound']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/utils/history.py,,test_history_get_convergence,"for (key, value) in kwargs.items():
    if key == 'agents' and (not self.save_agents):
        continue
    if key in ['agents', 'best_agent', 'local_position']:
        output = self._parse(key, value)
    else:
        output = value
    if not hasattr(self, key):
        setattr(self, key, [output])
    else:
        getattr(self, key).append(output)","for e_target in kwargs.items():
    value = e_target[1]
    key = e_target[0]
    if key == 'agents' and (not self.save_agents):
        continue
    if key in ['agents', 'best_agent', 'local_position']:
        output = self._parse(key, value)
    else:
        output = value
    if not hasattr(self, key):
        setattr(self, key, [output])
    else:
        getattr(self, key).append(output)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/utils/test_history.py', 'tests.opytimizer.utils.test_history', '', 'test_history_dump'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/utils/test_history.py', 'tests.opytimizer.utils.test_history', '', 'test_history_get_convergence']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/ffoa.py,,test_ffoa_update,"for (a, x_axis, y_axis) in zip(space.agents, self.x_axis, self.y_axis):
    r1 = r.generate_uniform_random_number()
    r2 = r.generate_uniform_random_number()
    x = x_axis.position + r1
    y = y_axis.position + r2
    distance = np.sqrt(x ** 2 + y ** 2)
    s = 1 / (distance + c.EPSILON)
    smell = function(s)
    if smell < a.fit:
        x_axis.position = copy.deepcopy(x)
        y_axis.position = copy.deepcopy(y)
        a.position = copy.deepcopy(s)
        a.fit = copy.deepcopy(smell)","for e_target in zip(space.agents, self.x_axis, self.y_axis):
    y_axis = e_target[2]
    x_axis = e_target[1]
    a = e_target[0]
    r1 = r.generate_uniform_random_number()
    r2 = r.generate_uniform_random_number()
    x = x_axis.position + r1
    y = y_axis.position + r2
    distance = np.sqrt(x ** 2 + y ** 2)
    s = 1 / (distance + c.EPSILON)
    smell = function(s)
    if smell < a.fit:
        x_axis.position = copy.deepcopy(x)
        y_axis.position = copy.deepcopy(y)
        a.position = copy.deepcopy(s)
        a.fit = copy.deepcopy(smell)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_ffoa.py', 'tests.opytimizer.optimizers.swarm.test_ffoa', '', 'test_ffoa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/csa.py,,test_csa_evaluate,"for (i, agent) in enumerate(space.agents):
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.memory[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.memory[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.memory[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.memory[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_csa.py', 'tests.opytimizer.optimizers.swarm.test_csa', '', 'test_csa_evaluate']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/mrfo.py,,test_mrfo_cyclone_foraging,"for (j, (lb, ub)) in enumerate(zip(agents[i].lb, agents[i].ub)):
    r_position[j] = r.generate_uniform_random_number(lb, ub, size=agents[i].n_dimensions)","for e_target in enumerate(zip(agents[i].lb, agents[i].ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    r_position[j] = r.generate_uniform_random_number(lb, ub, size=agents[i].n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_mrfo.py', 'tests.opytimizer.optimizers.swarm.test_mrfo', '', 'test_mrfo_cyclone_foraging']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/js.py,,test_js_initialize_chaotic_map,"for (i, agent) in enumerate(agents):
    if i == 0:
        for j in range(agent.n_variables):
            agent.position[j] = r.generate_uniform_random_number(size=agent.n_dimensions)
    else:
        for j in range(agent.n_variables):
            agent.position[j] = self.eta * agents[i - 1].position[j] * (1 - agents[i - 1].position[j])","for e_target in enumerate(agents):
    agent = e_target[1]
    i = e_target[0]
    if i == 0:
        for j in range(agent.n_variables):
            agent.position[j] = r.generate_uniform_random_number(size=agent.n_dimensions)
    else:
        for j in range(agent.n_variables):
            agent.position[j] = self.eta * agents[i - 1].position[j] * (1 - agents[i - 1].position[j])

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_js.py', 'tests.opytimizer.optimizers.swarm.test_js', '', 'test_js_initialize_chaotic_map']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/sso.py,,test_sso_evaluate,"for (i, agent) in enumerate(space.agents):
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_sso.py', 'tests.opytimizer.optimizers.swarm.test_sso', '', 'test_sso_evaluate']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/af.py,,test_af_update,"for (i, agent) in enumerate(space.agents):
    for _ in range(self.m):
        a = copy.deepcopy(agent)
        r1 = r.generate_uniform_random_number()
        r2 = r.generate_uniform_random_number()
        r3 = r.generate_uniform_random_number()
        distance = self.g_distance[i] * r1 * self.c1 + self.p_distance[i] * r2 * self.c2
        D = r.generate_gaussian_random_number(0, distance, (space.n_variables, space.n_dimensions))
        a.position += D
        a.clip_by_bound()
        a.fit = function(a.position)
        p = np.fabs(np.sqrt(a.fit / space.agents[-1].fit)) * self.Q
        if r3 < p:
            new_agents.append(a)
    self.g_distance[i] = self.p_distance[i]
    self.p_distance[i] = np.std(agent.position - a.position)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    for _ in range(self.m):
        a = copy.deepcopy(agent)
        r1 = r.generate_uniform_random_number()
        r2 = r.generate_uniform_random_number()
        r3 = r.generate_uniform_random_number()
        distance = self.g_distance[i] * r1 * self.c1 + self.p_distance[i] * r2 * self.c2
        D = r.generate_gaussian_random_number(0, distance, (space.n_variables, space.n_dimensions))
        a.position += D
        a.clip_by_bound()
        a.fit = function(a.position)
        p = np.fabs(np.sqrt(a.fit / space.agents[-1].fit)) * self.Q
        if r3 < p:
            new_agents.append(a)
    self.g_distance[i] = self.p_distance[i]
    self.p_distance[i] = np.std(agent.position - a.position)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_af.py', 'tests.opytimizer.optimizers.swarm.test_af', '', 'test_af_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/eho.py,,test_eho_updating_operator,"for (j, agent) in enumerate(clan_agents):
    a = copy.deepcopy(agent)
    r1 = r.generate_uniform_random_number()
    if j == 0:
        a.position = self.beta * centers[i]
    else:
        a.position += self.alpha * (clan_agents[0].position - a.position) * r1
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)","for e_target in enumerate(clan_agents):
    agent = e_target[1]
    j = e_target[0]
    a = copy.deepcopy(agent)
    r1 = r.generate_uniform_random_number()
    if j == 0:
        a.position = self.beta * centers[i]
    else:
        a.position += self.alpha * (clan_agents[0].position - a.position) * r1
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_eho.py', 'tests.opytimizer.optimizers.swarm.test_eho', '', 'test_eho_updating_operator']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/cs.py,,test_cs_evaluate_nests,"for (j, new_agent) in enumerate(new_agents):
    r1 = r.generate_uniform_random_number()
    k = r.generate_integer_random_number(0, len(agents) - 1)
    l = r.generate_integer_random_number(0, len(agents) - 1, exclude_value=k)
    step_size = r1 * (agents[k].position - agents[l].position)
    new_agent.position += step_size * b[j]","for e_target in enumerate(new_agents):
    new_agent = e_target[1]
    j = e_target[0]
    r1 = r.generate_uniform_random_number()
    k = r.generate_integer_random_number(0, len(agents) - 1)
    l = r.generate_integer_random_number(0, len(agents) - 1, exclude_value=k)
    step_size = r1 * (agents[k].position - agents[l].position)
    new_agent.position += step_size * b[j]

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_cs.py', 'tests.opytimizer.optimizers.swarm.test_cs', '', 'test_cs_generate_abandoned_nests'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_cs.py', 'tests.opytimizer.optimizers.swarm.test_cs', '', 'test_cs_evaluate_nests']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/abc.py,,test_abc_send_employee,"for (i, agent) in enumerate(agents):
    source = r.generate_integer_random_number(0, len(agents))
    self._evaluate_location(agent, agents[source], function, i)","for e_target in enumerate(agents):
    agent = e_target[1]
    i = e_target[0]
    source = r.generate_integer_random_number(0, len(agents))
    self._evaluate_location(agent, agents[source], function, i)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_abc.py', 'tests.opytimizer.optimizers.swarm.test_abc', '', 'test_abc_send_employee']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/boa.py,,test_boa_update,"for (i, agent) in enumerate(space.agents):
    self.fragrance[i] = self.c * agent.fit ** self.a","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    self.fragrance[i] = self.c * agent.fit ** self.a

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_boa.py', 'tests.opytimizer.optimizers.swarm.test_boa', '', 'test_boa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/boa.py,,test_boa_update,"for (i, agent) in enumerate(space.agents):
    r1 = r.generate_uniform_random_number()
    if r1 < self.p:
        agent.position = self._best_movement(agent.position, space.best_agent.position, self.fragrance[i], r1)
    else:
        j = r.generate_integer_random_number(0, len(space.agents))
        k = r.generate_integer_random_number(0, len(space.agents), exclude_value=j)
        agent.position = self._local_movement(agent.position, space.agents[j].position, space.agents[k].position, self.fragrance[i], r1)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    r1 = r.generate_uniform_random_number()
    if r1 < self.p:
        agent.position = self._best_movement(agent.position, space.best_agent.position, self.fragrance[i], r1)
    else:
        j = r.generate_integer_random_number(0, len(space.agents))
        k = r.generate_integer_random_number(0, len(space.agents), exclude_value=j)
        agent.position = self._local_movement(agent.position, space.agents[j].position, space.agents[k].position, self.fragrance[i], r1)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_boa.py', 'tests.opytimizer.optimizers.swarm.test_boa', '', 'test_boa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/ba.py,,test_ba_update,"for (i, agent) in enumerate(space.agents):
    beta = rnd.generate_uniform_random_number()
    self.frequency[i] = self.f_min + (self.f_min - self.f_max) * beta
    self.velocity[i] += (agent.position - space.best_agent.position) * self.frequency[i]
    agent.position += self.velocity[i]
    p = rnd.generate_uniform_random_number()
    e = rnd.generate_gaussian_random_number()
    if p > self.pulse_rate[i]:
        agent.position = space.best_agent.position + 0.001 * e * np.mean(self.loudness)
    agent.clip_by_bound()
    agent.fit = function(agent.position)
    if p < self.loudness[i] and agent.fit < space.best_agent.fit:
        space.best_agent = copy.deepcopy(agent)
        self.pulse_rate[i] = self.r * (1 - np.exp(-alpha * iteration))
        self.loudness[i] = self.A * alpha","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    beta = rnd.generate_uniform_random_number()
    self.frequency[i] = self.f_min + (self.f_min - self.f_max) * beta
    self.velocity[i] += (agent.position - space.best_agent.position) * self.frequency[i]
    agent.position += self.velocity[i]
    p = rnd.generate_uniform_random_number()
    e = rnd.generate_gaussian_random_number()
    if p > self.pulse_rate[i]:
        agent.position = space.best_agent.position + 0.001 * e * np.mean(self.loudness)
    agent.clip_by_bound()
    agent.fit = function(agent.position)
    if p < self.loudness[i] and agent.fit < space.best_agent.fit:
        space.best_agent = copy.deepcopy(agent)
        self.pulse_rate[i] = self.r * (1 - np.exp(-alpha * iteration))
        self.loudness[i] = self.A * alpha

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_ba.py', 'tests.opytimizer.optimizers.swarm.test_ba', '', 'test_ba_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/kh.py,,test_kh_local_alpha,"for (i, dist) in enumerate(eucl_distance):
    if idx != i and sensing_distance > dist:
        neighbours.append(agents[i])","for e_target in enumerate(eucl_distance):
    dist = e_target[1]
    i = e_target[0]
    if idx != i and sensing_distance > dist:
        neighbours.append(agents[i])

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_kh.py', 'tests.opytimizer.optimizers.swarm.test_kh', '', 'test_kh_get_neighbours'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_kh.py', 'tests.opytimizer.optimizers.swarm.test_kh', '', 'test_kh_local_alpha']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/pso.py,,test_pso_evaluate,"for (i, agent) in enumerate(space.agents):
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_pso.py', 'tests.opytimizer.optimizers.swarm.test_pso', '', 'test_pso_evaluate']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/pso.py,,test_aiwpso_compute_success,"for (i, agent) in enumerate(agents):
    if agent.fit < self.fitness[i]:
        p += 1
    self.fitness[i] = agent.fit","for e_target in enumerate(agents):
    agent = e_target[1]
    i = e_target[0]
    if agent.fit < self.fitness[i]:
        p += 1
    self.fitness[i] = agent.fit

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_pso.py', 'tests.opytimizer.optimizers.swarm.test_pso', '', 'test_aiwpso_compute_success']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/pso.py,,test_rpso_update,"for (i, agent) in enumerate(space.agents):
    r1 = r.generate_uniform_random_number()
    r2 = r.generate_uniform_random_number()
    gamma = 1 / np.sqrt(1 - max_velocity ** 2 / c.LIGHT_SPEED ** 2)
    self.velocity[i] = self.mass[i] * self.velocity[i] * gamma + self.c1 * r1 * (self.local_position[i] - agent.position) + self.c2 * r2 * (space.best_agent.position - agent.position)
    agent.position += self.velocity[i]","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    r1 = r.generate_uniform_random_number()
    r2 = r.generate_uniform_random_number()
    gamma = 1 / np.sqrt(1 - max_velocity ** 2 / c.LIGHT_SPEED ** 2)
    self.velocity[i] = self.mass[i] * self.velocity[i] * gamma + self.c1 * r1 * (self.local_position[i] - agent.position) + self.c2 * r2 * (space.best_agent.position - agent.position)
    agent.position += self.velocity[i]

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_pso.py', 'tests.opytimizer.optimizers.swarm.test_pso', '', 'test_rpso_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/pso.py,,test_savpso_update,"for (i, agent) in enumerate(space.agents):
    idx = r.generate_integer_random_number(0, len(space.agents))
    r1 = r.generate_uniform_random_number()
    self.velocity[i] = self.w * np.fabs(self.local_position[idx] - self.local_position[i]) * np.sign(self.velocity[i]) + r1 * (self.local_position[i] - agent.position) + (1 - r1) * (space.best_agent.position - agent.position)
    agent.position += self.velocity[i]
    for j in range(agent.n_variables):
        r4 = r.generate_uniform_random_number(0, 1)
        if agent.position[j] > agent.ub[j]:
            agent.position[j] = positions[j] + 1 * r4 * (agent.ub[j] - positions[j])
        if agent.position[j] < agent.lb[j]:
            agent.position[j] = positions[j] + 1 * r4 * (agent.lb[j] - positions[j])","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    idx = r.generate_integer_random_number(0, len(space.agents))
    r1 = r.generate_uniform_random_number()
    self.velocity[i] = self.w * np.fabs(self.local_position[idx] - self.local_position[i]) * np.sign(self.velocity[i]) + r1 * (self.local_position[i] - agent.position) + (1 - r1) * (space.best_agent.position - agent.position)
    agent.position += self.velocity[i]
    for j in range(agent.n_variables):
        r4 = r.generate_uniform_random_number(0, 1)
        if agent.position[j] > agent.ub[j]:
            agent.position[j] = positions[j] + 1 * r4 * (agent.ub[j] - positions[j])
        if agent.position[j] < agent.lb[j]:
            agent.position[j] = positions[j] + 1 * r4 * (agent.lb[j] - positions[j])

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_pso.py', 'tests.opytimizer.optimizers.swarm.test_pso', '', 'test_savpso_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/pso.py,,test_vpso_update,"for (i, agent) in enumerate(space.agents):
    r1 = r.generate_uniform_random_number()
    r2 = r.generate_uniform_random_number()
    self.velocity[i] = self.w * self.velocity[i] + self.c1 * r1 * (self.local_position[i] - agent.position) + self.c2 * r2 * (space.best_agent.position - agent.position)
    self.v_velocity[i] -= np.dot(self.velocity[i].T, self.v_velocity[i]) / (np.dot(self.velocity[i].T, self.velocity[i]) + c.EPSILON) * self.velocity[i]
    r1 = r.generate_uniform_random_number()
    agent.position += r1 * self.velocity[i] + (1 - r1) * self.v_velocity[i]","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    r1 = r.generate_uniform_random_number()
    r2 = r.generate_uniform_random_number()
    self.velocity[i] = self.w * self.velocity[i] + self.c1 * r1 * (self.local_position[i] - agent.position) + self.c2 * r2 * (space.best_agent.position - agent.position)
    self.v_velocity[i] -= np.dot(self.velocity[i].T, self.v_velocity[i]) / (np.dot(self.velocity[i].T, self.velocity[i]) + c.EPSILON) * self.velocity[i]
    r1 = r.generate_uniform_random_number()
    agent.position += r1 * self.velocity[i] + (1 - r1) * self.v_velocity[i]

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_pso.py', 'tests.opytimizer.optimizers.swarm.test_pso', '', 'test_vpso_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/pio.py,,test_pio_update,"for (i, agent) in enumerate(space.agents):
    r1 = r.generate_uniform_random_number()
    self.velocity[i] = self.velocity[i] * np.exp(-self.R * (iteration + 1)) + r1 * (space.best_agent.position - agent.position)
    agent.position += self.velocity[i]","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    r1 = r.generate_uniform_random_number()
    self.velocity[i] = self.velocity[i] * np.exp(-self.R * (iteration + 1)) + r1 * (space.best_agent.position - agent.position)
    agent.position += self.velocity[i]

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_pio.py', 'tests.opytimizer.optimizers.swarm.test_pio', '', 'test_pio_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/mfo.py,,test_mfo_update,"for (i, agent) in enumerate(space.agents):
    for j in range(agent.n_variables):
        t = rnd.generate_uniform_random_number(r, 1)
        if i < n_flames:
            D = np.fabs(flames[i].position[j] - agent.position[j])
            agent.position[j] = D * np.exp(self.b * t) * np.cos(2 * np.pi * t) + flames[i].position[j]
        else:
            D = np.fabs(flames[0].position[j] - agent.position[j])
            agent.position[j] = D * np.exp(self.b * t) * np.cos(2 * np.pi * t) + flames[0].position[j]","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    for j in range(agent.n_variables):
        t = rnd.generate_uniform_random_number(r, 1)
        if i < n_flames:
            D = np.fabs(flames[i].position[j] - agent.position[j])
            agent.position[j] = D * np.exp(self.b * t) * np.cos(2 * np.pi * t) + flames[i].position[j]
        else:
            D = np.fabs(flames[0].position[j] - agent.position[j])
            agent.position[j] = D * np.exp(self.b * t) * np.cos(2 * np.pi * t) + flames[0].position[j]

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_mfo.py', 'tests.opytimizer.optimizers.swarm.test_mfo', '', 'test_mfo_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/sos.py,,test_sos_update,"for (i, agent) in enumerate(space.agents):
    j = r.generate_integer_random_number(0, len(space.agents), exclude_value=i)
    self._mutualism(agent, space.agents[j], space.best_agent, function)
    j = r.generate_integer_random_number(0, len(space.agents), exclude_value=i)
    self._commensalism(agent, space.agents[j], space.best_agent, function)
    j = r.generate_integer_random_number(0, len(space.agents), exclude_value=i)
    self._parasitism(agent, space.agents[j], function)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    j = r.generate_integer_random_number(0, len(space.agents), exclude_value=i)
    self._mutualism(agent, space.agents[j], space.best_agent, function)
    j = r.generate_integer_random_number(0, len(space.agents), exclude_value=i)
    self._commensalism(agent, space.agents[j], space.best_agent, function)
    j = r.generate_integer_random_number(0, len(space.agents), exclude_value=i)
    self._parasitism(agent, space.agents[j], function)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_sos.py', 'tests.opytimizer.optimizers.swarm.test_sos', '', 'test_sos_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/ssa.py,,test_ssa_update,"for (i, _) in enumerate(space.agents):
    if i == 0:
        for (j, (lb, ub)) in enumerate(zip(space.agents[i].lb, space.agents[i].ub)):
            c2 = r.generate_uniform_random_number()
            c3 = r.generate_uniform_random_number()
            if c3 < 0.5:
                space.agents[i].position[j] = space.best_agent.position[j] + c1 * ((ub - lb) * c2 + lb)
            else:
                space.agents[i].position[j] = space.best_agent.position[j] - c1 * ((ub - lb) * c2 + lb)
    else:
        space.agents[i].position = 0.5 * (space.agents[i].position + space.agents[i - 1].position)","for e_target in enumerate(space.agents):
    _ = e_target[1]
    i = e_target[0]
    if i == 0:
        for (j, (lb, ub)) in enumerate(zip(space.agents[i].lb, space.agents[i].ub)):
            c2 = r.generate_uniform_random_number()
            c3 = r.generate_uniform_random_number()
            if c3 < 0.5:
                space.agents[i].position[j] = space.best_agent.position[j] + c1 * ((ub - lb) * c2 + lb)
            else:
                space.agents[i].position[j] = space.best_agent.position[j] - c1 * ((ub - lb) * c2 + lb)
    else:
        space.agents[i].position = 0.5 * (space.agents[i].position + space.agents[i - 1].position)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_ssa.py', 'tests.opytimizer.optimizers.swarm.test_ssa', '', 'test_ssa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/swarm/ssa.py,,test_ssa_update,"for (j, (lb, ub)) in enumerate(zip(space.agents[i].lb, space.agents[i].ub)):
    c2 = r.generate_uniform_random_number()
    c3 = r.generate_uniform_random_number()
    if c3 < 0.5:
        space.agents[i].position[j] = space.best_agent.position[j] + c1 * ((ub - lb) * c2 + lb)
    else:
        space.agents[i].position[j] = space.best_agent.position[j] - c1 * ((ub - lb) * c2 + lb)","for e_target in enumerate(zip(space.agents[i].lb, space.agents[i].ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    c2 = r.generate_uniform_random_number()
    c3 = r.generate_uniform_random_number()
    if c3 < 0.5:
        space.agents[i].position[j] = space.best_agent.position[j] + c1 * ((ub - lb) * c2 + lb)
    else:
        space.agents[i].position[j] = space.best_agent.position[j] - c1 * ((ub - lb) * c2 + lb)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/swarm/test_ssa.py', 'tests.opytimizer.optimizers.swarm.test_ssa', '', 'test_ssa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/population/gco.py,,test_gco_dark_zone,"for (i, agent) in enumerate(agents):
    r1 = r.generate_uniform_random_number(0, 100)
    if r1 < self.life[i]:
        self.counter[i] += 1
    else:
        self.counter[i] = 1
    C = d.generate_choice_distribution(len(agents), self.counter / np.sum(self.counter), size=3)
    a = self._mutate_cell(agent, agents[C[0]], agents[C[1]], agents[C[2]])
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)
        self.life[i] += 10","for e_target in enumerate(agents):
    agent = e_target[1]
    i = e_target[0]
    r1 = r.generate_uniform_random_number(0, 100)
    if r1 < self.life[i]:
        self.counter[i] += 1
    else:
        self.counter[i] = 1
    C = d.generate_choice_distribution(len(agents), self.counter / np.sum(self.counter), size=3)
    a = self._mutate_cell(agent, agents[C[0]], agents[C[1]], agents[C[2]])
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)
        self.life[i] += 10

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_gco.py', 'tests.opytimizer.optimizers.population.test_gco', '', 'test_gco_dark_zone']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/population/loa.py,,test_loa_defense,"for (i, agent) in enumerate(space.agents[:n_nomad]):
    agent.nomad = True
    agent.female = bool(nomad_gender[i])","for e_target in enumerate(space.agents[:n_nomad]):
    agent = e_target[1]
    i = e_target[0]
    agent.nomad = True
    agent.female = bool(nomad_gender[i])

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_mating'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_hunting'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_migrating'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_equilibrium'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_mating_operator'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_update'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_compile'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_get_nomad_lions'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_moving_safe_place'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_nomad_mating'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_roaming'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_nomad_roaming'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_check_prides_for_males'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_nomad_attack'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_get_pride_lions'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_defense']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/population/loa.py,,test_loa_defense,"for (i, agent) in enumerate(space.agents[n_nomad:]):
    agent.female = bool(pride_gender[i])
    agent.pride = i % self.P","for e_target in enumerate(space.agents[n_nomad:]):
    agent = e_target[1]
    i = e_target[0]
    agent.female = bool(pride_gender[i])
    agent.pride = i % self.P

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_mating'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_hunting'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_migrating'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_equilibrium'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_mating_operator'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_update'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_compile'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_get_nomad_lions'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_moving_safe_place'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_nomad_mating'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_roaming'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_nomad_roaming'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_check_prides_for_males'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_nomad_attack'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_get_pride_lions'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_loa.py', 'tests.opytimizer.optimizers.population.test_loa', '', 'test_loa_defense']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/population/aeo.py,,test_aeo_production,"for (j, (lb, ub)) in enumerate(zip(a.lb, a.ub)):
    a.position[j] = (1 - alpha) * best_agent.position[j] + alpha * r.generate_uniform_random_number(lb, ub, a.n_dimensions)","for e_target in enumerate(zip(a.lb, a.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    a.position[j] = (1 - alpha) * best_agent.position[j] + alpha * r.generate_uniform_random_number(lb, ub, a.n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_aeo.py', 'tests.opytimizer.optimizers.population.test_aeo', '', 'test_aeo_production']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/population/ppa.py,,test_ppa_nesting_phase,"for (i, crow) in enumerate(crows):
    idx = r.generate_integer_random_number(high=space.n_agents, exclude_value=i)
    step = d.generate_levy_distribution(size=crow.n_variables)
    step = np.expand_dims(step, axis=1)
    crow.position = 0.01 * step * (space.agents[idx].position - crow.position)
    crow.clip_by_bound()","for e_target in enumerate(crows):
    crow = e_target[1]
    i = e_target[0]
    idx = r.generate_integer_random_number(high=space.n_agents, exclude_value=i)
    step = d.generate_levy_distribution(size=crow.n_variables)
    step = np.expand_dims(step, axis=1)
    crow.position = 0.01 * step * (space.agents[idx].position - crow.position)
    crow.clip_by_bound()

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_ppa.py', 'tests.opytimizer.optimizers.population.test_ppa', '', 'test_ppa_nesting_phase']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/population/pvs.py,,test_pvs_update,"for (i, agent) in enumerate(space.agents):
    a = copy.deepcopy(agent)
    R = [0, 0]
    while R[0] == R[1]:
        R = r.generate_integer_random_number(0, space.n_agents, i, 2)
    D1 = 1 / space.n_agents * agent.fit
    D2 = 1 / space.n_agents * space.agents[R[0]].fit
    D3 = 1 / space.n_agents * space.agents[R[1]].fit
    V1 = r.generate_uniform_random_number() * (1 - D1)
    V2 = r.generate_uniform_random_number() * (1 - D2)
    V3 = r.generate_uniform_random_number() * (1 - D3)
    x = np.fabs(D3 - D1)
    y = np.fabs(D3 - D2)
    x1 = V3 * x / (V1 - V3)
    y1 = V2 * x / (V1 - V3)
    rnd = r.generate_uniform_random_number()
    if V3 < V1:
        if y - y1 > x1:
            Vco = V1 / (V1 - V3)
            a.position += Vco * rnd * (a.position - space.agents[R[1]].position)
        else:
            a.position += rnd * (a.position - space.agents[R[0]].position)
    else:
        a.position += rnd * (space.agents[R[1]].position - a.position)
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    a = copy.deepcopy(agent)
    R = [0, 0]
    while R[0] == R[1]:
        R = r.generate_integer_random_number(0, space.n_agents, i, 2)
    D1 = 1 / space.n_agents * agent.fit
    D2 = 1 / space.n_agents * space.agents[R[0]].fit
    D3 = 1 / space.n_agents * space.agents[R[1]].fit
    V1 = r.generate_uniform_random_number() * (1 - D1)
    V2 = r.generate_uniform_random_number() * (1 - D2)
    V3 = r.generate_uniform_random_number() * (1 - D3)
    x = np.fabs(D3 - D1)
    y = np.fabs(D3 - D2)
    x1 = V3 * x / (V1 - V3)
    y1 = V2 * x / (V1 - V3)
    rnd = r.generate_uniform_random_number()
    if V3 < V1:
        if y - y1 > x1:
            Vco = V1 / (V1 - V3)
            a.position += Vco * rnd * (a.position - space.agents[R[1]].position)
        else:
            a.position += rnd * (a.position - space.agents[R[0]].position)
    else:
        a.position += rnd * (space.agents[R[1]].position - a.position)
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/population/test_pvs.py', 'tests.opytimizer.optimizers.population.test_pvs', '', 'test_pvs_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/esa.py,,test_esa_update,"for (i, agent) in enumerate(space.agents):
    a = copy.deepcopy(agent)
    electrons = [copy.deepcopy(agent) for _ in range(self.n_electrons)]
    for electron in electrons:
        r1 = r.generate_uniform_random_number()
        n = r.generate_integer_random_number(2, 6)
        electron.position += (2 * r1 - 1) * (1 - 1 / n ** 2) / self.D[i]
        electron.clip_by_bound()
        electron.fit = function(electron.position)
    electrons.sort(key=lambda x: x.fit)
    Re = r.generate_uniform_random_number()
    Ac = r.generate_uniform_random_number()
    self.D[i] = electrons[0].position - space.best_agent.position + Re * (1 / space.best_agent.position ** 2 - 1 / a.position ** 2)
    a.position += Ac * self.D[i]
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    a = copy.deepcopy(agent)
    electrons = [copy.deepcopy(agent) for _ in range(self.n_electrons)]
    for electron in electrons:
        r1 = r.generate_uniform_random_number()
        n = r.generate_integer_random_number(2, 6)
        electron.position += (2 * r1 - 1) * (1 - 1 / n ** 2) / self.D[i]
        electron.clip_by_bound()
        electron.fit = function(electron.position)
    electrons.sort(key=lambda x: x.fit)
    Re = r.generate_uniform_random_number()
    Ac = r.generate_uniform_random_number()
    self.D[i] = electrons[0].position - space.best_agent.position + Re * (1 / space.best_agent.position ** 2 - 1 / a.position ** 2)
    a.position += Ac * self.D[i]
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_esa.py', 'tests.opytimizer.optimizers.science.test_esa', '', 'test_esa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/mvo.py,,test_mvo_update,"for (i, agent) in enumerate(space.agents):
    for j in range(agent.n_variables):
        r1 = r.generate_uniform_random_number()
        if r1 < norm_fitness[i]:
            white_hole = g.weighted_wheel_selection(norm_fitness)
            agent.position[j] = space.agents[white_hole].position[j]
        r2 = r.generate_uniform_random_number()
        if r2 < WEP:
            r3 = r.generate_uniform_random_number()
            width = r.generate_uniform_random_number(agent.lb[j], agent.ub[j])
            if r3 < 0.5:
                agent.position[j] = space.best_agent.position[j] + TDR * width
            else:
                agent.position[j] = space.best_agent.position[j] - TDR * width
    agent.clip_by_bound()
    agent.fit = function(agent.position)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    for j in range(agent.n_variables):
        r1 = r.generate_uniform_random_number()
        if r1 < norm_fitness[i]:
            white_hole = g.weighted_wheel_selection(norm_fitness)
            agent.position[j] = space.agents[white_hole].position[j]
        r2 = r.generate_uniform_random_number()
        if r2 < WEP:
            r3 = r.generate_uniform_random_number()
            width = r.generate_uniform_random_number(agent.lb[j], agent.ub[j])
            if r3 < 0.5:
                agent.position[j] = space.best_agent.position[j] + TDR * width
            else:
                agent.position[j] = space.best_agent.position[j] - TDR * width
    agent.clip_by_bound()
    agent.fit = function(agent.position)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_mvo.py', 'tests.opytimizer.optimizers.science.test_mvo', '', 'test_mvo_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/wdo.py,,test_wdo_update,"for (i, agent) in enumerate(space.agents):
    index = r.generate_integer_random_number(0, len(space.agents))
    self.velocity[i] = (1 - self.alpha) * self.velocity[i] - self.g * agent.position + self.RT * np.abs(1 / (index + 1) - 1) * (space.best_agent.position - agent.position) + self.c * self.velocity[index] / (index + 1)
    self.velocity = np.clip(self.velocity, -self.v_max, self.v_max)
    agent.position += self.velocity[i]
    agent.clip_by_bound()
    agent.fit = function(agent.position)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    index = r.generate_integer_random_number(0, len(space.agents))
    self.velocity[i] = (1 - self.alpha) * self.velocity[i] - self.g * agent.position + self.RT * np.abs(1 / (index + 1) - 1) * (space.best_agent.position - agent.position) + self.c * self.velocity[index] / (index + 1)
    self.velocity = np.clip(self.velocity, -self.v_max, self.v_max)
    agent.position += self.velocity[i]
    agent.clip_by_bound()
    agent.fit = function(agent.position)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_wdo.py', 'tests.opytimizer.optimizers.science.test_wdo', '', 'test_wdo_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/aso.py,,test_aso_calculate_acceleration,"for (i, agent) in enumerate(agents):
    total_potential = np.zeros((agent.n_variables, agent.n_dimensions))
    for K_agent in K_agents:
        total_potential += self._calculate_potential(agent, K_agent, average, iteration, n_iterations)
    acceleration[i] = G * self.alpha * total_potential + self.beta * (best_agent.position - agent.position) / mass[i]","for e_target in enumerate(agents):
    agent = e_target[1]
    i = e_target[0]
    total_potential = np.zeros((agent.n_variables, agent.n_dimensions))
    for K_agent in K_agents:
        total_potential += self._calculate_potential(agent, K_agent, average, iteration, n_iterations)
    acceleration[i] = G * self.alpha * total_potential + self.beta * (best_agent.position - agent.position) / mass[i]

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_aso.py', 'tests.opytimizer.optimizers.science.test_aso', '', 'test_aso_calculate_acceleration']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/hgso.py,,test_hgso_update,"for (i, cluster) in enumerate(clusters):
    T = np.exp(-iteration / n_iterations)
    self.coefficient[i] *= np.exp(-self.constant[i] * (1 / T - 1 / 298.15))
    cluster = list(cluster)
    cluster.sort(key=lambda x: x.fit)
    for (j, agent) in enumerate(cluster):
        solubility = self.K * self.coefficient[i] * self.pressure[i][j]
        agent.position = self._update_position(agent, cluster[0], space.best_agent, solubility)
        agent.clip_by_bound()
        agent.fit = function(agent.position)","for e_target in enumerate(clusters):
    cluster = e_target[1]
    i = e_target[0]
    T = np.exp(-iteration / n_iterations)
    self.coefficient[i] *= np.exp(-self.constant[i] * (1 / T - 1 / 298.15))
    cluster = list(cluster)
    cluster.sort(key=lambda x: x.fit)
    for (j, agent) in enumerate(cluster):
        solubility = self.K * self.coefficient[i] * self.pressure[i][j]
        agent.position = self._update_position(agent, cluster[0], space.best_agent, solubility)
        agent.clip_by_bound()
        agent.fit = function(agent.position)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_hgso.py', 'tests.opytimizer.optimizers.science.test_hgso', '', 'test_hgso_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/hgso.py,,test_hgso_update,"for (j, agent) in enumerate(cluster):
    solubility = self.K * self.coefficient[i] * self.pressure[i][j]
    agent.position = self._update_position(agent, cluster[0], space.best_agent, solubility)
    agent.clip_by_bound()
    agent.fit = function(agent.position)","for e_target in enumerate(cluster):
    agent = e_target[1]
    j = e_target[0]
    solubility = self.K * self.coefficient[i] * self.pressure[i][j]
    agent.position = self._update_position(agent, cluster[0], space.best_agent, solubility)
    agent.clip_by_bound()
    agent.fit = function(agent.position)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_hgso.py', 'tests.opytimizer.optimizers.science.test_hgso', '', 'test_hgso_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/wwo.py,,test_wwo_update_wave_length,"for (i, agent) in enumerate(agents):
    self.length[i] *= self.alpha ** (-((agent.fit - agents[-1].fit + c.EPSILON) / (agents[0].fit - agents[-1].fit + c.EPSILON)))","for e_target in enumerate(agents):
    agent = e_target[1]
    i = e_target[0]
    self.length[i] *= self.alpha ** (-((agent.fit - agents[-1].fit + c.EPSILON) / (agents[0].fit - agents[-1].fit + c.EPSILON)))

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_wwo.py', 'tests.opytimizer.optimizers.science.test_wwo', '', 'test_wwo_update_wave_length']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/gsa.py,,test_gsa_update,"for (i, agent) in enumerate(space.agents):
    acceleration = force[i] / (mass[i] + c.EPSILON)
    r1 = r.generate_uniform_random_number()
    self.velocity[i] = r1 * self.velocity[i] + acceleration
    agent.position += self.velocity[i]","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    acceleration = force[i] / (mass[i] + c.EPSILON)
    r1 = r.generate_uniform_random_number()
    self.velocity[i] = r1 * self.velocity[i] + acceleration
    agent.position += self.velocity[i]

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_gsa.py', 'tests.opytimizer.optimizers.science.test_gsa', '', 'test_gsa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/teo.py,,test_teo_update,"for (agent, env) in zip(space.agents, self.environment):
    beta = agent.fit / space.agents[-1].fit
    agent.position = env.position + (agent.position - env.position) * np.exp(-beta * time)
    r1 = r.generate_uniform_random_number()
    if r1 < self.pro:
        idx = r.generate_integer_random_number(high=agent.n_variables)
        r2 = r.generate_uniform_random_number()
        agent.position[idx] = agent.lb[idx] + r2 * (agent.ub[idx] - agent.lb[idx])","for e_target in zip(space.agents, self.environment):
    env = e_target[1]
    agent = e_target[0]
    beta = agent.fit / space.agents[-1].fit
    agent.position = env.position + (agent.position - env.position) * np.exp(-beta * time)
    r1 = r.generate_uniform_random_number()
    if r1 < self.pro:
        idx = r.generate_integer_random_number(high=agent.n_variables)
        r2 = r.generate_uniform_random_number()
        agent.position[idx] = agent.lb[idx] + r2 * (agent.ub[idx] - agent.lb[idx])

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_teo.py', 'tests.opytimizer.optimizers.science.test_teo', '', 'test_teo_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/two.py,,test_two_update,"for (i, temp1) in enumerate(temp_agents):
    delta = 0.0
    for (j, temp2) in enumerate(temp_agents):
        if weights[i] < weights[j]:
            force = np.maximum(weights[i] * self.mu_s, weights[j] * self.mu_s) - weights[i] * mu_k
            g = temp2.position - temp1.position
            acceleration = force / (weights[i] * mu_k) * g
            r1 = r.generate_gaussian_random_number(size=(temp1.n_variables, temp1.n_dimensions))
            delta += 0.5 * acceleration * self.delta_t ** 2 + np.multiply(self.alpha ** iteration * self.beta * (np.expand_dims(temp1.ub, -1) - np.expand_dims(temp1.lb, -1)), r1)
    temp1.position += delta","for e_target in enumerate(temp_agents):
    temp1 = e_target[1]
    i = e_target[0]
    delta = 0.0
    for (j, temp2) in enumerate(temp_agents):
        if weights[i] < weights[j]:
            force = np.maximum(weights[i] * self.mu_s, weights[j] * self.mu_s) - weights[i] * mu_k
            g = temp2.position - temp1.position
            acceleration = force / (weights[i] * mu_k) * g
            r1 = r.generate_gaussian_random_number(size=(temp1.n_variables, temp1.n_dimensions))
            delta += 0.5 * acceleration * self.delta_t ** 2 + np.multiply(self.alpha ** iteration * self.beta * (np.expand_dims(temp1.ub, -1) - np.expand_dims(temp1.lb, -1)), r1)
    temp1.position += delta

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_two.py', 'tests.opytimizer.optimizers.science.test_two', '', 'test_two_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/two.py,,test_two_update,"for (agent, temp) in zip(space.agents, temp_agents):
    if temp.fit < agent.fit:
        agent.position = copy.deepcopy(temp.position)
        agent.fit = copy.deepcopy(temp.fit)","for e_target in zip(space.agents, temp_agents):
    temp = e_target[1]
    agent = e_target[0]
    if temp.fit < agent.fit:
        agent.position = copy.deepcopy(temp.position)
        agent.fit = copy.deepcopy(temp.fit)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_two.py', 'tests.opytimizer.optimizers.science.test_two', '', 'test_two_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/two.py,,test_two_update,"for (j, temp2) in enumerate(temp_agents):
    if weights[i] < weights[j]:
        force = np.maximum(weights[i] * self.mu_s, weights[j] * self.mu_s) - weights[i] * mu_k
        g = temp2.position - temp1.position
        acceleration = force / (weights[i] * mu_k) * g
        r1 = r.generate_gaussian_random_number(size=(temp1.n_variables, temp1.n_dimensions))
        delta += 0.5 * acceleration * self.delta_t ** 2 + np.multiply(self.alpha ** iteration * self.beta * (np.expand_dims(temp1.ub, -1) - np.expand_dims(temp1.lb, -1)), r1)","for e_target in enumerate(temp_agents):
    temp2 = e_target[1]
    j = e_target[0]
    if weights[i] < weights[j]:
        force = np.maximum(weights[i] * self.mu_s, weights[j] * self.mu_s) - weights[i] * mu_k
        g = temp2.position - temp1.position
        acceleration = force / (weights[i] * mu_k) * g
        r1 = r.generate_gaussian_random_number(size=(temp1.n_variables, temp1.n_dimensions))
        delta += 0.5 * acceleration * self.delta_t ** 2 + np.multiply(self.alpha ** iteration * self.beta * (np.expand_dims(temp1.ub, -1) - np.expand_dims(temp1.lb, -1)), r1)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_two.py', 'tests.opytimizer.optimizers.science.test_two', '', 'test_two_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/science/moa.py,,test_moa_update,"for (i, agent) in enumerate(space.agents):
    root = np.sqrt(space.n_agents)
    north = int((i - root) % space.n_agents)
    south = int((i + root) % space.n_agents)
    west = int(i - 1 + (i + root - 1) % root // (root - 1) * root)
    east = int(i + 1 - i % root // (root - 1) * root)
    neighbours = [north, south, west, east]
    force = 0
    for n in neighbours:
        distance = g.euclidean_distance(agent.position, space.agents[n].position)
        force += (space.agents[n].position - agent.position) * fitness[n] / (distance + c.EPSILON)
    force = np.mean(force)
    r1 = r.generate_uniform_random_number()
    velocity = force / mass[i] * r1
    agent.position += velocity
    agent.clip_by_bound()","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    root = np.sqrt(space.n_agents)
    north = int((i - root) % space.n_agents)
    south = int((i + root) % space.n_agents)
    west = int(i - 1 + (i + root - 1) % root // (root - 1) * root)
    east = int(i + 1 - i % root // (root - 1) * root)
    neighbours = [north, south, west, east]
    force = 0
    for n in neighbours:
        distance = g.euclidean_distance(agent.position, space.agents[n].position)
        force += (space.agents[n].position - agent.position) * fitness[n] / (distance + c.EPSILON)
    force = np.mean(force)
    r1 = r.generate_uniform_random_number()
    velocity = force / mass[i] * r1
    agent.position += velocity
    agent.clip_by_bound()

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/science/test_moa.py', 'tests.opytimizer.optimizers.science.test_moa', '', 'test_moa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/social/ci.py,,test_ci_update,"for (i, agent) in enumerate(space.agents):
    s = g.weighted_wheel_selection(fitness)
    self.lower[i] = space.agents[s].position - self.lower[i] * self.r / 2
    self.upper[i] = space.agents[s].position - self.upper[i] * self.r / 2
    for _ in range(self.t):
        a = copy.deepcopy(agent)
        for (j, (lb, ub)) in enumerate(zip(self.lower[i], self.upper[i])):
            a.position[j] = rnd.generate_uniform_random_number(lb, ub, agent.n_dimensions)
        a.clip_by_bound()
        a.fit = function(a.position)
        if a.fit < agent.fit:
            agent.position = copy.deepcopy(a.position)
            agent.fit = copy.deepcopy(a.fit)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    s = g.weighted_wheel_selection(fitness)
    self.lower[i] = space.agents[s].position - self.lower[i] * self.r / 2
    self.upper[i] = space.agents[s].position - self.upper[i] * self.r / 2
    for _ in range(self.t):
        a = copy.deepcopy(agent)
        for (j, (lb, ub)) in enumerate(zip(self.lower[i], self.upper[i])):
            a.position[j] = rnd.generate_uniform_random_number(lb, ub, agent.n_dimensions)
        a.clip_by_bound()
        a.fit = function(a.position)
        if a.fit < agent.fit:
            agent.position = copy.deepcopy(a.position)
            agent.fit = copy.deepcopy(a.fit)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/social/test_ci.py', 'tests.opytimizer.optimizers.social.test_ci', '', 'test_ci_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/social/ci.py,,test_ci_update,"for (j, (lb, ub)) in enumerate(zip(self.lower[i], self.upper[i])):
    a.position[j] = rnd.generate_uniform_random_number(lb, ub, agent.n_dimensions)","for e_target in enumerate(zip(self.lower[i], self.upper[i])):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    a.position[j] = rnd.generate_uniform_random_number(lb, ub, agent.n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/social/test_ci.py', 'tests.opytimizer.optimizers.social.test_ci', '', 'test_ci_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/social/isa.py,,test_isa_evaluate,"for (i, agent) in enumerate(space.agents):
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/social/test_isa.py', 'tests.opytimizer.optimizers.social.test_isa', '', 'test_isa_evaluate']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/social/ssd.py,,test_ssd_evaluate,"for (i, agent) in enumerate(space.agents):
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/social/test_ssd.py', 'tests.opytimizer.optimizers.social.test_ssd', '', 'test_ssd_evaluate']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/social/qsa.py,,test_qsa_business_one,"for (i, agent) in enumerate(agents):
    a = copy.deepcopy(agent)
    if i < q_1:
        if i == 0:
            case = 1
        A = copy.deepcopy(A_1)
    elif q_1 <= i < q_1 + q_2:
        if i == q_1:
            case = 1
        A = copy.deepcopy(A_2)
    else:
        if i == q_1 + q_2:
            case = 1
        A = copy.deepcopy(A_3)
    alpha = r.generate_uniform_random_number(-1, 1)
    E = r.generate_gamma_random_number(1, 0.5, (agent.n_variables, agent.n_dimensions))
    if case == 1:
        e = r.generate_gamma_random_number(1, 0.5, 1)
        F_1 = beta * alpha * (E * np.fabs(A.position - a.position)) + e * (A.position - a.position)
        a.position = A.position + F_1
        a.fit = function(a.position)
        if a.fit < agent.fit:
            agent.position = copy.deepcopy(a.position)
            agent.fit = copy.deepcopy(a.fit)
            case = 1
        else:
            case = 2
    else:
        F_2 = beta * alpha * (E * np.fabs(A.position - a.position))
        a.position += F_2
        a.fit = function(a.position)
        if a.fit < agent.fit:
            agent.position = copy.deepcopy(a.position)
            agent.fit = copy.deepcopy(a.fit)
            case = 2
        else:
            case = 1","for e_target in enumerate(agents):
    agent = e_target[1]
    i = e_target[0]
    a = copy.deepcopy(agent)
    if i < q_1:
        if i == 0:
            case = 1
        A = copy.deepcopy(A_1)
    elif q_1 <= i < q_1 + q_2:
        if i == q_1:
            case = 1
        A = copy.deepcopy(A_2)
    else:
        if i == q_1 + q_2:
            case = 1
        A = copy.deepcopy(A_3)
    alpha = r.generate_uniform_random_number(-1, 1)
    E = r.generate_gamma_random_number(1, 0.5, (agent.n_variables, agent.n_dimensions))
    if case == 1:
        e = r.generate_gamma_random_number(1, 0.5, 1)
        F_1 = beta * alpha * (E * np.fabs(A.position - a.position)) + e * (A.position - a.position)
        a.position = A.position + F_1
        a.fit = function(a.position)
        if a.fit < agent.fit:
            agent.position = copy.deepcopy(a.position)
            agent.fit = copy.deepcopy(a.fit)
            case = 1
        else:
            case = 2
    else:
        F_2 = beta * alpha * (E * np.fabs(A.position - a.position))
        a.position += F_2
        a.fit = function(a.position)
        if a.fit < agent.fit:
            agent.position = copy.deepcopy(a.position)
            agent.fit = copy.deepcopy(a.fit)
            case = 2
        else:
            case = 1

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/social/test_qsa.py', 'tests.opytimizer.optimizers.social.test_qsa', '', 'test_qsa_business_one']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/es.py,,test_es_compile,"for (j, (lb, ub)) in enumerate(zip(space.lb, space.ub)):
    self.strategy[i][j] = 0.05 * r.generate_uniform_random_number(0, ub - lb, size=space.agents[i].n_dimensions)","for e_target in enumerate(zip(space.lb, space.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    self.strategy[i][j] = 0.05 * r.generate_uniform_random_number(0, ub - lb, size=space.agents[i].n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_es.py', 'tests.opytimizer.optimizers.evolutionary.test_es', '', 'test_es_update'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_es.py', 'tests.opytimizer.optimizers.evolutionary.test_es', '', 'test_es_update_strategy'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_es.py', 'tests.opytimizer.optimizers.evolutionary.test_es', '', 'test_es_mutate_parent'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_es.py', 'tests.opytimizer.optimizers.evolutionary.test_es', '', 'test_es_compile']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/gp.py,,test_gp_evaluate,"for (tree, agent) in zip(space.trees, space.agents):
    agent.position = copy.deepcopy(tree.position)
    agent.clip_by_bound()
    agent.fit = function(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_tree = copy.deepcopy(tree)
        space.best_agent.position = copy.deepcopy(agent.position)
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())","for e_target in zip(space.trees, space.agents):
    agent = e_target[1]
    tree = e_target[0]
    agent.position = copy.deepcopy(tree.position)
    agent.clip_by_bound()
    agent.fit = function(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_tree = copy.deepcopy(tree)
        space.best_agent.position = copy.deepcopy(agent.position)
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_gp.py', 'tests.opytimizer.optimizers.evolutionary.test_gp', '', 'test_gp_evaluate']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/foa.py,,test_foa_local_seeding,"for (i, agent) in enumerate(space.agents):
    if self.age[i] == 0:
        for _ in range(self.LSC):
            child = copy.deepcopy(agent)
            j = r.generate_integer_random_number(high=child.n_variables)
            child.position[j] += r.generate_uniform_random_number(child.lb[j], child.ub[j])
            child.clip_by_bound()
            child.fit = function(child.position)
            new_agents.append(child)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    if self.age[i] == 0:
        for _ in range(self.LSC):
            child = copy.deepcopy(agent)
            j = r.generate_integer_random_number(high=child.n_variables)
            child.position[j] += r.generate_uniform_random_number(child.lb[j], child.ub[j])
            child.clip_by_bound()
            child.fit = function(child.position)
            new_agents.append(child)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_foa.py', 'tests.opytimizer.optimizers.evolutionary.test_foa', '', 'test_foa_local_seeding']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/iwo.py,,test_iwo_produce_offspring,"for (j, (lb, ub)) in enumerate(zip(a.lb, a.ub)):
    a.position[j] += self.sigma * r.generate_uniform_random_number(lb, ub, a.n_dimensions)","for e_target in enumerate(zip(a.lb, a.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    a.position[j] += self.sigma * r.generate_uniform_random_number(lb, ub, a.n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_iwo.py', 'tests.opytimizer.optimizers.evolutionary.test_iwo', '', 'test_iwo_produce_offspring']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/hs.py,,test_hs_generate_new_harmony,"for (j, (lb, ub)) in enumerate(zip(a.lb, a.ub)):
    r1 = r.generate_uniform_random_number()
    if r1 <= self.HMCR:
        k = r.generate_integer_random_number(0, len(agents))
        a.position[j] = agents[k].position[j]
        r2 = r.generate_uniform_random_number()
        if r2 <= self.PAR:
            r3 = r.generate_uniform_random_number(-1, 1)
            a.position[j] += r3 * self.bw
    else:
        a.position[j] = r.generate_uniform_random_number(lb, ub, size=a.n_dimensions)","for e_target in enumerate(zip(a.lb, a.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    r1 = r.generate_uniform_random_number()
    if r1 <= self.HMCR:
        k = r.generate_integer_random_number(0, len(agents))
        a.position[j] = agents[k].position[j]
        r2 = r.generate_uniform_random_number()
        if r2 <= self.PAR:
            r3 = r.generate_uniform_random_number(-1, 1)
            a.position[j] += r3 * self.bw
    else:
        a.position[j] = r.generate_uniform_random_number(lb, ub, size=a.n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_hs.py', 'tests.opytimizer.optimizers.evolutionary.test_hs', '', 'test_hs_generate_new_harmony']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/hs.py,,test_ghs_generate_new_harmony,"for (j, (lb, ub)) in enumerate(zip(a.lb, a.ub)):
    r1 = r.generate_uniform_random_number()
    if r1 <= self.HMCR:
        k = r.generate_integer_random_number(0, len(agents))
        a.position[j] = agents[k].position[j]
        r2 = r.generate_uniform_random_number()
        if r2 <= self.PAR:
            z = r.generate_integer_random_number(0, a.n_variables)
            a.position[j] = agents[0].position[z]
    else:
        a.position[j] = r.generate_uniform_random_number(lb, ub, size=a.n_dimensions)","for e_target in enumerate(zip(a.lb, a.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    r1 = r.generate_uniform_random_number()
    if r1 <= self.HMCR:
        k = r.generate_integer_random_number(0, len(agents))
        a.position[j] = agents[k].position[j]
        r2 = r.generate_uniform_random_number()
        if r2 <= self.PAR:
            z = r.generate_integer_random_number(0, a.n_variables)
            a.position[j] = agents[0].position[z]
    else:
        a.position[j] = r.generate_uniform_random_number(lb, ub, size=a.n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_hs.py', 'tests.opytimizer.optimizers.evolutionary.test_hs', '', 'test_ghs_generate_new_harmony']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/hs.py,,test_sghs_generate_new_harmony,"for (j, (lb, ub)) in enumerate(zip(a.lb, a.ub)):
    r1 = r.generate_uniform_random_number()
    if r1 <= self.HMCR:
        r2 = r.generate_uniform_random_number(-1, 1)
        a.position[j] += r2 * self.bw
        r3 = r.generate_uniform_random_number()
        if r3 <= self.PAR:
            a.position[j] = agents[0].position[j]
    else:
        a.position[j] = r.generate_uniform_random_number(lb, ub, size=a.n_dimensions)","for e_target in enumerate(zip(a.lb, a.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    r1 = r.generate_uniform_random_number()
    if r1 <= self.HMCR:
        r2 = r.generate_uniform_random_number(-1, 1)
        a.position[j] += r2 * self.bw
        r3 = r.generate_uniform_random_number()
        if r3 <= self.PAR:
            a.position[j] = agents[0].position[j]
    else:
        a.position[j] = r.generate_uniform_random_number(lb, ub, size=a.n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_hs.py', 'tests.opytimizer.optimizers.evolutionary.test_hs', '', 'test_sghs_generate_new_harmony']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/hs.py,,test_nghs_generate_new_harmony,"for (j, (lb, ub)) in enumerate(zip(a.lb, a.ub)):
    new_position = 2 * (best.position[j] - worst.position[j])
    new_position = np.clip(new_position, lb, ub)
    r1 = r.generate_uniform_random_number()
    a.position[j] = worst.position[j] + r1 * (new_position - worst.position[j])
    r2 = r.generate_uniform_random_number()
    if r2 <= self.pm:
        a.position[j] = r.generate_uniform_random_number(lb, ub, size=a.n_dimensions)","for e_target in enumerate(zip(a.lb, a.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    new_position = 2 * (best.position[j] - worst.position[j])
    new_position = np.clip(new_position, lb, ub)
    r1 = r.generate_uniform_random_number()
    a.position[j] = worst.position[j] + r1 * (new_position - worst.position[j])
    r2 = r.generate_uniform_random_number()
    if r2 <= self.pm:
        a.position[j] = r.generate_uniform_random_number(lb, ub, size=a.n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_hs.py', 'tests.opytimizer.optimizers.evolutionary.test_hs', '', 'test_nghs_generate_new_harmony']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/ep.py,,test_ep_mutate_parent,"for (j, (lb, ub)) in enumerate(zip(space.lb, space.ub)):
    self.strategy[i][j] = 0.05 * r.generate_uniform_random_number(0, ub - lb, size=space.agents[i].n_dimensions)","for e_target in enumerate(zip(space.lb, space.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    self.strategy[i][j] = 0.05 * r.generate_uniform_random_number(0, ub - lb, size=space.agents[i].n_dimensions)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_ep.py', 'tests.opytimizer.optimizers.evolutionary.test_ep', '', 'test_ep_compile'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_ep.py', 'tests.opytimizer.optimizers.evolutionary.test_ep', '', 'test_ep_update_strategy'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_ep.py', 'tests.opytimizer.optimizers.evolutionary.test_ep', '', 'test_ep_update'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_ep.py', 'tests.opytimizer.optimizers.evolutionary.test_ep', '', 'test_ep_mutate_parent']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/bsa.py,,test_bsa_crossover,"for (trial_agent, agent, old_agent) in zip(trial_agents, agents, self.old_agents):
    trial_agent.position = agent.position + self.F * r1 * (old_agent.position - agent.position)
    trial_agent.clip_by_bound()","for e_target in zip(trial_agents, agents, self.old_agents):
    old_agent = e_target[2]
    agent = e_target[1]
    trial_agent = e_target[0]
    trial_agent.position = agent.position + self.F * r1 * (old_agent.position - agent.position)
    trial_agent.clip_by_bound()

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_bsa.py', 'tests.opytimizer.optimizers.evolutionary.test_bsa', '', 'test_bsa_mutate'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_bsa.py', 'tests.opytimizer.optimizers.evolutionary.test_bsa', '', 'test_bsa_crossover']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/evolutionary/de.py,,test_de_update,"for (i, agent) in enumerate(space.agents):
    C = d.generate_choice_distribution(np.setdiff1d(range(0, len(space.agents)), i), size=3)
    a = self._mutate_agent(agent, space.agents[C[0]], space.agents[C[1]], space.agents[C[2]])
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    C = d.generate_choice_distribution(np.setdiff1d(range(0, len(space.agents)), i), size=3)
    a = self._mutate_agent(agent, space.agents[C[0]], space.agents[C[1]], space.agents[C[2]])
    a.clip_by_bound()
    a.fit = function(a.position)
    if a.fit < agent.fit:
        agent.position = copy.deepcopy(a.position)
        agent.fit = copy.deepcopy(a.fit)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/evolutionary/test_de.py', 'tests.opytimizer.optimizers.evolutionary.test_de', '', 'test_de_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/misc/cem.py,,test_cem_update,"for (j, (lb, ub)) in enumerate(zip(space.lb, space.ub)):
    self.mean[j] = r.generate_uniform_random_number(lb, ub)
    self.std[j] = ub - lb","for e_target in enumerate(zip(space.lb, space.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    self.mean[j] = r.generate_uniform_random_number(lb, ub)
    self.std[j] = ub - lb

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/misc/test_cem.py', 'tests.opytimizer.optimizers.misc.test_cem', '', 'test_cem_create_new_samples'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/misc/test_cem.py', 'tests.opytimizer.optimizers.misc.test_cem', '', 'test_cem_update_mean'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/misc/test_cem.py', 'tests.opytimizer.optimizers.misc.test_cem', '', 'test_cem_compile'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/misc/test_cem.py', 'tests.opytimizer.optimizers.misc.test_cem', '', 'test_cem_update_std'], ['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/misc/test_cem.py', 'tests.opytimizer.optimizers.misc.test_cem', '', 'test_cem_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/misc/doa.py,,test_doa_update,"for (i, agent) in enumerate(space.agents):
    for (j, (lb, ub)) in enumerate(zip(agent.lb, agent.ub)):
        c_map = self._calculate_chaotic_map(lb, ub)
        agent.position[j] += 2 * (space.best_agent.position[j] - agent.position[j]) / (c_map - self.chaotic_map[i][j]) * (ub - lb) / len(space.agents)
        self.chaotic_map[i][j] = c_map
        if agent.position[j] < lb or agent.position[j] > ub:
            agent.position[j] = space.best_agent.position[j] * c_map","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    for (j, (lb, ub)) in enumerate(zip(agent.lb, agent.ub)):
        c_map = self._calculate_chaotic_map(lb, ub)
        agent.position[j] += 2 * (space.best_agent.position[j] - agent.position[j]) / (c_map - self.chaotic_map[i][j]) * (ub - lb) / len(space.agents)
        self.chaotic_map[i][j] = c_map
        if agent.position[j] < lb or agent.position[j] > ub:
            agent.position[j] = space.best_agent.position[j] * c_map

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/misc/test_doa.py', 'tests.opytimizer.optimizers.misc.test_doa', '', 'test_doa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/misc/doa.py,,test_doa_update,"for (j, (lb, ub)) in enumerate(zip(agent.lb, agent.ub)):
    c_map = self._calculate_chaotic_map(lb, ub)
    agent.position[j] += 2 * (space.best_agent.position[j] - agent.position[j]) / (c_map - self.chaotic_map[i][j]) * (ub - lb) / len(space.agents)
    self.chaotic_map[i][j] = c_map
    if agent.position[j] < lb or agent.position[j] > ub:
        agent.position[j] = space.best_agent.position[j] * c_map","for e_target in enumerate(zip(agent.lb, agent.ub)):
    ub = e_target[1][1]
    lb = e_target[1][0]
    j = e_target[0]
    c_map = self._calculate_chaotic_map(lb, ub)
    agent.position[j] += 2 * (space.best_agent.position[j] - agent.position[j]) / (c_map - self.chaotic_map[i][j]) * (ub - lb) / len(space.agents)
    self.chaotic_map[i][j] = c_map
    if agent.position[j] < lb or agent.position[j] > ub:
        agent.position[j] = space.best_agent.position[j] * c_map

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/misc/test_doa.py', 'tests.opytimizer.optimizers.misc.test_doa', '', 'test_doa_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/boolean/bmrfo.py,,test_bmrfo_update,"for (i, agent) in enumerate(space.agents):
    r1 = r.generate_uniform_random_number()
    if r1 < 0.5:
        agent.position = self._cyclone_foraging(space.agents, space.best_agent.position, i, iteration, n_iterations)
    else:
        agent.position = self._chain_foraging(space.agents, space.best_agent.position, i)
    agent.clip_by_bound()
    agent.fit = function(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(agent.position)
        space.best_agent.fit = copy.deepcopy(agent.fit)","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    r1 = r.generate_uniform_random_number()
    if r1 < 0.5:
        agent.position = self._cyclone_foraging(space.agents, space.best_agent.position, i, iteration, n_iterations)
    else:
        agent.position = self._chain_foraging(space.agents, space.best_agent.position, i)
    agent.clip_by_bound()
    agent.fit = function(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(agent.position)
        space.best_agent.fit = copy.deepcopy(agent.fit)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/boolean/test_bmrfo.py', 'tests.opytimizer.optimizers.boolean.test_bmrfo', '', 'test_bmrfo_update']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/optimizers/boolean/bpso.py,,test_bpso_evaluate,"for (i, agent) in enumerate(space.agents):
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())","for e_target in enumerate(space.agents):
    agent = e_target[1]
    i = e_target[0]
    fit = function(agent.position)
    if fit < agent.fit:
        agent.fit = fit
        self.local_position[i] = copy.deepcopy(agent.position)
    if agent.fit < space.best_agent.fit:
        space.best_agent.position = copy.deepcopy(self.local_position[i])
        space.best_agent.fit = copy.deepcopy(agent.fit)
        space.best_agent.ts = int(time.time())

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/optimizers/boolean/test_bpso.py', 'tests.opytimizer.optimizers.boolean.test_bpso', '', 'test_bpso_evaluate']]"
opytimizer,https://github.com/gugarosa/opytimizer/tree/master/opytimizer/visualization/convergence.py,,test_convergence_plot,"for (arg, label) in zip(args, labels):
    ax.plot(arg, label=label)","for e_target in zip(args, labels):
    label = e_target[1]
    arg = e_target[0]
    ax.plot(arg, label=label)

",1,"[['https://github.com/gugarosa/opytimizer/tree/master/tests/opytimizer/visualization/test_convergence.py', 'tests.opytimizer.visualization.test_convergence', '', 'test_convergence_plot']]"
html5lib-python,https://github.com/html5lib/html5lib-python/tree/master/html5lib/treeadapters/sax.py,,test_to_sax,"for (prefix, namespace) in prefix_mapping.items():
    handler.startPrefixMapping(prefix, namespace)","for e_target in prefix_mapping.items():
    namespace = e_target[1]
    prefix = e_target[0]
    handler.startPrefixMapping(prefix, namespace)

",1,"[['https://github.com/html5lib/html5lib-python/tree/master/html5lib/tests/test_treeadapters.py', 'html5lib.tests.test_treeadapters', '', 'test_to_sax']]"
html5lib-python,https://github.com/html5lib/html5lib-python/tree/master/html5lib/treeadapters/sax.py,,test_to_sax,"for (prefix, namespace) in prefix_mapping.items():
    handler.endPrefixMapping(prefix)","for e_target in prefix_mapping.items():
    namespace = e_target[1]
    prefix = e_target[0]
    handler.endPrefixMapping(prefix)

",1,"[['https://github.com/html5lib/html5lib-python/tree/master/html5lib/tests/test_treeadapters.py', 'html5lib.tests.test_treeadapters', '', 'test_to_sax']]"
beancount,https://github.com/beancount/beancount/tree/master/beancount/core/distribution.py,TestDistribution,test_distribution,"for (value, count) in sorted(self.hist.items()):
    if count >= max_count:
        max_count = count
        max_value = value","for e_target in sorted(self.hist.items()):
    count = e_target[1]
    value = e_target[0]
    if count >= max_count:
        max_count = count
        max_value = value

",1,"[['https://github.com/beancount/beancount/tree/master/beancount/core/distribution_test.py', 'beancount.core.distribution_test', 'TestDistribution', 'test_distribution']]"
beancount,https://github.com/beancount/beancount/tree/master/beancount/core/account.py,TestFileUtilsFind,test_find_files,"for (root, dirs, files) in os.walk(root_directory):
    dirs.sort()
    files.sort()
    relroot = root[len(root_directory) + 1:]
    account_name = relroot.replace(os.sep, sep)
    if is_valid(account_name):
        yield (root, account_name, dirs, files)","for e_target in os.walk(root_directory):
    files = e_target[2]
    dirs = e_target[1]
    root = e_target[0]
    dirs.sort()
    files.sort()
    relroot = root[len(root_directory) + 1:]
    account_name = relroot.replace(os.sep, sep)
    if is_valid(account_name):
        yield (root, account_name, dirs, files)

",1,"[['https://github.com/beancount/beancount/tree/master/beancount/utils/file_utils_test.py', 'beancount.utils.file_utils_test', 'TestFileUtilsFind', 'test_find_files']]"
beancount,https://github.com/beancount/beancount/tree/master/beancount/query/numberify.py,TestNumerifySimple,test_position,"for (index, col_desc) in enumerate(dtypes):
    (name, dtype) = col_desc
    convert_col_fun = CONVERTING_TYPES.get(dtype, None)
    if convert_col_fun is None:
        converters.append(IdentityConverter(name, dtype, index))
    else:
        col_converters = convert_col_fun(name, drows, index)
        converters.extend(col_converters)","for e_target in enumerate(dtypes):
    col_desc = e_target[1]
    index = e_target[0]
    (name, dtype) = col_desc
    convert_col_fun = CONVERTING_TYPES.get(dtype, None)
    if convert_col_fun is None:
        converters.append(IdentityConverter(name, dtype, index))
    else:
        col_converters = convert_col_fun(name, drows, index)
        converters.extend(col_converters)

",1,"[['https://github.com/beancount/beancount/tree/master/beancount/query/numberify_test.py', 'beancount.query.numberify_test', 'TestNumerifySimple', 'test_amount'], ['https://github.com/beancount/beancount/tree/master/beancount/query/numberify_test.py', 'beancount.query.numberify_test', 'TestNumerifyPrecision', 'test_precision'], ['https://github.com/beancount/beancount/tree/master/beancount/query/numberify_test.py', 'beancount.query.numberify_test', 'TestNumerifyInventory', 'test_inventory'], ['https://github.com/beancount/beancount/tree/master/beancount/query/numberify_test.py', 'beancount.query.numberify_test', 'TestNumerifyIdentity', 'test_identity'], ['https://github.com/beancount/beancount/tree/master/beancount/query/numberify_test.py', 'beancount.query.numberify_test', 'TestNumerifySimple', 'test_inventory'], ['https://github.com/beancount/beancount/tree/master/beancount/query/numberify_test.py', 'beancount.query.numberify_test', 'TestNumerifySimple', 'test_position']]"
beancount,https://github.com/beancount/beancount/tree/master/beancount/scripts/directories.py,TestScriptCheckDirectories,test_validation,"for (directory, account_name, _, _) in account.walk(document_dir):
    if account_name not in accounts_with_parents:
        errors.append(ValidateDirectoryError(""Invalid directory '{}': no corresponding account '{}'"".format(directory, account_name)))","for e_target in account.walk(document_dir):
    _ = e_target[3]
    account_name = e_target[1]
    directory = e_target[0]
    if account_name not in accounts_with_parents:
        errors.append(ValidateDirectoryError(""Invalid directory '{}': no corresponding account '{}'"".format(directory, account_name)))

",1,"[['https://github.com/beancount/beancount/tree/master/beancount/scripts/directories_test.py', 'beancount.scripts.directories_test', 'TestScriptCheckDirectories', 'test_validation_no_parent'], ['https://github.com/beancount/beancount/tree/master/beancount/scripts/directories_test.py', 'beancount.scripts.directories_test', 'TestScriptCheckDirectories', 'test_validation']]"
beancount,https://github.com/beancount/beancount/tree/master/beancount/utils/table.py,TestTable,test_create_table_with_index,"for (name, _, formatter) in field_spec:
    if isinstance(name, str):
        value = getattr(row, name)
    elif isinstance(name, int):
        value = row[name]
    else:
        raise ValueError('Invalid type for column name')
    if value is not None:
        if formatter is not None:
            value = formatter(value)
        else:
            value = str(value)
    else:
        value = ''
    body_row.append(value)","for e_target in field_spec:
    formatter = e_target[2]
    _ = e_target[1]
    name = e_target[0]
    if isinstance(name, str):
        value = getattr(row, name)
    elif isinstance(name, int):
        value = row[name]
    else:
        raise ValueError('Invalid type for column name')
    if value is not None:
        if formatter is not None:
            value = formatter(value)
        else:
            value = str(value)
    else:
        value = ''
    body_row.append(value)

",1,"[['https://github.com/beancount/beancount/tree/master/beancount/utils/table_test.py', 'beancount.utils.table_test', 'TestTable', 'test_create_table'], ['https://github.com/beancount/beancount/tree/master/beancount/utils/table_test.py', 'beancount.utils.table_test', 'TestTable', 'test_create_table_with_index']]"
beancount,https://github.com/beancount/beancount/tree/master/beancount/utils/misc_utils.py,TestMiscUtils,test_replace_tuple_values,"for (attribute_name, attribute) in zip(ntuple._fields, ntuple):
    if predicate(attribute):
        replacements[attribute_name] = mapper(attribute)
    elif type(attribute) is not tuple and isinstance(attribute, tuple):
        replacements[attribute_name] = replace_namedtuple_values(attribute, predicate, mapper, memo)
    elif type(attribute) in (list, tuple):
        replacements[attribute_name] = [replace_namedtuple_values(member, predicate, mapper, memo) for member in attribute]","for e_target in zip(ntuple._fields, ntuple):
    attribute = e_target[1]
    attribute_name = e_target[0]
    if predicate(attribute):
        replacements[attribute_name] = mapper(attribute)
    elif type(attribute) is not tuple and isinstance(attribute, tuple):
        replacements[attribute_name] = replace_namedtuple_values(attribute, predicate, mapper, memo)
    elif type(attribute) in (list, tuple):
        replacements[attribute_name] = [replace_namedtuple_values(member, predicate, mapper, memo) for member in attribute]

",1,"[['https://github.com/beancount/beancount/tree/master/beancount/utils/misc_utils_test.py', 'beancount.utils.misc_utils_test', 'TestMiscUtils', 'test_replace_tuple_values']]"
beancount,https://github.com/beancount/beancount/tree/master/beancount/utils/file_utils.py,TestFileUtilsFind,test_find_files,"for (root, dirs, filenames) in os.walk(ford):
    dirs[:] = sorted((dirname for dirname in dirs if dirname not in ignore_dirs))
    for filename in sorted(filenames):
        if filename in ignore_files:
            continue
        yield path.join(root, filename)","for e_target in os.walk(ford):
    filenames = e_target[2]
    dirs = e_target[1]
    root = e_target[0]
    dirs[:] = sorted((dirname for dirname in dirs if dirname not in ignore_dirs))
    for filename in sorted(filenames):
        if filename in ignore_files:
            continue
        yield path.join(root, filename)

",1,"[['https://github.com/beancount/beancount/tree/master/beancount/utils/file_utils_test.py', 'beancount.utils.file_utils_test', 'TestFileUtilsFind', 'test_find_files']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/ast.py,,test_gather_load_store_names_tuple,"for (nid, ctx) in map(get_id_ctx, walk(node)):
    if nid is None:
        continue
    elif isinstance(ctx, Load):
        load.add(nid)
    else:
        store.add(nid)","for e_target in map(get_id_ctx, walk(node)):
    ctx = e_target[1]
    nid = e_target[0]
    if nid is None:
        continue
    elif isinstance(ctx, Load):
        load.add(nid)
    else:
        store.add(nid)

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_ast.py', 'tests.test_ast', '', 'test_gather_load_store_names_tuple']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/tools.py,,test_swap_values,"for (k, v) in old.items():
    if v is default and k in d:
        del d[k]
    else:
        d[k] = v","for e_target in old.items():
    v = e_target[1]
    k = e_target[0]
    if v is default and k in d:
        del d[k]
    else:
        d[k] = v

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_tools.py', 'tests.test_tools', '', 'test_swap_values']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/wizard.py,,test_tuple_store_and_write,"for (path, value) in sorted(flat.items()):
    (rule, func) = self.find_rule(path)
    if func is None:
        continue
    line = func(path, value)
    lines.append(line)","for e_target in sorted(flat.items()):
    value = e_target[1]
    path = e_target[0]
    (rule, func) = self.find_rule(path)
    if func is None:
        continue
    line = func(path, value)
    lines.append(line)

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_wizard.py', 'tests.test_wizard', '', 'test_tuple_store_and_write']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/wizard.py,,test_tuple_store_and_write,"for (p, n) in zip(path[:-1], path[1:]):
    if isinstance(p, str) and p not in loc:
        loc[p] = {} if isinstance(n, str) else []
    elif isinstance(p, int) and abs(p) + (p >= 0) > len(loc):
        i = abs(p) + (p >= 0) - len(loc)
        if isinstance(n, str):
            ex = [{} for _ in range(i)]
        else:
            ex = [[] for _ in range(i)]
        loc.extend(ex)
    loc = loc[p]","for e_target in zip(path[:-1], path[1:]):
    n = e_target[1]
    p = e_target[0]
    if isinstance(p, str) and p not in loc:
        loc[p] = {} if isinstance(n, str) else []
    elif isinstance(p, int) and abs(p) + (p >= 0) > len(loc):
        i = abs(p) + (p >= 0) - len(loc)
        if isinstance(n, str):
            ex = [{} for _ in range(i)]
        else:
            ex = [[] for _ in range(i)]
        loc.extend(ex)
    loc = loc[p]

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_wizard.py', 'tests.test_wizard', '', 'test_state_visitor_store'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_wizard.py', 'tests.test_wizard', '', 'test_tuple_store_and_write']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/environ.py,,test_env_detype_no_dict,"for (key, val) in self._d.items():
    if not isinstance(key, str):
        key = str(key)
    detyper = self.get_detyper(key)
    if detyper is None:
        continue
    deval = detyper(val)
    if deval is None:
        continue
    ctx[key] = deval","for e_target in self._d.items():
    val = e_target[1]
    key = e_target[0]
    if not isinstance(key, str):
        key = str(key)
    detyper = self.get_detyper(key)
    if detyper is None:
        continue
    deval = detyper(val)
    if deval is None:
        continue
    ctx[key] = deval

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_environ.py', 'tests.test_environ', '', 'test_env_detype'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_environ.py', 'tests.test_environ', '', 'test_env_detype_no_dict']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/built_ins.py,,test_call_macro_ast_exec_statement,"for ((key, param), raw_arg) in zip(sig.parameters.items(), raw_args):
    i += 1
    if raw_arg == '*':
        break
    kind = param.annotation
    if kind is empty or kind is None:
        kind = str
    arg = convert_macro_arg(raw_arg, kind, glbs, locs, name=key, macroname=macroname)
    args.append(arg)","for e_target in zip(sig.parameters.items(), raw_args):
    raw_arg = e_target[1]
    param = e_target[0][1]
    key = e_target[0][0]
    i += 1
    if raw_arg == '*':
        break
    kind = param.annotation
    if kind is empty or kind is None:
        kind = str
    arg = convert_macro_arg(raw_arg, kind, glbs, locs, name=key, macroname=macroname)
    args.append(arg)

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_builtins.py', 'tests.test_builtins', '', 'test_call_macro_ast_single_expr'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_builtins.py', 'tests.test_builtins', '', 'test_call_macro_ast_eval_expr'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_builtins.py', 'tests.test_builtins', '', 'test_call_macro_ast_exec_expr'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_builtins.py', 'tests.test_builtins', '', 'test_call_macro_ast_eval_statement'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_builtins.py', 'tests.test_builtins', '', 'test_call_macro_ast_single_statement'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_builtins.py', 'tests.test_builtins', '', 'test_call_macro_ast_exec_statement']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/foreign_shells.py,,test_parse_aliases,"for (key, value) in items:
    try:
        key = key[6:]
        value = value.replace(""'\\''"", ""'"")
        if value[0] == ""'"" and value[-1] == ""'"":
            value = value[1:-1]
        if FS_EXEC_ALIAS_RE.search(value) is None:
            value = shlex.split(value)
        else:
            value = ForeignShellExecAlias(src=value, shell=shell, sourcer=sourcer, files=files, extra_args=extra_args)
    except ValueError as exc:
        warnings.warn(f'could not parse alias ""{key}"": {exc!r}', RuntimeWarning)
        continue
    aliases[key] = value","for e_target in items:
    value = e_target[1]
    key = e_target[0]
    try:
        key = key[6:]
        value = value.replace(""'\\''"", ""'"")
        if value[0] == ""'"" and value[-1] == ""'"":
            value = value[1:-1]
        if FS_EXEC_ALIAS_RE.search(value) is None:
            value = shlex.split(value)
        else:
            value = ForeignShellExecAlias(src=value, shell=shell, sourcer=sourcer, files=files, extra_args=extra_args)
    except ValueError as exc:
        warnings.warn(f'could not parse alias ""{key}"": {exc!r}', RuntimeWarning)
        continue
    aliases[key] = value

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_foreign_shells.py', 'tests.test_foreign_shells', '', 'test_parse_aliases']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/aliases.py,,test_source_path,"for (i, fname) in enumerate(args):
    fpath = fname
    if not os.path.isfile(fpath):
        fpath = locate_binary(fname)
        if fpath is None:
            if env.get('XONSH_DEBUG'):
                print('source: {}: No such file'.format(fname), file=sys.stderr)
            if i == 0:
                raise RuntimeError('must source at least one file, ' + fname + ' does not exist.')
            break
    (_, fext) = os.path.splitext(fpath)
    if fext and fext != '.xsh' and (fext != '.py'):
        raise RuntimeError('attempting to source non-xonsh file! If you are trying to source a file in another language, then please use the appropriate source command. For example, source-bash script.sh')
    with open(fpath, 'r', encoding=encoding, errors=errors) as fp:
        src = fp.read()
    if not src.endswith('\n'):
        src += '\n'
    ctx = XSH.ctx
    updates = {'__file__': fpath, '__name__': os.path.abspath(fpath)}
    with env.swap(**make_args_env(args[i + 1:])), swap_values(ctx, updates):
        try:
            XSH.builtins.execx(src, 'exec', ctx, filename=fpath)
        except Exception:
            print_color('{RED}You may be attempting to source non-xonsh file! {RESET}If you are trying to source a file in another language, then please use the appropriate source command. For example, {GREEN}source-bash script.sh{RESET}', file=sys.stderr)
            raise","for e_target in enumerate(args):
    fname = e_target[1]
    i = e_target[0]
    fpath = fname
    if not os.path.isfile(fpath):
        fpath = locate_binary(fname)
        if fpath is None:
            if env.get('XONSH_DEBUG'):
                print('source: {}: No such file'.format(fname), file=sys.stderr)
            if i == 0:
                raise RuntimeError('must source at least one file, ' + fname + ' does not exist.')
            break
    (_, fext) = os.path.splitext(fpath)
    if fext and fext != '.xsh' and (fext != '.py'):
        raise RuntimeError('attempting to source non-xonsh file! If you are trying to source a file in another language, then please use the appropriate source command. For example, source-bash script.sh')
    with open(fpath, 'r', encoding=encoding, errors=errors) as fp:
        src = fp.read()
    if not src.endswith('\n'):
        src += '\n'
    ctx = XSH.ctx
    updates = {'__file__': fpath, '__name__': os.path.abspath(fpath)}
    with env.swap(**make_args_env(args[i + 1:])), swap_values(ctx, updates):
        try:
            XSH.builtins.execx(src, 'exec', ctx, filename=fpath)
        except Exception:
            print_color('{RED}You may be attempting to source non-xonsh file! {RESET}If you are trying to source a file in another language, then please use the appropriate source command. For example, {GREEN}source-bash script.sh{RESET}', file=sys.stderr)
            raise

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/aliases/test_source.py', 'tests.aliases.test_source', '', 'test_source_current_dir'], ['https://github.com/xonsh/xonsh/tree/master/tests/aliases/test_source.py', 'tests.aliases.test_source', '', 'test_source_path']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/procs/specs.py,,test_tracer_help,"for (i, cmd) in enumerate(cmds):
    if isinstance(cmd, str):
        redirects.append(cmd)
    else:
        env = envs[i] if envs is not None else None
        spec = SubprocSpec.build(cmd, captured=captured, env=env)
        spec.pipeline_index = i
        specs.append(spec)
        i += 1","for e_target in enumerate(cmds):
    cmd = e_target[1]
    i = e_target[0]
    if isinstance(cmd, str):
        redirects.append(cmd)
    else:
        env = envs[i] if envs is not None else None
        spec = SubprocSpec.build(cmd, captured=captured, env=env)
        spec.pipeline_index = i
        specs.append(spec)
        i += 1

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_tracer.py', 'tests.test_tracer', '', 'test_tracer_help']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/procs/specs.py,,test_tracer_help,"for (i, redirect) in enumerate(redirects):
    if redirect == '|':
        (r, w) = os.pipe()
        specs[i].stdout = w
        specs[i + 1].stdin = r
    elif redirect == '&' and i == len(redirects) - 1:
        specs[i].background = True
    else:
        raise xt.XonshError(f'unrecognized redirect {redirect!r}')","for e_target in enumerate(redirects):
    redirect = e_target[1]
    i = e_target[0]
    if redirect == '|':
        (r, w) = os.pipe()
        specs[i].stdout = w
        specs[i + 1].stdin = r
    elif redirect == '&' and i == len(redirects) - 1:
        specs[i].background = True
    else:
        raise xt.XonshError(f'unrecognized redirect {redirect!r}')

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_tracer.py', 'tests.test_tracer', '', 'test_tracer_help']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xontrib/voxapi.py,,test_path,"for (k, v) in type(self).oldvars.items():
    env[k] = v","for e_target in type(self).oldvars.items():
    v = e_target[1]
    k = e_target[0]
    env[k] = v

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_vox.py', 'tests.test_vox', '', 'test_activate_non_vox_venv'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_vox.py', 'tests.test_vox', '', 'test_activate'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_vox.py', 'tests.test_vox', '', 'test_path']]"
xonsh,https://github.com/xonsh/xonsh/tree/master/xontrib/bashisms.py,,test_recursive_callable_partial_handles,"for (alias, cmd) in XSH.aliases.items():
    print('{}={}'.format(alias, cmd))","for e_target in XSH.aliases.items():
    cmd = e_target[1]
    alias = e_target[0]
    print('{}={}'.format(alias, cmd))

",1,"[['https://github.com/xonsh/xonsh/tree/master/tests/test_aliases.py', 'tests.test_aliases', '', 'test_recursive_callable_partial_none'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_aliases.py', 'tests.test_aliases', '', 'test_recursive_callable_partial_all'], ['https://github.com/xonsh/xonsh/tree/master/tests/test_aliases.py', 'tests.test_aliases', '', 'test_recursive_callable_partial_handles']]"
nanovna-saver,https://github.com/NanoVNA-Saver/nanovna-saver/tree/master/NanoVNASaver/Touchstone.py,TestTouchstoneTouchstone,test_save,"for (i, dp_s11) in enumerate(self.s11data):
    ts_str += f'{dp_s11.freq} {dp_s11.re} {dp_s11.im}'
    for j in range(1, nr_params):
        dp = self.sdata[j][i]
        if dp.freq != dp_s11.freq:
            raise LookupError('Frequencies of sdata not correlated')
        ts_str += f' {dp.re} {dp.im}'
    ts_str += '\n'","for e_target in enumerate(self.s11data):
    dp_s11 = e_target[1]
    i = e_target[0]
    ts_str += f'{dp_s11.freq} {dp_s11.re} {dp_s11.im}'
    for j in range(1, nr_params):
        dp = self.sdata[j][i]
        if dp.freq != dp_s11.freq:
            raise LookupError('Frequencies of sdata not correlated')
        ts_str += f' {dp.re} {dp.im}'
    ts_str += '\n'

",1,"[['https://github.com/NanoVNA-Saver/nanovna-saver/tree/master/test/test_touchstone.py', 'test.test_touchstone', 'TestTouchstoneTouchstone', 'test_save']]"
couler,https://github.com/couler-proj/couler/tree/master/couler/core/utils.py,PyfuncTest,test_check_gpu,"for (k, v) in resources.items():
    if 'gpu' in k.strip().lower() and int(v) > 0:
        return True","for e_target in resources.items():
    v = e_target[1]
    k = e_target[0]
    if 'gpu' in k.strip().lower() and int(v) > 0:
        return True

",1,"[['https://github.com/couler-proj/couler/tree/master/couler/tests/utils_test.py', 'couler.tests.utils_test', 'PyfuncTest', 'test_check_gpu']]"
CTCDecoder,https://github.com/githubharald/CTCDecoder/tree/master/ctc_decoder/token_passing.py,,test_token_passing,"for (w_idx, w) in enumerate(label_words):
    w = label_words[w_idx]
    w_prime = prime_words[w_idx]
    for s in range(len(w_prime)):
        for t in range(max_T):
            toks.set(w_idx, s + 1, t + 1, Token())
            toks.set(w_idx, beg, t, Token())
            toks.set(w_idx, end, t, Token())
    toks.set(w_idx, 1, 1, Token(log(mat[1 - 1, blank_idx]), [w_idx]))
    c_idx = w[1 - 1]
    toks.set(w_idx, 2, 1, Token(log(mat[1 - 1, c_idx]), [w_idx]))
    if len(w) == 1:
        toks.set(w_idx, end, 1, toks.get(w_idx, 2, 1))","for e_target in enumerate(label_words):
    w = e_target[1]
    w_idx = e_target[0]
    w = label_words[w_idx]
    w_prime = prime_words[w_idx]
    for s in range(len(w_prime)):
        for t in range(max_T):
            toks.set(w_idx, s + 1, t + 1, Token())
            toks.set(w_idx, beg, t, Token())
            toks.set(w_idx, end, t, Token())
    toks.set(w_idx, 1, 1, Token(log(mat[1 - 1, blank_idx]), [w_idx]))
    c_idx = w[1 - 1]
    toks.set(w_idx, 2, 1, Token(log(mat[1 - 1, c_idx]), [w_idx]))
    if len(w) == 1:
        toks.set(w_idx, end, 1, toks.get(w_idx, 2, 1))

",1,"[['https://github.com/githubharald/CTCDecoder/tree/master/tests/test_mini_example.py', 'tests.test_mini_example', '', 'test_token_passing']]"
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/test/helper.py,TestInfoExtractor,test_parse_f4m_formats,"for (index, (item_got, item_expected)) in enumerate(zip(got, expected)):
    type_got = type(item_got)
    type_expected = type(item_expected)
    self.assertEqual(type_expected, type_got, 'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (index, field, type_expected, type_got))
    expect_value(self, item_got, item_expected, field)","for e_target in enumerate(zip(got, expected)):
    item_expected = e_target[1][1]
    item_got = e_target[1][0]
    index = e_target[0]
    type_got = type(item_got)
    type_expected = type(item_expected)
    self.assertEqual(type_expected, type_got, 'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (index, field, type_expected, type_got))
    expect_value(self, item_got, item_expected, field)

",1,"[['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_m3u8_formats'], ['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_youtube_chapters.py', 'test.test_youtube_chapters', 'TestYoutubeChapters', 'test_youtube_chapters'], ['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_xspf'], ['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_mpd_formats'], ['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_InfoExtractor.py', 'test.test_InfoExtractor', 'TestInfoExtractor', 'test_parse_f4m_formats']]"
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/utils.py,TestUtil,test_sanitize_url,"for (mistake, fixup) in COMMON_TYPOS:
    if re.match(mistake, url):
        return re.sub(mistake, fixup, url)","for e_target in COMMON_TYPOS:
    fixup = e_target[1]
    mistake = e_target[0]
    if re.match(mistake, url):
        return re.sub(mistake, fixup, url)

",1,"[['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_utils.py', 'test.test_utils', 'TestUtil', 'test_sanitize_url']]"
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/options.py,TestOptions,test_hide_login_info,"for (idx, opt) in enumerate(opts):
    if opt in PRIVATE_OPTS and idx + 1 < len(opts):
        opts[idx + 1] = 'PRIVATE'","for e_target in enumerate(opts):
    opt = e_target[1]
    idx = e_target[0]
    if opt in PRIVATE_OPTS and idx + 1 < len(opts):
        opts[idx + 1] = 'PRIVATE'

",1,"[['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_options.py', 'test.test_options', 'TestOptions', 'test_hide_login_info']]"
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/compat.py,TestUtil,test_update_url_query,"for (name, value) in pairs:
    if name in parsed_result:
        parsed_result[name].append(value)
    else:
        parsed_result[name] = [value]","for e_target in pairs:
    value = e_target[1]
    name = e_target[0]
    if name in parsed_result:
        parsed_result[name].append(value)
    else:
        parsed_result[name] = [value]

",1,"[['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_utils.py', 'test.test_utils', 'TestUtil', 'test_update_url_query']]"
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/youtube.py,TestYoutubeChapters,test_youtube_chapters,"for (next_num, (chapter_line, time_point)) in enumerate(chapter_lines, start=1):
    start_time = parse_duration(time_point)
    if start_time is None:
        continue
    if start_time > duration:
        break
    end_time = duration if next_num == len(chapter_lines) else parse_duration(chapter_lines[next_num][1])
    if end_time is None:
        continue
    if end_time > duration:
        end_time = duration
    if start_time > end_time:
        break
    chapter_title = re.sub('<a[^>]+>[^<]+</a>', '', chapter_line).strip(' \t-')
    chapter_title = re.sub('\\s+', ' ', chapter_title)
    chapters.append({'start_time': start_time, 'end_time': end_time, 'title': chapter_title})","for e_target in enumerate(chapter_lines, start=1):
    time_point = e_target[1][1]
    chapter_line = e_target[1][0]
    next_num = e_target[0]
    start_time = parse_duration(time_point)
    if start_time is None:
        continue
    if start_time > duration:
        break
    end_time = duration if next_num == len(chapter_lines) else parse_duration(chapter_lines[next_num][1])
    if end_time is None:
        continue
    if end_time > duration:
        end_time = duration
    if start_time > end_time:
        break
    chapter_title = re.sub('<a[^>]+>[^<]+</a>', '', chapter_line).strip(' \t-')
    chapter_title = re.sub('\\s+', ' ', chapter_title)
    chapters.append({'start_time': start_time, 'end_time': end_time, 'title': chapter_title})

",1,"[['https://github.com/scastillo/not-youtube-dl/tree/master/test/test_youtube_chapters.py', 'test.test_youtube_chapters', 'TestYoutubeChapters', 'test_youtube_chapters']]"
