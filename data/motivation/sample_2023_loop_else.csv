repo_name,file_html,cl,me,code,complicate_code,has_break,,
flask-admin,https://github.com/flask-admin/flask-admin/tree/master/flask_admin/contrib/sqla/form.py,InlineModelConverter,_calculate_mapping_key_pair$644,"for prop in mapper.iterate_properties:
    if hasattr(prop, 'direction') and prop.direction.name == candidate:
        if prop.mapper.class_ == target_mapper.class_:
            forward_prop = prop
            break
else:
    raise Exception('Cannot find forward relation for model %s' % info.model)","flag_else = 1

for prop in mapper.iterate_properties:
    if hasattr(prop, 'direction') and prop.direction.name == candidate:
        if prop.mapper.class_ == target_mapper.class_:
            forward_prop = prop
            flag_else = 0
            break
if flag_else:
    raise Exception('Cannot find forward relation for model %s' % info.model)",1,FALSE,
mutagen,https://github.com/quodlibet/mutagen/tree/master/mutagen/mp4/_atom.py,Atoms,__getitem__$174,"for child in self.atoms:
    if child.name == names[0]:
        return child[names[1:]]
else:
    raise KeyError('%r not found' % names[0])","for child in self.atoms:
    if child.name == names[0]:
        return child[names[1:]]

raise KeyError('%r not found' % names[0])
",0,TRUE,
veusz,https://github.com/veusz/veusz/tree/master/veusz/windows/mainwindow.py,MainWindow,definePlugins$378,"for c in menulook:
    if c[0] == name:
        menulook = c[2]
        break
else:
    menulook.append([name, cmpt, []])
    menulook = menulook[-1][2]","flag_else = 1

for c in menulook:
    if c[0] == name:
        menulook = c[2]
        flag_else = 0
        break
if flag_else:
    menulook.append([name, cmpt, []])
    menulook = menulook[-1][2]",1,FALSE,
github3.py,https://github.com/sigmavirus24/github3.py/tree/master/tests/integration/test_pulls.py,TestPullFile,get_pull_request_file$225,"for pull_file in p.files():
    if pull_file.filename == filename:
        break
else:
    assert False, f""Could not find '{filename}'""","flag_else = 1

for pull_file in p.files():
    if pull_file.filename == filename:
        flag_else = 0
        break
if flag_else:
    assert False, f""Could not find '{filename}'""",1,FALSE,
rope,https://github.com/python-rope/rope/tree/master/ropetest/refactor/patchedasttest.py,_ResultChecker,check_children$1390,"for goal in goals:
    if goal == '' or isinstance(child, basestring):
        self.test_case.assertEqual(goal, child)
        break
else:
    self.test_case.assertNotEqual('', text, 'probably ignoring some node')
    if sys.version_info >= (3, 8) and expected in ['Num', 'Str', 'NameConstant', 'Ellipsis']:
        expected = 'Constant'
    self.test_case.assertTrue(child.__class__.__name__.startswith(expected), msg='Expected <%s> but was <%s>' % (expected, child.__class__.__name__))","flag_else = 1

for goal in goals:
    if goal == '' or isinstance(child, basestring):
        self.test_case.assertEqual(goal, child)
        flag_else = 0
        break
if flag_else:
    self.test_case.assertNotEqual('', text, 'probably ignoring some node')
    if sys.version_info >= (3, 8) and expected in ['Num', 'Str', 'NameConstant', 'Ellipsis']:
        expected = 'Constant'
    self.test_case.assertTrue(child.__class__.__name__.startswith(expected), msg='Expected <%s> but was <%s>' % (expected, child.__class__.__name__))",1,FALSE,
pyOCD,https://github.com/pyocd/pyOCD/tree/master/pyocd/coresight/dap.py,DebugPort,power_down_debug$470,"while time_out.check():
    r = self.read_reg(DP_CTRL_STAT)
    if r & (CDBGPWRUPACK | CSYSPWRUPACK) == CDBGPWRUPACK:
        break
else:
    return False","flag_else = 1

while time_out.check():
    r = self.read_reg(DP_CTRL_STAT)
    if r & (CDBGPWRUPACK | CSYSPWRUPACK) == CDBGPWRUPACK:
        flag_else = 0
        break
if flag_else:
    return False",1,FALSE,
cobbler,https://github.com/cobbler/cobbler/tree/master/cobbler/modules/managers/import_signatures.py,_ImportSignatureManager,scan_signatures$274,"for line in vf_lines:
    if vf_re.match(line):
        break
else:
    continue","flag_else = 1

for line in vf_lines:
    if vf_re.match(line):
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
mindsdb,https://github.com/mindsdb/mindsdb/tree/master/tests/integration_tests/flows/test_redis.py,RedisTest,test_8_test_online_learning$225,"while time.time() - start_time < 300:
    time.sleep(5)
    res = list(stream_out.read())
    if res and res[0]['status'] == 'success':
        break
else:
    raise Exception('Create predictor timeout')","flag_else = 1

while time.time() - start_time < 300:
    time.sleep(5)
    res = list(stream_out.read())
    if res and res[0]['status'] == 'success':
        flag_else = 0
        break
if flag_else:
    raise Exception('Create predictor timeout')",1,FALSE,
slam-mirrorbot,https://github.com/breakdowns/slam-mirrorbot/tree/master/bot/helper/telegram_helper/filters.py,_MirrorOwner,filter$33,"for (message_id, status) in download_dict.items():
    if status.gid() == args[1] and status.message.from_user.id == user_id:
        return True
else:
    return False","for (message_id, status) in download_dict.items():
    if status.gid() == args[1] and status.message.from_user.id == user_id:
        return True

return False
",0,TRUE,
meshio,https://github.com/nschloe/meshio/tree/master/src/meshio/gmsh/common.py,,_fast_forward_to_end_block$12,"for line in f:
    try:
        line = line.decode()
    except UnicodeDecodeError:
        pass
    if line.strip() == f'$End{block}':
        break
else:
    logging.warning(f'${block} not closed by $End{block}.')","flag_else = 1

for line in f:
    try:
        line = line.decode()
    except UnicodeDecodeError:
        pass
    if line.strip() == f'$End{block}':
        flag_else = 0
        break
if flag_else:
    logging.warning(f'${block} not closed by $End{block}.')",1,FALSE,
tangent,https://github.com/google/tangent/tree/master/tangent/compile.py,,compile_function$70,"for succ in node.body:
    if isinstance(succ, gast.FunctionDef):
        name = succ.name
        break
else:
    raise ValueError('no function found')","flag_else = 1

for succ in node.body:
    if isinstance(succ, gast.FunctionDef):
        name = succ.name
        flag_else = 0
        break
if flag_else:
    raise ValueError('no function found')",1,FALSE,
stash,https://github.com/ywangd/stash/tree/master/bin/pip.py,PyPIRepository,_determin_hit$1318,"for hit in versions:
    if flags is not None and (not self._dist_flags_allows_release(flags, pkg_data, hit)):
        continue
    if not self._release_matches_py_version(pkg_data, hit):
        continue
    if ver_spec is None or ver_spec.match(hit):
        return hit
else:
    raise PipError('Version not found: {}{}'.format(pkg_name, ver_spec if ver_spec is not None else ''))","for hit in versions:
    if flags is not None and (not self._dist_flags_allows_release(flags, pkg_data, hit)):
        continue
    if not self._release_matches_py_version(pkg_data, hit):
        continue
    if ver_spec is None or ver_spec.match(hit):
        return hit

raise PipError('Version not found: {}{}'.format(pkg_name, ver_spec if ver_spec is not None else ''))
",0,TRUE,
Stino,https://github.com/Robot-Will/Stino/tree/master/libs/serial/rfc2217.py,Serial,get_modem_state$889,"while not timeout.expired():
    time.sleep(0.05)
    if not self._modemstate_timeout.expired():
        break
else:
    if self.logger:
        self.logger.warning('poll for modem state failed')","flag_else = 1

while not timeout.expired():
    time.sleep(0.05)
    if not self._modemstate_timeout.expired():
        flag_else = 0
        break
if flag_else:
    if self.logger:
        self.logger.warning('poll for modem state failed')",1,FALSE,
RsaCtfTool,https://github.com/Ganapati/RsaCtfTool/tree/master/lib/rsalibnum.py,,miller_rabin$110,"while j <= r - 1:
    x = pow(x, 2, n)
    if x == n - 1:
        break
    j += 1
else:
    return False","flag_else = 1

while j <= r - 1:
    x = pow(x, 2, n)
    if x == n - 1:
        flag_else = 0
        break
    j += 1
if flag_else:
    return False",1,FALSE,
ssr-command-client,https://github.com/TyrantLucifer/ssr-command-client/tree/master/shadowsocksr_cli/shadowsocks/crypto/ctypes_openssl.py,,load_openssl$40,"for p in ('crypto', 'eay32', 'libeay32'):
    libcrypto_path = find_library(p)
    if libcrypto_path:
        break
else:
    raise Exception('libcrypto(OpenSSL) not found')","flag_else = 1

for p in ('crypto', 'eay32', 'libeay32'):
    libcrypto_path = find_library(p)
    if libcrypto_path:
        flag_else = 0
        break
if flag_else:
    raise Exception('libcrypto(OpenSSL) not found')",1,FALSE,
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/ply/ply/yacc.py,LRGeneratedTable,compute_lookback_includes$2374,"while li < p.len:
    if p.prod[li] in self.grammar.Terminals:
        break
    if p.prod[li] not in nullable:
        break
    li = li + 1
else:
    includes.append((j, t))","flag_else = 1

while li < p.len:
    if p.prod[li] in self.grammar.Terminals:
        flag_else = 0
        break
    if p.prod[li] not in nullable:
        flag_else = 0
        break
    li = li + 1
if flag_else:
    includes.append((j, t))",2,FALSE,
meld,https://github.com/GNOME/meld/tree/master/meld/ui/gtkcompat.py,,append_element$31,"for (class_name, class_state) in pseudo_classes:
    if name == class_name:
        path.iter_set_state(-1, path.iter_get_state(-1) | class_state)
        break
else:
    log.error('Unknown pseudo-class :%s', name)
    pass","flag_else = 1

for (class_name, class_state) in pseudo_classes:
    if name == class_name:
        path.iter_set_state(-1, path.iter_get_state(-1) | class_state)
        flag_else = 0
        break
if flag_else:
    log.error('Unknown pseudo-class :%s', name)
    pass",1,FALSE,
angr,https://github.com/angr/angr/tree/master/angr/sim_type.py,SimCppClassValue,__getitem__$1444,"for f in self._class.fields:
    if isinstance(f, NamedTypeMixin) and f.name is None:
        try:
            return f[k]
        except:
            continue
else:
    return self._values[k]","for f in self._class.fields:
    if isinstance(f, NamedTypeMixin) and f.name is None:
        try:
            return f[k]
        except:
            continue

return self._values[k]
",0,TRUE,
virtualenv,https://github.com/pypa/virtualenv/tree/master/src/virtualenv/discovery/py_info.py,PythonInfo,_check_exe$458,"for item in ['implementation', 'architecture', 'version_info']:
    found = getattr(info, item)
    searched = getattr(self, item)
    if found != searched:
        if item == 'version_info':
            (found, searched) = ('.'.join((str(i) for i in found)), '.'.join((str(i) for i in searched)))
        executable = info.executable
        logging.debug('refused interpreter %s because %s differs %s != %s', executable, item, found, searched)
        if exact is False:
            discovered.append(info)
        break
else:
    return info","flag_else = 1

for item in ['implementation', 'architecture', 'version_info']:
    found = getattr(info, item)
    searched = getattr(self, item)
    if found != searched:
        if item == 'version_info':
            (found, searched) = ('.'.join((str(i) for i in found)), '.'.join((str(i) for i in searched)))
        executable = info.executable
        logging.debug('refused interpreter %s because %s differs %s != %s', executable, item, found, searched)
        if exact is False:
            discovered.append(info)
        flag_else = 0
        break
if flag_else:
    return info",1,FALSE,
llvmlite,https://github.com/numba/llvmlite/tree/master//versioneer.py,,run_command$305,"for c in commands:
    try:
        p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % args[0])
            print(e)
        return None
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return None","flag_else = 1

for c in commands:
    try:
        p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % args[0])
            print(e)
        return None
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return None",1,FALSE,
ansible-modules-core,https://github.com/ansible/ansible-modules-core/tree/master/network/nxos/nxos_evpn_global.py,CustomNetworkConfig,add$133,"for child in ancestors[-1].children:
    if child.text == line:
        break
else:
    offset = len(parents) * self.indent
    item = ConfigLine(line)
    item.raw = line.rjust(len(line) + offset)
    item.parents = ancestors
    ancestors[-1].children.append(item)
    self.items.append(item)","flag_else = 1

for child in ancestors[-1].children:
    if child.text == line:
        flag_else = 0
        break
if flag_else:
    offset = len(parents) * self.indent
    item = ConfigLine(line)
    item.raw = line.rjust(len(line) + offset)
    item.parents = ancestors
    ancestors[-1].children.append(item)
    self.items.append(item)",1,FALSE,
checkmk,https://github.com/tribe29/checkmk/tree/master/cmk/base/plugins/agent_based/winperf_if.py,,_normalize_name$375,"for n in names:
    if from_token in n:
        break
else:
    mod_name = mod_name.replace(from_token, to_token).replace('  ', ' ')","flag_else = 1

for n in names:
    if from_token in n:
        flag_else = 0
        break
if flag_else:
    mod_name = mod_name.replace(from_token, to_token).replace('  ', ' ')",1,FALSE,
DDParser,https://github.com/baidu/DDParser/tree/master/ddparser/parser/data_struct/data.py,SequentialSampler,__iter__$140,"for i in range(self.corpus_length):
    batch.append(i)
    if len(batch) == self.batch_size:
        yield batch
        batch = []
else:
    if len(batch):
        yield batch","for i in range(self.corpus_length):
    batch.append(i)
    if len(batch) == self.batch_size:
        yield batch
        batch = []

if len(batch):
    yield batch
",0,TRUE,
openage,https://github.com/SFTtech/openage/tree/master/openage/convert/processor/conversion/aoc/ability_subprocessor.py,AoCAbilitySubprocessor,idle_ability$4036,"for (set_id, items) in gset_lookup_dict.items():
    if civ_id in items[0]:
        graphics_set_id = set_id
        break
else:
    raise Exception(f'No graphics set found for civ id {civ_id}')","flag_else = 1

for (set_id, items) in gset_lookup_dict.items():
    if civ_id in items[0]:
        graphics_set_id = set_id
        flag_else = 0
        break
if flag_else:
    raise Exception(f'No graphics set found for civ id {civ_id}')",1,FALSE,
indico,https://github.com/indico/indico/tree/master/indico/util/decorators.py,cached_classproperty,__get__$29,"for mrotype in objtype.__mro__:
    try:
        value = object.__getattribute__(mrotype, name)
    except AttributeError:
        pass
    else:
        break
else:
    raise AttributeError(name)","flag_else = 1

for mrotype in objtype.__mro__:
    try:
        value = object.__getattribute__(mrotype, name)
    except AttributeError:
        pass
    else:
        flag_else = 0
        break
if flag_else:
    raise AttributeError(name)",1,FALSE,
vispy,https://github.com/vispy/vispy/tree/master/codegen/annotations.py,FunctionAnnotation,is_arg_set$640,"for (line, comment) in self.lines:
    if line.startswith(needle):
        return True
else:
    return False","for (line, comment) in self.lines:
    if line.startswith(needle):
        return True

return False
",0,TRUE,
nova,https://github.com/openstack/nova/tree/master/nova/virt/libvirt/driver.py,LibvirtDriver,_volume_snapshot_delete$3480,"for guest_disk in device_info.devices:
    if guest_disk.root_name != 'disk':
        continue
    if guest_disk.target_dev is None or guest_disk.serial is None:
        continue
    if guest_disk.source_path is None and guest_disk.source_protocol is None:
        continue
    if guest_disk.serial == volume_id:
        my_dev = guest_disk.target_dev
        active_protocol = guest_disk.source_protocol
        active_disk_object = guest_disk
        break
else:
    LOG.debug('Domain XML: %s', xml, instance=instance)
    msg = _(""Disk with id '%s' not found attached to instance."") % volume_id
    raise exception.InternalError(msg)","flag_else = 1

for guest_disk in device_info.devices:
    if guest_disk.root_name != 'disk':
        continue
    if guest_disk.target_dev is None or guest_disk.serial is None:
        continue
    if guest_disk.source_path is None and guest_disk.source_protocol is None:
        continue
    if guest_disk.serial == volume_id:
        my_dev = guest_disk.target_dev
        active_protocol = guest_disk.source_protocol
        active_disk_object = guest_disk
        flag_else = 0
        break
if flag_else:
    LOG.debug('Domain XML: %s', xml, instance=instance)
    msg = _(""Disk with id '%s' not found attached to instance."") % volume_id
    raise exception.InternalError(msg)",1,FALSE,
backtesting.py,https://github.com/kernc/backtesting.py/tree/master/backtesting/lib.py,,resample_apply$201,"while frame and level <= 3:
    frame = frame.f_back
    level += 1
    if isinstance(frame.f_locals.get('self'), Strategy):
        strategy_I = frame.f_locals['self'].I
        break
else:

    def strategy_I(func, *args, **kwargs):
        return func(*args, **kwargs)","flag_else = 1

while frame and level <= 3:
    frame = frame.f_back
    level += 1
    if isinstance(frame.f_locals.get('self'), Strategy):
        strategy_I = frame.f_locals['self'].I
        flag_else = 0
        break
if flag_else:

    def strategy_I(func, *args, **kwargs):
        return func(*args, **kwargs)",1,FALSE,
pyshp,https://github.com/GeospatialPython/pyshp/tree/master//shapefile.py,Shape,__geo_interface__$484,"for part in self.parts:
    if ps == None:
        ps = part
        continue
    else:
        coordinates.append([tuple(p) for p in self.points[ps:part]])
        ps = part
else:
    coordinates.append([tuple(p) for p in self.points[part:]])","for part in self.parts:
    if ps == None:
        ps = part
        continue
    else:
        coordinates.append([tuple(p) for p in self.points[ps:part]])
        ps = part

coordinates.append([tuple(p) for p in self.points[part:]])
",0,TRUE,
DDNS,https://github.com/NewFuture/DDNS/tree/master/dns/cloudflare.py,,get_records$92,"for (k, value) in conditions.items():
    if record.get(k) != value:
        break
else:
    records[zid] = record","flag_else = 1

for (k, value) in conditions.items():
    if record.get(k) != value:
        flag_else = 0
        break
if flag_else:
    records[zid] = record",1,FALSE,
Hitomi-Downloader,https://github.com/KurtBestor/Hitomi-Downloader/tree/master/src/extractor/youtube_downloader.py,Downloader_youtube,read$380,"while videos:
    video = videos[0]
    try:
        video.url()
        break
    except Exception as e:
        e_ = e
        self.print_(print_error(e)[0])
        videos.remove(video)
else:
    raise e_","flag_else = 1

while videos:
    video = videos[0]
    try:
        video.url()
        flag_else = 0
        break
    except Exception as e:
        e_ = e
        self.print_(print_error(e)[0])
        videos.remove(video)
if flag_else:
    raise e_",1,FALSE,
CompilerGym,https://github.com/facebookresearch/CompilerGym/tree/master/tests/fuzzing/llvm_fork_env_fuzz_test.py,,test_fuzz$21,"for _ in range(PRE_FORK_ACTIONS):
    (_, _, done, _) = env.step(env.action_space.sample())
    if done:
        break
else:
    fkd = env.fork()
    try:
        print(env.state)
        assert env.state == fkd.state
        for _ in range(POST_FORK_ACTIONS):
            action = env.action_space.sample()
            (observation_a, reward_a, done_a, _) = env.step(action)
            (observation_b, reward_b, done_b, _) = fkd.step(action)
            print(env.state)
            assert done_a == done_b
            np.testing.assert_array_almost_equal(observation_a, observation_b)
            if reward_a != reward_b:
                pytest.fail(f'Parent environment produced reward {reward_a}, fork produced reward {reward_b}')
            if done_a:
                break
            assert env.state == fkd.state
    finally:
        fkd.close()","flag_else = 1

for _ in range(PRE_FORK_ACTIONS):
    (_, _, done, _) = env.step(env.action_space.sample())
    if done:
        flag_else = 0
        break
if flag_else:
    fkd = env.fork()
    try:
        print(env.state)
        assert env.state == fkd.state
        for _ in range(POST_FORK_ACTIONS):
            action = env.action_space.sample()
            (observation_a, reward_a, done_a, _) = env.step(action)
            (observation_b, reward_b, done_b, _) = fkd.step(action)
            print(env.state)
            assert done_a == done_b
            np.testing.assert_array_almost_equal(observation_a, observation_b)
            if reward_a != reward_b:
                pytest.fail(f'Parent environment produced reward {reward_a}, fork produced reward {reward_b}')
            if done_a:
                break
            assert env.state == fkd.state
    finally:
        fkd.close()",1,FALSE,
pywikibot,https://github.com/wikimedia/pywikibot/tree/master/tests/site_tests.py,SiteSysopTestCase,test_alldeletedrevisions$1977,"for data in gen:
    break
else:
    self.skipTest('{} does not have deleted edits.'.format(myuser))","flag_else = 1

for data in gen:
    flag_else = 0
    break
if flag_else:
    self.skipTest('{} does not have deleted edits.'.format(myuser))",1,FALSE,
KiKit,https://github.com/yaqwsx/KiKit/tree/master/kikit/_version.py,,run_command$70,"for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)","flag_else = 1

for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)",1,FALSE,
bpytop,https://github.com/aristocratos/bpytop/tree/master//bpytop.py,MemCollector,_collect$3268,"for names in io_counters:
    if names in dev_name:
        disk_io = io_counters[names]
        break
else:
    if cls.diskutil_map:
        for (names, items) in cls.diskutil_map.items():
            if items in dev_name and names in io_counters:
                disk_io = io_counters[names]","flag_else = 1

for names in io_counters:
    if names in dev_name:
        disk_io = io_counters[names]
        flag_else = 0
        break
if flag_else:
    if cls.diskutil_map:
        for (names, items) in cls.diskutil_map.items():
            if items in dev_name and names in io_counters:
                disk_io = io_counters[names]",1,FALSE,
gallery-dl,https://github.com/mikf/gallery-dl/tree/master/gallery_dl/extractor/oauth.py,OAuthMastodon,items$318,"for application in mastodon.INSTANCES.values():
    if self.instance == application['root'].partition('://')[2]:
        break
else:
    application = self._register(self.instance)","flag_else = 1

for application in mastodon.INSTANCES.values():
    if self.instance == application['root'].partition('://')[2]:
        flag_else = 0
        break
if flag_else:
    application = self._register(self.instance)",1,FALSE,
moto,https://github.com/spulec/moto/tree/master/moto/sqs/models.py,Queue,_setup_dlq$334,"for queue in sqs_backends[self.region].queues.values():
    if queue.queue_arn == self.redrive_policy['deadLetterTargetArn']:
        self.dead_letter_queue = queue
        if self.fifo_queue and (not queue.fifo_queue):
            raise RESTError('InvalidParameterCombination', 'Fifo queues cannot use non fifo dead letter queues')
        break
else:
    raise RESTError('AWS.SimpleQueueService.NonExistentQueue', 'Could not find DLQ for {0}'.format(self.redrive_policy['deadLetterTargetArn']))","flag_else = 1

for queue in sqs_backends[self.region].queues.values():
    if queue.queue_arn == self.redrive_policy['deadLetterTargetArn']:
        self.dead_letter_queue = queue
        if self.fifo_queue and (not queue.fifo_queue):
            raise RESTError('InvalidParameterCombination', 'Fifo queues cannot use non fifo dead letter queues')
        flag_else = 0
        break
if flag_else:
    raise RESTError('AWS.SimpleQueueService.NonExistentQueue', 'Could not find DLQ for {0}'.format(self.redrive_policy['deadLetterTargetArn']))",1,FALSE,
celery,https://github.com/celery/celery/tree/master/t/unit/worker/test_strategy.py,test_default_strategy_proto2,test_log_task_received_custom$183,"for record in caplog.records:
    if record.msg == custom_fmt:
        assert set(record.args) == {'id', 'name', 'kwargs', 'args'}
        break
else:
    raise ValueError('Expected message not in captured log records')","flag_else = 1

for record in caplog.records:
    if record.msg == custom_fmt:
        assert set(record.args) == {'id', 'name', 'kwargs', 'args'}
        flag_else = 0
        break
if flag_else:
    raise ValueError('Expected message not in captured log records')",1,FALSE,
integrations-core,https://github.com/DataDog/integrations-core/tree/master/datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/imports.py,,imports$61,"for check_name in checks:
    validation_fails = {}
    echo_debug(f'Checking {check_name}')
    for fpath in get_check_files(check_name):
        (success, lines) = validate_import(fpath, check_name, autofix)
        if not success:
            failed = True
            validation_fails[fpath] = lines
    if validation_fails:
        num_files = len(validation_fails)
        num_failures = sum((len(lines) for lines in validation_fails.values()))
        header_message = f'\nValidation failed: {num_failures} deprecated imports found in {num_files} files:\n'
        echo_failure(header_message)
        for (f, lines) in validation_fails.items():
            for line in lines:
                (linenum, linetext) = line
                echo_warning(f'{f}: line # {linenum + 1}', indent='  ')
                echo_info(f'{linetext}', indent='    ')
                message = 'Detected deprecated import: `{}`, run ""ddev validate imports --autofix"" to fix.'.format(linetext.strip('\n'))
                annotate_error(f, message, line=linenum + 1)
    if failed:
        abort()
else:
    echo_success('Validation passed!')","for check_name in checks:
    validation_fails = {}
    echo_debug(f'Checking {check_name}')
    for fpath in get_check_files(check_name):
        (success, lines) = validate_import(fpath, check_name, autofix)
        if not success:
            failed = True
            validation_fails[fpath] = lines
    if validation_fails:
        num_files = len(validation_fails)
        num_failures = sum((len(lines) for lines in validation_fails.values()))
        header_message = f'\nValidation failed: {num_failures} deprecated imports found in {num_files} files:\n'
        echo_failure(header_message)
        for (f, lines) in validation_fails.items():
            for line in lines:
                (linenum, linetext) = line
                echo_warning(f'{f}: line # {linenum + 1}', indent='  ')
                echo_info(f'{linetext}', indent='    ')
                message = 'Detected deprecated import: `{}`, run ""ddev validate imports --autofix"" to fix.'.format(linetext.strip('\n'))
                annotate_error(f, message, line=linenum + 1)
    if failed:
        abort()

echo_success('Validation passed!')
",0,TRUE,
espnet,https://github.com/espnet/espnet/tree/master/espnet2/utils/config_argparse.py,ArgumentParser,parse_known_args$24,"for action in self._actions:
    if key == action.dest:
        break
else:
    self.error(f'unrecognized arguments: {key} (from {_args.config})')","flag_else = 1

for action in self._actions:
    if key == action.dest:
        flag_else = 0
        break
if flag_else:
    self.error(f'unrecognized arguments: {key} (from {_args.config})')",1,FALSE,
pyload,https://github.com/pyload/pyload/tree/master/src/pyload/plugins/accounts/ExtmatrixCom.py,ExtmatrixCom,signin$42,"for i in range(5):
    m = re.search('<img src=""(.+?captcha\\.php.+?)""', html)
    if m is None:
        self.fail_login('Captcha pattern not found')
    captcha_url = urllib.parse.urljoin('https://www.extmatrix.com/', m.group(1))
    self.captcha = BaseCaptcha(pyfile)
    captcha_response = self.captcha.decrypt(captcha_url)
    html = self.load('https://www.extmatrix.com/login.php', post={'user': user, 'pass': password, 'submit': 'Login', 'task': 'dologin', 'return=': './members/myfiles.php', 'captcha': captcha_response})
    if 'Incorrect captcha code' in html:
        self.captcha.invalid()
    else:
        self.captcha.correct()
        break
else:
    self.fail_login(self._('Max captcha retries reached'))","flag_else = 1

for i in range(5):
    m = re.search('<img src=""(.+?captcha\\.php.+?)""', html)
    if m is None:
        self.fail_login('Captcha pattern not found')
    captcha_url = urllib.parse.urljoin('https://www.extmatrix.com/', m.group(1))
    self.captcha = BaseCaptcha(pyfile)
    captcha_response = self.captcha.decrypt(captcha_url)
    html = self.load('https://www.extmatrix.com/login.php', post={'user': user, 'pass': password, 'submit': 'Login', 'task': 'dologin', 'return=': './members/myfiles.php', 'captcha': captcha_response})
    if 'Incorrect captcha code' in html:
        self.captcha.invalid()
    else:
        self.captcha.correct()
        flag_else = 0
        break
if flag_else:
    self.fail_login(self._('Max captcha retries reached'))",1,FALSE,
nvda,https://github.com/nvaccess/nvda/tree/master/appveyor/mozillaSyms.py,,upload$83,"for i in range(7):
    if i > 0:
        print('Sleeping for 15 seconds before next attempt.')
        import time
        time.sleep(15)
    try:
        r = requests.post(URL, files={'symbols.zip': open(ZIP_FILE, 'rb')}, headers={'Auth-Token': os.getenv('mozillaSymsAuthToken')}, allow_redirects=False)
        break
    except Exception as e:
        print(f'Attempt {i + 1} failed: {e!r}')
        errors.append(repr(e))
else:
    allErrors = '\n'.join((f'Attempt {index + 1} error: \n{e}' for (index, e) in enumerate(errors)))
    raise RuntimeError(allErrors)","flag_else = 1

for i in range(7):
    if i > 0:
        print('Sleeping for 15 seconds before next attempt.')
        import time
        time.sleep(15)
    try:
        r = requests.post(URL, files={'symbols.zip': open(ZIP_FILE, 'rb')}, headers={'Auth-Token': os.getenv('mozillaSymsAuthToken')}, allow_redirects=False)
        flag_else = 0
        break
    except Exception as e:
        print(f'Attempt {i + 1} failed: {e!r}')
        errors.append(repr(e))
if flag_else:
    allErrors = '\n'.join((f'Attempt {index + 1} error: \n{e}' for (index, e) in enumerate(errors)))
    raise RuntimeError(allErrors)",1,FALSE,
klein,https://github.com/twisted/klein/tree/master/src/klein/_app.py,Klein,__get__$252,"for name in dir(owner):
    obj = getattr(owner, name, None)
    if obj is self:
        self._boundAs = name
        break
else:
    self._boundAs = 'unknown_' + str(id(self))","flag_else = 1

for name in dir(owner):
    obj = getattr(owner, name, None)
    if obj is self:
        self._boundAs = name
        flag_else = 0
        break
if flag_else:
    self._boundAs = 'unknown_' + str(id(self))",1,FALSE,
angr-doc,https://github.com/angr/angr-doc/tree/master/examples/insomnihack_aeg/solve.py,,main$55,"for buf_addr in find_symbolic_buffer(ep, len(shellcode)):
    l.info('found symbolic buffer at %#x', buf_addr)
    memory = ep.memory.load(buf_addr, len(shellcode))
    sc_bvv = ep.solver.BVV(shellcode)
    if ep.satisfiable(extra_constraints=(memory == sc_bvv, ep.regs.pc == buf_addr)):
        l.info('found buffer for shellcode, completing exploit')
        ep.add_constraints(memory == sc_bvv)
        l.info('pointing pc towards shellcode buffer')
        ep.add_constraints(ep.regs.pc == buf_addr)
        break
else:
    l.warning(""couldn't find a symbolic buffer for our shellcode! exiting..."")
    return 1","flag_else = 1

for buf_addr in find_symbolic_buffer(ep, len(shellcode)):
    l.info('found symbolic buffer at %#x', buf_addr)
    memory = ep.memory.load(buf_addr, len(shellcode))
    sc_bvv = ep.solver.BVV(shellcode)
    if ep.satisfiable(extra_constraints=(memory == sc_bvv, ep.regs.pc == buf_addr)):
        l.info('found buffer for shellcode, completing exploit')
        ep.add_constraints(memory == sc_bvv)
        l.info('pointing pc towards shellcode buffer')
        ep.add_constraints(ep.regs.pc == buf_addr)
        flag_else = 0
        break
if flag_else:
    l.warning(""couldn't find a symbolic buffer for our shellcode! exiting..."")
    return 1",1,FALSE,
pycparser,https://github.com/eliben/pycparser/tree/master/pycparser/ply/yacc.py,LRGeneratedTable,compute_nullable_nonterminals$2254,"for t in p.prod:
    if t not in nullable:
        break
else:
    nullable.add(p.name)","flag_else = 1

for t in p.prod:
    if t not in nullable:
        flag_else = 0
        break
if flag_else:
    nullable.add(p.name)",1,FALSE,
pyrogram,https://github.com/pyrogram/pyrogram/tree/master/compiler/docs/compiler.py,,build$45,"for node in ast.walk(p):
    if isinstance(node, ast.ClassDef):
        name = node.name
        break
else:
    continue","flag_else = 1

for node in ast.walk(p):
    if isinstance(node, ast.ClassDef):
        name = node.name
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
nltk,https://github.com/nltk/nltk/tree/master/nltk/draw/util.py,SymbolWidget,symbolsheet$892,"for (k, v) in list(SymbolWidget.SYMBOLS.items()):
    if v == chr(i):
        text.insert('end', '%-10s\t' % k)
        break
else:
    text.insert('end', '%-10d  \t' % i)","flag_else = 1

for (k, v) in list(SymbolWidget.SYMBOLS.items()):
    if v == chr(i):
        text.insert('end', '%-10s\t' % k)
        flag_else = 0
        break
if flag_else:
    text.insert('end', '%-10d  \t' % i)",1,FALSE,
sfepy,https://github.com/sfepy/sfepy/tree/master/sfepy/discrete/fem/fields_base.py,VolumeField,_setup_geometry$1139,"for (key, gel) in six.iteritems(self.domain.geom_els):
    ct = cmesh.cell_types
    if (ct[self.region.cells] == cmesh.key_to_index[gel.name]).all():
        self.gel = gel
        break
else:
    raise ValueError('region %s of field %s contains multiple reference geometries!' % (self.region.name, self.name))","flag_else = 1

for (key, gel) in six.iteritems(self.domain.geom_els):
    ct = cmesh.cell_types
    if (ct[self.region.cells] == cmesh.key_to_index[gel.name]).all():
        self.gel = gel
        flag_else = 0
        break
if flag_else:
    raise ValueError('region %s of field %s contains multiple reference geometries!' % (self.region.name, self.name))",1,FALSE,
nvda,https://github.com/nvaccess/nvda/tree/master/source/vision/visionHandler.py,,_getProviderClass$28,"for (loader, name, isPkg) in pkgutil.iter_modules(visionEnhancementProviders.__path__):
    if name.startswith('_') or name.lower() != moduleName.lower():
        continue
    return importlib.import_module('visionEnhancementProviders.%s' % name, package='visionEnhancementProviders').VisionEnhancementProvider
else:
    raise initialException","for (loader, name, isPkg) in pkgutil.iter_modules(visionEnhancementProviders.__path__):
    if name.startswith('_') or name.lower() != moduleName.lower():
        continue
    return importlib.import_module('visionEnhancementProviders.%s' % name, package='visionEnhancementProviders').VisionEnhancementProvider

raise initialException
",0,TRUE,
attic,https://github.com/jborg/attic/tree/master/attic/archive.py,RobustUnpacker,__next__$493,"for pattern in self.item_keys:
    if data[1:].startswith(pattern):
        break
else:
    data = data[1:]
    continue","flag_else = 1

for pattern in self.item_keys:
    if data[1:].startswith(pattern):
        flag_else = 0
        break
if flag_else:
    data = data[1:]
    continue",1,FALSE,
highway-env,https://github.com/eleurent/highway-env/tree/master/highway_env/envs/racetrack_env.py,RacetrackEnv,_make_vehicles$176,"for v in self.road.vehicles:
    if np.linalg.norm(vehicle.position - v.position) < 20:
        break
else:
    self.road.vehicles.append(vehicle)","flag_else = 1

for v in self.road.vehicles:
    if np.linalg.norm(vehicle.position - v.position) < 20:
        flag_else = 0
        break
if flag_else:
    self.road.vehicles.append(vehicle)",1,FALSE,
Montreal-Forced-Aligner,https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/tree/master/montreal_forced_aligner/models.py,DictionaryModel,__init__$910,"for (phone_set, pattern) in patterns.items():
    if pattern.search(line):
        counts[phone_set] += 1
        break
else:
    counts[PhoneSetType.UNKNOWN] += 1
    continue","flag_else = 1

for (phone_set, pattern) in patterns.items():
    if pattern.search(line):
        counts[phone_set] += 1
        flag_else = 0
        break
if flag_else:
    counts[PhoneSetType.UNKNOWN] += 1
    continue",1,FALSE,
keystone,https://github.com/openstack/keystone/tree/master/keystone/tests/unit/test_v3_auth.py,TestTokenRevokeApi,assertEventDataInList$3656,"for (key, value) in kwargs.items():
    try:
        if e[key] != value:
            break
    except KeyError:
        break
else:
    found = True","flag_else = 1

for (key, value) in kwargs.items():
    try:
        if e[key] != value:
            flag_else = 0
            break
    except KeyError:
        flag_else = 0
        break
if flag_else:
    found = True",2,FALSE,
swift,https://github.com/openstack/swift/tree/master/test/functional/test_symlink.py,TestSymlinkToSloSegments,test_slo_container_listing$1719,"for f_dict in listing:
    if f_dict['name'] == file_item.name:
        self.assertEqual(1024 * 1024, f_dict['bytes'])
        self.assertEqual('application/octet-stream', f_dict['content_type'])
        if tf.cluster_info.get('etag_quoter', {}).get('enable_by_default'):
            self.assertEqual(manifest_etag, '""%s""' % f_dict['hash'])
        else:
            self.assertEqual(manifest_etag, f_dict['hash'])
        self.assertEqual(slo_etag, f_dict['slo_etag'])
        break
else:
    self.fail('Failed to find manifest file in container listing')","flag_else = 1

for f_dict in listing:
    if f_dict['name'] == file_item.name:
        self.assertEqual(1024 * 1024, f_dict['bytes'])
        self.assertEqual('application/octet-stream', f_dict['content_type'])
        if tf.cluster_info.get('etag_quoter', {}).get('enable_by_default'):
            self.assertEqual(manifest_etag, '""%s""' % f_dict['hash'])
        else:
            self.assertEqual(manifest_etag, f_dict['hash'])
        self.assertEqual(slo_etag, f_dict['slo_etag'])
        flag_else = 0
        break
if flag_else:
    self.fail('Failed to find manifest file in container listing')",1,FALSE,
Hitomi-Downloader,https://github.com/KurtBestor/Hitomi-Downloader/tree/master/src/extractor/manatoki_downloader.py,Downloader_manatoki,init$55,"for (i, page) in enumerate(get_pages(url_page, self.soup)):
    if page.id == int(op['value']):
        break
else:
    raise Exception('can not find page')","flag_else = 1

for (i, page) in enumerate(get_pages(url_page, self.soup)):
    if page.id == int(op['value']):
        flag_else = 0
        break
if flag_else:
    raise Exception('can not find page')",1,FALSE,
python-driver,https://github.com/datastax/python-driver/tree/master/tests/integration/standard/test_cluster.py,ClusterTests,test_trace_unavailable$619,"for i in range(max_retry_count):
    future = session.execute_async(statement, trace=True)
    future.result()
    try:
        result = future.get_query_trace(-1.0)
        self._check_trace(result)
    except TraceUnavailable:
        break
else:
    raise Exception(""get_query_trace didn't raise TraceUnavailable after {} tries"".format(max_retry_count))","flag_else = 1

for i in range(max_retry_count):
    future = session.execute_async(statement, trace=True)
    future.result()
    try:
        result = future.get_query_trace(-1.0)
        self._check_trace(result)
    except TraceUnavailable:
        flag_else = 0
        break
if flag_else:
    raise Exception(""get_query_trace didn't raise TraceUnavailable after {} tries"".format(max_retry_count))",1,FALSE,
astropy,https://github.com/astropy/astropy/tree/master/astropy/utils/metadata.py,,merge$326,"for (left_type, right_type, merge_cls) in MERGE_STRATEGIES:
    if not merge_cls.enabled:
        continue
    if isinstance(left[key], left_type) and isinstance(right[key], right_type):
        out[key] = merge_cls.merge(left[key], right[key])
        break
else:
    raise MergeConflictError","flag_else = 1

for (left_type, right_type, merge_cls) in MERGE_STRATEGIES:
    if not merge_cls.enabled:
        continue
    if isinstance(left[key], left_type) and isinstance(right[key], right_type):
        out[key] = merge_cls.merge(left[key], right[key])
        flag_else = 0
        break
if flag_else:
    raise MergeConflictError",1,FALSE,
enterprise_gateway,https://github.com/jupyter/enterprise_gateway/tree/master/enterprise_gateway/tests/test_handlers.py,TestDefaults,test_kernel_comm$349,"for _ in range(8):
    msg = (yield ws.read_message())
    msg = json_decode(msg)
    print(f""test_kernel_comm, msg_type: {msg['msg_type']}"")
    if msg['msg_type'] == 'kernel_info_reply':
        break
else:
    self.assertTrue(False, 'never received kernel_info_reply')","flag_else = 1

for _ in range(8):
    msg = (yield ws.read_message())
    msg = json_decode(msg)
    print(f""test_kernel_comm, msg_type: {msg['msg_type']}"")
    if msg['msg_type'] == 'kernel_info_reply':
        flag_else = 0
        break
if flag_else:
    self.assertTrue(False, 'never received kernel_info_reply')",1,FALSE,
UnityPack,https://github.com/HearthSim/UnityPack/tree/master/unitypack/assetbundle.py,ArchiveBlockStorage,seek_to_block$238,"for b in self.blocks:
    if ofs + b.uncompressed_size > pos:
        self.current_block = b
        break
    baseofs += b.compressed_size
    ofs += b.uncompressed_size
else:
    self.current_block = None
    self.current_stream = BytesIO(b'')
    return","flag_else = 1

for b in self.blocks:
    if ofs + b.uncompressed_size > pos:
        self.current_block = b
        flag_else = 0
        break
    baseofs += b.compressed_size
    ofs += b.uncompressed_size
if flag_else:
    self.current_block = None
    self.current_stream = BytesIO(b'')
    return",1,FALSE,
astropy,https://github.com/astropy/astropy/tree/master/astropy/time/formats.py,TimeNumeric,_check_val_type$467,"for (subfmt, dtype, convert, _) in subfmts:
    if np.issubdtype(val_dtype, dtype):
        break
else:
    raise ValueError('input type not among selected sub-formats.')","flag_else = 1

for (subfmt, dtype, convert, _) in subfmts:
    if np.issubdtype(val_dtype, dtype):
        flag_else = 0
        break
if flag_else:
    raise ValueError('input type not among selected sub-formats.')",1,FALSE,
ShivyC,https://github.com/ShivamSarodia/ShivyC/tree/master/shivyc/parser/expression.py,,parse_series$262,"for s in separators:
    if token_is(index, s):
        break
else:
    return (cur, index)","flag_else = 1

for s in separators:
    if token_is(index, s):
        flag_else = 0
        break
if flag_else:
    return (cur, index)",1,FALSE,
koalas,https://github.com/databricks/koalas/tree/master/databricks/koalas/internal.py,InternalFrame,arguments_for_restore_index$954,"for (index_spark_column_name, index_spark_column) in zip(self.index_spark_column_names, self.index_spark_columns):
    if spark_column._jc.equals(index_spark_column._jc):
        column_names.append(index_spark_column_name)
        break
else:
    column_names.append(column_name)
    if isinstance(dtype, extension_dtypes):
        ext_dtypes[column_name] = dtype
    elif isinstance(dtype, CategoricalDtype):
        categorical_dtypes[column_name] = dtype","flag_else = 1

for (index_spark_column_name, index_spark_column) in zip(self.index_spark_column_names, self.index_spark_columns):
    if spark_column._jc.equals(index_spark_column._jc):
        column_names.append(index_spark_column_name)
        flag_else = 0
        break
if flag_else:
    column_names.append(column_name)
    if isinstance(dtype, extension_dtypes):
        ext_dtypes[column_name] = dtype
    elif isinstance(dtype, CategoricalDtype):
        categorical_dtypes[column_name] = dtype",1,FALSE,
RLBot,https://github.com/RLBot/RLBot/tree/master/src/main/python/rlbot/agents/base_dotnet_agent.py,BaseDotNetAgent,run_independently$20,"while not terminate_request_event.is_set():
    message = f'add\n{self.name}\n{self.team}\n{self.index}\n{game_interface.get_dll_directory()}'
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.connect(('127.0.0.1', self.port))
        s.send(bytes(message, 'ASCII'))
        s.close()
    except ConnectionRefusedError:
        self.logger.warn('Could not connect to server!')
    time.sleep(1)
else:
    self.retire()","while not terminate_request_event.is_set():
    message = f'add\n{self.name}\n{self.team}\n{self.index}\n{game_interface.get_dll_directory()}'
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.connect(('127.0.0.1', self.port))
        s.send(bytes(message, 'ASCII'))
        s.close()
    except ConnectionRefusedError:
        self.logger.warn('Could not connect to server!')
    time.sleep(1)

self.retire()
",0,TRUE,
elasticdl,https://github.com/sql-machine-learning/elasticdl/tree/master/elasticdl/python/worker/worker.py,Worker,_process_minibatch$181,"for _ in range(self._max_minibatch_retry_num):
    if task_type == elasticai_api_pb2.EVALUATION:
        self._trainer.evaluate_minibatch(features, labels)
        break
    elif task_type == elasticai_api_pb2.TRAINING:
        self._callbacks_list.on_train_batch_begin(self._model_version)
        (*accepted, min_model_version, loss) = self._trainer.train_minibatch(features, labels, train_with_local_model)
        self._model_version = self._trainer.get_model_version()
        if accepted:
            if self._model_version >= self._log_loss_count * self._log_loss_steps:
                self.logger.info('Loss = {}, steps = {}'.format(loss.numpy(), self._model_version))
                self._log_loss_count = int(self._model_version / self._log_loss_steps) + 1
            break
    elif task_type == elasticai_api_pb2.PREDICTION:
        accepted = self._trainer.predict_minibatch(features)
        if accepted:
            break
    else:
        raise RuntimeError('Unrecognized task type, %s' % task_type)
else:
    raise RuntimeError('Worker got stuck')","flag_else = 1

for _ in range(self._max_minibatch_retry_num):
    if task_type == elasticai_api_pb2.EVALUATION:
        self._trainer.evaluate_minibatch(features, labels)
        flag_else = 0
        break
    elif task_type == elasticai_api_pb2.TRAINING:
        self._callbacks_list.on_train_batch_begin(self._model_version)
        (*accepted, min_model_version, loss) = self._trainer.train_minibatch(features, labels, train_with_local_model)
        self._model_version = self._trainer.get_model_version()
        if accepted:
            if self._model_version >= self._log_loss_count * self._log_loss_steps:
                self.logger.info('Loss = {}, steps = {}'.format(loss.numpy(), self._model_version))
                self._log_loss_count = int(self._model_version / self._log_loss_steps) + 1
            flag_else = 0
            break
    elif task_type == elasticai_api_pb2.PREDICTION:
        accepted = self._trainer.predict_minibatch(features)
        if accepted:
            flag_else = 0
            break
    else:
        raise RuntimeError('Unrecognized task type, %s' % task_type)
if flag_else:
    raise RuntimeError('Worker got stuck')",3,FALSE,
retopoflow,https://github.com/CGCookie/retopoflow/tree/master/retopoflow/rfmesh/rfmesh_wrapper.py,RFEdge,get_left_right_link_faces$386,"for (lv0, lv1) in iter_pairs(bmfl.verts, True):
    if lv0 == v0 and lv1 == v1:
        break
else:
    (bmfl, bmfr) = (bmfr, bmfl)","flag_else = 1

for (lv0, lv1) in iter_pairs(bmfl.verts, True):
    if lv0 == v0 and lv1 == v1:
        flag_else = 0
        break
if flag_else:
    (bmfl, bmfr) = (bmfr, bmfl)",1,FALSE,
Hitomi-Downloader,https://github.com/KurtBestor/Hitomi-Downloader/tree/master/src/extractor/flickr_downloader.py,,find_ps$42,"for ps in pss:
    if ps.id == id:
        break
else:
    raise Exception('Not found photoset id')","flag_else = 1

for ps in pss:
    if ps.id == id:
        flag_else = 0
        break
if flag_else:
    raise Exception('Not found photoset id')",1,FALSE,
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/youtube_dlc/swfinterp.py,SWFInterpreter,extract_function$438,"for s in reversed(scopes):
    if mname in s:
        scope = s
        break
else:
    scope = avm_class.variables","flag_else = 1

for s in reversed(scopes):
    if mname in s:
        scope = s
        flag_else = 0
        break
if flag_else:
    scope = avm_class.variables",1,FALSE,
openage,https://github.com/SFTtech/openage/tree/master/openage/nyan/import_tree.py,ImportTree,get_alias_fqon$304,"for (index, namespace_part) in enumerate(namespace):
    current_node = current_node.get_child(namespace_part)
    if namespace_part != fqon[index]:
        break
else:
    if current_node.node_type in (NodeType.OBJECT, NodeType.NESTED):
        return (fqon[-1],)","flag_else = 1

for (index, namespace_part) in enumerate(namespace):
    current_node = current_node.get_child(namespace_part)
    if namespace_part != fqon[index]:
        flag_else = 0
        break
if flag_else:
    if current_node.node_type in (NodeType.OBJECT, NodeType.NESTED):
        return (fqon[-1],)",1,FALSE,
CurseBreaker,https://github.com/AcidWeb/CurseBreaker/tree/master/CB/GitHub.py,GitHubAddon,parse_metadata$60,"for release in self.payloads[self.releaseDepth]['assets']:
    if release['name'] and release['name'] == 'release.json':
        self.metadata = requests.get(release['url'], headers=dict({'Accept': 'application/octet-stream'}, **HEADERS), auth=APIAuth('token', self.apiKey), timeout=10).json()
        break
else:
    self.metadata = None","flag_else = 1

for release in self.payloads[self.releaseDepth]['assets']:
    if release['name'] and release['name'] == 'release.json':
        self.metadata = requests.get(release['url'], headers=dict({'Accept': 'application/octet-stream'}, **HEADERS), auth=APIAuth('token', self.apiKey), timeout=10).json()
        flag_else = 0
        break
if flag_else:
    self.metadata = None",1,FALSE,
barman,https://github.com/EnterpriseDB/barman/tree/master/barman/clients/cloud_restore.py,CloudBackupDownloader,download_backup$196,"for tblspc in backup_info.tablespaces:
    if oid == tblspc.oid:
        target_dir = tblspc.location
        if tblspc.name in tablespaces:
            target_dir = os.path.realpath(tablespaces[tblspc.name])
        logging.debug('Tablespace %s (oid=%s) will be located at %s', tblspc.name, oid, target_dir)
        link_jobs.append(['%s/pg_tblspc/%s' % (destination_dir, oid), target_dir])
        break
else:
    raise AssertionError(""The backup file oid '%s' must be present in backupinfo.tablespaces list"")","flag_else = 1

for tblspc in backup_info.tablespaces:
    if oid == tblspc.oid:
        target_dir = tblspc.location
        if tblspc.name in tablespaces:
            target_dir = os.path.realpath(tablespaces[tblspc.name])
        logging.debug('Tablespace %s (oid=%s) will be located at %s', tblspc.name, oid, target_dir)
        link_jobs.append(['%s/pg_tblspc/%s' % (destination_dir, oid), target_dir])
        flag_else = 0
        break
if flag_else:
    raise AssertionError(""The backup file oid '%s' must be present in backupinfo.tablespaces list"")",1,FALSE,
coq_nvim,https://github.com/ms-jpq/coq_nvim/tree/master/coq/snippets/parsers/lsp.py,,_parse_fmt$406,"for (pos, char) in context:
    if char in _INT_CHARS:
        idx_acc.append(char)
    elif char == '}':
        group = int(''.join(idx_acc)) if idx_acc else 0
        return (group, lambda x: x or '')
    elif char == ':':
        pushback_chars(context, (pos, char))
        group = int(''.join(idx_acc)) if idx_acc else 0
        trans = _parse_fmt_back(context)
        return (group, trans)
    else:
        raise_err(text=context.text, pos=pos, condition='while parsing format', expected=('[0-9]', ':'), actual=char)
else:
    raise_err(text=context.text, pos=pos, condition=""after ${'int'"", expected=('}', ':'), actual=char)","for (pos, char) in context:
    if char in _INT_CHARS:
        idx_acc.append(char)
    elif char == '}':
        group = int(''.join(idx_acc)) if idx_acc else 0
        return (group, lambda x: x or '')
    elif char == ':':
        pushback_chars(context, (pos, char))
        group = int(''.join(idx_acc)) if idx_acc else 0
        trans = _parse_fmt_back(context)
        return (group, trans)
    else:
        raise_err(text=context.text, pos=pos, condition='while parsing format', expected=('[0-9]', ':'), actual=char)

raise_err(text=context.text, pos=pos, condition=""after ${'int'"", expected=('}', ':'), actual=char)
",0,TRUE,
backtrader,https://github.com/mementum/backtrader/tree/master/backtrader/plot/locator.py,AutoDateLocator,get_locator$128,"for interval in self.intervald[freq]:
    if num <= interval * (self.maxticks[freq] - 1):
        break
else:
    warnings.warn(""AutoDateLocator was unable to pick an appropriate interval for this date range. It may be necessary to add an interval value to the AutoDateLocator's intervald dictionary. Defaulting to {0}."".format(interval))","flag_else = 1

for interval in self.intervald[freq]:
    if num <= interval * (self.maxticks[freq] - 1):
        flag_else = 0
        break
if flag_else:
    warnings.warn(""AutoDateLocator was unable to pick an appropriate interval for this date range. It may be necessary to add an interval value to the AutoDateLocator's intervald dictionary. Defaulting to {0}."".format(interval))",1,FALSE,
rtv,https://github.com/michael-lazar/rtv/tree/master/tests/test_mime_parsers.py,,test_parser$133,"for parser in parsers:
    if parser.pattern.match(url):
        (parsed_url, parsed_type) = parser.get_mimetype(url)
        if isinstance(modified_url, RegexpType):
            assert modified_url.match(parsed_url)
        else:
            assert modified_url == parsed_url
        assert parsed_type == mime_type
        break
else:
    assert False","flag_else = 1

for parser in parsers:
    if parser.pattern.match(url):
        (parsed_url, parsed_type) = parser.get_mimetype(url)
        if isinstance(modified_url, RegexpType):
            assert modified_url.match(parsed_url)
        else:
            assert modified_url == parsed_url
        assert parsed_type == mime_type
        flag_else = 0
        break
if flag_else:
    assert False",1,FALSE,
bot,https://github.com/python-discord/bot/tree/master/bot/exts/info/doc/_parsing.py,,_get_truncated_description$138,"for string_ in ('\n\n', '\n', '. ', ', ', ',', ' '):
    cutoff = force_truncated.rfind(string_)
    if cutoff != -1:
        truncated_result = force_truncated[:cutoff]
        break
else:
    truncated_result = force_truncated","flag_else = 1

for string_ in ('\n\n', '\n', '. ', ', ', ',', ' '):
    cutoff = force_truncated.rfind(string_)
    if cutoff != -1:
        truncated_result = force_truncated[:cutoff]
        flag_else = 0
        break
if flag_else:
    truncated_result = force_truncated",1,FALSE,
checkmk,https://github.com/tribe29/checkmk/tree/master/cmk/ec/history.py,,_get_files$439,"for (_column_name, _operator_name, predicate, _argument) in time_filters:
    if predicate(first_entry):
        break
    if predicate(last_entry):
        break
else:
    if len(time_filters):
        if history._settings.options.debug:
            history._logger.info('Skipping logfile %s.log because of time filter' % ts)
        continue","flag_else = 1

for (_column_name, _operator_name, predicate, _argument) in time_filters:
    if predicate(first_entry):
        flag_else = 0
        break
    if predicate(last_entry):
        flag_else = 0
        break
if flag_else:
    if len(time_filters):
        if history._settings.options.debug:
            history._logger.info('Skipping logfile %s.log because of time filter' % ts)
        continue",2,FALSE,
swift,https://github.com/openstack/swift/tree/master/test/functional/tests.py,TestFile,test_POST$2660,"for f_dict in listing:
    if f_dict['name'] == file_name:
        break
else:
    self.fail('Failed to find file %r in listing' % file_name)","flag_else = 1

for f_dict in listing:
    if f_dict['name'] == file_name:
        flag_else = 0
        break
if flag_else:
    self.fail('Failed to find file %r in listing' % file_name)",1,FALSE,
checkmk,https://github.com/tribe29/checkmk/tree/master/cmk/utils/livestatus_helpers/queries.py,Query,from_string$504,"for line in lines:
    if line.startswith('Columns: '):
        column_names = line.split(': ', 1)[1].lstrip().split()
        columns: List[Column] = []
        for col in column_names:
            try:
                columns.append(_get_column(table_class, col))
            except AttributeError:
                pass
        break
else:
    raise ValueError('No columns found')","flag_else = 1

for line in lines:
    if line.startswith('Columns: '):
        column_names = line.split(': ', 1)[1].lstrip().split()
        columns: List[Column] = []
        for col in column_names:
            try:
                columns.append(_get_column(table_class, col))
            except AttributeError:
                pass
        flag_else = 0
        break
if flag_else:
    raise ValueError('No columns found')",1,FALSE,
tfc,https://github.com/maqp/tfc/tree/master/src/relay/diffs.py,,account_checker$97,"for account in account_list:
    ratio = difflib.SequenceMatcher(a=account, b=purp_account).ratio()
    if ratio >= ACCOUNT_RATIO_LIMIT:
        break
else:
    account = get_account_from_user(account_list, onion_address_user, account_input_queue)","flag_else = 1

for account in account_list:
    ratio = difflib.SequenceMatcher(a=account, b=purp_account).ratio()
    if ratio >= ACCOUNT_RATIO_LIMIT:
        flag_else = 0
        break
if flag_else:
    account = get_account_from_user(account_list, onion_address_user, account_input_queue)",1,FALSE,
montydb,https://github.com/davidlatwe/montydb/tree/master/montydb/engine/field_walker.py,FieldWalker,get_matched$832,"for (path, node) in self.matched.items():
    if position_path is None or path.startswith(position_path + '.'):
        matched = node
        break
else:
    return","flag_else = 1

for (path, node) in self.matched.items():
    if position_path is None or path.startswith(position_path + '.'):
        matched = node
        flag_else = 0
        break
if flag_else:
    return",1,FALSE,
integrations-core,https://github.com/DataDog/integrations-core/tree/master/datadog_checks_base/datadog_checks/base/checks/prometheus/mixins.py,PrometheusScraperMixin,_text_filter_input$247,"for item in self._text_filter_blacklist:
    if item in line:
        break
else:
    yield line","flag_else = 1

for item in self._text_filter_blacklist:
    if item in line:
        flag_else = 0
        break
if flag_else:
    yield line",1,FALSE,
ansible-modules-core,https://github.com/ansible/ansible-modules-core/tree/master/network/nxos/nxos_igmp_snooping.py,CustomNetworkConfig,add$194,"for child in ancestors[-1].children:
    if child.text == line:
        break
else:
    offset = len(parents) * self.indent
    item = ConfigLine(line)
    item.raw = line.rjust(len(line) + offset)
    item.parents = ancestors
    ancestors[-1].children.append(item)
    self.items.append(item)","flag_else = 1

for child in ancestors[-1].children:
    if child.text == line:
        flag_else = 0
        break
if flag_else:
    offset = len(parents) * self.indent
    item = ConfigLine(line)
    item.raw = line.rjust(len(line) + offset)
    item.parents = ancestors
    ancestors[-1].children.append(item)
    self.items.append(item)",1,FALSE,
pyOCD,https://github.com/pyocd/pyOCD/tree/master/pyocd/coresight/cortex_m.py,CortexM,_post_reset_core_accessibility_test$715,"while time_out.check():
    try:
        dhcsr = self.read32(CortexM.DHCSR)
        if dhcsr & CortexM.S_RESET_ST == 0:
            break
    except exceptions.TransferError:
        try:
            self.flush()
        except exceptions.TransferError:
            pass
else:
    if dhcsr is None:
        LOG.warning('Core #%d is not accessible after reset', self.core_number)
    else:
        LOG.debug('Core #%d did not come out of reset within timeout', self.core_number)","flag_else = 1

while time_out.check():
    try:
        dhcsr = self.read32(CortexM.DHCSR)
        if dhcsr & CortexM.S_RESET_ST == 0:
            flag_else = 0
            break
    except exceptions.TransferError:
        try:
            self.flush()
        except exceptions.TransferError:
            pass
if flag_else:
    if dhcsr is None:
        LOG.warning('Core #%d is not accessible after reset', self.core_number)
    else:
        LOG.debug('Core #%d did not come out of reset within timeout', self.core_number)",1,FALSE,
salt,https://github.com/saltstack/salt/tree/master/salt/utils/gitfs.py,,enforce_types$158,"for item in non_string_params:
    try:
        if key.endswith('_' + item):
            ret = item
            break
    except TypeError:
        if key.endswith('_' + str(item)):
            ret = item
            break
else:
    ret = None","flag_else = 1

for item in non_string_params:
    try:
        if key.endswith('_' + item):
            ret = item
            flag_else = 0
            break
    except TypeError:
        if key.endswith('_' + str(item)):
            ret = item
            flag_else = 0
            break
if flag_else:
    ret = None",2,FALSE,
quodlibet,https://github.com/quodlibet/quodlibet/tree/master/quodlibet/ext/songsmenu/duplicates.py,DuplicateDialog,__init__$284,"for row in model:
    if view.row_expanded(row.path):
        view.collapse_row(row.path)
else:
    for row in model:
        view.expand_row(row.path, False)","for row in model:
    if view.row_expanded(row.path):
        view.collapse_row(row.path)

for row in model:
    view.expand_row(row.path, False)
",0,TRUE,
data-science-competition,https://github.com/DLLXW/data-science-competition/tree/master/else/--AI+z/code/scripts/preprocess/CHID_preprocess.py,,logits_matrix_to_array$343,"for (i, row) in enumerate(logits_matrix):
    for (j, col) in enumerate(row):
        tmp.append((i, j, col))
else:
    choice = set(range(i + 1))
    blanks = set(range(j + 1))","for (i, row) in enumerate(logits_matrix):
    for (j, col) in enumerate(row):
        tmp.append((i, j, col))

choice = set(range(i + 1))
blanks = set(range(j + 1))
",0,TRUE,
hamster,https://github.com/projecthamster/hamster/tree/master/waflib/extras/qt4.py,qxx,add_moc_tasks$173,"for x in include_nodes:
    for e in self.moc_h_ext():
        h_node = x.find_node(base2 + e)
        if h_node:
            break
    if h_node:
        m_node = h_node.change_ext('.moc')
        break
else:
    for k in EXT_QT4:
        if base2.endswith(k):
            for x in include_nodes:
                h_node = x.find_node(base2)
                if h_node:
                    break
            if h_node:
                m_node = h_node.change_ext(k + '.moc')
                break","flag_else = 1

for x in include_nodes:
    for e in self.moc_h_ext():
        h_node = x.find_node(base2 + e)
        if h_node:
            break
    if h_node:
        m_node = h_node.change_ext('.moc')
        flag_else = 0
        break
if flag_else:
    for k in EXT_QT4:
        if base2.endswith(k):
            for x in include_nodes:
                h_node = x.find_node(base2)
                if h_node:
                    break
            if h_node:
                m_node = h_node.change_ext(k + '.moc')
                break",1,FALSE,
shadowsocks-rm,https://github.com/mengskysama/shadowsocks-rm/tree/master/shadowsocks/daemon.py,,daemon_stop$134,"for i in range(0, 200):
    try:
        os.kill(pid, 0)
    except OSError as e:
        if e.errno == errno.ESRCH:
            break
    time.sleep(0.05)
else:
    logging.error('timed out when stopping pid %d', pid)
    sys.exit(1)","flag_else = 1

for i in range(0, 200):
    try:
        os.kill(pid, 0)
    except OSError as e:
        if e.errno == errno.ESRCH:
            flag_else = 0
            break
    time.sleep(0.05)
if flag_else:
    logging.error('timed out when stopping pid %d', pid)
    sys.exit(1)",1,FALSE,
beagle,https://github.com/yampelo/beagle/tree/master/beagle/datasources/virustotal/generic_vt_sandbox.py,GenericVTSandbox,_network_events$339,"for ip in dnslookup.get('resolved_ips', []):
    yield {FieldNames.EVENT_TYPE: EventTypes.DNS_LOOKUP, FieldNames.HTTP_HOST: dnslookup['hostname'], FieldNames.IP_ADDRESS: ip, **self.parent_process}
else:
    yield {FieldNames.EVENT_TYPE: EventTypes.DNS_LOOKUP, FieldNames.HTTP_HOST: dnslookup['hostname'], **self.parent_process}","for ip in dnslookup.get('resolved_ips', []):
    yield {FieldNames.EVENT_TYPE: EventTypes.DNS_LOOKUP, FieldNames.HTTP_HOST: dnslookup['hostname'], FieldNames.IP_ADDRESS: ip, **self.parent_process}

yield {FieldNames.EVENT_TYPE: EventTypes.DNS_LOOKUP, FieldNames.HTTP_HOST: dnslookup['hostname'], **self.parent_process}
",0,TRUE,
azure-cli,https://github.com/Azure/azure-cli/tree/master/src/azure-cli/azure/cli/command_modules/network/custom.py,WAFManagedRuleSetAdd,pre_instance_update$1988,"for rule_set in instance.properties.managed_rules.managed_rule_sets:
    if rule_set.rule_set_type == rule_set_type and rule_set.rule_set_version == rule_set_version:
        for rule_override in rule_set.rule_group_overrides:
            if rule_override.rule_group_name == rule_group_name:
                rule_override.rules.extend(managed_rule_overrides)
                break
        else:
            if rule_group_override is not None:
                rule_set.rule_group_overrides.append(rule_group_override)
        break
else:
    instance.properties.managed_rules.managed_rule_sets.append(new_managed_rule_set)","flag_else = 1

for rule_set in instance.properties.managed_rules.managed_rule_sets:
    if rule_set.rule_set_type == rule_set_type and rule_set.rule_set_version == rule_set_version:
        for rule_override in rule_set.rule_group_overrides:
            if rule_override.rule_group_name == rule_group_name:
                rule_override.rules.extend(managed_rule_overrides)
                break
        else:
            if rule_group_override is not None:
                rule_set.rule_group_overrides.append(rule_group_override)
        flag_else = 0
        break
if flag_else:
    instance.properties.managed_rules.managed_rule_sets.append(new_managed_rule_set)",1,FALSE,
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/youtube_dlc/utils.py,,long_to_bytes$5375,"for i in range(len(s)):
    if s[i] != b'\x00'[0]:
        break
else:
    s = b'\x00'
    i = 0","flag_else = 1

for i in range(len(s)):
    if s[i] != b'\x00'[0]:
        flag_else = 0
        break
if flag_else:
    s = b'\x00'
    i = 0",1,FALSE,
conan,https://github.com/conan-io/conan/tree/master/conans/test/utils/test_files.py,,wait_until_removed$18,"for _ in range(50):
    time.sleep(0.1)
    try:
        shutil.rmtree(folder)
        break
    except Exception as e:
        latest_exception = e
else:
    raise Exception('Could remove folder %s: %s' % (folder, latest_exception))","flag_else = 1

for _ in range(50):
    time.sleep(0.1)
    try:
        shutil.rmtree(folder)
        flag_else = 0
        break
    except Exception as e:
        latest_exception = e
if flag_else:
    raise Exception('Could remove folder %s: %s' % (folder, latest_exception))",1,FALSE,
fuxi,https://github.com/jeffzh3ng/fuxi/tree/master/fuxi/common/libs/nmap.py,PortScanner,analyse_nmap_xml_scan$272,"for dosmatch in dos.findall('osmatch'):
    name = dosmatch.get('name')
    accuracy = dosmatch.get('accuracy')
    line = dosmatch.get('line')
    osclass = []
    for dosclass in dosmatch.findall('osclass'):
        ostype = dosclass.get('type')
        vendor = dosclass.get('vendor')
        osfamily = dosclass.get('osfamily')
        osgen = dosclass.get('osgen')
        accuracy = dosclass.get('accuracy')
        cpe = []
        for dcpe in dosclass.findall('cpe'):
            cpe.append(dcpe.text)
        osclass.append({'type': ostype, 'vendor': vendor, 'osfamily': osfamily, 'osgen': osgen, 'accuracy': accuracy, 'cpe': cpe})
    osmatch.append({'name': name, 'accuracy': accuracy, 'line': line, 'osclass': osclass})
else:
    scan_result['scan'][host]['osmatch'] = osmatch","for dosmatch in dos.findall('osmatch'):
    name = dosmatch.get('name')
    accuracy = dosmatch.get('accuracy')
    line = dosmatch.get('line')
    osclass = []
    for dosclass in dosmatch.findall('osclass'):
        ostype = dosclass.get('type')
        vendor = dosclass.get('vendor')
        osfamily = dosclass.get('osfamily')
        osgen = dosclass.get('osgen')
        accuracy = dosclass.get('accuracy')
        cpe = []
        for dcpe in dosclass.findall('cpe'):
            cpe.append(dcpe.text)
        osclass.append({'type': ostype, 'vendor': vendor, 'osfamily': osfamily, 'osgen': osgen, 'accuracy': accuracy, 'cpe': cpe})
    osmatch.append({'name': name, 'accuracy': accuracy, 'line': line, 'osclass': osclass})

scan_result['scan'][host]['osmatch'] = osmatch
",0,TRUE,
pony,https://github.com/ponyorm/pony/tree/master/pony/orm/core.py,Discriminator,validate$2594,"for cls in entity._subclasses_:
    if val == cls._discriminator_:
        break
else:
    throw(TypeError, 'Invalid discriminator attribute value for %s. Expected: %r, got: %r' % (entity.__name__, entity._discriminator_, val))","flag_else = 1

for cls in entity._subclasses_:
    if val == cls._discriminator_:
        flag_else = 0
        break
if flag_else:
    throw(TypeError, 'Invalid discriminator attribute value for %s. Expected: %r, got: %r' % (entity.__name__, entity._discriminator_, val))",1,FALSE,
nltk,https://github.com/nltk/nltk/tree/master/nltk/corpus/reader/util.py,,concat$434,"for typ in types:
    if not issubclass(typ, (StreamBackedCorpusView, ConcatenatedCorpusView)):
        break
else:
    return ConcatenatedCorpusView(docs)","flag_else = 1

for typ in types:
    if not issubclass(typ, (StreamBackedCorpusView, ConcatenatedCorpusView)):
        flag_else = 0
        break
if flag_else:
    return ConcatenatedCorpusView(docs)",1,FALSE,
runipy,https://github.com/paulgb/runipy/tree/master/runipy/_version.py,,run_command$63,"for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return None
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return None","flag_else = 1

for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return None
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return None",1,FALSE,
exabgp,https://github.com/Exa-Networks/exabgp/tree/master/src/exabgp/application/cli.py,,cmdline$113,"for (nickname, name, match) in (('a', 'announce', lambda pos, pre: pos == 0 or pre.count('.') == 3 or pre.count(':') != 0), ('a', 'attributes', lambda pos, pre: pre[-1] == 'announce' or pre[-1] == 'withdraw'), ('c', 'configuration', lambda pos, pre: True), ('e', 'eor', lambda pos, pre: pre[-1] == 'announce'), ('e', 'extensive', lambda _, pre: 'show' in pre), ('f', 'flow', lambda pos, pre: pre[-1] == 'announce' or pre[-1] == 'withdraw'), ('f', 'flush', lambda pos, pre: pos == 0 or pre.count('.') == 3 or pre.count(':') != 0), ('h', 'help', lambda pos, pre: pos == 0), ('i', 'in', lambda pos, pre: pre[-1] == 'adj-rib'), ('n', 'neighbor', lambda pos, pre: pos == 0 or pre[-1] == 'show'), ('r', 'route', lambda pos, pre: pre == 'announce' or pre == 'withdraw'), ('rr', 'route-refresh', lambda _, pre: pre == 'announce'), ('s', 'show', lambda pos, pre: pos == 0), ('t', 'teardown', lambda pos, pre: pos == 0 or pre.count('.') == 3 or pre.count(':') != 0), ('s', 'summary', lambda pos, pre: pos != 0), ('v', 'vps', lambda pos, pre: pre[-1] == 'announce' or pre[-1] == 'withdraw'), ('o', 'operation', lambda pos, pre: pre[-1] == 'announce'), ('o', 'out', lambda pos, pre: pre[-1] == 'adj-rib'), ('a', 'adj-rib', lambda pos, pre: pre[-1] in ['clear', 'flush', 'show']), ('w', 'withdraw', lambda pos, pre: pos == 0 or pre.count('.') == 3 or pre.count(':') != 0), ('w', 'watchdog', lambda pos, pre: pre[-1] == 'announce' or pre[-1] == 'withdraw'), ('neighbour', 'neighbor', lambda pos, pre: True), ('neigbour', 'neighbor', lambda pos, pre: True), ('neigbor', 'neighbor', lambda pos, pre: True)):
    if (token == nickname or name.startswith(token)) and match(pos, renamed):
        renamed.append(name)
        break
else:
    renamed.append(token)","flag_else = 1

for (nickname, name, match) in (('a', 'announce', lambda pos, pre: pos == 0 or pre.count('.') == 3 or pre.count(':') != 0), ('a', 'attributes', lambda pos, pre: pre[-1] == 'announce' or pre[-1] == 'withdraw'), ('c', 'configuration', lambda pos, pre: True), ('e', 'eor', lambda pos, pre: pre[-1] == 'announce'), ('e', 'extensive', lambda _, pre: 'show' in pre), ('f', 'flow', lambda pos, pre: pre[-1] == 'announce' or pre[-1] == 'withdraw'), ('f', 'flush', lambda pos, pre: pos == 0 or pre.count('.') == 3 or pre.count(':') != 0), ('h', 'help', lambda pos, pre: pos == 0), ('i', 'in', lambda pos, pre: pre[-1] == 'adj-rib'), ('n', 'neighbor', lambda pos, pre: pos == 0 or pre[-1] == 'show'), ('r', 'route', lambda pos, pre: pre == 'announce' or pre == 'withdraw'), ('rr', 'route-refresh', lambda _, pre: pre == 'announce'), ('s', 'show', lambda pos, pre: pos == 0), ('t', 'teardown', lambda pos, pre: pos == 0 or pre.count('.') == 3 or pre.count(':') != 0), ('s', 'summary', lambda pos, pre: pos != 0), ('v', 'vps', lambda pos, pre: pre[-1] == 'announce' or pre[-1] == 'withdraw'), ('o', 'operation', lambda pos, pre: pre[-1] == 'announce'), ('o', 'out', lambda pos, pre: pre[-1] == 'adj-rib'), ('a', 'adj-rib', lambda pos, pre: pre[-1] in ['clear', 'flush', 'show']), ('w', 'withdraw', lambda pos, pre: pos == 0 or pre.count('.') == 3 or pre.count(':') != 0), ('w', 'watchdog', lambda pos, pre: pre[-1] == 'announce' or pre[-1] == 'withdraw'), ('neighbour', 'neighbor', lambda pos, pre: True), ('neigbour', 'neighbor', lambda pos, pre: True), ('neigbor', 'neighbor', lambda pos, pre: True)):
    if (token == nickname or name.startswith(token)) and match(pos, renamed):
        renamed.append(name)
        flag_else = 0
        break
if flag_else:
    renamed.append(token)",1,FALSE,
WatchAD,https://github.com/Qianlitp/WatchAD/tree/master/libs/pyasn1/codec/ber/decoder.py,OctetStringDecoder,indefLenValueDecoder$185,"while substrate:
    (component, substrate) = decodeFun(substrate)
    if eoo.endOfOctets.isSameTypeWith(component) and component == eoo.endOfOctets:
        break
    r = r + component
else:
    raise error.SubstrateUnderrunError('No EOO seen before substrate ends')","flag_else = 1

while substrate:
    (component, substrate) = decodeFun(substrate)
    if eoo.endOfOctets.isSameTypeWith(component) and component == eoo.endOfOctets:
        flag_else = 0
        break
    r = r + component
if flag_else:
    raise error.SubstrateUnderrunError('No EOO seen before substrate ends')",1,FALSE,
moto,https://github.com/spulec/moto/tree/master/moto/cognitoidp/models.py,CognitoIdpBackend,change_password$1305,"for user_pool in self.user_pools.values():
    if access_token in user_pool.access_tokens:
        (_, username) = user_pool.access_tokens[access_token]
        user = self.admin_get_user(user_pool.id, username)
        if user.password != previous_password:
            raise NotAuthorizedError(username)
        user.password = proposed_password
        if user.status in [UserStatus.FORCE_CHANGE_PASSWORD, UserStatus.RESET_REQUIRED]:
            user.status = UserStatus.CONFIRMED
        break
else:
    raise NotAuthorizedError(access_token)","flag_else = 1

for user_pool in self.user_pools.values():
    if access_token in user_pool.access_tokens:
        (_, username) = user_pool.access_tokens[access_token]
        user = self.admin_get_user(user_pool.id, username)
        if user.password != previous_password:
            raise NotAuthorizedError(username)
        user.password = proposed_password
        if user.status in [UserStatus.FORCE_CHANGE_PASSWORD, UserStatus.RESET_REQUIRED]:
            user.status = UserStatus.CONFIRMED
        flag_else = 0
        break
if flag_else:
    raise NotAuthorizedError(access_token)",1,FALSE,
qtile,https://github.com/qtile/qtile/tree/master/libqtile/layout/stack.py,Stack,focus_previous$171,"for i in iterator:
    if client in i:
        next = i.focus_previous(client)
        if next:
            return next
        break
else:
    return","flag_else = 1

for i in iterator:
    if client in i:
        next = i.focus_previous(client)
        if next:
            return next
        flag_else = 0
        break
if flag_else:
    return",1,FALSE,
mangum,https://github.com/jordaneremieff/mangum/tree/master/tests/integration/mock_server.py,,start_service$18,"for i in range(0, 30):
    output = process.poll()
    if output is not None:
        logging.info(f'moto_server exited status {output}')
        (stdout, stderr) = process.communicate()
        logging.info(f'moto_server stdout: {stdout}')
        logging.info(f'moto_server stderr: {stderr}')
        pytest.fail(f'Can not start service: {service_name}')
    try:
        requests.get(url, timeout=5, proxies=_proxy_bypass)
        break
    except requests.exceptions.ConnectionError:
        time.sleep(0.5)
else:
    stop_process(process)
    pytest.fail(f'Can not start service: {service_name}')","flag_else = 1

for i in range(0, 30):
    output = process.poll()
    if output is not None:
        logging.info(f'moto_server exited status {output}')
        (stdout, stderr) = process.communicate()
        logging.info(f'moto_server stdout: {stdout}')
        logging.info(f'moto_server stderr: {stderr}')
        pytest.fail(f'Can not start service: {service_name}')
    try:
        requests.get(url, timeout=5, proxies=_proxy_bypass)
        flag_else = 0
        break
    except requests.exceptions.ConnectionError:
        time.sleep(0.5)
if flag_else:
    stop_process(process)
    pytest.fail(f'Can not start service: {service_name}')",1,FALSE,
pywikibot,https://github.com/wikimedia/pywikibot/tree/master/scripts/interwiki.py,InterwikiBot,generateMore$1919,"for page in self.pageGenerator:
    if page in self.conf.skip:
        pywikibot.output('Skipping: {} is in the skip list'.format(page))
        continue
    if self.conf.skipauto:
        (dictName, year) = page.autoFormat()
        if dictName is not None:
            pywikibot.output('Skipping: {} is an auto entry {}({})'.format(page, dictName, year))
            continue
    if self.conf.parenthesesonly:
        if '(' not in page.title():
            continue
    if page.isTalkPage():
        pywikibot.output('Skipping: {} is a talk page'.format(page))
        continue
    if page.namespace() == 10:
        loc = None
        with suppress(KeyError):
            (tmpl, loc) = moved_links[page.site.code]
            del tmpl
        if loc is not None and loc in page.title():
            pywikibot.output('Skipping: {} is a templates subpage'.format(page.title()))
            continue
    break
else:
    break","flag_else = 1

for page in self.pageGenerator:
    if page in self.conf.skip:
        pywikibot.output('Skipping: {} is in the skip list'.format(page))
        continue
    if self.conf.skipauto:
        (dictName, year) = page.autoFormat()
        if dictName is not None:
            pywikibot.output('Skipping: {} is an auto entry {}({})'.format(page, dictName, year))
            continue
    if self.conf.parenthesesonly:
        if '(' not in page.title():
            continue
    if page.isTalkPage():
        pywikibot.output('Skipping: {} is a talk page'.format(page))
        continue
    if page.namespace() == 10:
        loc = None
        with suppress(KeyError):
            (tmpl, loc) = moved_links[page.site.code]
            del tmpl
        if loc is not None and loc in page.title():
            pywikibot.output('Skipping: {} is a templates subpage'.format(page.title()))
            continue
    flag_else = 0
    break
if flag_else:
    break",1,FALSE,
spilo,https://github.com/zalando/spilo/tree/master/postgres-appliance/major_upgrade/inplace_upgrade.py,InplaceUpgrade,do_upgrade$482,"for _ in polling_loop(10):
    try:
        result = self.request(member, 'post', 'restart', {})
        logger.info('   %s %s', result.status, result.data.decode('utf-8'))
        if result.status < 300:
            break
    except Exception as e:
        logger.error('POST /restart failed: %r', e)
else:
    logger.error('Failed to start primary after upgrade')","flag_else = 1

for _ in polling_loop(10):
    try:
        result = self.request(member, 'post', 'restart', {})
        logger.info('   %s %s', result.status, result.data.decode('utf-8'))
        if result.status < 300:
            flag_else = 0
            break
    except Exception as e:
        logger.error('POST /restart failed: %r', e)
if flag_else:
    logger.error('Failed to start primary after upgrade')",1,FALSE,
tvnamer,https://github.com/dbr/tvnamer/tree/master/tvnamer/files.py,FileParser,parse$264,"for cmatcher in self.compiled_regexs:
    match = cmatcher.match(filename)
    if match:
        namedgroups = match.groupdict().keys()
        if 'episodenumber1' in namedgroups:
            epnos = []
            for cur in namedgroups:
                epnomatch = re.match('episodenumber(\\d+)', cur)
                if epnomatch:
                    epnos.append(int(match.group(cur)))
            epnos.sort()
            episodenumbers = epnos
        elif 'episodenumberstart' in namedgroups:
            start = int(match.group('episodenumberstart'))
            end = int(match.group('episodenumberend'))
            if end - start > 5:
                warn('WARNING: %s episodes detected in file: %s, confused by numeric episode name, using first match: %s' % (end - start, filename, start))
                episodenumbers = [start]
            elif start > end:
                (start, end) = (end, start)
                episodenumbers = list(range(start, end + 1))
            else:
                episodenumbers = list(range(start, end + 1))
        elif 'episodenumber' in namedgroups:
            episodenumbers = [int(match.group('episodenumber'))]
        elif 'year' in namedgroups or 'month' in namedgroups or 'day' in namedgroups:
            if not all(['year' in namedgroups, 'month' in namedgroups, 'day' in namedgroups]):
                raise ConfigValueError(""Date-based regex must contain groups 'year', 'month' and 'day'"")
            match.group('year')
            year = intepret_year(match.group('year'))
            episodedates = [datetime.date(year, int(match.group('month')), int(match.group('day')))]
        else:
            raise ConfigValueError('Regex does not contain episode number group, shouldcontain episodenumber, episodenumber1-9, orepisodenumberstart and episodenumberend\n\nPatternwas:\n' + cmatcher.pattern)
        if 'seriesname' in namedgroups:
            seriesname = match.group('seriesname')
        else:
            raise ConfigValueError('Regex must contain seriesname. Pattern was:\n' + cmatcher.pattern)
        if seriesname is not None:
            seriesname = _clean_extracted_series_name(seriesname)
            seriesname = _replace_input_series_name(seriesname)
        extra_values = match.groupdict()
        if 'seasonnumber' in namedgroups:
            seasonnumber = int(match.group('seasonnumber'))
            episode = EpisodeInfo(seriesname=seriesname, seasonnumber=seasonnumber, episodenumbers=episodenumbers, filename=self.path, extra=extra_values)
        elif 'year' in namedgroups and 'month' in namedgroups and ('day' in namedgroups):
            episode = DatedEpisodeInfo(seriesname=seriesname, episodenumbers=episodedates, filename=self.path, extra=extra_values)
        elif 'group' in namedgroups:
            episode = AnimeEpisodeInfo(seriesname=seriesname, episodenumbers=episodenumbers, filename=self.path, extra=extra_values)
        else:
            episode = NoSeasonEpisodeInfo(seriesname=seriesname, episodenumbers=episodenumbers, filename=self.path, extra=extra_values)
        return episode
else:
    emsg = 'Cannot parse %r' % self.path
    if len(Config['input_filename_replacements']) > 0:
        emsg += ' with replacements: %r' % filename
    raise InvalidFilename(emsg)","for cmatcher in self.compiled_regexs:
    match = cmatcher.match(filename)
    if match:
        namedgroups = match.groupdict().keys()
        if 'episodenumber1' in namedgroups:
            epnos = []
            for cur in namedgroups:
                epnomatch = re.match('episodenumber(\\d+)', cur)
                if epnomatch:
                    epnos.append(int(match.group(cur)))
            epnos.sort()
            episodenumbers = epnos
        elif 'episodenumberstart' in namedgroups:
            start = int(match.group('episodenumberstart'))
            end = int(match.group('episodenumberend'))
            if end - start > 5:
                warn('WARNING: %s episodes detected in file: %s, confused by numeric episode name, using first match: %s' % (end - start, filename, start))
                episodenumbers = [start]
            elif start > end:
                (start, end) = (end, start)
                episodenumbers = list(range(start, end + 1))
            else:
                episodenumbers = list(range(start, end + 1))
        elif 'episodenumber' in namedgroups:
            episodenumbers = [int(match.group('episodenumber'))]
        elif 'year' in namedgroups or 'month' in namedgroups or 'day' in namedgroups:
            if not all(['year' in namedgroups, 'month' in namedgroups, 'day' in namedgroups]):
                raise ConfigValueError(""Date-based regex must contain groups 'year', 'month' and 'day'"")
            match.group('year')
            year = intepret_year(match.group('year'))
            episodedates = [datetime.date(year, int(match.group('month')), int(match.group('day')))]
        else:
            raise ConfigValueError('Regex does not contain episode number group, shouldcontain episodenumber, episodenumber1-9, orepisodenumberstart and episodenumberend\n\nPatternwas:\n' + cmatcher.pattern)
        if 'seriesname' in namedgroups:
            seriesname = match.group('seriesname')
        else:
            raise ConfigValueError('Regex must contain seriesname. Pattern was:\n' + cmatcher.pattern)
        if seriesname is not None:
            seriesname = _clean_extracted_series_name(seriesname)
            seriesname = _replace_input_series_name(seriesname)
        extra_values = match.groupdict()
        if 'seasonnumber' in namedgroups:
            seasonnumber = int(match.group('seasonnumber'))
            episode = EpisodeInfo(seriesname=seriesname, seasonnumber=seasonnumber, episodenumbers=episodenumbers, filename=self.path, extra=extra_values)
        elif 'year' in namedgroups and 'month' in namedgroups and ('day' in namedgroups):
            episode = DatedEpisodeInfo(seriesname=seriesname, episodenumbers=episodedates, filename=self.path, extra=extra_values)
        elif 'group' in namedgroups:
            episode = AnimeEpisodeInfo(seriesname=seriesname, episodenumbers=episodenumbers, filename=self.path, extra=extra_values)
        else:
            episode = NoSeasonEpisodeInfo(seriesname=seriesname, episodenumbers=episodenumbers, filename=self.path, extra=extra_values)
        return episode

emsg = 'Cannot parse %r' % self.path
if len(Config['input_filename_replacements']) > 0:
    emsg += ' with replacements: %r' % filename
raise InvalidFilename(emsg)
",0,TRUE,
Rasa_NLU_Chi,https://github.com/crownpku/Rasa_NLU_Chi/tree/master/rasa_nlu/config.py,RasaNLUModelConfig,for_component$136,"for c in self.pipeline:
    if c.get('name') == name:
        return override_defaults(defaults, c)
else:
    return defaults or {}","for c in self.pipeline:
    if c.get('name') == name:
        return override_defaults(defaults, c)

return defaults or {}
",0,TRUE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/simplify/cse_main.py,,_find_repeated$582,"for ign in ignore:
    if ign in expr.free_symbols:
        break
else:
    to_eliminate.add(expr)
    return","flag_else = 1

for ign in ignore:
    if ign in expr.free_symbols:
        flag_else = 0
        break
if flag_else:
    to_eliminate.add(expr)
    return",1,FALSE,
galaxy,https://github.com/ansible/galaxy/tree/master/lib/galaxy/jobs/runners/tasks.py,TaskedJobRunner,_stop_pid$212,"for sig in [15, 9]:
    try:
        os.killpg(pid, sig)
    except OSError as e:
        log.warning('_stop_pid(): %s: Got errno %s when attempting to signal %d to PID %d: %s' % (job_id, errno.errorcode[e.errno], sig, pid, e.strerror))
        return
    sleep(2)
    if not self._check_pid(pid):
        log.debug('_stop_pid(): %s: PID %d successfully killed with signal %d' % (job_id, pid, sig))
        return
else:
    log.warning('_stop_pid(): %s: PID %d refuses to die after signaling TERM/KILL' % (job_id, pid))","for sig in [15, 9]:
    try:
        os.killpg(pid, sig)
    except OSError as e:
        log.warning('_stop_pid(): %s: Got errno %s when attempting to signal %d to PID %d: %s' % (job_id, errno.errorcode[e.errno], sig, pid, e.strerror))
        return
    sleep(2)
    if not self._check_pid(pid):
        log.debug('_stop_pid(): %s: PID %d successfully killed with signal %d' % (job_id, pid, sig))
        return

log.warning('_stop_pid(): %s: PID %d refuses to die after signaling TERM/KILL' % (job_id, pid))
",0,TRUE,
kafka-python,https://github.com/dpkp/kafka-python/tree/master/kafka/client_async.py,KafkaClient,bootstrap_connected$955,"for node_id in self._conns:
    if not self.cluster.is_bootstrap(node_id):
        continue
    if self._conns[node_id].connected():
        return True
else:
    return False","for node_id in self._conns:
    if not self.cluster.is_bootstrap(node_id):
        continue
    if self._conns[node_id].connected():
        return True

return False
",0,TRUE,
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/flow/boykovkolmogorov.py,,boykov_kolmogorov_impl$161,"while v is not None:
    path.append(v)
    if v == s or v == t:
        base_dist = 0
        break
    elif timestamp[v] == time:
        base_dist = dist[v]
        break
    v = tree[v]
else:
    return False","flag_else = 1

while v is not None:
    path.append(v)
    if v == s or v == t:
        base_dist = 0
        flag_else = 0
        break
    elif timestamp[v] == time:
        base_dist = dist[v]
        flag_else = 0
        break
    v = tree[v]
if flag_else:
    return False",2,FALSE,
WeasyPrint,https://github.com/Kozea/WeasyPrint/tree/master/weasyprint/layout/preferred.py,,table_and_columns_preferred_widths$359,"for column in column_group.children:
    column_groups[column_number] = column_group
    columns[column_number] = column
    column_number += 1
    if column_number == grid_width:
        break
else:
    continue","flag_else = 1

for column in column_group.children:
    column_groups[column_number] = column_group
    columns[column_number] = column
    column_number += 1
    if column_number == grid_width:
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
warehouse,https://github.com/pypa/warehouse/tree/master/warehouse/forklift/legacy.py,,_is_valid_dist_file$624,"for zipname in zfp.namelist():
    parts = os.path.split(zipname)
    if len(parts) == 2 and parts[1] == 'WHEEL':
        break
else:
    return False","flag_else = 1

for zipname in zfp.namelist():
    parts = os.path.split(zipname)
    if len(parts) == 2 and parts[1] == 'WHEEL':
        flag_else = 0
        break
if flag_else:
    return False",1,FALSE,
thonny,https://github.com/thonny/thonny/tree/master/thonny/editors.py,EditorNotebook,indicate_modification$1018,"for editor in self.get_all_editors():
    if editor.is_modified():
        if mod != ('-modified', 1):
            self.winfo_toplevel().wm_attributes(*rest + ('-modified', 1))
        break
else:
    if mod == ('-modified', 1):
        self.winfo_toplevel().wm_attributes(*rest + ('-modified', 0))","flag_else = 1

for editor in self.get_all_editors():
    if editor.is_modified():
        if mod != ('-modified', 1):
            self.winfo_toplevel().wm_attributes(*rest + ('-modified', 1))
        flag_else = 0
        break
if flag_else:
    if mod == ('-modified', 1):
        self.winfo_toplevel().wm_attributes(*rest + ('-modified', 0))",1,FALSE,
pyusb,https://github.com/pyusb/pyusb/tree/master/usb/core.py,,find$1232,"for m in (libusb1, openusb, libusb0):
    backend = m.get_backend()
    if backend is not None:
        _logger.info('find(): using backend ""%s""', m.__name__)
        break
else:
    raise NoBackendError('No backend available')","flag_else = 1

for m in (libusb1, openusb, libusb0):
    backend = m.get_backend()
    if backend is not None:
        _logger.info('find(): using backend ""%s""', m.__name__)
        flag_else = 0
        break
if flag_else:
    raise NoBackendError('No backend available')",1,FALSE,
TauonMusicBox,https://github.com/Taiko2k/TauonMusicBox/tree/master/t_modules/t_main.py,QueueBox,play_now$37541,"for (i, item) in enumerate(pctl.force_queue):
    if item[5] == self.right_click_id:
        queue_item = item
        queue_index = i
        break
else:
    return","flag_else = 1

for (i, item) in enumerate(pctl.force_queue):
    if item[5] == self.right_click_id:
        queue_item = item
        queue_index = i
        flag_else = 0
        break
if flag_else:
    return",1,FALSE,
LightAutoML,https://github.com/sberbank-ai-lab/LightAutoML/tree/master/lightautoml/automl/base.py,AutoML,fit_predict$145,"for (k, ml_pipe) in enumerate(level):
    pipe_pred = ml_pipe.fit_predict(train_valid)
    level_predictions.append(pipe_pred)
    pipes.append(ml_pipe)
    logger.info('Time left {:.2f} secs\n'.format(self.timer.time_left))
    if self.timer.time_limit_exceeded():
        logger.info('Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n')
        flg_last_level = True
        break
else:
    if self.timer.child_out_of_time:
        logger.info('Time limit exceeded in one of the tasks. AutoML will blend level {0} models.\n'.format(leven_number))
        flg_last_level = True","flag_else = 1

for (k, ml_pipe) in enumerate(level):
    pipe_pred = ml_pipe.fit_predict(train_valid)
    level_predictions.append(pipe_pred)
    pipes.append(ml_pipe)
    logger.info('Time left {:.2f} secs\n'.format(self.timer.time_left))
    if self.timer.time_limit_exceeded():
        logger.info('Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n')
        flg_last_level = True
        flag_else = 0
        break
if flag_else:
    if self.timer.child_out_of_time:
        logger.info('Time limit exceeded in one of the tasks. AutoML will blend level {0} models.\n'.format(leven_number))
        flg_last_level = True",1,FALSE,
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/isomorphism/matchhelpers.py,,generic_multiedge_match$294,"for (xi, yi) in zip(values1, vals2):
    if not all(map(lambda x, y, z: z(x, y), xi, yi, op)):
        break
else:
    return True","flag_else = 1

for (xi, yi) in zip(values1, vals2):
    if not all(map(lambda x, y, z: z(x, y), xi, yi, op)):
        flag_else = 0
        break
if flag_else:
    return True",1,FALSE,
neutron,https://github.com/openstack/neutron/tree/master/neutron/agent/linux/interface.py,OVSInterfaceDriver,_set_device_address$338,"for i in range(9):
    try:
        device.link.set_address(mac_address)
        break
    except RuntimeError as e:
        LOG.warning('Got error trying to set mac, retrying: %s', str(e))
        time.sleep(1)
else:
    device.link.set_address(mac_address)","flag_else = 1

for i in range(9):
    try:
        device.link.set_address(mac_address)
        flag_else = 0
        break
    except RuntimeError as e:
        LOG.warning('Got error trying to set mac, retrying: %s', str(e))
        time.sleep(1)
if flag_else:
    device.link.set_address(mac_address)",1,FALSE,
anaconda,https://github.com/DamnWidget/anaconda/tree/master/anaconda_lib/jedi/inference/imports.py,,import_module$361,"for path in paths:
    if not isinstance(path, list):
        path = [path]
    (file_io_or_ns, is_pkg) = inference_state.compiled_subprocess.get_module_info(string=import_names[-1], path=path, full_name=module_name, is_global_search=False)
    if is_pkg is not None:
        break
else:
    return NO_VALUES","flag_else = 1

for path in paths:
    if not isinstance(path, list):
        path = [path]
    (file_io_or_ns, is_pkg) = inference_state.compiled_subprocess.get_module_info(string=import_names[-1], path=path, full_name=module_name, is_global_search=False)
    if is_pkg is not None:
        flag_else = 0
        break
if flag_else:
    return NO_VALUES",1,FALSE,
swift,https://github.com/openstack/swift/tree/master/test/probe/test_object_partpower_increase.py,TestPartPowerIncrease,_test_main$89,"for dev_root in self.devices:
    if loc.startswith(dev_root):
        break
else:
    self.fail('Unable to find device for %s' % loc)","flag_else = 1

for dev_root in self.devices:
    if loc.startswith(dev_root):
        flag_else = 0
        break
if flag_else:
    self.fail('Unable to find device for %s' % loc)",1,FALSE,
Growler,https://github.com/pyGrowler/Growler/tree/master/growler/middleware/renderer.py,Renderer,__call__$42,"for engine in self.engines:
    filename = engine.find_template_filename(template)
    if filename:
        if obj:
            self.res.locals.update(obj)
        html = engine.render_source(filename, self.res.locals)
        self.res.send_html(html)
        break
else:
    raise ValueError(""Could not find a template with name '%s'"" % template)","flag_else = 1

for engine in self.engines:
    filename = engine.find_template_filename(template)
    if filename:
        if obj:
            self.res.locals.update(obj)
        html = engine.render_source(filename, self.res.locals)
        self.res.send_html(html)
        flag_else = 0
        break
if flag_else:
    raise ValueError(""Could not find a template with name '%s'"" % template)",1,FALSE,
pyinfra,https://github.com/Fizzadar/pyinfra/tree/master/pyinfra/operations/lxd.py,,get_container_named$10,"for container in containers:
    if container['name'] == name:
        return container
else:
    return None","for container in containers:
    if container['name'] == name:
        return container

return None
",0,TRUE,
sfepy,https://github.com/sfepy/sfepy/tree/master/sfepy/discrete/fem/meshio.py,ANSYSCDBMeshIO,guess$1706,"for ii in range(1000):
    row = fd.readline()
    if not row:
        break
    if len(row) == 0:
        continue
    row = row.split(',')
    kw = row[0].lower()
    if kw == 'nblock':
        ok = True
        break
else:
    ok = False","flag_else = 1

for ii in range(1000):
    row = fd.readline()
    if not row:
        flag_else = 0
        break
    if len(row) == 0:
        continue
    row = row.split(',')
    kw = row[0].lower()
    if kw == 'nblock':
        ok = True
        flag_else = 0
        break
if flag_else:
    ok = False",2,FALSE,
nengo,https://github.com/nengo/nengo/tree/master/nengo/network.py,Network,add$113,"for cls in type(obj).__mro__:
    if cls in network.objects:
        network.objects[cls].append(obj)
        break
else:
    raise NetworkContextError(f""Objects of type '{type(obj).__name__}' cannot be added to networks."")","flag_else = 1

for cls in type(obj).__mro__:
    if cls in network.objects:
        network.objects[cls].append(obj)
        flag_else = 0
        break
if flag_else:
    raise NetworkContextError(f""Objects of type '{type(obj).__name__}' cannot be added to networks."")",1,FALSE,
LibCST,https://github.com/Instagram/LibCST/tree/master/libcst/matchers/_visitors.py,,_verify_parameter_annotations$165,"for annotation in possible_annotated_classes:
    if issubclass(match, annotation):
        break
else:
    raise MatchDecoratorMismatch(meth.__qualname__, f'@{decorator_name} can be called with {match.__name__} ' + 'but the decorated function parameter annotations do ' + 'not include this type.')","flag_else = 1

for annotation in possible_annotated_classes:
    if issubclass(match, annotation):
        flag_else = 0
        break
if flag_else:
    raise MatchDecoratorMismatch(meth.__qualname__, f'@{decorator_name} can be called with {match.__name__} ' + 'but the decorated function parameter annotations do ' + 'not include this type.')",1,FALSE,
trinity,https://github.com/ethereum/trinity/tree/master/trinity/_utils/ipc.py,,wait_for_ipc$14,"while time.monotonic() - start_at < timeout:
    if ipc_path.exists():
        return
    else:
        time.sleep(0.05)
else:
    raise TimeoutError('IPC socket file has not appeared in %d seconds!' % timeout)","while time.monotonic() - start_at < timeout:
    if ipc_path.exists():
        return
    else:
        time.sleep(0.05)

raise TimeoutError('IPC socket file has not appeared in %d seconds!' % timeout)
",0,TRUE,
dpark,https://github.com/douban/dpark/tree/master/dpark/utils/frame.py,Scope,get_callsite$94,"for (i, lasti) in enumerate(calls):
    if lasti == caller.lasti:
        seq = i
        break
else:
    seq = i + 1
    calls.append(caller.lasti)","flag_else = 1

for (i, lasti) in enumerate(calls):
    if lasti == caller.lasti:
        seq = i
        flag_else = 0
        break
if flag_else:
    seq = i + 1
    calls.append(caller.lasti)",1,FALSE,
unmanic,https://github.com/Unmanic/unmanic/tree/master/unmanic/libs/unffmpeg/hardware_acceleration_handle.py,HardwareAccelerationHandle,list_available_cuda_decoders$151,"for libname in libnames:
    try:
        cuda = ctypes.CDLL(libname)
    except OSError:
        continue
    else:
        break
else:
    return decoders","flag_else = 1

for libname in libnames:
    try:
        cuda = ctypes.CDLL(libname)
    except OSError:
        continue
    else:
        flag_else = 0
        break
if flag_else:
    return decoders",1,FALSE,
marshmallow,https://github.com/marshmallow-code/marshmallow/tree/master/src/marshmallow/schema.py,SchemaMeta,__new__$90,"for base_ in bases:
    if hasattr(base_, 'Meta') and hasattr(base_.Meta, 'ordered'):
        ordered = base_.Meta.ordered
        break
else:
    ordered = False","flag_else = 1

for base_ in bases:
    if hasattr(base_, 'Meta') and hasattr(base_.Meta, 'ordered'):
        ordered = base_.Meta.ordered
        flag_else = 0
        break
if flag_else:
    ordered = False",1,FALSE,
cachebrowser,https://github.com/CacheBrowser/cachebrowser/tree/master/cachebrowser/pipes/scrambler.py,,clean_netname$512,"for org in ORGS:
    if any([x in lower for x in org[1]]):
        return org[0]
else:
    org = netname.split()[0]
    parts = org.split('-')
    if len(parts) < 3:
        org = parts[0]
    elif parts[1].isdigit():
        org = parts[0]
    else:
        org = parts[0] + '-' + parts[1]","for org in ORGS:
    if any([x in lower for x in org[1]]):
        return org[0]

org = netname.split()[0]
parts = org.split('-')
if len(parts) < 3:
    org = parts[0]
elif parts[1].isdigit():
    org = parts[0]
else:
    org = parts[0] + '-' + parts[1]
",0,TRUE,
PaddleHub,https://github.com/PaddlePaddle/PaddleHub/tree/master/modules/text/lexical_analysis/lac/ahocorasick.py,Ahocorasick,search$71,"while word not in p.next:
    if p == self.__root:
        break
    p = p.fail
else:
    p = p.next[word]
    if p.length > 0:
        result.append((current_position - p.length + 1, current_position))","flag_else = 1

while word not in p.next:
    if p == self.__root:
        flag_else = 0
        break
    p = p.fail
if flag_else:
    p = p.next[word]
    if p.length > 0:
        result.append((current_position - p.length + 1, current_position))",1,FALSE,
MxShop,https://github.com/derek-zhang123/MxShop/tree/master/extra_apps/rest_framework/pagination.py,CursorPagination,get_previous_link$638,"for item in self.page:
    position = self._get_position_from_instance(item, self.ordering)
    if position != compare:
        break
    compare = position
    offset += 1
else:
    if not self.has_next:
        offset = self.page_size
        position = None
    elif self.cursor.reverse:
        offset = self.cursor.offset + self.page_size
        position = self.next_position
    else:
        offset = 0
        position = self.next_position","flag_else = 1

for item in self.page:
    position = self._get_position_from_instance(item, self.ordering)
    if position != compare:
        flag_else = 0
        break
    compare = position
    offset += 1
if flag_else:
    if not self.has_next:
        offset = self.page_size
        position = None
    elif self.cursor.reverse:
        offset = self.cursor.offset + self.page_size
        position = self.next_position
    else:
        offset = 0
        position = self.next_position",1,FALSE,
neutron,https://github.com/openstack/neutron/tree/master/neutron/plugins/ml2/drivers/type_vlan.py,VlanTypeDriver,allocate_tenant_segment$271,"for physnet in ranges:
    filters['physical_network'] = physnet
    alloc = self.allocate_partially_specified_segment(context, **filters)
    if alloc:
        break
else:
    return","flag_else = 1

for physnet in ranges:
    filters['physical_network'] = physnet
    alloc = self.allocate_partially_specified_segment(context, **filters)
    if alloc:
        flag_else = 0
        break
if flag_else:
    return",1,FALSE,
salt,https://github.com/saltstack/salt/tree/master/salt/modules/yumpkg.py,,latest_version$505,"for pkg in (x for x in updates if x.name == name):
    if pkg.arch == 'noarch' or pkg.arch == arch or salt.utils.pkg.rpm.check_32(pkg.arch):
        if _check_cur(pkg):
            ret[name] = pkg.version
            break
else:
    ret[name] = ''","flag_else = 1

for pkg in (x for x in updates if x.name == name):
    if pkg.arch == 'noarch' or pkg.arch == arch or salt.utils.pkg.rpm.check_32(pkg.arch):
        if _check_cur(pkg):
            ret[name] = pkg.version
            flag_else = 0
            break
if flag_else:
    ret[name] = ''",1,FALSE,
guiscrcpy,https://github.com/srevinsaju/guiscrcpy/tree/master/guiscrcpy/launcher.py,InterfaceGuiscrcpy,scan_devices_update_list_view$620,"for paired_device in paired_devices:
    if paired_device.text().split()[0] == i['model']:
        self.logger.info('Paired device detected {}'.format(i['identifier']))
        paired = True
        devices_view_list_item = paired_device
        self.remove_device_device_view(i['identifier'], statuses=['offline', 'unauthorized'])
        break
    elif paired_device.text().split()[1] == i['identifier']:
        self.logger.info('Device detected, but unpaired {}'.format(i['identifier']))
        self.remove_device_device_view(i['identifier'], statuses=['offline', 'unauthorized'])
        devices_view_list_item = QListWidgetItem()
        paired = False
        break
else:
    self.logger.debug(""Couldn't find any device"")
    paired = False
    devices_view_list_item = QListWidgetItem()","flag_else = 1

for paired_device in paired_devices:
    if paired_device.text().split()[0] == i['model']:
        self.logger.info('Paired device detected {}'.format(i['identifier']))
        paired = True
        devices_view_list_item = paired_device
        self.remove_device_device_view(i['identifier'], statuses=['offline', 'unauthorized'])
        flag_else = 0
        break
    elif paired_device.text().split()[1] == i['identifier']:
        self.logger.info('Device detected, but unpaired {}'.format(i['identifier']))
        self.remove_device_device_view(i['identifier'], statuses=['offline', 'unauthorized'])
        devices_view_list_item = QListWidgetItem()
        paired = False
        flag_else = 0
        break
if flag_else:
    self.logger.debug(""Couldn't find any device"")
    paired = False
    devices_view_list_item = QListWidgetItem()",2,FALSE,
freeipa,https://github.com/freeipa/freeipa/tree/master/ipaserver/install/ipa_restore.py,Restore,run$248,"for (instance, backend) in databases:
    if backend == options.backend:
        break
else:
    raise admintool.ScriptError('Backend %s not found in backup' % options.backend)","flag_else = 1

for (instance, backend) in databases:
    if backend == options.backend:
        flag_else = 0
        break
if flag_else:
    raise admintool.ScriptError('Backend %s not found in backup' % options.backend)",1,FALSE,
action-detection,https://github.com/yjxiong/action-detection/tree/master/ops/sequence_funcs.py,,build_box_by_search$101,"for y in range(x + 1, len(up)):
    if y < len(down) and signal[up[y]] > s:
        boxes.append((up[x], down[y - 1] + 1, cls, sum(frm_scores[up[x]:down[y - 1] + 1])))
        break
else:
    boxes.append((up[x], down[-1] + 1, cls, sum(frm_scores[up[x]:down[-1] + 1])))","flag_else = 1

for y in range(x + 1, len(up)):
    if y < len(down) and signal[up[y]] > s:
        boxes.append((up[x], down[y - 1] + 1, cls, sum(frm_scores[up[x]:down[y - 1] + 1])))
        flag_else = 0
        break
if flag_else:
    boxes.append((up[x], down[-1] + 1, cls, sum(frm_scores[up[x]:down[-1] + 1])))",1,FALSE,
contextualbandits,https://github.com/david-cortes/contextualbandits/tree/master/contextualbandits/online.py,_BasePolicy,_get_drop_ix$180,"for choice in range(self.nchoices):
    if self.choice_names[choice] == arm_name:
        drop_ix = choice
        break
else:
    raise ValueError(""No arm named '"", str(arm_name), ""' - current names are stored in attribute 'choice_names'."")","flag_else = 1

for choice in range(self.nchoices):
    if self.choice_names[choice] == arm_name:
        drop_ix = choice
        flag_else = 0
        break
if flag_else:
    raise ValueError(""No arm named '"", str(arm_name), ""' - current names are stored in attribute 'choice_names'."")",1,FALSE,
electrum,https://github.com/spesmilo/electrum/tree/master/electrum/gui/qt/network_dialog.py,TorDetector,run$462,"for p in ports:
    net_addr = ('127.0.0.1', p)
    if TorDetector.is_tor_port(net_addr):
        self.found_proxy.emit(net_addr)
        break
else:
    self.found_proxy.emit(None)","flag_else = 1

for p in ports:
    net_addr = ('127.0.0.1', p)
    if TorDetector.is_tor_port(net_addr):
        self.found_proxy.emit(net_addr)
        flag_else = 0
        break
if flag_else:
    self.found_proxy.emit(None)",1,FALSE,
falcon,https://github.com/falconry/falcon/tree/master/e2e-tests/conftest.py,,base_url$30,"for attempt in range(3):
    try:
        resp = requests.get(f'{base_url}/ping', timeout=1)
        resp.raise_for_status()
        break
    except requests.exceptions.RequestException:
        pass
    time.sleep(attempt + 0.5)
else:
    pytest.fail('Could not start Uvicorn')","flag_else = 1

for attempt in range(3):
    try:
        resp = requests.get(f'{base_url}/ping', timeout=1)
        resp.raise_for_status()
        flag_else = 0
        break
    except requests.exceptions.RequestException:
        pass
    time.sleep(attempt + 0.5)
if flag_else:
    pytest.fail('Could not start Uvicorn')",1,FALSE,
xonsh,https://github.com/xonsh/xonsh/tree/master/xonsh/ply/ply/cpp.py,Preprocessor,include$798,"while i < len(tokens):
    if tokens[i].value == '>':
        break
    i += 1
else:
    print('Malformed #include <...>')
    return","flag_else = 1

while i < len(tokens):
    if tokens[i].value == '>':
        flag_else = 0
        break
    i += 1
if flag_else:
    print('Malformed #include <...>')
    return",1,FALSE,
ldap3,https://github.com/cannatag/ldap3/tree/master/ldap3/core/connection.py,Connection,_get_entries$1562,"for object_def in object_defs:
    if resp_attr_set <= object_def[0]:
        entry = object_def[2]._create_entry(response)
        entries.append(entry)
        break
else:
    self.last_error = 'attribute set not found for ' + str(resp_attr_set)
    if log_enabled(ERROR):
        log(ERROR, self.last_error, self)
    raise LDAPObjectError(self.last_error)","flag_else = 1

for object_def in object_defs:
    if resp_attr_set <= object_def[0]:
        entry = object_def[2]._create_entry(response)
        entries.append(entry)
        flag_else = 0
        break
if flag_else:
    self.last_error = 'attribute set not found for ' + str(resp_attr_set)
    if log_enabled(ERROR):
        log(ERROR, self.last_error, self)
    raise LDAPObjectError(self.last_error)",1,FALSE,
dataclasses-json,https://github.com/lidatong/dataclasses-json/tree/master/dataclasses_json/mm.py,_UnionField,_deserialize$96,"for (type_, schema_) in self.desc.items():
    if isinstance(tmp_value, _get_type_origin(type_)):
        return schema_._deserialize(tmp_value, attr, data, **kwargs)
else:
    warnings.warn(f'The type ""{type(tmp_value).__name__}"" (value: ""{tmp_value}"") is not in the list of possible types of typing.Union (dataclass: {self.cls.__name__}, field: {self.field.name}). Value cannot be deserialized properly.')","for (type_, schema_) in self.desc.items():
    if isinstance(tmp_value, _get_type_origin(type_)):
        return schema_._deserialize(tmp_value, attr, data, **kwargs)

warnings.warn(f'The type ""{type(tmp_value).__name__}"" (value: ""{tmp_value}"") is not in the list of possible types of typing.Union (dataclass: {self.cls.__name__}, field: {self.field.name}). Value cannot be deserialized properly.')
",0,TRUE,
taurus,https://github.com/Blazemeter/taurus/tree/master/bzt/modules/provisioning.py,Local,_get_start_shift$42,"for time_format in time_formats:
    try:
        date = datetime.datetime.strptime(shift, time_format)
    except ValueError:
        continue
    except TypeError:
        self.log.warning('Start time must be string type (""%s""), ignored ""%s""', time_format[0], shift)
        break
    today = datetime.date.today()
    if today > date.date():
        date = datetime.datetime(today.year, today.month, today.day, date.hour, date.minute, date.second)
    return time.mktime(date.timetuple()) - self.start_time
else:
    self.log.warning('Unrecognized time format: %s (""%s"" required), ignored', shift, time_formats[0])","flag_else = 1

for time_format in time_formats:
    try:
        date = datetime.datetime.strptime(shift, time_format)
    except ValueError:
        continue
    except TypeError:
        self.log.warning('Start time must be string type (""%s""), ignored ""%s""', time_format[0], shift)
        flag_else = 0
        break
    today = datetime.date.today()
    if today > date.date():
        date = datetime.datetime(today.year, today.month, today.day, date.hour, date.minute, date.second)
    return time.mktime(date.timetuple()) - self.start_time
if flag_else:
    self.log.warning('Unrecognized time format: %s (""%s"" required), ignored', shift, time_formats[0])",1,FALSE,
ansible-runner,https://github.com/ansible/ansible-runner/tree/master/test/integration/containerized/test_container_management.py,CancelStandIn,cancel$32,"for i in range(5):
    if is_running(self.cli, self.runtime, self.container_name):
        break
    time.sleep(0.2)
else:
    print(self.cli([self.runtime, 'ps', '-a'], bare=True).stdout)
    raise Exception('Never spawned expected container')","flag_else = 1

for i in range(5):
    if is_running(self.cli, self.runtime, self.container_name):
        flag_else = 0
        break
    time.sleep(0.2)
if flag_else:
    print(self.cli([self.runtime, 'ps', '-a'], bare=True).stdout)
    raise Exception('Never spawned expected container')",1,FALSE,
lektor,https://github.com/lektor/lektor/tree/master/lektor/environment/config.py,,update_config_from_ini$63,"for (alt, alt_data) in config['ALTERNATIVES'].items():
    if alt_data['primary']:
        config['PRIMARY_ALTERNATIVE'] = alt
        break
else:
    if config['ALTERNATIVES']:
        raise RuntimeError('Alternatives defined but no primary set.')","flag_else = 1

for (alt, alt_data) in config['ALTERNATIVES'].items():
    if alt_data['primary']:
        config['PRIMARY_ALTERNATIVE'] = alt
        flag_else = 0
        break
if flag_else:
    if config['ALTERNATIVES']:
        raise RuntimeError('Alternatives defined but no primary set.')",1,FALSE,
sopel,https://github.com/sopel-irc/sopel/tree/master/sopel/modules/tell.py,,_format_safe_lstrip$133,"while pos < len(text):
    is_whitespace = unicodedata.category(text[pos]) == 'Zs'
    is_non_printing = text[pos] in formatting.CONTROL_NON_PRINTING and text[pos] not in formatting.CONTROL_FORMATTING
    if not is_whitespace and (not is_non_printing):
        start = pos
        break
    pos += 1
else:
    return ''","flag_else = 1

while pos < len(text):
    is_whitespace = unicodedata.category(text[pos]) == 'Zs'
    is_non_printing = text[pos] in formatting.CONTROL_NON_PRINTING and text[pos] not in formatting.CONTROL_FORMATTING
    if not is_whitespace and (not is_non_printing):
        start = pos
        flag_else = 0
        break
    pos += 1
if flag_else:
    return ''",1,FALSE,
mopidy,https://github.com/mopidy/mopidy/tree/master/mopidy/config/keyring.py,,_collection$145,"for name in ('aliases/default', 'collection/login', 'collection/session'):
    path = '/org/freedesktop/secrets/' + name
    if _collection_exists(bus, path):
        break
else:
    return None","flag_else = 1

for name in ('aliases/default', 'collection/login', 'collection/session'):
    path = '/org/freedesktop/secrets/' + name
    if _collection_exists(bus, path):
        flag_else = 0
        break
if flag_else:
    return None",1,FALSE,
you-get,https://github.com/soimort/you-get/tree/master/src/you_get/processor/join_flv.py,ECMAObject,set$41,"for i in range(len(self.data)):
    if self.data[i][0] == k:
        self.data[i] = (k, v)
        break
else:
    raise KeyError(k)","flag_else = 1

for i in range(len(self.data)):
    if self.data[i][0] == k:
        self.data[i] = (k, v)
        flag_else = 0
        break
if flag_else:
    raise KeyError(k)",1,FALSE,
jellyfin-kodi,https://github.com/jellyfin/jellyfin-kodi/tree/master/jellyfin_kodi/objects/music.py,Music,remove$470,"for song in self.jellyfin_db.get_item_by_parent_id(*values(obj, QUEM.get_item_by_parent_song_obj)):
    self.remove_song(song[1], obj['Id'])
else:
    self.jellyfin_db.remove_items_by_parent_id(*values(obj, QUEM.delete_item_by_parent_song_obj))","for song in self.jellyfin_db.get_item_by_parent_id(*values(obj, QUEM.get_item_by_parent_song_obj)):
    self.remove_song(song[1], obj['Id'])

self.jellyfin_db.remove_items_by_parent_id(*values(obj, QUEM.delete_item_by_parent_song_obj))
",0,TRUE,
distributed,https://github.com/dask/distributed/tree/master/distributed/_version.py,,run_command$71,"for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except FileNotFoundError:
        continue
    except OSError as e:
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print(f'unable to find command, tried {commands}')
    return (None, None)","flag_else = 1

for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except FileNotFoundError:
        continue
    except OSError as e:
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print(f'unable to find command, tried {commands}')
    return (None, None)",1,FALSE,
Mathics,https://github.com/mathics/Mathics/tree/master/mathics/builtin/string/operations.py,StringInsert,_insert$243,"for pos in listpos:
    stop = pos - 1
    result += str[start:stop] + add
    start = stop
else:
    result += str[start:len(str)]","for pos in listpos:
    stop = pos - 1
    result += str[start:stop] + add
    start = stop

result += str[start:len(str)]
",0,TRUE,
capirca,https://github.com/google/capirca/tree/master/tools/cgrep.py,,check_encapsulated$232,"for sec_obj in second:
    if obj.version == sec_obj.version:
        if obj.subnet_of(sec_obj):
            break
else:
    return False","flag_else = 1

for sec_obj in second:
    if obj.version == sec_obj.version:
        if obj.subnet_of(sec_obj):
            flag_else = 0
            break
if flag_else:
    return False",1,FALSE,
pyserial,https://github.com/pyserial/pyserial/tree/master/serial/rfc2217.py,Serial,get_modem_state$898,"while not timeout.expired():
    time.sleep(0.05)
    if not self._modemstate_timeout.expired():
        break
else:
    if self.logger:
        self.logger.warning('poll for modem state failed')","flag_else = 1

while not timeout.expired():
    time.sleep(0.05)
    if not self._modemstate_timeout.expired():
        flag_else = 0
        break
if flag_else:
    if self.logger:
        self.logger.warning('poll for modem state failed')",1,FALSE,
aptsources-cleanup,https://github.com/davidfoerster/aptsources-cleanup/tree/master/src/aptsources_cleanup/util/strings.py,,_lstrip_start$128,"for prefix in prefixes:
    step = start + len(prefix)
    if start < step <= stop and s.find(prefix, start, step) >= 0:
        start = step
        break
else:
    break","flag_else = 1

for prefix in prefixes:
    step = start + len(prefix)
    if start < step <= stop and s.find(prefix, start, step) >= 0:
        start = step
        flag_else = 0
        break
if flag_else:
    break",1,FALSE,
viewflow,https://github.com/viewflow/viewflow/tree/master/viewflow/fsm.py,SuperTransitionDescriptor,get_descriptor$126,"for cls in instance.__class__.__mro__:
    if hasattr(cls, self.name):
        super_descriptor = getattr(cls, self.name)
        if not isinstance(super_descriptor, SuperTransitionDescriptor):
            break
else:
    raise ValueError('Base transition not found for {}'.format(self.name))","flag_else = 1

for cls in instance.__class__.__mro__:
    if hasattr(cls, self.name):
        super_descriptor = getattr(cls, self.name)
        if not isinstance(super_descriptor, SuperTransitionDescriptor):
            flag_else = 0
            break
if flag_else:
    raise ValueError('Base transition not found for {}'.format(self.name))",1,FALSE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/polys/matrices/dense.py,,ddm_idet$156,"for i in range(k + 1, n):
    if a[i][k]:
        (a[k], a[i]) = (a[i], a[k])
        uf = -uf
        break
else:
    return K.zero","flag_else = 1

for i in range(k + 1, n):
    if a[i][k]:
        (a[k], a[i]) = (a[i], a[k])
        uf = -uf
        flag_else = 0
        break
if flag_else:
    return K.zero",1,FALSE,
pandas-datareader,https://github.com/pydata/pandas-datareader/tree/master/pandas_datareader/_version.py,,run_command$71,"for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)","flag_else = 1

for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)",1,FALSE,
pwncat,https://github.com/calebstewart/pwncat/tree/master/pwncat/platform/linux.py,Linux,get_host_hash$725,"for line in ip_out.split('\n'):
    if 'link/ether' in line and '00:00:00:00:00:00' not in line:
        mac = line.split('link/ether ')[1].split(' ')[0]
        break
else:
    mac = None","flag_else = 1

for line in ip_out.split('\n'):
    if 'link/ether' in line and '00:00:00:00:00:00' not in line:
        mac = line.split('link/ether ')[1].split(' ')[0]
        flag_else = 0
        break
if flag_else:
    mac = None",1,FALSE,
openpifpaf,https://github.com/openpifpaf/openpifpaf/tree/master/src/openpifpaf/_version.py,,run_command$73,"for command in commands:
    try:
        dispcmd = str([command] + args)
        process = subprocess.Popen([command] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None, **popen_kwargs)
        break
    except OSError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)","flag_else = 1

for command in commands:
    try:
        dispcmd = str([command] + args)
        process = subprocess.Popen([command] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None, **popen_kwargs)
        flag_else = 0
        break
    except OSError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)",1,FALSE,
spaCy,https://github.com/explosion/spaCy/tree/master/spacy/lang/lex_attrs.py,,like_url$90,"for i in range(len(text)):
    if text[i] == '.':
        break
else:
    return False","flag_else = 1

for i in range(len(text)):
    if text[i] == '.':
        flag_else = 0
        break
if flag_else:
    return False",1,FALSE,
blaze,https://github.com/blaze/blaze/tree/master//versioneer.py,,run_command$436,"for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return None
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return None","flag_else = 1

for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return None
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return None",1,FALSE,
joycontrol,https://github.com/mart1nro/joycontrol/tree/master/joycontrol/device.py,HidDevice,__init__$15,"for (path, ifaces) in manager.GetManagedObjects().items():
    adapter_info = ifaces.get('org.bluez.Adapter1')
    if adapter_info is None:
        continue
    elif device_id is None or device_id == adapter_info['Address'] or path.endswith(str(device_id)):
        obj = bus.get_object('org.bluez', path)
        self.adapter = dbus.Interface(obj, 'org.bluez.Adapter1')
        self.address = adapter_info['Address']
        self._adapter_name = path.split('/')[-1]
        self.properties = dbus.Interface(self.adapter, 'org.freedesktop.DBus.Properties')
        break
else:
    raise ValueError(f'Adapter {device_id} not found.')","flag_else = 1

for (path, ifaces) in manager.GetManagedObjects().items():
    adapter_info = ifaces.get('org.bluez.Adapter1')
    if adapter_info is None:
        continue
    elif device_id is None or device_id == adapter_info['Address'] or path.endswith(str(device_id)):
        obj = bus.get_object('org.bluez', path)
        self.adapter = dbus.Interface(obj, 'org.bluez.Adapter1')
        self.address = adapter_info['Address']
        self._adapter_name = path.split('/')[-1]
        self.properties = dbus.Interface(self.adapter, 'org.freedesktop.DBus.Properties')
        flag_else = 0
        break
if flag_else:
    raise ValueError(f'Adapter {device_id} not found.')",1,FALSE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/simplify/hyperexpand.py,Formula,find_instantiations$749,"for (bucket, obucket) in [(abuckets, symb_a), (bbuckets, symb_b)]:
    for mod in set(list(bucket.keys()) + list(obucket.keys())):
        if not mod in bucket or not mod in obucket or len(bucket[mod]) != len(obucket[mod]):
            break
        for (a, vals) in zip(self.symbols, critical_values):
            if repl[a].free_symbols:
                continue
            exprs = [expr for expr in obucket[mod] if expr.has(a)]
            repl0 = repl.copy()
            repl0[a] += _n
            for expr in exprs:
                for target in bucket[mod]:
                    (n0,) = solve(expr.xreplace(repl0) - target, _n)
                    if n0.free_symbols:
                        raise ValueError('Value should not be true')
                    vals.append(n0)
else:
    values = []
    for (a, vals) in zip(self.symbols, critical_values):
        a0 = repl[a]
        min_ = floor(min(vals))
        max_ = ceiling(max(vals))
        values.append([a0 + n for n in range(min_, max_ + 1)])
    result.extend((dict(list(zip(self.symbols, l))) for l in product(*values)))","for (bucket, obucket) in [(abuckets, symb_a), (bbuckets, symb_b)]:
    for mod in set(list(bucket.keys()) + list(obucket.keys())):
        if not mod in bucket or not mod in obucket or len(bucket[mod]) != len(obucket[mod]):
            break
        for (a, vals) in zip(self.symbols, critical_values):
            if repl[a].free_symbols:
                continue
            exprs = [expr for expr in obucket[mod] if expr.has(a)]
            repl0 = repl.copy()
            repl0[a] += _n
            for expr in exprs:
                for target in bucket[mod]:
                    (n0,) = solve(expr.xreplace(repl0) - target, _n)
                    if n0.free_symbols:
                        raise ValueError('Value should not be true')
                    vals.append(n0)

values = []
for (a, vals) in zip(self.symbols, critical_values):
    a0 = repl[a]
    min_ = floor(min(vals))
    max_ = ceiling(max(vals))
    values.append([a0 + n for n in range(min_, max_ + 1)])
result.extend((dict(list(zip(self.symbols, l))) for l in product(*values)))
",0,TRUE,
anaconda,https://github.com/DamnWidget/anaconda/tree/master/anaconda_lib/parso/pgen2/generator.py,,_make_dfas$160,"for nested_state in states:
    if nested_state.nfa_set == nfa_set:
        break
else:
    nested_state = DFAState(start.from_rule, nfa_set, finish)
    states.append(nested_state)","flag_else = 1

for nested_state in states:
    if nested_state.nfa_set == nfa_set:
        flag_else = 0
        break
if flag_else:
    nested_state = DFAState(start.from_rule, nfa_set, finish)
    states.append(nested_state)",1,FALSE,
PyTorch-NLP,https://github.com/PetrochukM/PyTorch-NLP/tree/master/torchnlp/encoders/text/subword_text_tokenizer.py,SubwordTextTokenizer,_escaped_token_to_subtoken_strings$236,"for end in six.moves.xrange(min(token_len, start + self._max_subtoken_len), start, -1):
    subtoken = escaped_token[start:end]
    if subtoken in self._all_subtoken_strings:
        ret.append(subtoken)
        start = end
        break
else:
    assert False, 'Token substring not found in subtoken vocabulary.'","flag_else = 1

for end in six.moves.xrange(min(token_len, start + self._max_subtoken_len), start, -1):
    subtoken = escaped_token[start:end]
    if subtoken in self._all_subtoken_strings:
        ret.append(subtoken)
        start = end
        flag_else = 0
        break
if flag_else:
    assert False, 'Token substring not found in subtoken vocabulary.'",1,FALSE,
anchore-engine,https://github.com/anchore/anchore-engine/tree/master/anchore_engine/apis/authorization.py,ExternalAuthorizationHandler,notify$737,"for i in range(retries):
    try:
        resp = fn(notification_value)
        if not resp:
            logger.warn('Bad response from authz service, will retry: {}'.format(resp))
        else:
            logger.debug('Notification succeeded to authz plugin service')
            break
    except Exception as ex:
        err = ex
        logger.exception('Error calling {} against authz plugin client'.format(fn.__name__))
else:
    logger.error('Could not confirm successful response of authz handler for notification {} with value {}'.format(notification_type, notification_value))
    raise Exception('Error invoking POST /domains on external authz handler: {}'.format(str(err) if err else 'Retry count exceeded {}'.format(retries)))","flag_else = 1

for i in range(retries):
    try:
        resp = fn(notification_value)
        if not resp:
            logger.warn('Bad response from authz service, will retry: {}'.format(resp))
        else:
            logger.debug('Notification succeeded to authz plugin service')
            flag_else = 0
            break
    except Exception as ex:
        err = ex
        logger.exception('Error calling {} against authz plugin client'.format(fn.__name__))
if flag_else:
    logger.error('Could not confirm successful response of authz handler for notification {} with value {}'.format(notification_type, notification_value))
    raise Exception('Error invoking POST /domains on external authz handler: {}'.format(str(err) if err else 'Retry count exceeded {}'.format(retries)))",1,FALSE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/core/expr.py,Expr,coeff$1378,"for i in range(0, len(l) - n + 1):
    if all((l[i + j] == sub[j] for j in range(n))):
        break
else:
    i = None","flag_else = 1

for i in range(0, len(l) - n + 1):
    if all((l[i + j] == sub[j] for j in range(n))):
        flag_else = 0
        break
if flag_else:
    i = None",1,FALSE,
Montreal-Forced-Aligner,https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/tree/master/tests/test_corpus.py,,test_speaker_groupings$311,"for file in files:
    if name == file.name:
        break
else:
    raise Exception(f'File {name} not loaded')","flag_else = 1

for file in files:
    if name == file.name:
        flag_else = 0
        break
if flag_else:
    raise Exception(f'File {name} not loaded')",1,FALSE,
highway-env,https://github.com/eleurent/highway-env/tree/master/highway_env/vehicle/controller.py,ControlledVehicle,get_routes_at_intersection$157,"for index in range(min(len(self.route), 3)):
    try:
        next_destinations = self.road.network.graph[self.route[index][1]]
    except KeyError:
        continue
    if len(next_destinations) >= 2:
        break
else:
    return [self.route]","flag_else = 1

for index in range(min(len(self.route), 3)):
    try:
        next_destinations = self.road.network.graph[self.route[index][1]]
    except KeyError:
        continue
    if len(next_destinations) >= 2:
        flag_else = 0
        break
if flag_else:
    return [self.route]",1,FALSE,
ANGRYsearch,https://github.com/DoTheEvo/ANGRYsearch/tree/master//angrysearch.py,ThreadDBUpdate,remove_excluded_dirs$394,"for z in to_ignore:
    if x == z['ign']:
        if z['case'] == 1:
            if root == z['up']:
                self.show_ignored(root, z['ign'])
                break
        elif z['case'] == 2:
            self.show_ignored(root, z['ign'])
            break
        elif z['case'] == 3:
            y = [k for k in root.split(b'/') if k]
            if y[-1] == z['up']:
                self.show_ignored(root, z['ign'])
                break
else:
    after_exclusion.append(x)","flag_else = 1

for z in to_ignore:
    if x == z['ign']:
        if z['case'] == 1:
            if root == z['up']:
                self.show_ignored(root, z['ign'])
                flag_else = 0
                break
        elif z['case'] == 2:
            self.show_ignored(root, z['ign'])
            flag_else = 0
            break
        elif z['case'] == 3:
            y = [k for k in root.split(b'/') if k]
            if y[-1] == z['up']:
                self.show_ignored(root, z['ign'])
                flag_else = 0
                break
if flag_else:
    after_exclusion.append(x)",3,FALSE,
pyzmq,https://github.com/zeromq/pyzmq/tree/master/zmq/devices/basedevice.py,Device,_reserve_random_port$159,"for i in range(5):
    port = binder.bind_to_random_port(addr, *args, **kwargs)
    new_addr = '%s:%i' % (addr, port)
    if new_addr in self._random_addrs:
        continue
    else:
        break
else:
    raise ZMQBindError('Could not reserve random port.')","flag_else = 1

for i in range(5):
    port = binder.bind_to_random_port(addr, *args, **kwargs)
    new_addr = '%s:%i' % (addr, port)
    if new_addr in self._random_addrs:
        continue
    else:
        flag_else = 0
        break
if flag_else:
    raise ZMQBindError('Could not reserve random port.')",1,FALSE,
mutagen,https://github.com/quodlibet/mutagen/tree/master/mutagen/id3/_tags.py,,determine_bpi$114,"while o < len(data) - 10:
    part = data[o:o + 10]
    if part == EMPTY:
        intoff = -((len(data) - o) % 10)
        break
    (name, size, flags) = struct.unpack('>4sLH', part)
    o += 10 + size
    try:
        name = name.decode('ascii')
    except UnicodeDecodeError:
        continue
    if name in frames:
        asint += 1
else:
    intoff = o - len(data)","flag_else = 1

while o < len(data) - 10:
    part = data[o:o + 10]
    if part == EMPTY:
        intoff = -((len(data) - o) % 10)
        flag_else = 0
        break
    (name, size, flags) = struct.unpack('>4sLH', part)
    o += 10 + size
    try:
        name = name.decode('ascii')
    except UnicodeDecodeError:
        continue
    if name in frames:
        asint += 1
if flag_else:
    intoff = o - len(data)",1,FALSE,
pyload,https://github.com/pyload/pyload/tree/master/src/pyload/plugins/downloaders/SimplyPremiumCom.py,SimplyPremiumCom,handle_premium$60,"for i in range(5):
    self.data = self.load('http://www.simply-premium.com/premium.php', get={'info': '', 'link': self.pyfile.url})
    if self.data:
        self.log_debug('JSON data: ' + self.data)
        break
else:
    self.log_info(self._('Unable to get API data, waiting 1 minute and retry'))
    self.retry(5, 60, self._('Unable to get API data'))","flag_else = 1

for i in range(5):
    self.data = self.load('http://www.simply-premium.com/premium.php', get={'info': '', 'link': self.pyfile.url})
    if self.data:
        self.log_debug('JSON data: ' + self.data)
        flag_else = 0
        break
if flag_else:
    self.log_info(self._('Unable to get API data, waiting 1 minute and retry'))
    self.retry(5, 60, self._('Unable to get API data'))",1,FALSE,
SpeedTorch,https://github.com/Santosh-Gupta/SpeedTorch/tree/master/SpeedTorch/CPUCupyPinned.py,COMMM,_preInit$318,"while os.path.isfile(diskself.disknamename + str(fileNumber) + 'memmap') == false:
    fileNumber = fileNumber + 1
else:
    self.fileName = self.diskname + str(fileNumber)","while os.path.isfile(diskself.disknamename + str(fileNumber) + 'memmap') == false:
    fileNumber = fileNumber + 1

self.fileName = self.diskname + str(fileNumber)
",0,TRUE,
joeynmt,https://github.com/joeynmt/joeynmt/tree/master/joeynmt/training.py,TrainManager,train_and_validate$361,"for epoch_no in range(self.epochs):
    logger.info('EPOCH %d', epoch_no + 1)
    if self.scheduler_step_at == 'epoch':
        self.scheduler.step(epoch=epoch_no)
    self.model.train()
    start = time.time()
    total_valid_duration = 0
    start_tokens = self.stats.total_tokens
    start_correct = self.stats.total_correct
    self.model.zero_grad()
    epoch_loss = 0
    total_batch_loss = 0
    if train_data.random_subset > 0:
        try:
            train_data.reset_random_subset()
            train_data.sample_random_subset(seed=epoch_no)
            logger.info('Sample random subset from dev set: n=%d, seed=%d', len(train_data), epoch_no)
        except AssertionError as e:
            logger.warning(e)
    batch: Batch
    for (i, batch) in enumerate(self.train_iter):
        batch.sort_by_src_length()
        norm_batch_loss = self._train_step(batch)
        total_batch_loss += norm_batch_loss
        if (i + 1) % self.batch_multiplier == 0:
            if self.clip_grad_fun is not None:
                self.clip_grad_fun(parameters=self.model.parameters())
            self.scaler.step(self.optimizer)
            self.scaler.update()
            if self.scheduler_step_at == 'step':
                self.scheduler.step(self.stats.steps)
            self.model.zero_grad()
            self.stats.steps += 1
            if self.stats.steps >= self.max_updates:
                self.stats.is_max_update = True
            if self.stats.steps % self.logging_freq == 0:
                elapsed = time.time() - start - total_valid_duration
                elapsed_tok = self.stats.total_tokens - start_tokens
                elapsed_correct = self.stats.total_correct - start_correct
                self.tb_writer.add_scalar('train/batch_loss', total_batch_loss, self.stats.steps)
                self.tb_writer.add_scalar('train/batch_acc', elapsed_correct / elapsed_tok, self.stats.steps)
                logger.info('Epoch %3d, Step: %8d, Batch Loss: %12.6f, Batch Acc: %.6f, Tokens per Sec: %8.0f, Lr: %.6f', epoch_no + 1, self.stats.steps, total_batch_loss, elapsed_correct / elapsed_tok, elapsed_tok / elapsed, self.optimizer.param_groups[0]['lr'])
                start = time.time()
                total_valid_duration = 0
                start_tokens = self.stats.total_tokens
                start_correct = self.stats.total_correct
            epoch_loss += total_batch_loss
            total_batch_loss = 0
            if self.stats.steps % self.validation_freq == 0:
                valid_duration = self._validate(valid_data)
                total_valid_duration += valid_duration
            current_lr = self.optimizer.param_groups[0]['lr']
            if current_lr < self.learning_rate_min:
                self.stats.is_min_lr = True
            self.tb_writer.add_scalar('train/learning_rate', current_lr, self.stats.steps)
        if self.stats.is_min_lr or self.stats.is_max_update:
            break
    if self.stats.is_min_lr or self.stats.is_max_update:
        log_str = f'minimum lr {self.learning_rate_min}' if self.stats.is_min_lr else f'maximum num. of updates {self.max_updates}'
        logger.info('Training ended since %s was reached.', log_str)
        break
    logger.info('Epoch %3d: total training loss %.2f', epoch_no + 1, epoch_loss)
else:
    logger.info('Training ended after %3d epochs.', epoch_no + 1)","flag_else = 1

for epoch_no in range(self.epochs):
    logger.info('EPOCH %d', epoch_no + 1)
    if self.scheduler_step_at == 'epoch':
        self.scheduler.step(epoch=epoch_no)
    self.model.train()
    start = time.time()
    total_valid_duration = 0
    start_tokens = self.stats.total_tokens
    start_correct = self.stats.total_correct
    self.model.zero_grad()
    epoch_loss = 0
    total_batch_loss = 0
    if train_data.random_subset > 0:
        try:
            train_data.reset_random_subset()
            train_data.sample_random_subset(seed=epoch_no)
            logger.info('Sample random subset from dev set: n=%d, seed=%d', len(train_data), epoch_no)
        except AssertionError as e:
            logger.warning(e)
    batch: Batch
    for (i, batch) in enumerate(self.train_iter):
        batch.sort_by_src_length()
        norm_batch_loss = self._train_step(batch)
        total_batch_loss += norm_batch_loss
        if (i + 1) % self.batch_multiplier == 0:
            if self.clip_grad_fun is not None:
                self.clip_grad_fun(parameters=self.model.parameters())
            self.scaler.step(self.optimizer)
            self.scaler.update()
            if self.scheduler_step_at == 'step':
                self.scheduler.step(self.stats.steps)
            self.model.zero_grad()
            self.stats.steps += 1
            if self.stats.steps >= self.max_updates:
                self.stats.is_max_update = True
            if self.stats.steps % self.logging_freq == 0:
                elapsed = time.time() - start - total_valid_duration
                elapsed_tok = self.stats.total_tokens - start_tokens
                elapsed_correct = self.stats.total_correct - start_correct
                self.tb_writer.add_scalar('train/batch_loss', total_batch_loss, self.stats.steps)
                self.tb_writer.add_scalar('train/batch_acc', elapsed_correct / elapsed_tok, self.stats.steps)
                logger.info('Epoch %3d, Step: %8d, Batch Loss: %12.6f, Batch Acc: %.6f, Tokens per Sec: %8.0f, Lr: %.6f', epoch_no + 1, self.stats.steps, total_batch_loss, elapsed_correct / elapsed_tok, elapsed_tok / elapsed, self.optimizer.param_groups[0]['lr'])
                start = time.time()
                total_valid_duration = 0
                start_tokens = self.stats.total_tokens
                start_correct = self.stats.total_correct
            epoch_loss += total_batch_loss
            total_batch_loss = 0
            if self.stats.steps % self.validation_freq == 0:
                valid_duration = self._validate(valid_data)
                total_valid_duration += valid_duration
            current_lr = self.optimizer.param_groups[0]['lr']
            if current_lr < self.learning_rate_min:
                self.stats.is_min_lr = True
            self.tb_writer.add_scalar('train/learning_rate', current_lr, self.stats.steps)
        if self.stats.is_min_lr or self.stats.is_max_update:
            break
    if self.stats.is_min_lr or self.stats.is_max_update:
        log_str = f'minimum lr {self.learning_rate_min}' if self.stats.is_min_lr else f'maximum num. of updates {self.max_updates}'
        logger.info('Training ended since %s was reached.', log_str)
        flag_else = 0
        break
    logger.info('Epoch %3d: total training loss %.2f', epoch_no + 1, epoch_loss)
if flag_else:
    logger.info('Training ended after %3d epochs.', epoch_no + 1)",1,FALSE,
tumblr-crawler,https://github.com/dixudx/tumblr-crawler/tree/master//tumblr-photo-video-ripper.py,DownloadWorker,_handle_medium_url$86,"for regex_rule in self.regex_rules:
    matched_url = regex_rule(video_player)
    if matched_url is not None:
        return matched_url
else:
    raise Exception","for regex_rule in self.regex_rules:
    matched_url = regex_rule(video_player)
    if matched_url is not None:
        return matched_url

raise Exception
",0,TRUE,
galaxy,https://github.com/ansible/galaxy/tree/master/lib/galaxy/web_stack/handlers.py,ConfiguresHandlers,_findall_with_required$204,"for attrib in attribs:
    if attrib not in elem.attrib:
        log.warning(f""required '{attrib}' attribute is missing from <{match}> element"")
        break
else:
    rval.append(elem)","flag_else = 1

for attrib in attribs:
    if attrib not in elem.attrib:
        log.warning(f""required '{attrib}' attribute is missing from <{match}> element"")
        flag_else = 0
        break
if flag_else:
    rval.append(elem)",1,FALSE,
POT,https://github.com/PythonOT/POT/tree/master/ot/bregman.py,,sinkhorn_stabilized$903,"for ii in range(numItermax):
    uprev = u
    vprev = v
    v = b / nx.dot(K.T, u)
    u = a / nx.dot(K, v)
    if nx.max(nx.abs(u)) > tau or nx.max(nx.abs(v)) > tau:
        if n_hists:
            (alpha, beta) = (alpha + reg * nx.max(nx.log(u), 1), beta + reg * nx.max(nx.log(v)))
        else:
            (alpha, beta) = (alpha + reg * nx.log(u), beta + reg * nx.log(v))
            if n_hists:
                u = nx.ones((dim_a, n_hists), type_as=M) / dim_a
                v = nx.ones((dim_b, n_hists), type_as=M) / dim_b
            else:
                u = nx.ones(dim_a, type_as=M) / dim_a
                v = nx.ones(dim_b, type_as=M) / dim_b
        K = get_K(alpha, beta)
    if ii % print_period == 0:
        if n_hists:
            err_u = nx.max(nx.abs(u - uprev))
            err_u /= max(nx.max(nx.abs(u)), nx.max(nx.abs(uprev)), 1.0)
            err_v = nx.max(nx.abs(v - vprev))
            err_v /= max(nx.max(nx.abs(v)), nx.max(nx.abs(vprev)), 1.0)
            err = 0.5 * (err_u + err_v)
        else:
            transp = get_Gamma(alpha, beta, u, v)
            err = nx.norm(nx.sum(transp, axis=0) - b)
        if log:
            log['err'].append(err)
        if verbose:
            if ii % (print_period * 20) == 0:
                print('{:5s}|{:12s}'.format('It.', 'Err') + '\n' + '-' * 19)
            print('{:5d}|{:8e}|'.format(ii, err))
    if err <= stopThr:
        break
    if nx.any(nx.isnan(u)) or nx.any(nx.isnan(v)):
        warnings.warn('Numerical errors at iteration %d' % ii)
        u = uprev
        v = vprev
        break
else:
    if warn:
        warnings.warn('Sinkhorn did not converge. You might want to increase the number of iterations `numItermax` or the regularization parameter `reg`.')","flag_else = 1

for ii in range(numItermax):
    uprev = u
    vprev = v
    v = b / nx.dot(K.T, u)
    u = a / nx.dot(K, v)
    if nx.max(nx.abs(u)) > tau or nx.max(nx.abs(v)) > tau:
        if n_hists:
            (alpha, beta) = (alpha + reg * nx.max(nx.log(u), 1), beta + reg * nx.max(nx.log(v)))
        else:
            (alpha, beta) = (alpha + reg * nx.log(u), beta + reg * nx.log(v))
            if n_hists:
                u = nx.ones((dim_a, n_hists), type_as=M) / dim_a
                v = nx.ones((dim_b, n_hists), type_as=M) / dim_b
            else:
                u = nx.ones(dim_a, type_as=M) / dim_a
                v = nx.ones(dim_b, type_as=M) / dim_b
        K = get_K(alpha, beta)
    if ii % print_period == 0:
        if n_hists:
            err_u = nx.max(nx.abs(u - uprev))
            err_u /= max(nx.max(nx.abs(u)), nx.max(nx.abs(uprev)), 1.0)
            err_v = nx.max(nx.abs(v - vprev))
            err_v /= max(nx.max(nx.abs(v)), nx.max(nx.abs(vprev)), 1.0)
            err = 0.5 * (err_u + err_v)
        else:
            transp = get_Gamma(alpha, beta, u, v)
            err = nx.norm(nx.sum(transp, axis=0) - b)
        if log:
            log['err'].append(err)
        if verbose:
            if ii % (print_period * 20) == 0:
                print('{:5s}|{:12s}'.format('It.', 'Err') + '\n' + '-' * 19)
            print('{:5d}|{:8e}|'.format(ii, err))
    if err <= stopThr:
        flag_else = 0
        break
    if nx.any(nx.isnan(u)) or nx.any(nx.isnan(v)):
        warnings.warn('Numerical errors at iteration %d' % ii)
        u = uprev
        v = vprev
        flag_else = 0
        break
if flag_else:
    if warn:
        warnings.warn('Sinkhorn did not converge. You might want to increase the number of iterations `numItermax` or the regularization parameter `reg`.')",2,FALSE,
netmiko,https://github.com/ktbyers/netmiko/tree/master/netmiko/base_connection.py,BaseConnection,send_command$1482,"while time.time() - start_time < read_timeout:
    if new_data:
        output += new_data
        past_three_reads.append(new_data)
        if not first_line_processed:
            (output, first_line_processed) = self._first_line_handler(output, search_pattern)
            if re.search(search_pattern, output):
                break
        elif re.search(search_pattern, ''.join(past_three_reads)):
            break
    time.sleep(loop_delay)
    new_data = self.read_channel()
else:
    msg = f'\nPattern not detected: {repr(search_pattern)} in output.\n\nThings you might try to fix this:\n1. Explicitly set your pattern using the expect_string argument.\n2. Increase the read_timeout to a larger value.\n\nYou can also look at the Netmiko session_log or debug log for more information.\n\n'
    raise ReadTimeout(msg)","flag_else = 1

while time.time() - start_time < read_timeout:
    if new_data:
        output += new_data
        past_three_reads.append(new_data)
        if not first_line_processed:
            (output, first_line_processed) = self._first_line_handler(output, search_pattern)
            if re.search(search_pattern, output):
                flag_else = 0
                break
        elif re.search(search_pattern, ''.join(past_three_reads)):
            flag_else = 0
            break
    time.sleep(loop_delay)
    new_data = self.read_channel()
if flag_else:
    msg = f'\nPattern not detected: {repr(search_pattern)} in output.\n\nThings you might try to fix this:\n1. Explicitly set your pattern using the expect_string argument.\n2. Increase the read_timeout to a larger value.\n\nYou can also look at the Netmiko session_log or debug log for more information.\n\n'
    raise ReadTimeout(msg)",2,FALSE,
HeyTapTask,https://github.com/Mashiro2000/HeyTapTask/tree/master/Backup/Community.py,,main_handler$210,"for count in range(3):
    try:
        time.sleep(random.randint(2, 5))
        community.start()
        break
    except requests.exceptions.ConnectionError:
        notify(f""{community.dic['user']}\t"")
        time.sleep(random.randint(2, 5))
        continue
else:
    notify(f"": {community.dic['user']}\n: n: "")","flag_else = 1

for count in range(3):
    try:
        time.sleep(random.randint(2, 5))
        community.start()
        flag_else = 0
        break
    except requests.exceptions.ConnectionError:
        notify(f""{community.dic['user']}\t"")
        time.sleep(random.randint(2, 5))
        continue
if flag_else:
    notify(f"": {community.dic['user']}\n: n: "")",1,FALSE,
youtube-dl,https://github.com/lrvick/youtube-dl/tree/master/youtube_dl/utils.py,,is_html$4314,"for (bom, enc) in BOMS:
    if first_bytes.startswith(bom):
        s = first_bytes[len(bom):].decode(enc, 'replace')
        break
else:
    s = first_bytes.decode('utf-8', 'replace')","flag_else = 1

for (bom, enc) in BOMS:
    if first_bytes.startswith(bom):
        s = first_bytes[len(bom):].decode(enc, 'replace')
        flag_else = 0
        break
if flag_else:
    s = first_bytes.decode('utf-8', 'replace')",1,FALSE,
salt,https://github.com/saltstack/salt/tree/master/salt/cloud/clouds/ec2.py,,wait_for_instance$2341,"for user in vm_['usernames']:
    if salt.utils.cloud.wait_for_passwd(host=ip_address, port=ssh_port, username=user, ssh_timeout=config.get_cloud_config_value('wait_for_passwd_timeout', vm_, __opts__, default=1 * 60), key_filename=vm_['key_filename'], display_ssh_output=display_ssh_output, gateway=ssh_gateway_config, maxtries=config.get_cloud_config_value('wait_for_passwd_maxtries', vm_, __opts__, default=15), known_hosts_file=config.get_cloud_config_value('known_hosts_file', vm_, __opts__, default='/dev/null')):
        __opts__['ssh_username'] = user
        vm_['ssh_username'] = user
        break
else:
    raise SaltCloudSystemExit('Failed to authenticate against remote ssh')","flag_else = 1

for user in vm_['usernames']:
    if salt.utils.cloud.wait_for_passwd(host=ip_address, port=ssh_port, username=user, ssh_timeout=config.get_cloud_config_value('wait_for_passwd_timeout', vm_, __opts__, default=1 * 60), key_filename=vm_['key_filename'], display_ssh_output=display_ssh_output, gateway=ssh_gateway_config, maxtries=config.get_cloud_config_value('wait_for_passwd_maxtries', vm_, __opts__, default=15), known_hosts_file=config.get_cloud_config_value('known_hosts_file', vm_, __opts__, default='/dev/null')):
        __opts__['ssh_username'] = user
        vm_['ssh_username'] = user
        flag_else = 0
        break
if flag_else:
    raise SaltCloudSystemExit('Failed to authenticate against remote ssh')",1,FALSE,
pywikibot,https://github.com/wikimedia/pywikibot/tree/master/tests/flow_thanks_tests.py,TestThankFlowPost,test_thank_post$31,"for post in reversed(topic.replies()):
    user = post.creator
    if site.user() == user.username:
        continue
    if user.is_thankable:
        break
else:
    self.skipTest(NO_THANKABLE_POSTS)","flag_else = 1

for post in reversed(topic.replies()):
    user = post.creator
    if site.user() == user.username:
        continue
    if user.is_thankable:
        flag_else = 0
        break
if flag_else:
    self.skipTest(NO_THANKABLE_POSTS)",1,FALSE,
ansible-modules-core,https://github.com/ansible/ansible-modules-core/tree/master/utilities/logic/wait_for.py,,main$390,"while datetime.datetime.now() < end:
    if path:
        try:
            os.stat(path)
        except OSError:
            e = get_exception()
            if e.errno != 2:
                elapsed = datetime.datetime.now() - start
                module.fail_json(msg='Failed to stat %s, %s' % (path, e.strerror), elapsed=elapsed.seconds)
        else:
            if not compiled_search_re:
                break
            try:
                f = open(path)
                try:
                    if re.search(compiled_search_re, f.read()):
                        break
                finally:
                    f.close()
            except IOError:
                pass
    elif port:
        alt_connect_timeout = math.ceil(_timedelta_total_seconds(end - datetime.datetime.now()))
        try:
            s = _create_connection(host, port, min(connect_timeout, alt_connect_timeout))
        except:
            pass
        else:
            if compiled_search_re:
                data = ''
                matched = False
                while datetime.datetime.now() < end:
                    max_timeout = math.ceil(_timedelta_total_seconds(end - datetime.datetime.now()))
                    (readable, w, e) = select.select([s], [], [], max_timeout)
                    if not readable:
                        continue
                    response = s.recv(1024)
                    if not response:
                        break
                    data += to_native(response, errors='surrogate_or_strict')
                    if re.search(compiled_search_re, data):
                        matched = True
                        break
                s.shutdown(socket.SHUT_RDWR)
                s.close()
                if matched:
                    break
            else:
                s.shutdown(socket.SHUT_RDWR)
                s.close()
                break
    time.sleep(params['sleep'])
else:
    elapsed = datetime.datetime.now() - start
    if port:
        if search_regex:
            module.fail_json(msg='Timeout when waiting for search string %s in %s:%s' % (search_regex, host, port), elapsed=elapsed.seconds)
        else:
            module.fail_json(msg='Timeout when waiting for %s:%s' % (host, port), elapsed=elapsed.seconds)
    elif path:
        if search_regex:
            module.fail_json(msg='Timeout when waiting for search string %s in %s' % (search_regex, path), elapsed=elapsed.seconds)
        else:
            module.fail_json(msg='Timeout when waiting for file %s' % path, elapsed=elapsed.seconds)","flag_else = 1

while datetime.datetime.now() < end:
    if path:
        try:
            os.stat(path)
        except OSError:
            e = get_exception()
            if e.errno != 2:
                elapsed = datetime.datetime.now() - start
                module.fail_json(msg='Failed to stat %s, %s' % (path, e.strerror), elapsed=elapsed.seconds)
        else:
            if not compiled_search_re:
                flag_else = 0
                break
            try:
                f = open(path)
                try:
                    if re.search(compiled_search_re, f.read()):
                        flag_else = 0
                        break
                finally:
                    f.close()
            except IOError:
                pass
    elif port:
        alt_connect_timeout = math.ceil(_timedelta_total_seconds(end - datetime.datetime.now()))
        try:
            s = _create_connection(host, port, min(connect_timeout, alt_connect_timeout))
        except:
            pass
        else:
            if compiled_search_re:
                data = ''
                matched = False
                while datetime.datetime.now() < end:
                    max_timeout = math.ceil(_timedelta_total_seconds(end - datetime.datetime.now()))
                    (readable, w, e) = select.select([s], [], [], max_timeout)
                    if not readable:
                        continue
                    response = s.recv(1024)
                    if not response:
                        break
                    data += to_native(response, errors='surrogate_or_strict')
                    if re.search(compiled_search_re, data):
                        matched = True
                        break
                s.shutdown(socket.SHUT_RDWR)
                s.close()
                if matched:
                    flag_else = 0
                    break
            else:
                s.shutdown(socket.SHUT_RDWR)
                s.close()
                flag_else = 0
                break
    time.sleep(params['sleep'])
if flag_else:
    elapsed = datetime.datetime.now() - start
    if port:
        if search_regex:
            module.fail_json(msg='Timeout when waiting for search string %s in %s:%s' % (search_regex, host, port), elapsed=elapsed.seconds)
        else:
            module.fail_json(msg='Timeout when waiting for %s:%s' % (host, port), elapsed=elapsed.seconds)
    elif path:
        if search_regex:
            module.fail_json(msg='Timeout when waiting for search string %s in %s' % (search_regex, path), elapsed=elapsed.seconds)
        else:
            module.fail_json(msg='Timeout when waiting for file %s' % path, elapsed=elapsed.seconds)",4,FALSE,
jax,https://github.com/google/jax/tree/master/jax/_src/lax/control_flow.py,,_while_partial_eval$532,"for _ in range(1 + len(carry_uk)):
    (body_jaxpr_known, _, carry_out_uk) = pe.partial_eval_jaxpr(body_jaxpr, body_consts_uk + carry_uk, instantiate=carry_uk)
    if carry_out_uk == carry_uk:
        break
    else:
        carry_uk = _map(operator.or_, carry_uk, carry_out_uk)
else:
    assert False, 'Fixpoint not reached'","flag_else = 1

for _ in range(1 + len(carry_uk)):
    (body_jaxpr_known, _, carry_out_uk) = pe.partial_eval_jaxpr(body_jaxpr, body_consts_uk + carry_uk, instantiate=carry_uk)
    if carry_out_uk == carry_uk:
        flag_else = 0
        break
    else:
        carry_uk = _map(operator.or_, carry_uk, carry_out_uk)
if flag_else:
    assert False, 'Fixpoint not reached'",1,FALSE,
flask-cors,https://github.com/corydolphin/flask-cors/tree/master/flask_cors/extension.py,,cors_after_request$179,"for (res_regex, res_options) in resources:
    if try_match(normalized_path, res_regex):
        LOG.debug(""Request to '%s' matches CORS resource '%s'. Using options: %s"", request.path, get_regexp_pattern(res_regex), res_options)
        set_cors_headers(resp, res_options)
        break
else:
    LOG.debug('No CORS rule matches')","flag_else = 1

for (res_regex, res_options) in resources:
    if try_match(normalized_path, res_regex):
        LOG.debug(""Request to '%s' matches CORS resource '%s'. Using options: %s"", request.path, get_regexp_pattern(res_regex), res_options)
        set_cors_headers(resp, res_options)
        flag_else = 0
        break
if flag_else:
    LOG.debug('No CORS rule matches')",1,FALSE,
moto,https://github.com/spulec/moto/tree/master/moto/ec2/models.py,VPCBackend,_matches_service_by_tags$4192,"for tag in service['Tags']:
    if tag['Key'] == tag_name and tag['Value'] in filter_item['Value']:
        break
else:
    matched = False","flag_else = 1

for tag in service['Tags']:
    if tag['Key'] == tag_name and tag['Value'] in filter_item['Value']:
        flag_else = 0
        break
if flag_else:
    matched = False",1,FALSE,
bCNC,https://github.com/vlachoudis/bCNC/tree/master/bCNC/lib/dxf.py,Layer,sort$697,"for (i, entity) in enumerate(self.entities):
    (sx, sy) = entity.start()
    d2 = (sx - ex) ** 2 + (sy - ey) ** 2
    err = EPS2 * ((abs(sx) + abs(ex)) ** 2 + (abs(sy) + abs(ey)) ** 2 + 1.0)
    if d2 < err:
        new.append(entity)
        del self.entities[i]
        break
    (sx, sy) = entity.end()
    d2 = (sx - ex) ** 2 + (sy - ey) ** 2
    err = EPS2 * ((abs(sx) + abs(ex)) ** 2 + (abs(sy) + abs(ey)) ** 2 + 1.0)
    if d2 < err:
        entity.invert()
        new.append(entity)
        del self.entities[i]
        break
else:
    pushStart()","flag_else = 1

for (i, entity) in enumerate(self.entities):
    (sx, sy) = entity.start()
    d2 = (sx - ex) ** 2 + (sy - ey) ** 2
    err = EPS2 * ((abs(sx) + abs(ex)) ** 2 + (abs(sy) + abs(ey)) ** 2 + 1.0)
    if d2 < err:
        new.append(entity)
        del self.entities[i]
        flag_else = 0
        break
    (sx, sy) = entity.end()
    d2 = (sx - ex) ** 2 + (sy - ey) ** 2
    err = EPS2 * ((abs(sx) + abs(ex)) ** 2 + (abs(sy) + abs(ey)) ** 2 + 1.0)
    if d2 < err:
        entity.invert()
        new.append(entity)
        del self.entities[i]
        flag_else = 0
        break
if flag_else:
    pushStart()",2,FALSE,
brat,https://github.com/nlplab/brat/tree/master/server/src/annotator.py,,_set_comments$587,"for com_ann in ann_obj.get_oneline_comments():
    if com_ann.type == 'AnnotatorNotes' and com_ann.target == ann.id:
        found = com_ann
        undo_resp['comment'] = found.tail[1:]
        break
else:
    found = None","flag_else = 1

for com_ann in ann_obj.get_oneline_comments():
    if com_ann.type == 'AnnotatorNotes' and com_ann.target == ann.id:
        found = com_ann
        undo_resp['comment'] = found.tail[1:]
        flag_else = 0
        break
if flag_else:
    found = None",1,FALSE,
deluge,https://github.com/deluge-torrent/deluge/tree/master/deluge/tests/test_core.py,CoreTestCase,start_web_server$94,"for dummy in range(10):
    try:
        self.webserver = reactor.listenTCP(self.listen_port, website)
    except CannotListenError as ex:
        error = ex
        self.listen_port += 1
    else:
        break
else:
    raise error","flag_else = 1

for dummy in range(10):
    try:
        self.webserver = reactor.listenTCP(self.listen_port, website)
    except CannotListenError as ex:
        error = ex
        self.listen_port += 1
    else:
        flag_else = 0
        break
if flag_else:
    raise error",1,FALSE,
VSCodeNotebook,https://github.com/aviaryan/VSCodeNotebook/tree/master/vscode_notebook/pyaes/aes.py,Counter,increment$285,"for i in xrange(len(self._counter) - 1, -1, -1):
    self._counter[i] += 1
    if self._counter[i] < 256:
        break
    self._counter[i] = 0
else:
    self._counter = [0] * len(self._counter)","flag_else = 1

for i in xrange(len(self._counter) - 1, -1, -1):
    self._counter[i] += 1
    if self._counter[i] < 256:
        flag_else = 0
        break
    self._counter[i] = 0
if flag_else:
    self._counter = [0] * len(self._counter)",1,FALSE,
orchest,https://github.com/orchest/orchest/tree/master/services/orchest-webserver/app/app/utils.py,,resolve_absolute_path$751,"for (prefix, fs_prefix) in prefix_map.items():
    if abs_path.startswith(prefix):
        matched_prefix = prefix
        resolved_prefix = fs_prefix
        break
else:
    return","flag_else = 1

for (prefix, fs_prefix) in prefix_map.items():
    if abs_path.startswith(prefix):
        matched_prefix = prefix
        resolved_prefix = fs_prefix
        flag_else = 0
        break
if flag_else:
    return",1,FALSE,
QUANTAXIS,https://github.com/QUANTAXIS/QUANTAXIS/tree/master/QUANTAXIS/QAUtil/QADate_trade.py,,QA_util_get_real_date$7947,"while date not in trade_list:
    date = str(datetime.datetime.strptime(str(date)[0:10], '%Y-%m-%d') + datetime.timedelta(days=1))[0:10]
else:
    return str(date)[0:10]","while date not in trade_list:
    date = str(datetime.datetime.strptime(str(date)[0:10], '%Y-%m-%d') + datetime.timedelta(days=1))[0:10]

return str(date)[0:10]
",0,TRUE,
glance,https://github.com/openstack/glance/tree/master/glance/db/simple/api.py,,image_member_delete$629,"for (i, member) in enumerate(DATA['members']):
    if member['id'] == member_id:
        del DATA['members'][i]
        break
else:
    raise exception.NotFound()","flag_else = 1

for (i, member) in enumerate(DATA['members']):
    if member['id'] == member_id:
        del DATA['members'][i]
        flag_else = 0
        break
if flag_else:
    raise exception.NotFound()",1,FALSE,
mutagen,https://github.com/quodlibet/mutagen/tree/master/mutagen/_util.py,DictMixin,popitem$483,"for key in self.keys():
    break
else:
    raise KeyError('dictionary is empty')","flag_else = 1

for key in self.keys():
    flag_else = 0
    break
if flag_else:
    raise KeyError('dictionary is empty')",1,FALSE,
salt,https://github.com/saltstack/salt/tree/master/salt/engines/slack.py,SlackClient,generate_triggered_messages$472,"for sleeps in (5, 10, 30, 60):
    if self.slack_connect:
        break
    else:
        log.warning('Slack connection is invalid. Server: %s, sleeping %s', self.sc.server, sleeps)
        time.sleep(sleeps)
else:
    raise UserWarning('Connection to slack is still invalid, giving up: {}'.format(self.slack_connect))","flag_else = 1

for sleeps in (5, 10, 30, 60):
    if self.slack_connect:
        flag_else = 0
        break
    else:
        log.warning('Slack connection is invalid. Server: %s, sleeping %s', self.sc.server, sleeps)
        time.sleep(sleeps)
if flag_else:
    raise UserWarning('Connection to slack is still invalid, giving up: {}'.format(self.slack_connect))",1,FALSE,
py-junos-eznc,https://github.com/Juniper/py-junos-eznc/tree/master/lib/jnpr/junos/exception.py,RpcError,__init__$22,"for error in errs.errors:
    if error.severity == 'error':
        self.rsp = JXML.remove_namespaces(error.xml)
        break
else:
    if errs.severity == 'warning':
        for error in errs.errors:
            if error.severity == 'warning':
                self.rsp = JXML.remove_namespaces(error.xml)
                break","flag_else = 1

for error in errs.errors:
    if error.severity == 'error':
        self.rsp = JXML.remove_namespaces(error.xml)
        flag_else = 0
        break
if flag_else:
    if errs.severity == 'warning':
        for error in errs.errors:
            if error.severity == 'warning':
                self.rsp = JXML.remove_namespaces(error.xml)
                break",1,FALSE,
jellyfin-kodi,https://github.com/jellyfin/jellyfin-kodi/tree/master/jellyfin_kodi/views.py,Views,node_random$561,"for rule in root.findall('.//limit'):
    rule.text = str(self.limit)
    break
else:
    etree.SubElement(root, 'limit').text = str(self.limit)","flag_else = 1

for rule in root.findall('.//limit'):
    rule.text = str(self.limit)
    flag_else = 0
    break
if flag_else:
    etree.SubElement(root, 'limit').text = str(self.limit)",1,FALSE,
satpy,https://github.com/pytroll/satpy/tree/master/satpy/modifiers/_crefl_utils.py,_Coefficients,_find_coefficient_index$108,"for res in sorted(index_map.keys()):
    if resolution <= res:
        index_map = index_map[res]
        break
else:
    raise ValueError('Unrecognized data resolution: {}', resolution)","flag_else = 1

for res in sorted(index_map.keys()):
    if resolution <= res:
        index_map = index_map[res]
        flag_else = 0
        break
if flag_else:
    raise ValueError('Unrecognized data resolution: {}', resolution)",1,FALSE,
imageio,https://github.com/imageio/imageio/tree/master/imageio/plugins/_tifffile.py,,validate_jhove$10031,"for i in ignore:
    if i in error:
        break
else:
    raise ValueError(error)","flag_else = 1

for i in ignore:
    if i in error:
        flag_else = 0
        break
if flag_else:
    raise ValueError(error)",1,FALSE,
seldom,https://github.com/SeldomQA/seldom/tree/master/seldom/case.py,TestCase,assertInUrl$154,"for _ in range(Seldom.timeout + 1):
    current_url = unquote(Seldom.driver.current_url)
    try:
        self.assertIn(url, current_url)
        break
    except AssertionError:
        sleep(1)
else:
    self.assertIn(url, Seldom.driver.current_url, msg=msg)","flag_else = 1

for _ in range(Seldom.timeout + 1):
    current_url = unquote(Seldom.driver.current_url)
    try:
        self.assertIn(url, current_url)
        flag_else = 0
        break
    except AssertionError:
        sleep(1)
if flag_else:
    self.assertIn(url, Seldom.driver.current_url, msg=msg)",1,FALSE,
bumblebee-status,https://github.com/tobi-wan-kenobi/bumblebee-status/tree/master//versioneer.py,,run_command$389,"for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)","flag_else = 1

for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)",1,FALSE,
aptsources-cleanup,https://github.com/davidfoerster/aptsources-cleanup/tree/master/src/aptsources_cleanup/util/collections/abc.py,,_check_methods$16,"for B in mro:
    if method in B.__dict__:
        if B.__dict__[method] is None:
            return NotImplemented
        break
else:
    return NotImplemented","flag_else = 1

for B in mro:
    if method in B.__dict__:
        if B.__dict__[method] is None:
            return NotImplemented
        flag_else = 0
        break
if flag_else:
    return NotImplemented",1,FALSE,
hypothesis,https://github.com/HypothesisWorks/hypothesis/tree/master/hypothesis-python/src/hypothesis/strategies/_internal/datetime.py,,_valid_key_cacheable$347,"for root in tzpath:
    if os.path.exists(os.path.join(root, key)):
        return True
else:
    if importlib_resources is None:
        raise ImportError('The importlib_resources module is required, but could not be imported.  Run `pip install hypothesis[zoneinfo]` and try again.')
    (*package_loc, resource_name) = key.split('/')
    package = 'tzdata.zoneinfo.' + '.'.join(package_loc)
    try:
        return importlib_resources.is_resource(package, resource_name)
    except ModuleNotFoundError:
        return False","for root in tzpath:
    if os.path.exists(os.path.join(root, key)):
        return True

if importlib_resources is None:
    raise ImportError('The importlib_resources module is required, but could not be imported.  Run `pip install hypothesis[zoneinfo]` and try again.')
(*package_loc, resource_name) = key.split('/')
package = 'tzdata.zoneinfo.' + '.'.join(package_loc)
try:
    return importlib_resources.is_resource(package, resource_name)
except ModuleNotFoundError:
    return False
",0,TRUE,
dephell,https://github.com/dephell/dephell/tree/master/dephell/commands/project_validate.py,ProjectValidateCommand,__call__$22,"for classifier in root.classifiers:
    if classifier.startswith('Programming Language :: Python ::'):
        break
else:
    self.logger.error('no python version specified in classifier')
    ok = False","flag_else = 1

for classifier in root.classifiers:
    if classifier.startswith('Programming Language :: Python ::'):
        flag_else = 0
        break
if flag_else:
    self.logger.error('no python version specified in classifier')
    ok = False",1,FALSE,
ClipBERT,https://github.com/jayleicn/ClipBERT/tree/master/src/datasets/dataset_video_qa.py,ClipBertVideoQADataset,__getitem__$83,"for _ in range(num_retries):
    (vid_id, examples) = self.datalist[index]
    if self.ensemble_n_clips > 1:
        if self.is_train and self.random_sample_clips:
            vid_frm_array = self._load_video_multi_clips_random(vid_id)
        else:
            vid_frm_array = self._load_video_multi_clips_uniform(vid_id)
    elif self.is_train and self.random_sample_clips:
        (vid_frm_array, _) = self._load_video(vid_id)
    else:
        (vid_frm_array, _) = self._load_video(vid_id, num_clips=1, clip_idx=0)
    if vid_frm_array is None:
        LOGGER.info(f'Failed to load examples with video: {vid_id}. Will randomly sample an example as a replacement.')
        index = random.randint(0, len(self) - 1)
        continue
    examples = [self._get_single_example(e) for e in examples]
    return dict(vid=vid_frm_array, examples=examples, n_examples=len(examples))
else:
    raise RuntimeError(f'Failed to fetch video after {num_retries} retries.')","for _ in range(num_retries):
    (vid_id, examples) = self.datalist[index]
    if self.ensemble_n_clips > 1:
        if self.is_train and self.random_sample_clips:
            vid_frm_array = self._load_video_multi_clips_random(vid_id)
        else:
            vid_frm_array = self._load_video_multi_clips_uniform(vid_id)
    elif self.is_train and self.random_sample_clips:
        (vid_frm_array, _) = self._load_video(vid_id)
    else:
        (vid_frm_array, _) = self._load_video(vid_id, num_clips=1, clip_idx=0)
    if vid_frm_array is None:
        LOGGER.info(f'Failed to load examples with video: {vid_id}. Will randomly sample an example as a replacement.')
        index = random.randint(0, len(self) - 1)
        continue
    examples = [self._get_single_example(e) for e in examples]
    return dict(vid=vid_frm_array, examples=examples, n_examples=len(examples))

raise RuntimeError(f'Failed to fetch video after {num_retries} retries.')
",0,TRUE,
dateparser,https://github.com/scrapinghub/dateparser/tree/master/dateparser/parser.py,_parser,parse_alpha$567,"for (component, directives) in self.alpha_directives.items():
    if skip_component == component:
        continue
    for directive in directives:
        try:
            do = self._get_date_obj(token, directive)
            prev_value = getattr(self, component, None)
            if not prev_value:
                return set_and_return(token, type, component, do, skip_date_order=True)
            elif component == 'month':
                index = self.auto_order.index('month')
                self.auto_order[index] = 'day'
                setattr(self, '_token_day', self._token_month)
                setattr(self, '_token_month', (token, type))
                return [(component, getattr(do, component)), ('day', prev_value)]
        except:
            pass
else:
    raise ValueError('Unable to parse: %s' % token)","for (component, directives) in self.alpha_directives.items():
    if skip_component == component:
        continue
    for directive in directives:
        try:
            do = self._get_date_obj(token, directive)
            prev_value = getattr(self, component, None)
            if not prev_value:
                return set_and_return(token, type, component, do, skip_date_order=True)
            elif component == 'month':
                index = self.auto_order.index('month')
                self.auto_order[index] = 'day'
                setattr(self, '_token_day', self._token_month)
                setattr(self, '_token_month', (token, type))
                return [(component, getattr(do, component)), ('day', prev_value)]
        except:
            pass

raise ValueError('Unable to parse: %s' % token)
",0,TRUE,
sqlalchemy-utils,https://github.com/kvesteri/sqlalchemy-utils/tree/master/sqlalchemy_utils/functions/mock.py,,mock_engine$61,"for frame in inspect.stack()[1:]:
    try:
        frame = frame[0]
        expression = '__target = %s' % engine
        exec(expression, frame.f_globals, frame.f_locals)
        target = frame.f_locals['__target']
        break
    except Exception:
        pass
else:
    raise ValueError('Not a valid python expression', engine)","flag_else = 1

for frame in inspect.stack()[1:]:
    try:
        frame = frame[0]
        expression = '__target = %s' % engine
        exec(expression, frame.f_globals, frame.f_locals)
        target = frame.f_locals['__target']
        flag_else = 0
        break
    except Exception:
        pass
if flag_else:
    raise ValueError('Not a valid python expression', engine)",1,FALSE,
thriftpy2,https://github.com/Thriftpy/thriftpy2/tree/master/thriftpy2/parser/parser.py,,p_ref_type$390,"for attr in dir(ref_type):
    if attr in {'__doc__', '__loader__', '__name__', '__package__', '__spec__', '__thrift_file__', '__thrift_meta__'}:
        continue
    if p[1].startswith(attr + '.'):
        name = p[1][len(attr) + 1:]
        included_ref_type = getattr(ref_type, attr)
        resolved_ref_type = getattr(included_ref_type, name, None)
        if resolved_ref_type is not None:
            ref_type = resolved_ref_type
            break
else:
    for (index, name) in enumerate(p[1].split('.')):
        ref_type = getattr(ref_type, name, None)
        if ref_type is None:
            if index != len(p[1].split('.')) - 1:
                raise ThriftParserError('No type found: %r, at line %d' % (p[1], p.lineno(1)))
            p[0] = incomplete_type.set_info((p[1], p.lineno(1)))
            return","flag_else = 1

for attr in dir(ref_type):
    if attr in {'__doc__', '__loader__', '__name__', '__package__', '__spec__', '__thrift_file__', '__thrift_meta__'}:
        continue
    if p[1].startswith(attr + '.'):
        name = p[1][len(attr) + 1:]
        included_ref_type = getattr(ref_type, attr)
        resolved_ref_type = getattr(included_ref_type, name, None)
        if resolved_ref_type is not None:
            ref_type = resolved_ref_type
            flag_else = 0
            break
if flag_else:
    for (index, name) in enumerate(p[1].split('.')):
        ref_type = getattr(ref_type, name, None)
        if ref_type is None:
            if index != len(p[1].split('.')) - 1:
                raise ThriftParserError('No type found: %r, at line %d' % (p[1], p.lineno(1)))
            p[0] = incomplete_type.set_info((p[1], p.lineno(1)))
            return",1,FALSE,
nova,https://github.com/openstack/nova/tree/master/nova/virt/disk/mount/nbd.py,NbdMount,_inner_get_dev$73,"for _i in range(CONF.timeout_nbd):
    if os.path.exists(pidfile):
        self.device = device
        break
    time.sleep(1)
else:
    self.error = _('nbd device %s did not show up') % device
    LOG.info('NBD mount error: %s', self.error)
    try:
        (_out, err) = nova.privsep.fs.nbd_disconnect(device)
    except processutils.ProcessExecutionError as exc:
        err = str(exc)
    if err:
        LOG.warning('Detaching from erroneous nbd device returned error: %s', err)
    return False","flag_else = 1

for _i in range(CONF.timeout_nbd):
    if os.path.exists(pidfile):
        self.device = device
        flag_else = 0
        break
    time.sleep(1)
if flag_else:
    self.error = _('nbd device %s did not show up') % device
    LOG.info('NBD mount error: %s', self.error)
    try:
        (_out, err) = nova.privsep.fs.nbd_disconnect(device)
    except processutils.ProcessExecutionError as exc:
        err = str(exc)
    if err:
        LOG.warning('Detaching from erroneous nbd device returned error: %s', err)
    return False",1,FALSE,
opencensus-python,https://github.com/census-instrumentation/opencensus-python/tree/master/opencensus/stats/aggregation_data.py,DistributionAggregationData,increment_bucket_count$243,"for (ii, bb) in enumerate(self._bounds):
    if value < bb:
        self._counts_per_bucket[ii] += 1
        return ii
else:
    last_bucket_index = len(self._bounds)
    self._counts_per_bucket[last_bucket_index] += 1
    return last_bucket_index","for (ii, bb) in enumerate(self._bounds):
    if value < bb:
        self._counts_per_bucket[ii] += 1
        return ii

last_bucket_index = len(self._bounds)
self._counts_per_bucket[last_bucket_index] += 1
return last_bucket_index
",0,TRUE,
astropy,https://github.com/astropy/astropy/tree/master/astropy/io/fits/header.py,Header,index$1399,"for idx in range(start, stop, step):
    if self._cards[idx].keyword.upper() == norm_keyword:
        return idx
else:
    raise ValueError(f'The keyword {keyword!r} is not in the  header.')","for idx in range(start, stop, step):
    if self._cards[idx].keyword.upper() == norm_keyword:
        return idx

raise ValueError(f'The keyword {keyword!r} is not in the  header.')
",0,TRUE,
gallery-dl,https://github.com/mikf/gallery-dl/tree/master/gallery_dl/extractor/photobucket.py,PhotobucketImageExtractor,items$134,"while tries < 5:
    data = self.request(url, method='POST', params=params).json()
    image = data['mediaDocuments']
    if 'message' not in image:
        break
    tries += 1
    self.log.debug(image['message'])
else:
    raise exception.StopExtraction(image['message'])","flag_else = 1

while tries < 5:
    data = self.request(url, method='POST', params=params).json()
    image = data['mediaDocuments']
    if 'message' not in image:
        flag_else = 0
        break
    tries += 1
    self.log.debug(image['message'])
if flag_else:
    raise exception.StopExtraction(image['message'])",1,FALSE,
pyOCD,https://github.com/pyocd/pyOCD/tree/master/pyocd/target/builtin/target_s5js100.py,CortexM_S5JS100,reset$198,"while t_o.check():
    try:
        dhcsr_reg = self.read32(CortexM.DHCSR)
        LOG.debug('reg = %x', dhcsr_reg)
        if dhcsr_reg & CortexM.S_RESET_ST != 0:
            break
        sleep(0.1)
    except exceptions.TransferError:
        self.flush()
        self._ap.dp.connect()
        sleep(0.01)
else:
    raise exceptions.TimeoutError('Timeout waiting for reset')","flag_else = 1

while t_o.check():
    try:
        dhcsr_reg = self.read32(CortexM.DHCSR)
        LOG.debug('reg = %x', dhcsr_reg)
        if dhcsr_reg & CortexM.S_RESET_ST != 0:
            flag_else = 0
            break
        sleep(0.1)
    except exceptions.TransferError:
        self.flush()
        self._ap.dp.connect()
        sleep(0.01)
if flag_else:
    raise exceptions.TimeoutError('Timeout waiting for reset')",1,FALSE,
GotoX,https://github.com/SeaHOH/GotoX/tree/master/local/RangeFetch.py,RangeFetch,fetch$42,"while self.expect_begin < length:
    try:
        if has_peek:
            (begin, data) = data_queue.peek(timeout=peek_timeout)
            if self.expect_begin == begin:
                data_queue.get()
            elif self.expect_begin < begin:
                sleep(0.1)
                continue
            else:
                logging.error('%s RangeFetch egin(%r) < expect_begin(%r)', self.address_string(), begin, self.expect_begin)
                break
        else:
            (begin, data) = data_queue.get(timeout=peek_timeout)
            if self.expect_begin == begin:
                pass
            elif self.expect_begin < begin:
                data_queue.put((begin, data))
                sleep(0.1)
                continue
            else:
                logging.error('%s RangeFetch egin(%r) < expect_begin(%r)', self.address_string(), begin, self.expect_begin)
                break
    except queue.Empty:
        logging.error('%s data_queue peek eak', self.address_string())
        break
    try:
        self.write(data)
        self.expect_begin += len(data)
    except Exception as e:
        logging.info('%s RangeFetch %r, %r', self.address_string(), self.url, e)
        break
else:
    logging.info('%s RangeFetch  %r', self.address_string(), self.url)","flag_else = 1

while self.expect_begin < length:
    try:
        if has_peek:
            (begin, data) = data_queue.peek(timeout=peek_timeout)
            if self.expect_begin == begin:
                data_queue.get()
            elif self.expect_begin < begin:
                sleep(0.1)
                continue
            else:
                logging.error('%s RangeFetch egin(%r) < expect_begin(%r)', self.address_string(), begin, self.expect_begin)
                flag_else = 0
                break
        else:
            (begin, data) = data_queue.get(timeout=peek_timeout)
            if self.expect_begin == begin:
                pass
            elif self.expect_begin < begin:
                data_queue.put((begin, data))
                sleep(0.1)
                continue
            else:
                logging.error('%s RangeFetch egin(%r) < expect_begin(%r)', self.address_string(), begin, self.expect_begin)
                flag_else = 0
                break
    except queue.Empty:
        logging.error('%s data_queue peek eak', self.address_string())
        flag_else = 0
        break
    try:
        self.write(data)
        self.expect_begin += len(data)
    except Exception as e:
        logging.info('%s RangeFetch %r, %r', self.address_string(), self.url, e)
        flag_else = 0
        break
if flag_else:
    logging.info('%s RangeFetch  %r', self.address_string(), self.url)",4,FALSE,
core,https://github.com/home-assistant/core/tree/master/homeassistant/components/lcn/helpers.py,,import_lcn_config$148,"for device_config in data[host_name][CONF_DEVICES]:
    if address == device_config[CONF_ADDRESS]:
        break
else:
    device_config = {CONF_ADDRESS: address, CONF_NAME: '', CONF_HARDWARE_SERIAL: -1, CONF_SOFTWARE_SERIAL: -1, CONF_HARDWARE_TYPE: -1}
    data[host_name][CONF_DEVICES].append(device_config)","flag_else = 1

for device_config in data[host_name][CONF_DEVICES]:
    if address == device_config[CONF_ADDRESS]:
        flag_else = 0
        break
if flag_else:
    device_config = {CONF_ADDRESS: address, CONF_NAME: '', CONF_HARDWARE_SERIAL: -1, CONF_SOFTWARE_SERIAL: -1, CONF_HARDWARE_TYPE: -1}
    data[host_name][CONF_DEVICES].append(device_config)",1,FALSE,
astropy,https://github.com/astropy/astropy/tree/master/astropy/io/ascii/ui.py,,_guess$449,"for guess_kwargs in filtered_guess_kwargs:
    t0 = time.time()
    try:
        if 'Reader' not in read_kwargs:
            guess_kwargs['strict_names'] = True
        reader = get_reader(**guess_kwargs)
        reader.guessing = True
        dat = reader.read(table)
        _read_trace.append({'kwargs': copy.deepcopy(guess_kwargs), 'Reader': reader.__class__, 'status': 'Success (guessing)', 'dt': f'{(time.time() - t0) * 1000:.3f} ms'})
        return dat
    except guess_exception_classes as err:
        _read_trace.append({'kwargs': copy.deepcopy(guess_kwargs), 'status': f'{err.__class__.__name__}: {str(err)}', 'dt': f'{(time.time() - t0) * 1000:.3f} ms'})
        failed_kwargs.append(guess_kwargs)
else:
    try:
        reader = get_reader(**read_kwargs)
        dat = reader.read(table)
        _read_trace.append({'kwargs': copy.deepcopy(read_kwargs), 'Reader': reader.__class__, 'status': 'Success with original kwargs without strict_names (guessing)'})
        return dat
    except guess_exception_classes as err:
        _read_trace.append({'kwargs': copy.deepcopy(read_kwargs), 'status': f'{err.__class__.__name__}: {str(err)}'})
        failed_kwargs.append(read_kwargs)
        lines = ['\nERROR: Unable to guess table format with the guesses listed below:']
        for kwargs in failed_kwargs:
            sorted_keys = sorted((x for x in sorted(kwargs) if x not in ('Reader', 'Outputter')))
            reader_repr = repr(kwargs.get('Reader', basic.Basic))
            keys_vals = ['Reader:' + re.search(""\\.(\\w+)'>"", reader_repr).group(1)]
            kwargs_sorted = ((key, kwargs[key]) for key in sorted_keys)
            keys_vals.extend([f'{key}: {val!r}' for (key, val) in kwargs_sorted])
            lines.append(' '.join(keys_vals))
        msg = ['', '************************************************************************', '** ERROR: Unable to guess table format with the guesses listed above. **', '**                                                                    **', '** To figure out why the table did not read, use guess=False and      **', '** fast_reader=False, along with any appropriate arguments to read(). **', '** In particular specify the format and any known attributes like the **', '** delimiter.                                                         **', '************************************************************************']
        lines.extend(msg)
        raise core.InconsistentTableError('\n'.join(lines)) from None","for guess_kwargs in filtered_guess_kwargs:
    t0 = time.time()
    try:
        if 'Reader' not in read_kwargs:
            guess_kwargs['strict_names'] = True
        reader = get_reader(**guess_kwargs)
        reader.guessing = True
        dat = reader.read(table)
        _read_trace.append({'kwargs': copy.deepcopy(guess_kwargs), 'Reader': reader.__class__, 'status': 'Success (guessing)', 'dt': f'{(time.time() - t0) * 1000:.3f} ms'})
        return dat
    except guess_exception_classes as err:
        _read_trace.append({'kwargs': copy.deepcopy(guess_kwargs), 'status': f'{err.__class__.__name__}: {str(err)}', 'dt': f'{(time.time() - t0) * 1000:.3f} ms'})
        failed_kwargs.append(guess_kwargs)

try:
    reader = get_reader(**read_kwargs)
    dat = reader.read(table)
    _read_trace.append({'kwargs': copy.deepcopy(read_kwargs), 'Reader': reader.__class__, 'status': 'Success with original kwargs without strict_names (guessing)'})
    return dat
except guess_exception_classes as err:
    _read_trace.append({'kwargs': copy.deepcopy(read_kwargs), 'status': f'{err.__class__.__name__}: {str(err)}'})
    failed_kwargs.append(read_kwargs)
    lines = ['\nERROR: Unable to guess table format with the guesses listed below:']
    for kwargs in failed_kwargs:
        sorted_keys = sorted((x for x in sorted(kwargs) if x not in ('Reader', 'Outputter')))
        reader_repr = repr(kwargs.get('Reader', basic.Basic))
        keys_vals = ['Reader:' + re.search(""\\.(\\w+)'>"", reader_repr).group(1)]
        kwargs_sorted = ((key, kwargs[key]) for key in sorted_keys)
        keys_vals.extend([f'{key}: {val!r}' for (key, val) in kwargs_sorted])
        lines.append(' '.join(keys_vals))
    msg = ['', '************************************************************************', '** ERROR: Unable to guess table format with the guesses listed above. **', '**                                                                    **', '** To figure out why the table did not read, use guess=False and      **', '** fast_reader=False, along with any appropriate arguments to read(). **', '** In particular specify the format and any known attributes like the **', '** delimiter.                                                         **', '************************************************************************']
    lines.extend(msg)
    raise core.InconsistentTableError('\n'.join(lines)) from None
",0,TRUE,
nnabla,https://github.com/sony/nnabla/tree/master/python/src/nnabla/utils/get_file_handle.py,,_load_files$360,"for (supported_extensions, file_loader) in file_loaders.items():
    if ext in supported_extensions:
        file_loader(ctx, file_loaders, None, filename, ext)
        handled = True
else:
    if not handled:
        logger.warn('{} is omitted.'.format(filename))","for (supported_extensions, file_loader) in file_loaders.items():
    if ext in supported_extensions:
        file_loader(ctx, file_loaders, None, filename, ext)
        handled = True

if not handled:
    logger.warn('{} is omitted.'.format(filename))
",0,TRUE,
nbviewer,https://github.com/jupyter/nbviewer/tree/master/nbviewer/_version.py,,run_command$69,"for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except OSError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print(f'unable to find command, tried {commands}')
    return (None, None)","flag_else = 1

for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except OSError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print(f'unable to find command, tried {commands}')
    return (None, None)",1,FALSE,
FileMonitor,https://github.com/TheKingOfDuck/FileMonitor/tree/master/watchdog/utils/echo.py,,is_static_method$49,"for c in klass.mro():
    if name(method) in c.__dict__:
        return isinstance(c.__dict__[name(method)], staticmethod)
else:
    return False","for c in klass.mro():
    if name(method) in c.__dict__:
        return isinstance(c.__dict__[name(method)], staticmethod)

return False
",0,TRUE,
vprof,https://github.com/nvdv/vprof/tree/master/examples/permutations.py,,permutations$9,"for i in reversed(range(r)):
    cycles[i] -= 1
    if cycles[i] == 0:
        indices[i:] = indices[i + 1:] + indices[i:i + 1]
        cycles[i] = n - i
    else:
        j = cycles[i]
        (indices[i], indices[-j]) = (indices[-j], indices[i])
        yield tuple((pool[i] for i in indices[:r]))
        break
else:
    return","flag_else = 1

for i in reversed(range(r)):
    cycles[i] -= 1
    if cycles[i] == 0:
        indices[i:] = indices[i + 1:] + indices[i:i + 1]
        cycles[i] = n - i
    else:
        j = cycles[i]
        (indices[i], indices[-j]) = (indices[-j], indices[i])
        yield tuple((pool[i] for i in indices[:r]))
        flag_else = 0
        break
if flag_else:
    return",1,FALSE,
python-hunter,https://github.com/ionelmc/python-hunter/tree/master/src/hunter/predicates.py,Or,__call__$520,"for predicate in self.predicates:
    if predicate(event):
        return True
else:
    return False","for predicate in self.predicates:
    if predicate(event):
        return True

return False
",0,TRUE,
electrum,https://github.com/spesmilo/electrum/tree/master/electrum/transaction.py,Transaction,output_value_for_address$1035,"for o in self.outputs():
    if o.address == addr:
        return o.value
else:
    raise Exception('output not found', addr)","for o in self.outputs():
    if o.address == addr:
        return o.value

raise Exception('output not found', addr)
",0,TRUE,
pyOCD,https://github.com/pyocd/pyOCD/tree/master/pyocd/probe/pydapaccess/interface/pywinusb_backend.py,PyWinUSB,read$147,"while t_o.check():
    if len(self.rcv_data):
        break
    sleep(0)
else:
    raise DAPAccessIntf.DeviceError('Read timed out')","flag_else = 1

while t_o.check():
    if len(self.rcv_data):
        flag_else = 0
        break
    sleep(0)
if flag_else:
    raise DAPAccessIntf.DeviceError('Read timed out')",1,FALSE,
pyvisa,https://github.com/pyvisa/pyvisa/tree/master/pyvisa/highlevel.py,VisaLibraryBase,__new__$145,"for path in cls.get_library_paths():
    try:
        return cls(path)
    except OSError as e:
        logger.debug('Could not open VISA library %s: %s', path, str(e))
        errs.append(str(e))
    except Exception as e:
        errs.append(str(e))
else:
    raise OSError('Could not open VISA library:\n' + '\n'.join(errs))","for path in cls.get_library_paths():
    try:
        return cls(path)
    except OSError as e:
        logger.debug('Could not open VISA library %s: %s', path, str(e))
        errs.append(str(e))
    except Exception as e:
        errs.append(str(e))

raise OSError('Could not open VISA library:\n' + '\n'.join(errs))
",0,TRUE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/assumptions/ask.py,,_extract_all_facts$308,"for literal in clause:
    if isinstance(literal.lit, AppliedPredicate) and len(literal.lit.arguments) == 1:
        if literal.lit.arg in exprs:
            args.append(Literal(literal.lit.function, literal.is_Not))
        else:
            break
else:
    if args:
        facts.add(frozenset(args))","flag_else = 1

for literal in clause:
    if isinstance(literal.lit, AppliedPredicate) and len(literal.lit.arguments) == 1:
        if literal.lit.arg in exprs:
            args.append(Literal(literal.lit.function, literal.is_Not))
        else:
            flag_else = 0
            break
if flag_else:
    if args:
        facts.add(frozenset(args))",1,FALSE,
glance,https://github.com/openstack/glance/tree/master/glance/db/simple/api.py,,metadef_object_get$1360,"for object in DATA['metadef_objects']:
    if object['namespace_id'] == namespace['id'] and object['name'] == object_name:
        return object
else:
    LOG.debug('The metadata definition object with name=%(name)s was not found in namespace=%(namespace_name)s.', {'name': object_name, 'namespace_name': namespace_name})
    raise exception.MetadefObjectNotFound(namespace_name=namespace_name, object_name=object_name)","for object in DATA['metadef_objects']:
    if object['namespace_id'] == namespace['id'] and object['name'] == object_name:
        return object

LOG.debug('The metadata definition object with name=%(name)s was not found in namespace=%(namespace_name)s.', {'name': object_name, 'namespace_name': namespace_name})
raise exception.MetadefObjectNotFound(namespace_name=namespace_name, object_name=object_name)
",0,TRUE,
dateutil,https://github.com/dateutil/dateutil/tree/master/src/dateutil/tz/tz.py,GettzFunc,nocache$1591,"for path in TZPATHS:
    filepath = os.path.join(path, filename)
    if os.path.isfile(filepath):
        break
else:
    continue","flag_else = 1

for path in TZPATHS:
    filepath = os.path.join(path, filename)
    if os.path.isfile(filepath):
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
freeipa,https://github.com/freeipa/freeipa/tree/master/ipapython/ipaldap.py,LDAPClient,find_entries$1468,"for ctrl in res_ctrls:
    if isinstance(ctrl, SimplePagedResultsControl):
        cookie = ctrl.cookie
        break
else:
    cookie = ''","flag_else = 1

for ctrl in res_ctrls:
    if isinstance(ctrl, SimplePagedResultsControl):
        cookie = ctrl.cookie
        flag_else = 0
        break
if flag_else:
    cookie = ''",1,FALSE,
buildbot,https://github.com/buildbot/buildbot/tree/master/master/docs/bbdocs/ext.py,BBDomain,resolve_xref$355,"for idx in self.indices:
    if idx.name == target:
        break
else:
    raise KeyError(""no index named '{}'"".format(target))","flag_else = 1

for idx in self.indices:
    if idx.name == target:
        flag_else = 0
        break
if flag_else:
    raise KeyError(""no index named '{}'"".format(target))",1,FALSE,
s3fs,https://github.com/fsspec/s3fs/tree/master/s3fs/_version.py,,run_command$72,"for command in commands:
    try:
        dispcmd = str([command] + args)
        process = subprocess.Popen([command] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)","flag_else = 1

for command in commands:
    try:
        dispcmd = str([command] + args)
        process = subprocess.Popen([command] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)",1,FALSE,
keepsake,https://github.com/replicate/keepsake/tree/master/python/keepsake/_vendor/yaml/representer.py,BaseRepresenter,represent_data$33,"for data_type in data_types:
    if data_type in self.yaml_multi_representers:
        node = self.yaml_multi_representers[data_type](self, data)
        break
else:
    if None in self.yaml_multi_representers:
        node = self.yaml_multi_representers[None](self, data)
    elif None in self.yaml_representers:
        node = self.yaml_representers[None](self, data)
    else:
        node = ScalarNode(None, str(data))","flag_else = 1

for data_type in data_types:
    if data_type in self.yaml_multi_representers:
        node = self.yaml_multi_representers[data_type](self, data)
        flag_else = 0
        break
if flag_else:
    if None in self.yaml_multi_representers:
        node = self.yaml_multi_representers[None](self, data)
    elif None in self.yaml_representers:
        node = self.yaml_representers[None](self, data)
    else:
        node = ScalarNode(None, str(data))",1,FALSE,
galaxy,https://github.com/ansible/galaxy/tree/master/lib/galaxy/jobs/runners/util/process_groups.py,,kill_pg$25,"for sig in [signal.SIGTERM, signal.SIGKILL]:
    try:
        os.killpg(pgid, sig)
    except OSError as e:
        if e.errno == errno.ESRCH:
            return
        log.warning('Got errno %s when sending signal %d to process group %d: %s', errno.errorcode[e.errno], sig, pgid, e.strerror)
    sleep(1)
    if not check_pg(pgid):
        log.debug('Processes in process group %d successfully killed with signal %d', pgid, sig)
        return
else:
    log.warning('Some process in process group %d refuses to die after signaling TERM/KILL', pgid)","for sig in [signal.SIGTERM, signal.SIGKILL]:
    try:
        os.killpg(pgid, sig)
    except OSError as e:
        if e.errno == errno.ESRCH:
            return
        log.warning('Got errno %s when sending signal %d to process group %d: %s', errno.errorcode[e.errno], sig, pgid, e.strerror)
    sleep(1)
    if not check_pg(pgid):
        log.debug('Processes in process group %d successfully killed with signal %d', pgid, sig)
        return

log.warning('Some process in process group %d refuses to die after signaling TERM/KILL', pgid)
",0,TRUE,
rpyc,https://github.com/tomerfiliba-org/rpyc/tree/master/rpyc/core/protocol.py,Connection,_serve_bound$454,"for thread in self._thread_pool:
    if not thread._event.is_set():
        self._receiving = False
        thread._event.set()
        break
else:
    self._receiving = False","flag_else = 1

for thread in self._thread_pool:
    if not thread._event.is_set():
        self._receiving = False
        thread._event.set()
        flag_else = 0
        break
if flag_else:
    self._receiving = False",1,FALSE,
vdirsyncer,https://github.com/pimutils/vdirsyncer/tree/master/vdirsyncer/vobject.py,_Component,__getitem__$343,"for line in iterlines:
    if line.startswith(prefix_without_params):
        rv = line[len(prefix_without_params):]
        break
    elif line.startswith(prefix_with_params):
        rv = line[len(prefix_with_params):].split(':', 1)[-1]
        break
else:
    raise KeyError()","flag_else = 1

for line in iterlines:
    if line.startswith(prefix_without_params):
        rv = line[len(prefix_without_params):]
        flag_else = 0
        break
    elif line.startswith(prefix_with_params):
        rv = line[len(prefix_with_params):].split(':', 1)[-1]
        flag_else = 0
        break
if flag_else:
    raise KeyError()",2,FALSE,
bugwarrior,https://github.com/ralphbean/bugwarrior/tree/master/bugwarrior/db.py,,find_taskwarrior_uuid$121,"for r in results[1:]:
    for k in key_list:
        if r[k] != results[0][k]:
            break
else:
    new_possibilities = set([new_possibilities.pop()])","for r in results[1:]:
    for k in key_list:
        if r[k] != results[0][k]:
            break

new_possibilities = set([new_possibilities.pop()])
",0,TRUE,
alembic,https://github.com/sqlalchemy/alembic/tree/master/alembic/util/pyfiles.py,,pyc_file_from_path$69,"for ext in importlib.machinery.BYTECODE_SUFFIXES:
    if os.path.exists(filepath + ext):
        return filepath + ext
else:
    return None","for ext in importlib.machinery.BYTECODE_SUFFIXES:
    if os.path.exists(filepath + ext):
        return filepath + ext

return None
",0,TRUE,
paramiko,https://github.com/paramiko/paramiko/tree/master/paramiko/sftp_server.py,SFTPServer,_check_file$293,"for x in alg_list:
    if x in _hash_class:
        algname = x
        alg = _hash_class[x]
        break
else:
    self._send_status(request_number, SFTP_FAILURE, 'No supported hash types found')
    return","flag_else = 1

for x in alg_list:
    if x in _hash_class:
        algname = x
        alg = _hash_class[x]
        flag_else = 0
        break
if flag_else:
    self._send_status(request_number, SFTP_FAILURE, 'No supported hash types found')
    return",1,FALSE,
MxShop,https://github.com/derek-zhang123/MxShop/tree/master/extra_apps/rest_framework/pagination.py,CursorPagination,get_next_link$590,"for item in reversed(self.page):
    position = self._get_position_from_instance(item, self.ordering)
    if position != compare:
        break
    compare = position
    offset += 1
else:
    if not self.has_previous:
        offset = self.page_size
        position = None
    elif self.cursor.reverse:
        offset = 0
        position = self.previous_position
    else:
        offset = self.cursor.offset + self.page_size
        position = self.previous_position","flag_else = 1

for item in reversed(self.page):
    position = self._get_position_from_instance(item, self.ordering)
    if position != compare:
        flag_else = 0
        break
    compare = position
    offset += 1
if flag_else:
    if not self.has_previous:
        offset = self.page_size
        position = None
    elif self.cursor.reverse:
        offset = 0
        position = self.previous_position
    else:
        offset = self.cursor.offset + self.page_size
        position = self.previous_position",1,FALSE,
unknown-horizons,https://github.com/unknown-horizons/unknown-horizons/tree/master/horizons/util/pathfinding/pathfinding.py,FindPath,execute$115,"while to_check:
    (_, cur_node_coords) = heappop(heap)
    cur_node_data = to_check[cur_node_coords]
    x = cur_node_coords[0]
    y = cur_node_coords[1]
    if self.diagonal:
        x_p1 = x + 1
        x_m1 = x - 1
        y_p1 = y + 1
        y_m1 = y - 1
        neighbors = (i for i in ((x_m1, y_m1), (x_m1, y), (x_m1, y_p1), (x, y_m1), (x, y_p1), (x_p1, y_m1), (x_p1, y), (x_p1, y_p1)) if i not in checked and (i in path_nodes or i in source_coords or i in dest_coords_set) and (i not in blocked_coords))
    else:
        neighbors = (i for i in ((x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)) if (i in path_nodes or i in source_coords or i in dest_coords_set) and i not in checked and (i not in blocked_coords))
    for neighbor_node in neighbors:
        if neighbor_node not in to_check:
            dist_to_here = cur_node_data[1] + path_nodes.get(cur_node_coords, 0)
            total_dist_estimation = destination_to_tuple_distance_func(destination, neighbor_node) + dist_to_here
            to_check[neighbor_node] = (cur_node_coords, dist_to_here, total_dist_estimation)
            heappush(heap, (total_dist_estimation, neighbor_node))
        else:
            distance_to_neighbor = cur_node_data[1] + path_nodes.get(cur_node_coords, 0)
            neighbor = to_check[neighbor_node]
            if neighbor[1] > distance_to_neighbor:
                neighbor = (cur_node_coords, distance_to_neighbor, distance_to_neighbor + (neighbor[2] - neighbor[1]))
    checked[cur_node_coords] = cur_node_data
    del to_check[cur_node_coords]
    if cur_node_coords in dest_coords_set:
        path = [cur_node_coords]
        previous_node = cur_node_data[0]
        while previous_node is not None:
            path.insert(0, previous_node)
            previous_node = checked[previous_node][0]
        return path
else:
    return None","while to_check:
    (_, cur_node_coords) = heappop(heap)
    cur_node_data = to_check[cur_node_coords]
    x = cur_node_coords[0]
    y = cur_node_coords[1]
    if self.diagonal:
        x_p1 = x + 1
        x_m1 = x - 1
        y_p1 = y + 1
        y_m1 = y - 1
        neighbors = (i for i in ((x_m1, y_m1), (x_m1, y), (x_m1, y_p1), (x, y_m1), (x, y_p1), (x_p1, y_m1), (x_p1, y), (x_p1, y_p1)) if i not in checked and (i in path_nodes or i in source_coords or i in dest_coords_set) and (i not in blocked_coords))
    else:
        neighbors = (i for i in ((x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)) if (i in path_nodes or i in source_coords or i in dest_coords_set) and i not in checked and (i not in blocked_coords))
    for neighbor_node in neighbors:
        if neighbor_node not in to_check:
            dist_to_here = cur_node_data[1] + path_nodes.get(cur_node_coords, 0)
            total_dist_estimation = destination_to_tuple_distance_func(destination, neighbor_node) + dist_to_here
            to_check[neighbor_node] = (cur_node_coords, dist_to_here, total_dist_estimation)
            heappush(heap, (total_dist_estimation, neighbor_node))
        else:
            distance_to_neighbor = cur_node_data[1] + path_nodes.get(cur_node_coords, 0)
            neighbor = to_check[neighbor_node]
            if neighbor[1] > distance_to_neighbor:
                neighbor = (cur_node_coords, distance_to_neighbor, distance_to_neighbor + (neighbor[2] - neighbor[1]))
    checked[cur_node_coords] = cur_node_data
    del to_check[cur_node_coords]
    if cur_node_coords in dest_coords_set:
        path = [cur_node_coords]
        previous_node = cur_node_data[0]
        while previous_node is not None:
            path.insert(0, previous_node)
            previous_node = checked[previous_node][0]
        return path

return None
",0,TRUE,
metaflow,https://github.com/Netflix/metaflow/tree/master/test/core/tests/catch_retry.py,CatchRetryTest,check_results$61,"for task in checker.artifact_dict(step.name, 'end_ex').values():
    assert_equals('catch me!', str(task['end_ex'].exception))
    break
else:
    raise Exception(""No artifact 'end_ex' in step 'end'"")","flag_else = 1

for task in checker.artifact_dict(step.name, 'end_ex').values():
    assert_equals('catch me!', str(task['end_ex'].exception))
    flag_else = 0
    break
if flag_else:
    raise Exception(""No artifact 'end_ex' in step 'end'"")",1,FALSE,
matplotlib,https://github.com/matplotlib/matplotlib/tree/master/lib/matplotlib/pyplot.py,,switch_backend$212,"for candidate in candidates:
    try:
        switch_backend(candidate)
    except ImportError:
        continue
    else:
        rcParamsOrig['backend'] = candidate
        return
else:
    switch_backend('agg')
    rcParamsOrig['backend'] = 'agg'
    return","for candidate in candidates:
    try:
        switch_backend(candidate)
    except ImportError:
        continue
    else:
        rcParamsOrig['backend'] = candidate
        return

switch_backend('agg')
rcParamsOrig['backend'] = 'agg'
return
",0,TRUE,
shadowsocksr,https://github.com/shadowsocksr-backup/shadowsocksr/tree/master/shadowsocks/crypto/ctypes_libsodium.py,,load_libsodium$41,"for p in ('sodium',):
    libsodium_path = find_library(p)
    if libsodium_path:
        break
else:
    raise Exception('libsodium not found')","flag_else = 1

for p in ('sodium',):
    libsodium_path = find_library(p)
    if libsodium_path:
        flag_else = 0
        break
if flag_else:
    raise Exception('libsodium not found')",1,FALSE,
PyBitmessage,https://github.com/Bitmessage/PyBitmessage/tree/master/src/tests/test_api.py,TestAPI,test_send_broadcast$368,"for m in json.loads(self.api.getAllSentMessages())['sentMessages']:
    if m['ackData'] == ackdata:
        sent_msg = m['message']
        sent_msgid = m['msgid']
        break
else:
    raise KeyError","flag_else = 1

for m in json.loads(self.api.getAllSentMessages())['sentMessages']:
    if m['ackData'] == ackdata:
        sent_msg = m['message']
        sent_msgid = m['msgid']
        flag_else = 0
        break
if flag_else:
    raise KeyError",1,FALSE,
node-gyp,https://github.com/nodejs/node-gyp/tree/master/gyp/pylib/gyp/generator/eclipse.py,,GetJavaSourceDirs$422,"while os.path.basename(parent_search) not in ['src', 'java']:
    (parent_search, _) = os.path.split(parent_search)
    if not parent_search or parent_search == toplevel_dir:
        yield dir_
        break
else:
    yield parent_search","flag_else = 1

while os.path.basename(parent_search) not in ['src', 'java']:
    (parent_search, _) = os.path.split(parent_search)
    if not parent_search or parent_search == toplevel_dir:
        yield dir_
        flag_else = 0
        break
if flag_else:
    yield parent_search",1,FALSE,
adversarial-robustness-toolbox,https://github.com/Trusted-AI/adversarial-robustness-toolbox/tree/master/art/attacks/evasion/hop_skip_jump.py,HopSkipJump,_init_sample$263,"for _ in range(self.init_size):
    random_img = nprd.uniform(clip_min, clip_max, size=x.shape).astype(x.dtype)
    if mask is not None:
        random_img = random_img * mask + x * (1 - mask)
    random_class = np.argmax(self.estimator.predict(np.array([random_img]), batch_size=self.batch_size), axis=1)[0]
    if random_class != y_p:
        random_img = self._binary_search(current_sample=random_img, original_sample=x, target=y_p, norm=2, clip_min=clip_min, clip_max=clip_max, threshold=0.001)
        initial_sample = (random_img, y_p)
        logger.info('Found initial adversarial image for untargeted attack.')
        break
else:
    logger.warning('Failed to draw a random image that is adversarial, attack failed.')","flag_else = 1

for _ in range(self.init_size):
    random_img = nprd.uniform(clip_min, clip_max, size=x.shape).astype(x.dtype)
    if mask is not None:
        random_img = random_img * mask + x * (1 - mask)
    random_class = np.argmax(self.estimator.predict(np.array([random_img]), batch_size=self.batch_size), axis=1)[0]
    if random_class != y_p:
        random_img = self._binary_search(current_sample=random_img, original_sample=x, target=y_p, norm=2, clip_min=clip_min, clip_max=clip_max, threshold=0.001)
        initial_sample = (random_img, y_p)
        logger.info('Found initial adversarial image for untargeted attack.')
        flag_else = 0
        break
if flag_else:
    logger.warning('Failed to draw a random image that is adversarial, attack failed.')",1,FALSE,
moto,https://github.com/spulec/moto/tree/master/moto/ses/models.py,SESBackend,describe_receipt_rule$437,"for receipt_rule in rule_set:
    if receipt_rule['name'] == rule_name:
        return receipt_rule
else:
    raise RuleDoesNotExist('Invalid Rule Name.')","for receipt_rule in rule_set:
    if receipt_rule['name'] == rule_name:
        return receipt_rule

raise RuleDoesNotExist('Invalid Rule Name.')
",0,TRUE,
pywikibot,https://github.com/wikimedia/pywikibot/tree/master/pywikibot/data/api.py,ParamInfo,_generate_submodules$382,"for param in parameters:
    if param['name'] == 'generator':
        break
else:
    param = {}","flag_else = 1

for param in parameters:
    if param['name'] == 'generator':
        flag_else = 0
        break
if flag_else:
    param = {}",1,FALSE,
micropython-lib,https://github.com/micropython/micropython-lib/tree/master/python-stdlib/textwrap/textwrap.py,TextWrapper,_wrap_chunks$222,"while cur_line:
    if cur_line[-1].strip() and cur_len + len(self.placeholder) <= width:
        cur_line.append(self.placeholder)
        lines.append(indent + ''.join(cur_line))
        break
    cur_len -= len(cur_line[-1])
    del cur_line[-1]
else:
    if lines:
        prev_line = lines[-1].rstrip()
        if len(prev_line) + len(self.placeholder) <= self.width:
            lines[-1] = prev_line + self.placeholder
            break
    lines.append(indent + self.placeholder.lstrip())","flag_else = 1

while cur_line:
    if cur_line[-1].strip() and cur_len + len(self.placeholder) <= width:
        cur_line.append(self.placeholder)
        lines.append(indent + ''.join(cur_line))
        flag_else = 0
        break
    cur_len -= len(cur_line[-1])
    del cur_line[-1]
if flag_else:
    if lines:
        prev_line = lines[-1].rstrip()
        if len(prev_line) + len(self.placeholder) <= self.width:
            lines[-1] = prev_line + self.placeholder
            break
    lines.append(indent + self.placeholder.lstrip())",1,FALSE,
qutebrowser,https://github.com/qutebrowser/qutebrowser/tree/master/qutebrowser/utils/debug.py,,qenum_key$102,"for (name, obj) in vars(base).items():
    if isinstance(obj, klass) and obj == value:
        ret = name
        break
else:
    ret = '0x{:04x}'.format(int(value))","flag_else = 1

for (name, obj) in vars(base).items():
    if isinstance(obj, klass) and obj == value:
        ret = name
        flag_else = 0
        break
if flag_else:
    ret = '0x{:04x}'.format(int(value))",1,FALSE,
tgbot,https://github.com/PaulSonOfLars/tgbot/tree/master/tg_bot/modules/helper_funcs/string_handling.py,,split_quotes$189,"while counter < len(text):
    if text[counter] == '\\':
        counter += 1
    elif text[counter] == text[0] or (text[0] == SMART_OPEN and text[counter] == SMART_CLOSE):
        break
    counter += 1
else:
    return text.split(None, 1)","flag_else = 1

while counter < len(text):
    if text[counter] == '\\':
        counter += 1
    elif text[counter] == text[0] or (text[0] == SMART_OPEN and text[counter] == SMART_CLOSE):
        flag_else = 0
        break
    counter += 1
if flag_else:
    return text.split(None, 1)",1,FALSE,
django-cms,https://github.com/django-cms/django-cms/tree/master/cms/toolbar/items.py,ToolbarAPIMixin,get_alphabetical_insert_position$101,"for result in sorted(results, key=lambda x: x.item.name):
    if result.item.name > new_menu_name:
        return result.index
    if result.index > last_position:
        last_position = result.index
else:
    return last_position + 1","for result in sorted(results, key=lambda x: x.item.name):
    if result.item.name > new_menu_name:
        return result.index
    if result.index > last_position:
        last_position = result.index

return last_position + 1
",0,TRUE,
PhiFlow,https://github.com/tum-pbs/PhiFlow/tree/master/phi/math/_shape.py,Shape,meshgrid$764,"for i in range(self.rank - 1, -1, -1):
    indices[i] = (indices[i] + 1) % self.sizes[i]
    if indices[i] != 0:
        break
else:
    return","flag_else = 1

for i in range(self.rank - 1, -1, -1):
    indices[i] = (indices[i] + 1) % self.sizes[i]
    if indices[i] != 0:
        flag_else = 0
        break
if flag_else:
    return",1,FALSE,
mypy,https://github.com/python/mypy/tree/master/mypy/mro.py,,merge$45,"for seq in seqs:
    head = seq[0]
    if not [s for s in seqs if head in s[1:]]:
        break
else:
    raise MroError()","flag_else = 1

for seq in seqs:
    head = seq[0]
    if not [s for s in seqs if head in s[1:]]:
        flag_else = 0
        break
if flag_else:
    raise MroError()",1,FALSE,
unilm,https://github.com/microsoft/unilm/tree/master/adalm/incr_bpe/text_encoder.py,SubwordTextEncoder,_escaped_token_to_subtoken_strings$388,"for end in range(min(token_len, start + self._max_subtoken_len), start, -1):
    subtoken = escaped_token[start:end]
    if subtoken in self._subtoken_string_to_id:
        ret.append(subtoken)
        start = end
        break
else:
    assert False, 'Token substring not found in subtoken vocabulary.'","flag_else = 1

for end in range(min(token_len, start + self._max_subtoken_len), start, -1):
    subtoken = escaped_token[start:end]
    if subtoken in self._subtoken_string_to_id:
        ret.append(subtoken)
        start = end
        flag_else = 0
        break
if flag_else:
    assert False, 'Token substring not found in subtoken vocabulary.'",1,FALSE,
tinygrad,https://github.com/geohot/tinygrad/tree/master/examples/mnist_gan.py,,if_main_my$52,"for epoch in tqdm(range(epochs)):
    loss_g = 0.0
    loss_d = 0.0
    print(f'Epoch {epoch} of {epochs}')
    for i in tqdm(range(n_steps)):
        image = generator_batch()
        for step in range(k):
            noise = Tensor(np.random.randn(batch_size, 128))
            data_fake = generator.forward(noise).detach()
            data_real = image
            loss_d_step = train_discriminator(optim_d, data_real, data_fake)
            loss_d += loss_d_step
        noise = Tensor(np.random.randn(batch_size, 128))
        data_fake = generator.forward(noise)
        loss_g_step = train_generator(optim_g, data_fake)
        loss_g += loss_g_step
    fake_images = generator.forward(ds_noise).detach().cpu().data
    fake_images = (fake_images.reshape(-1, 1, 28, 28) + 1) / 2
    fake_images = make_grid(torch.tensor(fake_images))
    save_image(fake_images, os.path.join(output_folder, f'image_{epoch}.jpg'))
    epoch_loss_g = loss_g / n_steps
    epoch_loss_d = loss_d / n_steps
    print(f'EPOCH: Generator loss: {epoch_loss_g}, Discriminator loss: {epoch_loss_d}')
else:
    print('Training Completed!')","for epoch in tqdm(range(epochs)):
    loss_g = 0.0
    loss_d = 0.0
    print(f'Epoch {epoch} of {epochs}')
    for i in tqdm(range(n_steps)):
        image = generator_batch()
        for step in range(k):
            noise = Tensor(np.random.randn(batch_size, 128))
            data_fake = generator.forward(noise).detach()
            data_real = image
            loss_d_step = train_discriminator(optim_d, data_real, data_fake)
            loss_d += loss_d_step
        noise = Tensor(np.random.randn(batch_size, 128))
        data_fake = generator.forward(noise)
        loss_g_step = train_generator(optim_g, data_fake)
        loss_g += loss_g_step
    fake_images = generator.forward(ds_noise).detach().cpu().data
    fake_images = (fake_images.reshape(-1, 1, 28, 28) + 1) / 2
    fake_images = make_grid(torch.tensor(fake_images))
    save_image(fake_images, os.path.join(output_folder, f'image_{epoch}.jpg'))
    epoch_loss_g = loss_g / n_steps
    epoch_loss_d = loss_d / n_steps
    print(f'EPOCH: Generator loss: {epoch_loss_g}, Discriminator loss: {epoch_loss_d}')

print('Training Completed!')
",0,TRUE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/simplify/gammasimp.py,,_gammasimp$65,"for y in dg:
    n = x - 2 * y
    if n.is_Integer:
        break
else:
    continue","flag_else = 1

for y in dg:
    n = x - 2 * y
    if n.is_Integer:
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
weblate,https://github.com/WeblateOrg/weblate/tree/master/weblate/lang/models.py,LanguageManager,setup$360,"for plural in plurals[code][Plural.SOURCE_GETTEXT]:
    try:
        if plural.same_plural(nplurals, plural_formula):
            break
    except ValueError:
        if plural.number == nplurals and plural.formula == plural_formula:
            break
else:
    plural = lang.plural_set.create(source=Plural.SOURCE_GETTEXT, number=nplurals, formula=plural_formula, type=get_plural_type(lang.base_code, plural_formula))
    logger(f'Created plural {plural_formula} for language {code}')","flag_else = 1

for plural in plurals[code][Plural.SOURCE_GETTEXT]:
    try:
        if plural.same_plural(nplurals, plural_formula):
            flag_else = 0
            break
    except ValueError:
        if plural.number == nplurals and plural.formula == plural_formula:
            flag_else = 0
            break
if flag_else:
    plural = lang.plural_set.create(source=Plural.SOURCE_GETTEXT, number=nplurals, formula=plural_formula, type=get_plural_type(lang.base_code, plural_formula))
    logger(f'Created plural {plural_formula} for language {code}')",2,FALSE,
dictdiffer,https://github.com/inveniosoftware/dictdiffer/tree/master/dictdiffer/resolve.py,Resolver,resolve_conflicts$100,"for sub_path in self._consecutive_slices(conflict_path):
    try:
        if self.actions[sub_path](conflict, first_patches, second_patches, self.additional_info):
            break
    except NoFurtherResolutionException:
        self.unresolved_conflicts.append(conflict)
        break
    except KeyError:
        pass
else:
    self.unresolved_conflicts.append(conflict)","flag_else = 1

for sub_path in self._consecutive_slices(conflict_path):
    try:
        if self.actions[sub_path](conflict, first_patches, second_patches, self.additional_info):
            flag_else = 0
            break
    except NoFurtherResolutionException:
        self.unresolved_conflicts.append(conflict)
        flag_else = 0
        break
    except KeyError:
        pass
if flag_else:
    self.unresolved_conflicts.append(conflict)",2,FALSE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/core/mul.py,Mul,as_real_imag$864,"for (i, x) in enumerate(other):
    if x == a.conjugate():
        coeffr.append(Abs(x) ** 2)
        del other[i]
        break
else:
    if a.is_Add:
        addterms *= a
    else:
        other.append(a)","flag_else = 1

for (i, x) in enumerate(other):
    if x == a.conjugate():
        coeffr.append(Abs(x) ** 2)
        del other[i]
        flag_else = 0
        break
if flag_else:
    if a.is_Add:
        addterms *= a
    else:
        other.append(a)",1,FALSE,
nova,https://github.com/openstack/nova/tree/master/nova/compute/api.py,API,_check_requested_volume_type$1769,"for vol_type in volume_types:
    if volume_type_id_or_name == vol_type['id'] or volume_type_id_or_name == vol_type['name']:
        bdm.volume_type = vol_type['name']
        break
else:
    raise exception.VolumeTypeNotFound(id_or_name=volume_type_id_or_name)","flag_else = 1

for vol_type in volume_types:
    if volume_type_id_or_name == vol_type['id'] or volume_type_id_or_name == vol_type['name']:
        bdm.volume_type = vol_type['name']
        flag_else = 0
        break
if flag_else:
    raise exception.VolumeTypeNotFound(id_or_name=volume_type_id_or_name)",1,FALSE,
Misago,https://github.com/rafalp/Misago/tree/master/misago/threads/api/threadendpoints/patch.py,,patch_remove_participant$322,"for participant in thread.participants_list:
    if participant.user_id == user_id:
        break
else:
    raise PermissionDenied(_(""Participant doesn't exist.""))","flag_else = 1

for participant in thread.participants_list:
    if participant.user_id == user_id:
        flag_else = 0
        break
if flag_else:
    raise PermissionDenied(_(""Participant doesn't exist.""))",1,FALSE,
vsphere-automation-sdk-python,https://github.com/vmware/vsphere-automation-sdk-python/tree/master/samples/vmc/draas/deploy_additional_node.py,DeployAdditionalNode,query_deployment$79,"while time.time() < timeout:
    node_details = self.vmc_client.draas.SiteRecovery.get(self.org_id, self.sddc_id)
    time.sleep(self.wait_time)
    if node_details.srm_nodes[node_index].state in ['READY', 'DELETING', 'CANCELLED', 'FAILED']:
        print('Site Recovery (DRaaS) Additonal Node Deployment Status {} : {}'.format(node_details.updated, node_details.srm_nodes[node_index].state))
        break
    else:
        print('Site Recovery (DRaaS) Additonal Node Deployment Status {} : {}'.format(node_details.updated, node_details.srm_nodes[node_index].state))
        continue
else:
    raise Exception('Max time out reached {}'.format(self.max_wait_time))","flag_else = 1

while time.time() < timeout:
    node_details = self.vmc_client.draas.SiteRecovery.get(self.org_id, self.sddc_id)
    time.sleep(self.wait_time)
    if node_details.srm_nodes[node_index].state in ['READY', 'DELETING', 'CANCELLED', 'FAILED']:
        print('Site Recovery (DRaaS) Additonal Node Deployment Status {} : {}'.format(node_details.updated, node_details.srm_nodes[node_index].state))
        flag_else = 0
        break
    else:
        print('Site Recovery (DRaaS) Additonal Node Deployment Status {} : {}'.format(node_details.updated, node_details.srm_nodes[node_index].state))
        continue
if flag_else:
    raise Exception('Max time out reached {}'.format(self.max_wait_time))",1,FALSE,
freeipa,https://github.com/freeipa/freeipa/tree/master/ipaserver/install/ipa_restore.py,Restore,run$248,"for (instance, backend) in databases:
    if instance == options.instance:
        break
else:
    raise admintool.ScriptError('Instance %s not found in backup' % options.instance)","flag_else = 1

for (instance, backend) in databases:
    if instance == options.instance:
        flag_else = 0
        break
if flag_else:
    raise admintool.ScriptError('Instance %s not found in backup' % options.instance)",1,FALSE,
tfx,https://github.com/tensorflow/tfx/tree/master/tfx/orchestration/airflow/test_utils.py,,create_mysql_container$27,"for _ in range(_MYSQL_POLLING_MAX_ATTEMPTS):
    logging.info('Waiting for mysqld container...')
    time.sleep(_MYSQL_POLLING_INTERVAL_SEC)
    check_available = subprocess.run(['mysql', '-uroot', '-proot', '-h', '127.0.0.1', '-P', str(port), '-e', 'SELECT 1;'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if check_available.returncode == 0:
        break
else:
    logging.error('Logs from mysql container:\n%s', container.logs())
    raise RuntimeError('MySql could not started in %d seconds' % (_MYSQL_POLLING_INTERVAL_SEC * _MYSQL_POLLING_MAX_ATTEMPTS))","flag_else = 1

for _ in range(_MYSQL_POLLING_MAX_ATTEMPTS):
    logging.info('Waiting for mysqld container...')
    time.sleep(_MYSQL_POLLING_INTERVAL_SEC)
    check_available = subprocess.run(['mysql', '-uroot', '-proot', '-h', '127.0.0.1', '-P', str(port), '-e', 'SELECT 1;'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if check_available.returncode == 0:
        flag_else = 0
        break
if flag_else:
    logging.error('Logs from mysql container:\n%s', container.logs())
    raise RuntimeError('MySql could not started in %d seconds' % (_MYSQL_POLLING_INTERVAL_SEC * _MYSQL_POLLING_MAX_ATTEMPTS))",1,FALSE,
deluge,https://github.com/deluge-torrent/deluge/tree/master/deluge/ui/hostlist.py,HostList,remove_host$264,"for host_entry in self.config['hosts']:
    if host_id == host_entry[0]:
        self.config['hosts'].remove(host_entry)
        self.config.save()
        return True
else:
    return False","for host_entry in self.config['hosts']:
    if host_id == host_entry[0]:
        self.config['hosts'].remove(host_entry)
        self.config.save()
        return True

return False
",0,TRUE,
sheetfu,https://github.com/socialpoint-labs/sheetfu/tree/master/sheetfu/model.py,Spreadsheet,get_sheet_by_id$87,"for sheet in self.sheets:
    if sheet.sid == sid:
        return sheet
else:
    raise SheetIdNoMatchError","for sheet in self.sheets:
    if sheet.sid == sid:
        return sheet

raise SheetIdNoMatchError
",0,TRUE,
salt,https://github.com/saltstack/salt/tree/master/tests/support/mock.py,MockOpen,__call__$365,"for pat in self.read_data:
    if pat == '*':
        continue
    if fnmatch.fnmatch(name, pat):
        matched_pattern = pat
        break
else:
    matched_pattern = '*'","flag_else = 1

for pat in self.read_data:
    if pat == '*':
        continue
    if fnmatch.fnmatch(name, pat):
        matched_pattern = pat
        flag_else = 0
        break
if flag_else:
    matched_pattern = '*'",1,FALSE,
pycparser,https://github.com/eliben/pycparser/tree/master/pycparser/ply/cpp.py,Preprocessor,include$742,"while i < len(tokens):
    if tokens[i].value == '>':
        break
    i += 1
else:
    print('Malformed #include <...>')
    return","flag_else = 1

while i < len(tokens):
    if tokens[i].value == '>':
        flag_else = 0
        break
    i += 1
if flag_else:
    print('Malformed #include <...>')
    return",1,FALSE,
checkmk,https://github.com/tribe29/checkmk/tree/master/tests/integration/cmk/gui/test_webapi.py,,graph_test_config$808,"for attempt in range(50):
    time.sleep(0.1)
    proc = subprocess.Popen([site.path('bin/unixcat'), site.path('tmp/run/rrdcached.sock')], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding='utf-8')
    (out, err) = proc.communicate('FLUSH %s\n' % rrd_path)
    if os.path.exists(rrd_path):
        break
    sys.stdout.write('waiting for %s (attempt %d)%s%s\n' % (rrd_path, attempt + 1, ', stdout: %s' % out if out else '', ', stderr: %s' % err if err else ''))
else:
    raise AssertionError('RRD file %s missing' % rrd_path)","flag_else = 1

for attempt in range(50):
    time.sleep(0.1)
    proc = subprocess.Popen([site.path('bin/unixcat'), site.path('tmp/run/rrdcached.sock')], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding='utf-8')
    (out, err) = proc.communicate('FLUSH %s\n' % rrd_path)
    if os.path.exists(rrd_path):
        flag_else = 0
        break
    sys.stdout.write('waiting for %s (attempt %d)%s%s\n' % (rrd_path, attempt + 1, ', stdout: %s' % out if out else '', ', stderr: %s' % err if err else ''))
if flag_else:
    raise AssertionError('RRD file %s missing' % rrd_path)",1,FALSE,
python-igraph,https://github.com/igraph/python-igraph/tree/master/tests/test_foreign.py,ForeignTests,testMultigraphGraphTool$820,"for edge2 in g2.es:
    if edge2 in edge2_found:
        continue
    if edge.source != edge2.source:
        continue
    if edge.target != edge2.target:
        continue
    for an in edge.attribute_names():
        if edge.attributes()[an] != edge2.attributes()[an]:
            break
    else:
        edge2_found.add(edge2)
        break
else:
    self.assertTrue(False)","flag_else = 1

for edge2 in g2.es:
    if edge2 in edge2_found:
        continue
    if edge.source != edge2.source:
        continue
    if edge.target != edge2.target:
        continue
    for an in edge.attribute_names():
        if edge.attributes()[an] != edge2.attributes()[an]:
            break
    else:
        edge2_found.add(edge2)
        flag_else = 0
        break
if flag_else:
    self.assertTrue(False)",1,FALSE,
nltk,https://github.com/nltk/nltk/tree/master/nltk/tree/parented.py,MultiParentedTree,_delparent$557,"for (i, c) in enumerate(self):
    if c is child and i != index:
        break
else:
    child._parents.remove(self)","flag_else = 1

for (i, c) in enumerate(self):
    if c is child and i != index:
        flag_else = 0
        break
if flag_else:
    child._parents.remove(self)",1,FALSE,
freeipa,https://github.com/freeipa/freeipa/tree/master/ipaserver/install/dogtaginstance.py,DogtagInstance,setup_admin$745,"while time.time() < deadline:
    time.sleep(1)
    try:
        master_conn.simple_bind(self.admin_dn, self.admin_password)
    except errors.ACIError:
        pass
    else:
        logger.debug('Successfully logged in as %s', self.admin_dn)
        break
else:
    logger.error('Unable to log in as %s on %s', self.admin_dn, master_conn)
    logger.info('[hint] tune with replication_wait_timeout')
    raise errors.NotFound(reason='{} did not replicate to {}'.format(self.admin_dn, master_conn))","flag_else = 1

while time.time() < deadline:
    time.sleep(1)
    try:
        master_conn.simple_bind(self.admin_dn, self.admin_password)
    except errors.ACIError:
        pass
    else:
        logger.debug('Successfully logged in as %s', self.admin_dn)
        flag_else = 0
        break
if flag_else:
    logger.error('Unable to log in as %s on %s', self.admin_dn, master_conn)
    logger.info('[hint] tune with replication_wait_timeout')
    raise errors.NotFound(reason='{} did not replicate to {}'.format(self.admin_dn, master_conn))",1,FALSE,
security_monkey,https://github.com/Netflix/security_monkey/tree/master/security_monkey/sso/views.py,Ping,post$64,"for key in r.json()['keys']:
    if key['kid'] == header_data['kid']:
        secret = get_rsa_public_key(key['n'], key['e'])
        algo = header_data['alg']
        break
else:
    return (dict(message='Key not found'), 403)","flag_else = 1

for key in r.json()['keys']:
    if key['kid'] == header_data['kid']:
        secret = get_rsa_public_key(key['n'], key['e'])
        algo = header_data['alg']
        flag_else = 0
        break
if flag_else:
    return (dict(message='Key not found'), 403)",1,FALSE,
pockyt,https://github.com/achembarpu/pockyt/tree/master/pockyt/client.py,Client,run$220,"for info in self._output:
    self._print_to_console(info)
    if self._args.archive:
        self._save_to_archive(info)
    elif self._args.output == 'browser':
        self._open_in_browser(info)
else:
    if self._args.output:
        self._output_to_file()","for info in self._output:
    self._print_to_console(info)
    if self._args.archive:
        self._save_to_archive(info)
    elif self._args.output == 'browser':
        self._open_in_browser(info)

if self._args.output:
    self._output_to_file()
",0,TRUE,
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/youtube_dlc/extractor/cammodels.py,CamModelsIE,_real_extract$20,"for (pattern, message) in ERRORS:
    if pattern in webpage:
        error = message
        expected = True
        break
else:
    error = 'Unable to find manifest URL root'
    expected = False","flag_else = 1

for (pattern, message) in ERRORS:
    if pattern in webpage:
        error = message
        expected = True
        flag_else = 0
        break
if flag_else:
    error = 'Unable to find manifest URL root'
    expected = False",1,FALSE,
django-shop,https://github.com/awesto/django-shop/tree/master/shop/models/product.py,AvailableProductMixin,check$94,"for cart_field in CartItemModel._meta.fields:
    if cart_field.attname == 'quantity':
        break
else:
    msg = 'Class `{}` must implement a field named `quantity`.'
    errors.append(checks.Error(msg.format(CartItemModel.__name__)))","flag_else = 1

for cart_field in CartItemModel._meta.fields:
    if cart_field.attname == 'quantity':
        flag_else = 0
        break
if flag_else:
    msg = 'Class `{}` must implement a field named `quantity`.'
    errors.append(checks.Error(msg.format(CartItemModel.__name__)))",1,FALSE,
swift,https://github.com/openstack/swift/tree/master/test/unit/obj/test_reconstructor.py,TestObjectReconstructor,test_build_jobs_handoff$3797,"for partition in range(2 ** ring.part_power):
    part_nodes = ring.get_part_nodes(partition)
    if self.local_dev['id'] not in [n['id'] for n in part_nodes]:
        break
else:
    self.fail(""the ring doesn't work: %r"" % ring._replica2part2dev_id)","flag_else = 1

for partition in range(2 ** ring.part_power):
    part_nodes = ring.get_part_nodes(partition)
    if self.local_dev['id'] not in [n['id'] for n in part_nodes]:
        flag_else = 0
        break
if flag_else:
    self.fail(""the ring doesn't work: %r"" % ring._replica2part2dev_id)",1,FALSE,
salt,https://github.com/saltstack/salt/tree/master/salt/states/file.py,,patch$6546,"for item in ('-N', '--forward', '-r', '--reject-file', '-o', '--output'):
    if option.startswith(item):
        blacklisted = option
        break
else:
    blacklisted = None","flag_else = 1

for item in ('-N', '--forward', '-r', '--reject-file', '-o', '--output'):
    if option.startswith(item):
        blacklisted = option
        flag_else = 0
        break
if flag_else:
    blacklisted = None",1,FALSE,
TauonMusicBox,https://github.com/Taiko2k/TauonMusicBox/tree/master/t_modules/t_main.py,TextBox2,draw$10395,"for i in range(len(text)):
    post = ddt.get_text_w(text[0:i + 1], font)
    if x + pre - 0 <= mouse_position[0] <= x + post + 0:
        diff = post - pre
        if mouse_position[0] >= x + pre + int(diff / 2):
            self.selection = len(text) - i - 1
        else:
            self.selection = len(text) - i
        break
    pre = post
else:
    self.selection = 0","flag_else = 1

for i in range(len(text)):
    post = ddt.get_text_w(text[0:i + 1], font)
    if x + pre - 0 <= mouse_position[0] <= x + post + 0:
        diff = post - pre
        if mouse_position[0] >= x + pre + int(diff / 2):
            self.selection = len(text) - i - 1
        else:
            self.selection = len(text) - i
        flag_else = 0
        break
    pre = post
if flag_else:
    self.selection = 0",1,FALSE,
tg2,https://github.com/TurboGears/tg2/tree/master/tests/test_errorware.py,TestSlowReqsReporterConfig,test_actually_reports$144,"for i in range(100):
    if 'request' in REPORTED_CONTEXT:
        break
    time.sleep(0.01)
else:
    assert False, 'Timeout!'","flag_else = 1

for i in range(100):
    if 'request' in REPORTED_CONTEXT:
        flag_else = 0
        break
    time.sleep(0.01)
if flag_else:
    assert False, 'Timeout!'",1,FALSE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/functions/elementary/complexes.py,arg,eval$752,"for i in range(3):
    if isinstance(a, cls):
        a = a.args[0]
    else:
        if i == 2 and a.is_extended_real:
            return S.NaN
        break
else:
    return S.NaN","flag_else = 1

for i in range(3):
    if isinstance(a, cls):
        a = a.args[0]
    else:
        if i == 2 and a.is_extended_real:
            return S.NaN
        flag_else = 0
        break
if flag_else:
    return S.NaN",1,FALSE,
tf-quant-finance,https://github.com/google/tf-quant-finance/tree/master/tf_quant_finance/models/hull_white/hull_white_test.py,HullWhiteTest,setUp$30,"for j in range(len(intervals) - 1):
    if tt >= intervals[j] and tt < intervals[j + 1]:
        var = var + vol[j] ** 2 / 2 / k * (np.exp(2 * k * tt) - np.exp(2 * k * intervals[j]))
        break
    else:
        var = var + vol[j] ** 2 / 2 / k * (np.exp(2 * k * intervals[j + 1]) - np.exp(2 * k * intervals[j]))
else:
    var = var + vol[-1] ** 2 / 2 / k * (np.exp(2 * k * tt) - np.exp(2 * k * intervals[-1]))","flag_else = 1

for j in range(len(intervals) - 1):
    if tt >= intervals[j] and tt < intervals[j + 1]:
        var = var + vol[j] ** 2 / 2 / k * (np.exp(2 * k * tt) - np.exp(2 * k * intervals[j]))
        flag_else = 0
        break
    else:
        var = var + vol[j] ** 2 / 2 / k * (np.exp(2 * k * intervals[j + 1]) - np.exp(2 * k * intervals[j]))
if flag_else:
    var = var + vol[-1] ** 2 / 2 / k * (np.exp(2 * k * tt) - np.exp(2 * k * intervals[-1]))",1,FALSE,
PaddleOCR,https://github.com/PaddlePaddle/PaddleOCR/tree/master/PPOCRLabel/libs/canvas.py,Canvas,mouseMoveEvent$129,"for shape in reversed([s for s in self.shapes if self.isVisible(s)]):
    index = shape.nearestVertex(pos, self.epsilon)
    if index is not None:
        if self.selectedVertex():
            self.hShape.highlightClear()
        (self.hVertex, self.hShape) = (index, shape)
        shape.highlightVertex(index, shape.MOVE_VERTEX)
        self.overrideCursor(CURSOR_POINT)
        self.setToolTip('Click & drag to move point')
        self.setStatusTip(self.toolTip())
        self.update()
        break
    elif shape.containsPoint(pos):
        if self.selectedVertex():
            self.hShape.highlightClear()
        (self.hVertex, self.hShape) = (None, shape)
        self.setToolTip(""Click & drag to move shape '%s'"" % shape.label)
        self.setStatusTip(self.toolTip())
        self.overrideCursor(CURSOR_GRAB)
        self.update()
        break
else:
    if self.hShape:
        self.hShape.highlightClear()
        self.update()
    (self.hVertex, self.hShape) = (None, None)
    self.overrideCursor(CURSOR_DEFAULT)","flag_else = 1

for shape in reversed([s for s in self.shapes if self.isVisible(s)]):
    index = shape.nearestVertex(pos, self.epsilon)
    if index is not None:
        if self.selectedVertex():
            self.hShape.highlightClear()
        (self.hVertex, self.hShape) = (index, shape)
        shape.highlightVertex(index, shape.MOVE_VERTEX)
        self.overrideCursor(CURSOR_POINT)
        self.setToolTip('Click & drag to move point')
        self.setStatusTip(self.toolTip())
        self.update()
        flag_else = 0
        break
    elif shape.containsPoint(pos):
        if self.selectedVertex():
            self.hShape.highlightClear()
        (self.hVertex, self.hShape) = (None, shape)
        self.setToolTip(""Click & drag to move shape '%s'"" % shape.label)
        self.setStatusTip(self.toolTip())
        self.overrideCursor(CURSOR_GRAB)
        self.update()
        flag_else = 0
        break
if flag_else:
    if self.hShape:
        self.hShape.highlightClear()
        self.update()
    (self.hVertex, self.hShape) = (None, None)
    self.overrideCursor(CURSOR_DEFAULT)",2,FALSE,
social-core,https://github.com/python-social-auth/social-core/tree/master/social_core/backends/open_id_connect.py,OpenIdConnectAuth,find_valid_key$145,"for key in keys:
    if kid == key.get('kid'):
        break
else:
    self.get_jwks_keys.invalidate()
    keys = self.get_jwks_keys()","flag_else = 1

for key in keys:
    if kid == key.get('kid'):
        flag_else = 0
        break
if flag_else:
    self.get_jwks_keys.invalidate()
    keys = self.get_jwks_keys()",1,FALSE,
getproxy,https://github.com/fate0/getproxy/tree/master/getproxy/plugin/cnproxy.py,Proxy,extract_proxy$46,"while self.proxies:
    new_proxy = self.proxies.pop(0)
    self.cur_proxy = {new_proxy['type']: '%s:%s' % (new_proxy['host'], new_proxy['port'])}
    raise e
else:
    return []","while self.proxies:
    new_proxy = self.proxies.pop(0)
    self.cur_proxy = {new_proxy['type']: '%s:%s' % (new_proxy['host'], new_proxy['port'])}
    raise e

return []
",0,TRUE,
hachoir,https://github.com/vstinner/hachoir/tree/master/hachoir/parser/misc/dsstore.py,DSStore,createFields$196,"for dir in self['allocator'].array('dir'):
    if dir['name'].value == 'DSDB':
        break
else:
    raise ParserError('DSDB not found.')","flag_else = 1

for dir in self['allocator'].array('dir'):
    if dir['name'].value == 'DSDB':
        flag_else = 0
        break
if flag_else:
    raise ParserError('DSDB not found.')",1,FALSE,
integrations-core,https://github.com/DataDog/integrations-core/tree/master/datadog_checks_base/tests/base/checks/windows/perf_counters/test_config.py,TestSingleInstanceLogUnusedOptions,test_instance_counts$522,"for (_, level, message) in caplog.record_tuples:
    if level == logging.WARNING and message == expected_message:
        break
else:
    raise AssertionError('Expected WARNING log with message `{}`'.format(expected_message))","flag_else = 1

for (_, level, message) in caplog.record_tuples:
    if level == logging.WARNING and message == expected_message:
        flag_else = 0
        break
if flag_else:
    raise AssertionError('Expected WARNING log with message `{}`'.format(expected_message))",1,FALSE,
python-driver,https://github.com/datastax/python-driver/tree/master/tests/integration/standard/test_cluster.py,ClusterTests,test_trace_unavailable$619,"for i in range(max_retry_count):
    future = session.execute_async(statement, trace=True)
    try:
        result = future.get_query_trace(max_wait=120)
        self._check_trace(result)
    except TraceUnavailable:
        break
else:
    raise Exception(""get_query_trace didn't raise TraceUnavailable after {} tries"".format(max_retry_count))","flag_else = 1

for i in range(max_retry_count):
    future = session.execute_async(statement, trace=True)
    try:
        result = future.get_query_trace(max_wait=120)
        self._check_trace(result)
    except TraceUnavailable:
        flag_else = 0
        break
if flag_else:
    raise Exception(""get_query_trace didn't raise TraceUnavailable after {} tries"".format(max_retry_count))",1,FALSE,
httpie,https://github.com/httpie/httpie/tree/master/httpie/output/formatters/colors.py,,get_lexer$142,"for mime_type in mime_types:
    try:
        lexer = pygments.lexers.get_lexer_for_mimetype(mime_type)
        break
    except ClassNotFound:
        pass
else:
    for name in lexer_names:
        try:
            lexer = pygments.lexers.get_lexer_by_name(name)
        except ClassNotFound:
            pass","flag_else = 1

for mime_type in mime_types:
    try:
        lexer = pygments.lexers.get_lexer_for_mimetype(mime_type)
        flag_else = 0
        break
    except ClassNotFound:
        pass
if flag_else:
    for name in lexer_names:
        try:
            lexer = pygments.lexers.get_lexer_by_name(name)
        except ClassNotFound:
            pass",1,FALSE,
localstack,https://github.com/localstack/localstack/tree/master/localstack/services/events/events_starter.py,,filter_event_with_content_base_parameter$267,"for index in range(len(element_value)):
    if isinstance(element_value[index], int):
        continue
    if element_value[index] == '>' and isinstance(element_value[index + 1], int) and (event_value <= element_value[index + 1]):
        break
    elif element_value[index] == '>=' and isinstance(element_value[index + 1], int) and (event_value < element_value[index + 1]):
        break
    elif element_value[index] == '<' and isinstance(element_value[index + 1], int) and (event_value >= element_value[index + 1]):
        break
    elif element_value[index] == '<=' and isinstance(element_value[index + 1], int) and (event_value > element_value[index + 1]):
        break
else:
    return True","flag_else = 1

for index in range(len(element_value)):
    if isinstance(element_value[index], int):
        continue
    if element_value[index] == '>' and isinstance(element_value[index + 1], int) and (event_value <= element_value[index + 1]):
        flag_else = 0
        break
    elif element_value[index] == '>=' and isinstance(element_value[index + 1], int) and (event_value < element_value[index + 1]):
        flag_else = 0
        break
    elif element_value[index] == '<' and isinstance(element_value[index + 1], int) and (event_value >= element_value[index + 1]):
        flag_else = 0
        break
    elif element_value[index] == '<=' and isinstance(element_value[index + 1], int) and (event_value > element_value[index + 1]):
        flag_else = 0
        break
if flag_else:
    return True",4,FALSE,
server-tools,https://github.com/OCA/server-tools/tree/master/base_changeset/tests/common.py,ChangesetTestCommon,assert_changeset$7,"for change in changes:
    if (change.field_id, change.get_origin_value(), change.get_new_value(), change.state) == expected_change:
        changes -= change
        break
else:
    missing.append(expected_change)","flag_else = 1

for change in changes:
    if (change.field_id, change.get_origin_value(), change.get_new_value(), change.state) == expected_change:
        changes -= change
        flag_else = 0
        break
if flag_else:
    missing.append(expected_change)",1,FALSE,
nvda,https://github.com/nvaccess/nvda/tree/master/source/brailleDisplayDrivers/baum.py,BrailleDisplayDriver,__init__$70,"for (portType, portId, port, portInfo) in self._getTryPorts(port):
    self.isHid = portType == bdDetect.KEY_HID
    try:
        if self.isHid:
            self._dev = hwIo.Hid(port, onReceive=self._onReceive)
        else:
            self._dev = hwIo.Serial(port, baudrate=BAUD_RATE, timeout=TIMEOUT, writeTimeout=TIMEOUT, onReceive=self._onReceive)
    except EnvironmentError:
        log.debugWarning('', exc_info=True)
        continue
    if self.isHid:
        try:
            self._sendRequest(BAUM_PROTOCOL_ONOFF, True)
        except EnvironmentError:
            pass
        self._sendRequest(BAUM_REQUEST_INFO, 0)
    else:
        self._sendRequest(BAUM_PROTOCOL_ONOFF, False)
        self._sendRequest(BAUM_PROTOCOL_ONOFF, True)
        self._sendRequest(BAUM_PROTOCOL_ONOFF, True)
    for i in range(3):
        self._dev.waitForRead(TIMEOUT)
        if self.numCells and self._deviceID:
            break
    if self.numCells:
        log.info('Found {device} connected via {type} ({port})'.format(device=self._deviceID, type=portType, port=port))
        break
    self._dev.close()
else:
    raise RuntimeError('No Baum display found')","flag_else = 1

for (portType, portId, port, portInfo) in self._getTryPorts(port):
    self.isHid = portType == bdDetect.KEY_HID
    try:
        if self.isHid:
            self._dev = hwIo.Hid(port, onReceive=self._onReceive)
        else:
            self._dev = hwIo.Serial(port, baudrate=BAUD_RATE, timeout=TIMEOUT, writeTimeout=TIMEOUT, onReceive=self._onReceive)
    except EnvironmentError:
        log.debugWarning('', exc_info=True)
        continue
    if self.isHid:
        try:
            self._sendRequest(BAUM_PROTOCOL_ONOFF, True)
        except EnvironmentError:
            pass
        self._sendRequest(BAUM_REQUEST_INFO, 0)
    else:
        self._sendRequest(BAUM_PROTOCOL_ONOFF, False)
        self._sendRequest(BAUM_PROTOCOL_ONOFF, True)
        self._sendRequest(BAUM_PROTOCOL_ONOFF, True)
    for i in range(3):
        self._dev.waitForRead(TIMEOUT)
        if self.numCells and self._deviceID:
            break
    if self.numCells:
        log.info('Found {device} connected via {type} ({port})'.format(device=self._deviceID, type=portType, port=port))
        flag_else = 0
        break
    self._dev.close()
if flag_else:
    raise RuntimeError('No Baum display found')",1,FALSE,
Cyberbrain,https://github.com/laike9m/Cyberbrain/tree/master/test/test_while_loop.py,,test_while_loop$5,"while True:
    break
else:
    a = 1","flag_else = 1

while True:
    flag_else = 0
    break
if flag_else:
    a = 1",1,FALSE,
legendary,https://github.com/derrod/legendary/tree/master/legendary/core.py,LegendaryCore,get_cdn_manifest$1222,"for url in manifest_urls:
    self.log.debug(f'Trying to download manifest from ""{url}""...')
    r = self.egs.unauth_session.get(url)
    if r.status_code == 200:
        manifest_bytes = r.content
        break
    else:
        self.log.warning(f'Unable to download manifest from ""{urlparse(url).netloc}"" (status: {r.status_code}), trying next URL...')
else:
    raise ValueError(f'Unable to get manifest from any CDN URL, last result: {r.status_code} ({r.reason})')","flag_else = 1

for url in manifest_urls:
    self.log.debug(f'Trying to download manifest from ""{url}""...')
    r = self.egs.unauth_session.get(url)
    if r.status_code == 200:
        manifest_bytes = r.content
        flag_else = 0
        break
    else:
        self.log.warning(f'Unable to download manifest from ""{urlparse(url).netloc}"" (status: {r.status_code}), trying next URL...')
if flag_else:
    raise ValueError(f'Unable to get manifest from any CDN URL, last result: {r.status_code} ({r.reason})')",1,FALSE,
rich,https://github.com/willmcgugan/rich/tree/master/rich/columns.py,Columns,__rich_console__$62,"for (renderable_width, _) in iter_renderables(column_count):
    widths[column_no] = max(widths[column_no], renderable_width)
    total_width = sum(widths.values()) + width_padding * (len(widths) - 1)
    if total_width > max_width:
        column_count = len(widths) - 1
        break
    else:
        column_no = (column_no + 1) % column_count
else:
    break","flag_else = 1

for (renderable_width, _) in iter_renderables(column_count):
    widths[column_no] = max(widths[column_no], renderable_width)
    total_width = sum(widths.values()) + width_padding * (len(widths) - 1)
    if total_width > max_width:
        column_count = len(widths) - 1
        flag_else = 0
        break
    else:
        column_no = (column_no + 1) % column_count
if flag_else:
    break",1,FALSE,
dateparser,https://github.com/scrapinghub/dateparser/tree/master/dateparser/parser.py,_time_parser,__call__$86,"for directive in self.time_directives:
    try:
        return strptime(timestring.strip(), directive).time()
    except ValueError:
        pass
else:
    raise ValueError('%s does not seem to be a valid time string' % _timestring)","for directive in self.time_directives:
    try:
        return strptime(timestring.strip(), directive).time()
    except ValueError:
        pass

raise ValueError('%s does not seem to be a valid time string' % _timestring)
",0,TRUE,
dash,https://github.com/plotly/dash/tree/master/tests/integration/devtools/test_callback_validation.py,,check_errors$12,"for (j, (msg, txt)) in enumerate(found):
    if msg == message and all((snip in txt for snip in snippets)):
        print(j)
        found.pop(j)
        break
else:
    raise AssertionError('error {} ({}) not found with text:\n  {}\nThe found messages were:\n---\n{}'.format(i, message, '\n  '.join(snippets), '\n---\n'.join(('{}\n{}'.format(msg, txt) for (msg, txt) in orig_found))))","flag_else = 1

for (j, (msg, txt)) in enumerate(found):
    if msg == message and all((snip in txt for snip in snippets)):
        print(j)
        found.pop(j)
        flag_else = 0
        break
if flag_else:
    raise AssertionError('error {} ({}) not found with text:\n  {}\nThe found messages were:\n---\n{}'.format(i, message, '\n  '.join(snippets), '\n---\n'.join(('{}\n{}'.format(msg, txt) for (msg, txt) in orig_found))))",1,FALSE,
bCNC,https://github.com/vlachoudis/bCNC/tree/master/bCNC/CNCCanvas.py,CNCCanvas,click$497,"for item in self.find_overlapping(i - CLOSE_DISTANCE, j - CLOSE_DISTANCE, i + CLOSE_DISTANCE, j + CLOSE_DISTANCE):
    tags = self.gettags(item)
    if 'sel' in tags or 'sel2' in tags or 'sel3' in tags or ('sel4' in tags):
        break
else:
    self._mouseAction = ACTION_SELECT_SINGLE
    return","flag_else = 1

for item in self.find_overlapping(i - CLOSE_DISTANCE, j - CLOSE_DISTANCE, i + CLOSE_DISTANCE, j + CLOSE_DISTANCE):
    tags = self.gettags(item)
    if 'sel' in tags or 'sel2' in tags or 'sel3' in tags or ('sel4' in tags):
        flag_else = 0
        break
if flag_else:
    self._mouseAction = ACTION_SELECT_SINGLE
    return",1,FALSE,
GitSavvy,https://github.com/timbrel/GitSavvy/tree/master/core/base_commands.py,WithInputHandlers,run_$48,"for name in ordered_positional_args(self.run):
    if name not in present and name in self.defaults:
        sync_mode = Flag()
        done = make_on_done_fn(lambda : None if sync_mode else run_command(self, args), args, name)
        with sync_mode.set():
            self.defaults[name](self, args, done)
        if not done.called:
            break
else:
    return super().run_(edit_token, args)","flag_else = 1

for name in ordered_positional_args(self.run):
    if name not in present and name in self.defaults:
        sync_mode = Flag()
        done = make_on_done_fn(lambda : None if sync_mode else run_command(self, args), args, name)
        with sync_mode.set():
            self.defaults[name](self, args, done)
        if not done.called:
            flag_else = 0
            break
if flag_else:
    return super().run_(edit_token, args)",1,FALSE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/integrals/heurisch.py,,heurisch$289,"for mapping in mappings:
    mapping = list(mapping)
    mapping = mapping + unnecessary_permutations
    diffs = [_substitute(dcache.get_diff(g)) for g in terms]
    denoms = [g.as_numer_denom()[1] for g in diffs]
    if all((h.is_polynomial(*V) for h in denoms)) and _substitute(f).is_rational_function(*V):
        denom = reduce(lambda p, q: lcm(p, q, *V), denoms)
        break
else:
    if not rewrite:
        result = heurisch(f, x, rewrite=True, hints=hints, unnecessary_permutations=unnecessary_permutations)
        if result is not None:
            return indep * result
    return None","flag_else = 1

for mapping in mappings:
    mapping = list(mapping)
    mapping = mapping + unnecessary_permutations
    diffs = [_substitute(dcache.get_diff(g)) for g in terms]
    denoms = [g.as_numer_denom()[1] for g in diffs]
    if all((h.is_polynomial(*V) for h in denoms)) and _substitute(f).is_rational_function(*V):
        denom = reduce(lambda p, q: lcm(p, q, *V), denoms)
        flag_else = 0
        break
if flag_else:
    if not rewrite:
        result = heurisch(f, x, rewrite=True, hints=hints, unnecessary_permutations=unnecessary_permutations)
        if result is not None:
            return indep * result
    return None",1,FALSE,
gcovr,https://github.com/gcovr/gcovr/tree/master/gcovr/gcov_parser.py,,_make_is_in_any_range$975,"for i in range(hint_index, len(ranges)):
    (start, end) = ranges[i]
    hint_index = i
    if value < start:
        break
    if start <= value < end:
        return True
else:
    hint_index = len(ranges)","flag_else = 1

for i in range(hint_index, len(ranges)):
    (start, end) = ranges[i]
    hint_index = i
    if value < start:
        flag_else = 0
        break
    if start <= value < end:
        return True
if flag_else:
    hint_index = len(ranges)",1,FALSE,
edx-platform,https://github.com/edx/edx-platform/tree/master/lms/djangoapps/ccx/api/v0/views.py,,get_valid_input$100,"for course_module_id in course_modules:
    try:
        UsageKey.from_string(course_module_id)
    except InvalidKeyError:
        field_errors['course_modules'] = {'error_code': 'invalid_course_module_keys'}
        break
else:
    valid_input['course_modules'] = course_modules","flag_else = 1

for course_module_id in course_modules:
    try:
        UsageKey.from_string(course_module_id)
    except InvalidKeyError:
        field_errors['course_modules'] = {'error_code': 'invalid_course_module_keys'}
        flag_else = 0
        break
if flag_else:
    valid_input['course_modules'] = course_modules",1,FALSE,
hyper,https://github.com/python-hyper/hyper/tree/master/hyper/ssl_compat.py,SSLContext,cb$281,"for p in self.protocols:
    if p in overlap:
        return p
else:
    return b''","for p in self.protocols:
    if p in overlap:
        return p

return b''
",0,TRUE,
django-shop,https://github.com/awesto/django-shop/tree/master/shop/models/inventory.py,BaseInventory,check$123,"for field in cls._meta.fields:
    if field.attname == 'quantity':
        if field.get_internal_type() != cart_field.get_internal_type():
            msg = 'Field `{}.quantity` must be of same type as `{}.quantity`.'
            errors.append(checks.Error(msg.format(cls.__name__, CartItemModel.__name__)))
        break
else:
    msg = 'Class `{}` must implement a field named `quantity`.'
    errors.append(checks.Error(msg.format(cls.__name__)))","flag_else = 1

for field in cls._meta.fields:
    if field.attname == 'quantity':
        if field.get_internal_type() != cart_field.get_internal_type():
            msg = 'Field `{}.quantity` must be of same type as `{}.quantity`.'
            errors.append(checks.Error(msg.format(cls.__name__, CartItemModel.__name__)))
        flag_else = 0
        break
if flag_else:
    msg = 'Class `{}` must implement a field named `quantity`.'
    errors.append(checks.Error(msg.format(cls.__name__)))",1,FALSE,
SiCKRAGE,https://github.com/SiCKRAGE/SiCKRAGE/tree/master/sickrage/series_providers/helpers.py,,map_series_providers$31,"for dbData in session.query(MainDB.SeriesProviderMapping).filter_by(series_id=series_id, series_provider_id=series_provider_id):
    if len([i for i in dbData if i is not None]) >= 4:
        sickrage.app.log.debug('Found series_provider_id mapping in cache for show: ' + name)
        mapped[dbData.mapped_series_provider_id.name] = dbData.mapped_series_id
        return mapped
else:
    for mapped_series_provider_id in SeriesProviderID:
        if mapped_series_provider_id == series_provider_id:
            mapped[mapped_series_provider_id.name] = series_id
            continue
        mapped_series_provider = sickrage.app.series_provider[mapped_series_provider_id]
        mapped_show = mapped_series_provider.search(name)
        if not mapped_show:
            continue
        if mapped_show and len(mapped_show) == 1:
            sickrage.app.log.debug(f'Mapping {sickrage.app.series_providers[series_provider_id].name} -> {mapped_series_provider} for show: {name}')
            mapped[mapped_series_provider_id.name] = int(mapped_show['id'])
            sickrage.app.log.debug('Adding series_provider_id mapping to DB for show: ' + name)
            try:
                session.query(MainDB.SeriesProviderMapping).filter_by(series_id=series_id, series_provider_id=series_provider_id, mapped_series_id=int(mapped_show['id'])).one()
            except orm.exc.NoResultFound:
                session.add(MainDB.SeriesProviderMapping(**{'series_id': series_id, 'series_provider_id': series_provider_id, 'mapped_series_id': int(mapped_show['id']), 'mapped_series_provider_id': mapped_series_provider_id['id']}))
                session.commit()","for dbData in session.query(MainDB.SeriesProviderMapping).filter_by(series_id=series_id, series_provider_id=series_provider_id):
    if len([i for i in dbData if i is not None]) >= 4:
        sickrage.app.log.debug('Found series_provider_id mapping in cache for show: ' + name)
        mapped[dbData.mapped_series_provider_id.name] = dbData.mapped_series_id
        return mapped

for mapped_series_provider_id in SeriesProviderID:
    if mapped_series_provider_id == series_provider_id:
        mapped[mapped_series_provider_id.name] = series_id
        continue
    mapped_series_provider = sickrage.app.series_provider[mapped_series_provider_id]
    mapped_show = mapped_series_provider.search(name)
    if not mapped_show:
        continue
    if mapped_show and len(mapped_show) == 1:
        sickrage.app.log.debug(f'Mapping {sickrage.app.series_providers[series_provider_id].name} -> {mapped_series_provider} for show: {name}')
        mapped[mapped_series_provider_id.name] = int(mapped_show['id'])
        sickrage.app.log.debug('Adding series_provider_id mapping to DB for show: ' + name)
        try:
            session.query(MainDB.SeriesProviderMapping).filter_by(series_id=series_id, series_provider_id=series_provider_id, mapped_series_id=int(mapped_show['id'])).one()
        except orm.exc.NoResultFound:
            session.add(MainDB.SeriesProviderMapping(**{'series_id': series_id, 'series_provider_id': series_provider_id, 'mapped_series_id': int(mapped_show['id']), 'mapped_series_provider_id': mapped_series_provider_id['id']}))
            session.commit()
",0,TRUE,
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_index.py,SimpleIndexTestCase,test_iterblobs$112,"for w in warnings_list:
    if type(w) == type(expected_warning) and w.args == expected_warning.args:
        break
else:
    raise AssertionError('Expected warning %r not in %r' % (expected_warning, warnings_list))","flag_else = 1

for w in warnings_list:
    if type(w) == type(expected_warning) and w.args == expected_warning.args:
        flag_else = 0
        break
if flag_else:
    raise AssertionError('Expected warning %r not in %r' % (expected_warning, warnings_list))",1,FALSE,
twarc,https://github.com/DocNow/twarc/tree/master/utils/extractor.py,,parse$55,"for entity in json_object['entities']['hashtags']:
    if entity['text'].lower() == args.hashtag:
        break
else:
    continue","flag_else = 1

for entity in json_object['entities']['hashtags']:
    if entity['text'].lower() == args.hashtag:
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
py3status,https://github.com/ultrabug/py3status/tree/master/py3status/modules/xkb_input.py,Xkb_Switch,get_xkb_inputs$266,"for (variant, symbol, name) in self.variant_mapping:
    if (v, s) == (variant, symbol):
        n = name
        break
else:
    n = self.name_mapping.get(s)","flag_else = 1

for (variant, symbol, name) in self.variant_mapping:
    if (v, s) == (variant, symbol):
        n = name
        flag_else = 0
        break
if flag_else:
    n = self.name_mapping.get(s)",1,FALSE,
astropy,https://github.com/astropy/astropy/tree/master/astropy/io/fits/hdu/table.py,_TableBaseHDU,_update_column_attribute_changed$645,"for before_keyword in reversed(KEYWORD_NAMES[:keyword_idx]):
    before_keyword += str(col_idx + 1)
    if before_keyword in self._header:
        self._header.insert(before_keyword, (keyword, new_value), after=True)
        break
else:
    for after_keyword in KEYWORD_NAMES[keyword_idx + 1:]:
        after_keyword += str(col_idx + 1)
        if after_keyword in self._header:
            self._header.insert(after_keyword, (keyword, new_value))
            break
    else:
        self._header[keyword] = new_value","flag_else = 1

for before_keyword in reversed(KEYWORD_NAMES[:keyword_idx]):
    before_keyword += str(col_idx + 1)
    if before_keyword in self._header:
        self._header.insert(before_keyword, (keyword, new_value), after=True)
        flag_else = 0
        break
if flag_else:
    for after_keyword in KEYWORD_NAMES[keyword_idx + 1:]:
        after_keyword += str(col_idx + 1)
        if after_keyword in self._header:
            self._header.insert(after_keyword, (keyword, new_value))
            break
    else:
        self._header[keyword] = new_value",1,FALSE,
MusicBox,https://github.com/HuberTRoy/MusicBox/tree/master/MusicPlayer/features/configNeteaseFeatures.py,ConfigNetEase,threadSetSings$134,"for i in range(30):
    i += self.offset
    if i >= length:
        self.offsetComplement = length % 30
        break
    picName = makeMd5(self.singPicUrls[i])
    frame = OneSing(self.gridRow, self.gridColumn, self.playlistIds[i], self, picName)
    frame.clicked.connect(self.startRequest)
    frame.nameLabel.setText(self.singNames[i])
    self.netEase.mainLayout.addWidget(frame, self.gridRow, self.gridColumn)
    self.singsFrames.append(frame)
    if self.gridColumn == 3:
        self.gridColumn = 0
        self.gridRow += 1
    else:
        self.gridColumn += 1
    try:
        cacheList = os.listdir('cache')
    except:
        os.mkdir('cache')
        cacheList = os.listdir('cache')
    url = self.singPicUrls[i]
    names = makeMd5(url)
    if names in cacheList:
        frame.setStyleSheets('QLabel#picLabel{border-image: url(cache/%s)}' % names)
    else:
        task = _PicThreadTask(self.queue, frame, url)
        self.picThreadPool.start(task)
else:
    self.offsetComplement = 30","flag_else = 1

for i in range(30):
    i += self.offset
    if i >= length:
        self.offsetComplement = length % 30
        flag_else = 0
        break
    picName = makeMd5(self.singPicUrls[i])
    frame = OneSing(self.gridRow, self.gridColumn, self.playlistIds[i], self, picName)
    frame.clicked.connect(self.startRequest)
    frame.nameLabel.setText(self.singNames[i])
    self.netEase.mainLayout.addWidget(frame, self.gridRow, self.gridColumn)
    self.singsFrames.append(frame)
    if self.gridColumn == 3:
        self.gridColumn = 0
        self.gridRow += 1
    else:
        self.gridColumn += 1
    try:
        cacheList = os.listdir('cache')
    except:
        os.mkdir('cache')
        cacheList = os.listdir('cache')
    url = self.singPicUrls[i]
    names = makeMd5(url)
    if names in cacheList:
        frame.setStyleSheets('QLabel#picLabel{border-image: url(cache/%s)}' % names)
    else:
        task = _PicThreadTask(self.queue, frame, url)
        self.picThreadPool.start(task)
if flag_else:
    self.offsetComplement = 30",1,FALSE,
hamster,https://github.com/projecthamster/hamster/tree/master/waflib/Tools/ccroot.py,,apply_link$254,"for x in self.features:
    if x == 'cprogram' and 'cxx' in self.features:
        x = 'cxxprogram'
    elif x == 'cshlib' and 'cxx' in self.features:
        x = 'cxxshlib'
    if x in Task.classes:
        if issubclass(Task.classes[x], link_task):
            link = x
            break
else:
    return","flag_else = 1

for x in self.features:
    if x == 'cprogram' and 'cxx' in self.features:
        x = 'cxxprogram'
    elif x == 'cshlib' and 'cxx' in self.features:
        x = 'cxxshlib'
    if x in Task.classes:
        if issubclass(Task.classes[x], link_task):
            link = x
            flag_else = 0
            break
if flag_else:
    return",1,FALSE,
dcc,https://github.com/amimo/dcc/tree/master/dex2c/instruction.py,Value,add_user$110,"for use in self.uses:
    if use.get_user() == instr:
        return
else:
    use = Use(self, instr)
    self.uses.add(use)","for use in self.uses:
    if use.get_user() == instr:
        return

use = Use(self, instr)
self.uses.add(use)
",0,TRUE,
pdpipe,https://github.com/pdpipe/pdpipe/tree/master//versioneer.py,,run_command$384,"for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)","flag_else = 1

for c in commands:
    try:
        dispcmd = str([c] + args)
        p = subprocess.Popen([c] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)",1,FALSE,
asyncssh,https://github.com/ronf/asyncssh/tree/master/asyncssh/asn1.py,,der_decode_partial$700,"for b in data[offset:]:
    offset += 1
    if b < 128:
        tag |= b
        break
    else:
        tag |= b & 127
        tag <<= 7
else:
    raise ASN1DecodeError('Incomplete tag')","flag_else = 1

for b in data[offset:]:
    offset += 1
    if b < 128:
        tag |= b
        flag_else = 0
        break
    else:
        tag |= b & 127
        tag <<= 7
if flag_else:
    raise ASN1DecodeError('Incomplete tag')",1,FALSE,
ansible-modules-extras,https://github.com/ansible/ansible-modules-extras/tree/master/cloud/lxc/lxc_container.py,LxcContainerManagement,_get_vars$670,"for (k, v) in variables.items():
    _var = self.module.params.get(k)
    if _var not in false_values:
        return_dict[v] = _var
else:
    return return_dict","for (k, v) in variables.items():
    _var = self.module.params.get(k)
    if _var not in false_values:
        return_dict[v] = _var

return return_dict
",0,TRUE,
mtprotoproxy,https://github.com/alexbers/mtprotoproxy/tree/master/pyaes/aes.py,Counter,increment$285,"for i in xrange(len(self._counter) - 1, -1, -1):
    self._counter[i] += 1
    if self._counter[i] < 256:
        break
    self._counter[i] = 0
else:
    self._counter = [0] * len(self._counter)","flag_else = 1

for i in xrange(len(self._counter) - 1, -1, -1):
    self._counter[i] += 1
    if self._counter[i] < 256:
        flag_else = 0
        break
    self._counter[i] = 0
if flag_else:
    self._counter = [0] * len(self._counter)",1,FALSE,
angr,https://github.com/angr/angr/tree/master/tests/test_decompiler.py,,test_decompilation_x86_64_stack_arguments$627,"for line in lines:
    if 'snprintf' in line:
        assert '1900' in line, 'There is a missing stack argument.'
        break
else:
    assert False, 'The line with snprintf() is not found.'","flag_else = 1

for line in lines:
    if 'snprintf' in line:
        assert '1900' in line, 'There is a missing stack argument.'
        flag_else = 0
        break
if flag_else:
    assert False, 'The line with snprintf() is not found.'",1,FALSE,
flexx,https://github.com/flexxui/flexx/tree/master/flexx/ui/widgets/_tree.py,TreeWidget,highlight_show$354,"while 0 <= index2 < len(all_items):
    (visible, _) = all_items[index2]
    if visible:
        break
    index2 += step
else:
    index2 = index1","flag_else = 1

while 0 <= index2 < len(all_items):
    (visible, _) = all_items[index2]
    if visible:
        flag_else = 0
        break
    index2 += step
if flag_else:
    index2 = index1",1,FALSE,
kafka-python,https://github.com/dpkp/kafka-python/tree/master/test/test_sasl_integration.py,,test_client$66,"for _ in range(10):
    result = client.poll(timeout_ms=10000)
    if len(result) > 0:
        break
else:
    raise RuntimeError(""Couldn't fetch topic response from Broker."")","flag_else = 1

for _ in range(10):
    result = client.poll(timeout_ms=10000)
    if len(result) > 0:
        flag_else = 0
        break
if flag_else:
    raise RuntimeError(""Couldn't fetch topic response from Broker."")",1,FALSE,
django,https://github.com/django/django/tree/master/django/utils/timesince.py,,timesince$27,"for (i, (seconds, name)) in enumerate(TIMESINCE_CHUNKS):
    count = since // seconds
    if count != 0:
        break
else:
    return avoid_wrapping(time_strings['minute'] % {'num': 0})","flag_else = 1

for (i, (seconds, name)) in enumerate(TIMESINCE_CHUNKS):
    count = since // seconds
    if count != 0:
        flag_else = 0
        break
if flag_else:
    return avoid_wrapping(time_strings['minute'] % {'num': 0})",1,FALSE,
t,https://github.com/sjl/t/tree/master//t.py,,_prefixes$86,"for j in range(i, id_len + 1):
    if other_id[:j] == id[:j]:
        ps[id[:j]] = ''
    else:
        ps[other_id[:j]] = other_id
        ps[id[:j]] = id
        break
else:
    ps[other_id[:id_len + 1]] = other_id
    ps[id] = id","flag_else = 1

for j in range(i, id_len + 1):
    if other_id[:j] == id[:j]:
        ps[id[:j]] = ''
    else:
        ps[other_id[:j]] = other_id
        ps[id[:j]] = id
        flag_else = 0
        break
if flag_else:
    ps[other_id[:id_len + 1]] = other_id
    ps[id] = id",1,FALSE,
volatility3,https://github.com/volatilityfoundation/volatility3/tree/master/volatility3/framework/symbols/intermed.py,Version2Format,_get_natives$476,"for base_type in self._json_object['base_types']:
    try:
        if self._json_object['base_types'][base_type]['size'] != native_class.get_type(base_type).size:
            break
    except TypeError:
        pass
else:
    vollog.debug(f'Choosing appropriate natives for symbol library: {nc}')
    return native_class.natives","flag_else = 1

for base_type in self._json_object['base_types']:
    try:
        if self._json_object['base_types'][base_type]['size'] != native_class.get_type(base_type).size:
            flag_else = 0
            break
    except TypeError:
        pass
if flag_else:
    vollog.debug(f'Choosing appropriate natives for symbol library: {nc}')
    return native_class.natives",1,FALSE,
neutron,https://github.com/openstack/neutron/tree/master/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_db_sync.py,OvnNbSynchronizer,_calculate_fip_pfs_differences$380,"for db_pf in db_pfs:
    pf_fip_id = db_pf.get('floatingip_id')
    if pf_fip_id == fip_id:
        break
else:
    to_remove.append(fip_id)","flag_else = 1

for db_pf in db_pfs:
    pf_fip_id = db_pf.get('floatingip_id')
    if pf_fip_id == fip_id:
        flag_else = 0
        break
if flag_else:
    to_remove.append(fip_id)",1,FALSE,
ansible-modules-core,https://github.com/ansible/ansible-modules-core/tree/master/network/nxos/nxos_vxlan_vtep.py,CustomNetworkConfig,add$187,"for child in ancestors[-1].children:
    if child.text == line:
        break
else:
    offset = len(parents) * self.indent
    item = ConfigLine(line)
    item.raw = line.rjust(len(line) + offset)
    item.parents = ancestors
    ancestors[-1].children.append(item)
    self.items.append(item)","flag_else = 1

for child in ancestors[-1].children:
    if child.text == line:
        flag_else = 0
        break
if flag_else:
    offset = len(parents) * self.indent
    item = ConfigLine(line)
    item.raw = line.rjust(len(line) + offset)
    item.parents = ancestors
    ancestors[-1].children.append(item)
    self.items.append(item)",1,FALSE,
pip-tools,https://github.com/jazzband/pip-tools/tree/master/piptools/repositories/pypi.py,PyPIRepository,_setup_logging$439,"for handler in logger.handlers:
    if handler.name == 'console':
        assert isinstance(handler, logging.StreamHandler)
        handler.stream = log.stream
        break
else:
    log.warning(""Couldn't find a 'console' logging handler"")","flag_else = 1

for handler in logger.handlers:
    if handler.name == 'console':
        assert isinstance(handler, logging.StreamHandler)
        handler.stream = log.stream
        flag_else = 0
        break
if flag_else:
    log.warning(""Couldn't find a 'console' logging handler"")",1,FALSE,
semshi,https://github.com/numirias/semshi/tree/master/test/data/grammar36.py,GrammarTests,test_while$1004,"while 0:
    x = 1
else:
    x = 2","while 0:
    x = 1

x = 2
",0,TRUE,
dynaconf,https://github.com/rochacbruno/dynaconf/tree/master/dynaconf/vendor/box/box.py,Box,__dir__$86,"for E in A:
    if E not in D:
        break
else:
    C.add(A)","flag_else = 1

for E in A:
    if E not in D:
        flag_else = 0
        break
if flag_else:
    C.add(A)",1,FALSE,
sanic,https://github.com/sanic-org/sanic/tree/master/sanic/errorpages.py,,exception_response$428,"for accept in acceptable:
    mtype = f'{accept.type_}/{accept.subtype}'
    maybe = RENDERERS_BY_CONTENT_TYPE.get(mtype)
    if maybe:
        renderer = maybe
        break
else:
    renderer = base","flag_else = 1

for accept in acceptable:
    mtype = f'{accept.type_}/{accept.subtype}'
    maybe = RENDERERS_BY_CONTENT_TYPE.get(mtype)
    if maybe:
        renderer = maybe
        flag_else = 0
        break
if flag_else:
    renderer = base",1,FALSE,
vulncode-db,https://github.com/google/vulncode-db/tree/master/app/api/routes.py,,calculate_revision_updates$55,"for attr in attrs:
    if getattr(old, attr) != getattr(new, attr):
        break
else:
    current_app.logger.debug(f'No changes for {k!s}')
    continue","flag_else = 1

for attr in attrs:
    if getattr(old, attr) != getattr(new, attr):
        flag_else = 0
        break
if flag_else:
    current_app.logger.debug(f'No changes for {k!s}')
    continue",1,FALSE,
OctoPrint,https://github.com/OctoPrint/OctoPrint/tree/master/src/octoprint/server/views.py,,index$355,"for plugin in ui_plugins:
    try:
        if plugin.will_handle_ui(request):
            permissions = plugin.get_ui_permissions()
            response = require_login_with(permissions=permissions)
            if not response:
                response = plugin_view(plugin)
                if response is not None:
                    if _logger.isEnabledFor(logging.DEBUG) and isinstance(response, Response):
                        response.headers['X-Ui-Plugin'] = plugin._identifier
                    break
                else:
                    _logger.warning('UiPlugin {} returned an empty response'.format(plugin._identifier))
    except Exception:
        _logger.exception('Error while calling plugin {}, skipping it'.format(plugin._identifier), extra={'plugin': plugin._identifier})
else:
    response = require_login_with(permissions=default_permissions)
    if not response:
        response = default_view()
        if _logger.isEnabledFor(logging.DEBUG) and isinstance(response, Response):
            response.headers['X-Ui-Plugin'] = '_default'","flag_else = 1

for plugin in ui_plugins:
    try:
        if plugin.will_handle_ui(request):
            permissions = plugin.get_ui_permissions()
            response = require_login_with(permissions=permissions)
            if not response:
                response = plugin_view(plugin)
                if response is not None:
                    if _logger.isEnabledFor(logging.DEBUG) and isinstance(response, Response):
                        response.headers['X-Ui-Plugin'] = plugin._identifier
                    flag_else = 0
                    break
                else:
                    _logger.warning('UiPlugin {} returned an empty response'.format(plugin._identifier))
    except Exception:
        _logger.exception('Error while calling plugin {}, skipping it'.format(plugin._identifier), extra={'plugin': plugin._identifier})
if flag_else:
    response = require_login_with(permissions=default_permissions)
    if not response:
        response = default_view()
        if _logger.isEnabledFor(logging.DEBUG) and isinstance(response, Response):
            response.headers['X-Ui-Plugin'] = '_default'",1,FALSE,
adapter-transformers,https://github.com/Adapter-Hub/adapter-transformers/tree/master/src/transformers/models/marian/convert_marian_to_pytorch.py,,_parse_readme$344,"for k in ['download', 'dataset', 'models', 'model', 'pre-processing']:
    if ln.startswith(k):
        break
else:
    continue","flag_else = 1

for k in ['download', 'dataset', 'models', 'model', 'pre-processing']:
    if ln.startswith(k):
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
aurman,https://github.com/polygamma/aurman/tree/master/src/aurman/main.py,,group_by_function_sort_by_deps$596,"for dep in deps_to_check:
    if current_system.provided_by(dep):
        ordered_package_groups.insert(i, package_group)
        break
else:
    continue","flag_else = 1

for dep in deps_to_check:
    if current_system.provided_by(dep):
        ordered_package_groups.insert(i, package_group)
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
moto,https://github.com/spulec/moto/tree/master/moto/ecs/models.py,EC2ContainerServiceBackend,list_tags_for_resource$1541,"for service in self.services.values():
    if service.arn == resource_arn:
        return service.tags
else:
    raise ServiceNotFoundException","for service in self.services.values():
    if service.arn == resource_arn:
        return service.tags

raise ServiceNotFoundException
",0,TRUE,
repo2docker,https://github.com/jupyterhub/repo2docker/tree/master/tests/unit/test_ports.py,,read_port_mapping_response$18,"for i in range(5):
    try:
        r = requests.get(url)
        r.raise_for_status()
    except Exception as e:
        print('No response from {}: {}'.format(url, e))
        container.reload()
        assert container.status == 'running'
        time.sleep(3)
        continue
    else:
        break
else:
    pytest.fail('Never succeded in talking to %s' % url)","flag_else = 1

for i in range(5):
    try:
        r = requests.get(url)
        r.raise_for_status()
    except Exception as e:
        print('No response from {}: {}'.format(url, e))
        container.reload()
        assert container.status == 'running'
        time.sleep(3)
        continue
    else:
        flag_else = 0
        break
if flag_else:
    pytest.fail('Never succeded in talking to %s' % url)",1,FALSE,
numpy,https://github.com/numpy/numpy/tree/master/numpy/random/tests/test_extending.py,,test_cython$50,"for (i, line) in enumerate(fid):
    if txt_to_find in line:
        break
else:
    assert False, ""Could not find '{}' in C file, wrong pxd used"".format(txt_to_find)","flag_else = 1

for (i, line) in enumerate(fid):
    if txt_to_find in line:
        flag_else = 0
        break
if flag_else:
    assert False, ""Could not find '{}' in C file, wrong pxd used"".format(txt_to_find)",1,FALSE,
prefect,https://github.com/PrefectHQ/prefect/tree/master/src/prefect/_version.py,,run_command$72,"for command in commands:
    try:
        dispcmd = str([command] + args)
        process = subprocess.Popen([command] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)","flag_else = 1

for command in commands:
    try:
        dispcmd = str([command] + args)
        process = subprocess.Popen([command] + args, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE if hide_stderr else None)
        flag_else = 0
        break
    except EnvironmentError:
        e = sys.exc_info()[1]
        if e.errno == errno.ENOENT:
            continue
        if verbose:
            print('unable to run %s' % dispcmd)
            print(e)
        return (None, None)
if flag_else:
    if verbose:
        print('unable to find command, tried %s' % (commands,))
    return (None, None)",1,FALSE,
Hitomi-Downloader,https://github.com/KurtBestor/Hitomi-Downloader/tree/master/src/extractor/artstation_downloader.py,,get_imgs$78,"for try_ in range(4):
    try:
        html = downloader.read_html(url, session=session, referer=referer)
        break
    except Exception as e:
        print(e)
else:
    raise","flag_else = 1

for try_ in range(4):
    try:
        html = downloader.read_html(url, session=session, referer=referer)
        flag_else = 0
        break
    except Exception as e:
        print(e)
if flag_else:
    raise",1,FALSE,
distributed,https://github.com/dask/distributed/tree/master/distributed/scheduler.py,Scheduler,adaptive_target$7717,"for ws in self.workers.values():
    tasks_ready += len(ws.processing)
    if tasks_ready > cpu:
        break
else:
    cpu = min(tasks_ready, cpu)","flag_else = 1

for ws in self.workers.values():
    tasks_ready += len(ws.processing)
    if tasks_ready > cpu:
        flag_else = 0
        break
if flag_else:
    cpu = min(tasks_ready, cpu)",1,FALSE,
sentry,https://github.com/getsentry/sentry/tree/master/src/sentry/utils/committers.py,,tokenize_path$36,"for sep in PATH_SEPARATORS:
    if sep in path:
        return reversed([x for x in path.split(sep) if x != ''])
else:
    return iter([path])","for sep in PATH_SEPARATORS:
    if sep in path:
        return reversed([x for x in path.split(sep) if x != ''])

return iter([path])
",0,TRUE,
integrations-core,https://github.com/DataDog/integrations-core/tree/master/snmp/tests/test_check.py,,test_metric_tag_multiple$1155,"for (_, level, message) in caplog.record_tuples:
    if level == logging.WARNING and message == expected_message:
        break
else:
    raise AssertionError('Expected WARNING log with message `{}`'.format(expected_message))","flag_else = 1

for (_, level, message) in caplog.record_tuples:
    if level == logging.WARNING and message == expected_message:
        flag_else = 0
        break
if flag_else:
    raise AssertionError('Expected WARNING log with message `{}`'.format(expected_message))",1,FALSE,
nltk,https://github.com/nltk/nltk/tree/master/nltk/parse/corenlp.py,CoreNLPServer,start$102,"for i in range(60):
    try:
        response = requests.get(requests.compat.urljoin(self.url, 'ready'))
    except requests.exceptions.ConnectionError:
        time.sleep(1)
    else:
        if response.ok:
            break
else:
    raise CoreNLPServerError('The server is not ready.')","flag_else = 1

for i in range(60):
    try:
        response = requests.get(requests.compat.urljoin(self.url, 'ready'))
    except requests.exceptions.ConnectionError:
        time.sleep(1)
    else:
        if response.ok:
            flag_else = 0
            break
if flag_else:
    raise CoreNLPServerError('The server is not ready.')",1,FALSE,
horizon,https://github.com/openstack/horizon/tree/master/openstack_dashboard/test/integration_tests/regions/menus.py,ProjectDropDownRegion,click_on_project$320,"for item in self.menu_items:
    if item.text == name:
        item.click()
        break
else:
    raise exceptions.NoSuchElementException('Not found element with text: %s' % name)","flag_else = 1

for item in self.menu_items:
    if item.text == name:
        item.click()
        flag_else = 0
        break
if flag_else:
    raise exceptions.NoSuchElementException('Not found element with text: %s' % name)",1,FALSE,
virt-manager,https://github.com/virt-manager/virt-manager/tree/master/virtinst/uri.py,URI,_split$62,"for c in '/?#':
    delim = url.find(c, start)
    if delim >= 0:
        break
else:
    delim = len(url)","flag_else = 1

for c in '/?#':
    delim = url.find(c, start)
    if delim >= 0:
        flag_else = 0
        break
if flag_else:
    delim = len(url)",1,FALSE,
vmaf,https://github.com/Netflix/vmaf/tree/master/python/vmaf/core/raw_extractor.py,DisYUVRawVideoExtractor,_wait_for_workfiles$115,"for i in range(10):
    if os.path.exists(asset.dis_workfile_path):
        break
    sleep(0.1)
else:
    raise RuntimeError('dis video workfile path {} is missing.'.format(asset.dis_workfile_path))","flag_else = 1

for i in range(10):
    if os.path.exists(asset.dis_workfile_path):
        flag_else = 0
        break
    sleep(0.1)
if flag_else:
    raise RuntimeError('dis video workfile path {} is missing.'.format(asset.dis_workfile_path))",1,FALSE,
CellProfiler,https://github.com/CellProfiler/CellProfiler/tree/master/cellprofiler/gui/pipelinelistview.py,PipelineListView,__on_module_disabled$1042,"for module in self.__pipeline.modules():
    if module.module_num > event.module.module_num:
        self.set_current_debug_module(module)
        break
else:
    for module in reversed(self.__pipeline.modules()):
        if module.module_num < event.module.module_num and (not module.is_input_module()):
            self.set_current_debug_module(module)
            break
    else:
        self.__controller.stop_debugging()","flag_else = 1

for module in self.__pipeline.modules():
    if module.module_num > event.module.module_num:
        self.set_current_debug_module(module)
        flag_else = 0
        break
if flag_else:
    for module in reversed(self.__pipeline.modules()):
        if module.module_num < event.module.module_num and (not module.is_input_module()):
            self.set_current_debug_module(module)
            break
    else:
        self.__controller.stop_debugging()",1,FALSE,
astropy,https://github.com/astropy/astropy/tree/master/astropy/time/core.py,TimeBase,_get_time_fmt$556,"for (name, cls) in formats:
    try:
        return cls(val, val2, scale, precision, in_subfmt, out_subfmt)
    except UnitConversionError:
        raise
    except (ValueError, TypeError) as err:
        if len(formats) == 1:
            raise ValueError(f'Input values did not match the format class {format}:' + os.linesep + f'{err.__class__.__name__}: {err}') from err
        else:
            problems[name] = err
else:
    raise ValueError(f'Input values did not match any of the formats where the format keyword is optional: {problems}') from problems[formats[0][0]]","for (name, cls) in formats:
    try:
        return cls(val, val2, scale, precision, in_subfmt, out_subfmt)
    except UnitConversionError:
        raise
    except (ValueError, TypeError) as err:
        if len(formats) == 1:
            raise ValueError(f'Input values did not match the format class {format}:' + os.linesep + f'{err.__class__.__name__}: {err}') from err
        else:
            problems[name] = err

raise ValueError(f'Input values did not match any of the formats where the format keyword is optional: {problems}') from problems[formats[0][0]]
",0,TRUE,
Poco,https://github.com/AirtestProject/Poco/tree/master/poco/utils/hrpc/utils.py,,wrapped$20,"for t in tolerance_exc_types:
    if e.error_type == t or e.error_type.endswith('.' + t):
        raise PocoTargetRemovedException('{}: {}'.format(func.__name__, name), safe_repr(nodes))
else:
    raise","for t in tolerance_exc_types:
    if e.error_type == t or e.error_type.endswith('.' + t):
        raise PocoTargetRemovedException('{}: {}'.format(func.__name__, name), safe_repr(nodes))

raise
",0,TRUE,
pyyaml,https://github.com/yaml/pyyaml/tree/master/lib/yaml/constructor.py,BaseConstructor,construct_object$67,"for tag_prefix in self.yaml_multi_constructors:
    if tag_prefix is not None and node.tag.startswith(tag_prefix):
        tag_suffix = node.tag[len(tag_prefix):]
        constructor = self.yaml_multi_constructors[tag_prefix]
        break
else:
    if None in self.yaml_multi_constructors:
        tag_suffix = node.tag
        constructor = self.yaml_multi_constructors[None]
    elif None in self.yaml_constructors:
        constructor = self.yaml_constructors[None]
    elif isinstance(node, ScalarNode):
        constructor = self.__class__.construct_scalar
    elif isinstance(node, SequenceNode):
        constructor = self.__class__.construct_sequence
    elif isinstance(node, MappingNode):
        constructor = self.__class__.construct_mapping","flag_else = 1

for tag_prefix in self.yaml_multi_constructors:
    if tag_prefix is not None and node.tag.startswith(tag_prefix):
        tag_suffix = node.tag[len(tag_prefix):]
        constructor = self.yaml_multi_constructors[tag_prefix]
        flag_else = 0
        break
if flag_else:
    if None in self.yaml_multi_constructors:
        tag_suffix = node.tag
        constructor = self.yaml_multi_constructors[None]
    elif None in self.yaml_constructors:
        constructor = self.yaml_constructors[None]
    elif isinstance(node, ScalarNode):
        constructor = self.__class__.construct_scalar
    elif isinstance(node, SequenceNode):
        constructor = self.__class__.construct_sequence
    elif isinstance(node, MappingNode):
        constructor = self.__class__.construct_mapping",1,FALSE,
micropython-lib,https://github.com/micropython/micropython-lib/tree/master/python-stdlib/email.message/email/message.py,Message,replace_header$499,"for (i, (k, v)) in zip(range(len(self._headers)), self._headers):
    if k.lower() == _name:
        self._headers[i] = self.policy.header_store_parse(k, _value)
        break
else:
    raise KeyError(_name)","flag_else = 1

for (i, (k, v)) in zip(range(len(self._headers)), self._headers):
    if k.lower() == _name:
        self._headers[i] = self.policy.header_store_parse(k, _value)
        flag_else = 0
        break
if flag_else:
    raise KeyError(_name)",1,FALSE,
TauonMusicBox,https://github.com/Taiko2k/TauonMusicBox/tree/master/t_modules/t_main.py,TextBox2,draw$10395,"for i in range(len(self.text)):
    post = ddt.get_text_w(self.text[0:i + 1], font)
    if x + pre - 0 <= mouse_position[0] <= x + post + 0:
        diff = post - pre
        if mouse_position[0] >= x + pre + int(diff / 2):
            self.cursor_position = len(self.text) - i - 1
        else:
            self.cursor_position = len(self.text) - i
        break
    pre = post
else:
    self.cursor_position = 0","flag_else = 1

for i in range(len(self.text)):
    post = ddt.get_text_w(self.text[0:i + 1], font)
    if x + pre - 0 <= mouse_position[0] <= x + post + 0:
        diff = post - pre
        if mouse_position[0] >= x + pre + int(diff / 2):
            self.cursor_position = len(self.text) - i - 1
        else:
            self.cursor_position = len(self.text) - i
        flag_else = 0
        break
    pre = post
if flag_else:
    self.cursor_position = 0",1,FALSE,
sympy,https://github.com/sympy/sympy/tree/master/sympy/solvers/solvers.py,,_solve_system$1732,"for r in result:
    eq2 = eq.subs(r)
    if check and r:
        b = checksol(u, u, eq2, minimal=True)
        if b is not None:
            if b:
                newresult.append(r)
            else:
                bad_results.append(r)
            continue
    ok_syms = _ok_syms(eq2, sort=True)
    if not ok_syms:
        if r:
            newresult.append(r)
        break
    for s in ok_syms:
        try:
            soln = _solve(eq2, s, **flags)
        except NotImplementedError:
            continue
        for sol in soln:
            if got_s and any((ss in sol.free_symbols for ss in got_s)):
                continue
            rnew = r.copy()
            for (k, v) in r.items():
                rnew[k] = v.subs(s, sol)
            rnew[s] = sol
            iset = set(rnew.items())
            for i in newresult:
                if len(i) < len(iset) and (not set(i.items()) - iset):
                    break
            else:
                newresult.append(rnew)
        hit = True
        got_s.add(s)
    if not hit:
        raise NotImplementedError('could not solve %s' % eq2)
else:
    result = newresult
    for b in bad_results:
        if b in result:
            result.remove(b)","flag_else = 1

for r in result:
    eq2 = eq.subs(r)
    if check and r:
        b = checksol(u, u, eq2, minimal=True)
        if b is not None:
            if b:
                newresult.append(r)
            else:
                bad_results.append(r)
            continue
    ok_syms = _ok_syms(eq2, sort=True)
    if not ok_syms:
        if r:
            newresult.append(r)
        flag_else = 0
        break
    for s in ok_syms:
        try:
            soln = _solve(eq2, s, **flags)
        except NotImplementedError:
            continue
        for sol in soln:
            if got_s and any((ss in sol.free_symbols for ss in got_s)):
                continue
            rnew = r.copy()
            for (k, v) in r.items():
                rnew[k] = v.subs(s, sol)
            rnew[s] = sol
            iset = set(rnew.items())
            for i in newresult:
                if len(i) < len(iset) and (not set(i.items()) - iset):
                    break
            else:
                newresult.append(rnew)
        hit = True
        got_s.add(s)
    if not hit:
        raise NotImplementedError('could not solve %s' % eq2)
if flag_else:
    result = newresult
    for b in bad_results:
        if b in result:
            result.remove(b)",1,FALSE,
ProperTree,https://github.com/corpnewt/ProperTree/tree/master/Scripts/plistwindow.py,PlistWindow,oc_snapshot$1021,"for (kpath, ksubdirs, kfiles) in os.walk(os.path.join(path, name)):
    for kname in kfiles:
        if kname.lower() == 'info.plist':
            plist_full_path = os.path.join(kpath, kname)
            plist_rel_path = plist_full_path[len(os.path.join(path, name)):].replace('\\', '/').lstrip('/')
            break
    if plist_full_path:
        break
else:
    continue","flag_else = 1

for (kpath, ksubdirs, kfiles) in os.walk(os.path.join(path, name)):
    for kname in kfiles:
        if kname.lower() == 'info.plist':
            plist_full_path = os.path.join(kpath, kname)
            plist_rel_path = plist_full_path[len(os.path.join(path, name)):].replace('\\', '/').lstrip('/')
            break
    if plist_full_path:
        flag_else = 0
        break
if flag_else:
    continue",1,FALSE,
qqbot,https://github.com/pandolia/qqbot/tree/master/qqbot/qcontactdb/contactdb.py,ContactDB,List$133,"for tag in TAGS:
    if cinfo.startswith(tag):
        column = tag[:-1]
        cinfo = cinfo[len(tag):]
        break
    if cinfo.startswith(tag[:-1] + ':like:'):
        column = tag[:-1]
        cinfo = cinfo[len(tag) + 5:]
        if not cinfo:
            return []
        like = True
        break
else:
    if cinfo.startswith(':like:'):
        cinfo = cinfo[6:]
        if not cinfo:
            return []
        if cinfo.isdigit():
            column = 'qq'
        else:
            column = 'name'
        like = True
    else:
        column = 'name'","flag_else = 1

for tag in TAGS:
    if cinfo.startswith(tag):
        column = tag[:-1]
        cinfo = cinfo[len(tag):]
        flag_else = 0
        break
    if cinfo.startswith(tag[:-1] + ':like:'):
        column = tag[:-1]
        cinfo = cinfo[len(tag) + 5:]
        if not cinfo:
            return []
        like = True
        flag_else = 0
        break
if flag_else:
    if cinfo.startswith(':like:'):
        cinfo = cinfo[6:]
        if not cinfo:
            return []
        if cinfo.isdigit():
            column = 'qq'
        else:
            column = 'name'
        like = True
    else:
        column = 'name'",2,FALSE,
yt-dlp,https://github.com/yt-dlp/yt-dlp/tree/master/yt_dlp/extractor/afreecatv.py,AfreecaTVIE,_real_extract$225,"for _ in range(2):
    query = {'nTitleNo': video_id, 'nStationNo': station_id, 'nBbsNo': bbs_id}
    if partial_view:
        query['partialView'] = 'SKIP_ADULT'
    if adult_view:
        query['adultView'] = 'ADULT_VIEW'
    video_xml = self._download_xml('http://afbbs.afreecatv.com:8080/api/video/get_video_info.php', video_id, 'Downloading video info XML%s' % (' (skipping adult)' if partial_view else ''), video_id, headers={'Referer': url}, query=query)
    flag = xpath_text(video_xml, './track/flag', 'flag', default=None)
    if flag and flag == 'SUCCEED':
        break
    if flag == 'PARTIAL_ADULT':
        self.report_warning('In accordance with local laws and regulations, underage users are restricted from watching adult content. Only content suitable for all ages will be downloaded. Provide account credentials if you wish to download restricted content.')
        partial_view = True
        continue
    elif flag == 'ADULT':
        if not adult_view:
            adult_view = True
            continue
        error = 'Only users older than 19 are able to watch this video. Provide account credentials to download this content.'
    else:
        error = flag
    raise ExtractorError('%s said: %s' % (self.IE_NAME, error), expected=True)
else:
    raise ExtractorError('Unable to download video info')","flag_else = 1

for _ in range(2):
    query = {'nTitleNo': video_id, 'nStationNo': station_id, 'nBbsNo': bbs_id}
    if partial_view:
        query['partialView'] = 'SKIP_ADULT'
    if adult_view:
        query['adultView'] = 'ADULT_VIEW'
    video_xml = self._download_xml('http://afbbs.afreecatv.com:8080/api/video/get_video_info.php', video_id, 'Downloading video info XML%s' % (' (skipping adult)' if partial_view else ''), video_id, headers={'Referer': url}, query=query)
    flag = xpath_text(video_xml, './track/flag', 'flag', default=None)
    if flag and flag == 'SUCCEED':
        flag_else = 0
        break
    if flag == 'PARTIAL_ADULT':
        self.report_warning('In accordance with local laws and regulations, underage users are restricted from watching adult content. Only content suitable for all ages will be downloaded. Provide account credentials if you wish to download restricted content.')
        partial_view = True
        continue
    elif flag == 'ADULT':
        if not adult_view:
            adult_view = True
            continue
        error = 'Only users older than 19 are able to watch this video. Provide account credentials to download this content.'
    else:
        error = flag
    raise ExtractorError('%s said: %s' % (self.IE_NAME, error), expected=True)
if flag_else:
    raise ExtractorError('Unable to download video info')",1,FALSE,
TauonMusicBox,https://github.com/Taiko2k/TauonMusicBox/tree/master/t_modules/t_main.py,,regenerate_playlist$17365,"for result in search_over.results:
    if result[0] == 5:
        found_name = result[1]
        break
else:
    print('No folder search result found')
    continue","flag_else = 1

for result in search_over.results:
    if result[0] == 5:
        found_name = result[1]
        flag_else = 0
        break
if flag_else:
    print('No folder search result found')
    continue",1,FALSE,
PyExecJS,https://github.com/doloopwhile/PyExecJS/tree/master/execjs/_runtimes.py,,_find_runtime_by_name$52,"for (runtime_name, runtime) in _runtimes:
    if runtime_name.lower() == name.lower():
        break
else:
    raise exceptions.RuntimeUnavailableError('{name} runtime is not defined'.format(name=name))","flag_else = 1

for (runtime_name, runtime) in _runtimes:
    if runtime_name.lower() == name.lower():
        flag_else = 0
        break
if flag_else:
    raise exceptions.RuntimeUnavailableError('{name} runtime is not defined'.format(name=name))",1,FALSE,
patroni,https://github.com/zalando/patroni/tree/master/.github/workflows/install_deps.py,,setup_kubernetes$130,"for _ in range(0, 120):
    if subprocess.call(['wget', '-qO', '-', 'http://127.0.0.1:8080/'], stdout=devnull, stderr=devnull) == 0:
        break
    time.sleep(1)
else:
    print('localkube did not start')
    return 1","flag_else = 1

for _ in range(0, 120):
    if subprocess.call(['wget', '-qO', '-', 'http://127.0.0.1:8080/'], stdout=devnull, stderr=devnull) == 0:
        flag_else = 0
        break
    time.sleep(1)
if flag_else:
    print('localkube did not start')
    return 1",1,FALSE,
cupy,https://github.com/cupy/cupy/tree/master/cupy/_environment.py,,_preload_library$306,"for libpath in libpath_cands:
    if not os.path.exists(libpath):
        _log('Rejected candidate (not found): {}'.format(libpath))
        continue
    try:
        _log(f'Trying to load {libpath}')
        _preload_libs[lib][libpath] = ctypes.CDLL(libpath)
        _log('Loaded')
        break
    except Exception as e:
        e_type = type(e).__name__
        msg = f'CuPy failed to preload library ({libpath}): {e_type} ({e})'
        _log(msg)
        warnings.warn(msg)
else:
    _log('File {} could not be found'.format(filename))
    _log(f'Trying to load {filename} from default search path')
    try:
        _preload_libs[lib][filename] = ctypes.CDLL(filename)
        _log('Loaded')
    except Exception as e:
        _log(f'Library {lib} could not be preloaded: {e}')","flag_else = 1

for libpath in libpath_cands:
    if not os.path.exists(libpath):
        _log('Rejected candidate (not found): {}'.format(libpath))
        continue
    try:
        _log(f'Trying to load {libpath}')
        _preload_libs[lib][libpath] = ctypes.CDLL(libpath)
        _log('Loaded')
        flag_else = 0
        break
    except Exception as e:
        e_type = type(e).__name__
        msg = f'CuPy failed to preload library ({libpath}): {e_type} ({e})'
        _log(msg)
        warnings.warn(msg)
if flag_else:
    _log('File {} could not be found'.format(filename))
    _log(f'Trying to load {filename} from default search path')
    try:
        _preload_libs[lib][filename] = ctypes.CDLL(filename)
        _log('Loaded')
    except Exception as e:
        _log(f'Library {lib} could not be preloaded: {e}')",1,FALSE,
metaflow,https://github.com/Netflix/metaflow/tree/master/test/core/tests/catch_retry.py,CatchRetryTest,check_results$61,"for task in checker.artifact_dict(step.name, 'retry_with_catch').values():
    assert_equals(task['retry_with_catch'], 2)
    break
else:
    raise Exception(""No artifact 'retry_with_catch' in step '%s'"" % step.name)","flag_else = 1

for task in checker.artifact_dict(step.name, 'retry_with_catch').values():
    assert_equals(task['retry_with_catch'], 2)
    flag_else = 0
    break
if flag_else:
    raise Exception(""No artifact 'retry_with_catch' in step '%s'"" % step.name)",1,FALSE,
metaflow,https://github.com/Netflix/metaflow/tree/master/metaflow/metadata/metadata.py,MetadataProvider,_reconstruct_metadata_for_attempt$563,"for t in all_tags:
    match_result = attempt_id_re.match(t)
    if match_result:
        if int(match_result.group(1)) == attempt_id:
            post_filter.append(v)
        break
else:
    have_all_attempt_id = False","flag_else = 1

for t in all_tags:
    match_result = attempt_id_re.match(t)
    if match_result:
        if int(match_result.group(1)) == attempt_id:
            post_filter.append(v)
        flag_else = 0
        break
if flag_else:
    have_all_attempt_id = False",1,FALSE,
,,,,,,325,FALSE,0
,,,,,,296,FALSE,0.177777778
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
